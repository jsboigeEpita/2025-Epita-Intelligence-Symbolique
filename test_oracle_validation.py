#!/usr/bin/env python3
"""
Test de validation de l'environnement Oracle Enhanced v2.1.0
Validation en conditions r√©elles des orchestrations Sherlock-Watson
"""

import sys
import os
import traceback
from datetime import datetime

def test_oracle_imports():
    """Test des imports principaux du syst√®me Oracle Enhanced v2.1.0"""
    print("=== TEST ORACLE ENHANCED v2.1.0 - VALIDATION IMPORTS ===")
    print(f"Timestamp: {datetime.now().isoformat()}")
    print(f"Python: {sys.version}")
    print(f"PYTHONPATH: {os.environ.get('PYTHONPATH', 'Non d√©fini')}")
    print(f"JAVA_HOME: {os.environ.get('JAVA_HOME', 'Non d√©fini')}")
    print(f"USE_REAL_JPYPE: {os.environ.get('USE_REAL_JPYPE', 'Non d√©fini')}")
    print()
    
    success_count = 0
    total_tests = 0
    
    # Test 1: Import base argumentation_analysis
    total_tests += 1
    try:
        import argumentation_analysis
        print("‚úÖ Import argumentation_analysis: OK")
        success_count += 1
    except Exception as e:
        print(f"‚ùå Import argumentation_analysis: ERREUR - {e}")
        traceback.print_exc()
    
    # Test 2: Import agents.core
    total_tests += 1
    try:
        from argumentation_analysis.agents.core import oracle
        print("‚úÖ Import agents.core.oracle: OK")
        success_count += 1
    except Exception as e:
        print(f"‚ùå Import agents.core.oracle: ERREUR - {e}")
        traceback.print_exc()
    
    # Test 3: Import Oracle Base Agent
    total_tests += 1
    try:
        from argumentation_analysis.agents.core.oracle.oracle_base_agent import OracleBaseAgent
        print("‚úÖ Import OracleBaseAgent: OK")
        success_count += 1
    except Exception as e:
        print(f"‚ùå Import OracleBaseAgent: ERREUR - {e}")
        traceback.print_exc()
    
    # Test 4: Import Moriarty Interrogator Agent
    total_tests += 1
    try:
        from argumentation_analysis.agents.core.oracle.moriarty_interrogator_agent import MoriartyInterrogatorAgent
        print("‚úÖ Import MoriartyInterrogatorAgent: OK")
        success_count += 1
    except Exception as e:
        print(f"‚ùå Import MoriartyInterrogatorAgent: ERREUR - {e}")
        traceback.print_exc()
    
    # Test 5: Import Dataset Access Manager
    total_tests += 1
    try:
        from argumentation_analysis.agents.core.oracle.dataset_access_manager import DatasetAccessManager
        print("‚úÖ Import DatasetAccessManager: OK")
        success_count += 1
    except Exception as e:
        print(f"‚ùå Import DatasetAccessManager: ERREUR - {e}")
        traceback.print_exc()
    
    # Test 6: Import Cluedo Dataset
    total_tests += 1
    try:
        from argumentation_analysis.agents.core.oracle.cluedo_dataset import CluedoDataset
        print("‚úÖ Import CluedoDataset: OK")
        success_count += 1
    except Exception as e:
        print(f"‚ùå Import CluedoDataset: ERREUR - {e}")
        traceback.print_exc()
    
    # Test 7: Import Phase D Extensions
    total_tests += 1
    try:
        from argumentation_analysis.agents.core.oracle.phase_d_extensions import PhaseDExtensions
        print("‚úÖ Import PhaseDExtensions: OK")
        success_count += 1
    except Exception as e:
        print(f"‚ùå Import PhaseDExtensions: ERREUR - {e}")
        traceback.print_exc()
    
    # Test 8: Test Tweety Bridge (JPype)
    total_tests += 1
    try:
        from argumentation_analysis.agents.core.logic.tweety_bridge import TweetyBridge
        print("‚úÖ Import TweetyBridge: OK")
        success_count += 1
    except Exception as e:
        print(f"‚ùå Import TweetyBridge: ERREUR - {e}")
        traceback.print_exc()
    
    # Test 9: Test Orchestration
    total_tests += 1
    try:
        from argumentation_analysis.orchestration import cluedo_orchestrator
        print("‚úÖ Import orchestration.cluedo_orchestrator: OK")
        success_count += 1
    except Exception as e:
        print(f"‚ùå Import orchestration.cluedo_orchestrator: ERREUR - {e}")
        traceback.print_exc()
    
    print()
    print("=== R√âSUM√â DES TESTS ===")
    success_rate = (success_count / total_tests) * 100
    print(f"Tests r√©ussis: {success_count}/{total_tests} ({success_rate:.1f}%)")
    
    if success_rate >= 80:
        print("‚úÖ ORACLE ENHANCED v2.1.0 - ENVIRONNEMENT VALIDE")
        return True
    else:
        print("‚ùå ORACLE ENHANCED v2.1.0 - ENVIRONNEMENT NON VALIDE")
        return False

def test_agents_configuration():
    """Test de la configuration des agents en mode r√©el"""
    print("\n=== TEST CONFIGURATION AGENTS GPT-4o-mini ===")
    
    try:
        openai_model = os.environ.get('OPENAI_CHAT_MODEL_ID', 'Non d√©fini')
        print(f"Mod√®le configur√©: {openai_model}")
        
        if openai_model == 'gpt-4o-mini':
            print("‚úÖ Configuration GPT-4o-mini: OK")
            return True
        else:
            print("‚ùå Configuration GPT-4o-mini: ERREUR - Mod√®le incorrect")
            return False
    except Exception as e:
        print(f"‚ùå Configuration agents: ERREUR - {e}")
        return False

if __name__ == "__main__":
    print("VALIDATION ORACLE ENHANCED v2.1.0 - CONDITIONS R√âELLES")
    print("=" * 60)
    
    # Test des imports
    imports_ok = test_oracle_imports()
    
    # Test de la configuration
    config_ok = test_agents_configuration()
    
    overall_success = imports_ok and config_ok
    
    print("\n" + "=" * 60)
    if overall_success:
        print("üéâ VALIDATION ORACLE ENHANCED v2.1.0: SUCC√àS")
        sys.exit(0)
    else:
        print("‚ùå VALIDATION ORACLE ENHANCED v2.1.0: √âCHEC")
        sys.exit(1)