#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""Test pour afficher la vraie conversation avec GPT-4o-mini."""

import asyncio
import os
import logging
from dotenv import load_dotenv
import semantic_kernel as sk
from semantic_kernel.connectors.ai.open_ai import OpenAIChatCompletion
from semantic_kernel.functions.kernel_arguments import KernelArguments

# Configuration du logging d√©taill√©
logging.basicConfig(
    level=logging.DEBUG,
    format='%(asctime)s [%(levelname)s] [%(name)s] %(message)s',
    handlers=[
        logging.StreamHandler(),
    ]
)

# Activer le logging d√©taill√© pour Semantic Kernel et OpenAI
logging.getLogger("semantic_kernel").setLevel(logging.DEBUG)
logging.getLogger("openai").setLevel(logging.DEBUG)
logging.getLogger("httpx").setLevel(logging.DEBUG)

logger = logging.getLogger(__name__)

async def test_gpt4o_conversation():
    """Test direct avec GPT-4o-mini pour voir la conversation."""
    
    # Charger les variables d'environnement
    load_dotenv()
    
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        logger.error("‚ùå OPENAI_API_KEY non trouv√©e")
        return False
    
    logger.info("üîë Cl√© API OpenAI charg√©e")
    
    try:
        # Cr√©er le kernel
        kernel = sk.Kernel()
        
        # Ajouter le service OpenAI
        chat_service = OpenAIChatCompletion(
            service_id="openai_chat",
            ai_model_id="gpt-4o-mini",
            api_key=api_key
        )
        kernel.add_service(chat_service)
        
        logger.info("ü§ñ Service GPT-4o-mini configur√©")
        
        # Cr√©er une fonction de test simple qui montre la conversation
        prompt_conversation_test = """
[INSTRUCTION POUR GPT-4o-mini]
Tu es un expert en analyse d'argumentation. Analyze ce texte politique et explique-moi EN D√âTAIL ton processus de r√©flexion.

Je veux voir:
1. Ta compr√©hension initiale du texte
2. Les arguments que tu identifies 
3. Ton analyse des techniques rh√©toriques
4. Les sophismes potentiels que tu d√©tectes
5. Ta conclusion finale

Sois TR√àS bavard et d√©taill√© dans tes explications. Montre-moi comment tu raisonnes √©tape par √©tape.

TEXTE √Ä ANALYSER:
{{$input}}

R√âPONDS EN FRAN√áAIS avec beaucoup de d√©tails sur ton processus d'analyse:
"""

        # Pas besoin de cr√©er une fonction, on va directement faire invoke_prompt
        
        # Texte de test politique court
        texte_test = """
Les citoyens fran√ßais m√©ritent mieux que ces politiques actuelles. 
Tous les experts s'accordent √† dire que notre approche est la seule viable.
Si nous ne changeons pas maintenant, c'est la catastrophe assur√©e pour nos enfants.
L'opposition ne propose que des solutions irr√©alistes qui ont d√©j√† √©chou√© partout ailleurs.
"""
        
        logger.info("üîç Lancement de l'analyse avec GPT-4o-mini...")
        logger.info(f"üìù Texte analys√©: {texte_test[:100]}...")
        
        # Ex√©cuter l'analyse directement avec invoke_prompt
        arguments = KernelArguments(input=texte_test)
        result = await kernel.invoke_prompt(
            prompt=prompt_conversation_test,
            arguments=arguments
        )
        
        # Afficher le r√©sultat complet
        response_text = str(result)
        
        logger.info("=" * 80)
        logger.info("üéØ CONVERSATION COMPL√àTE AVEC GPT-4o-mini:")
        logger.info("=" * 80)
        print(f"\n{response_text}\n")
        logger.info("=" * 80)
        logger.info("‚úÖ Conversation GPT-4o-mini termin√©e avec succ√®s!")
        
        return True
        
    except Exception as e:
        logger.error(f"‚ùå Erreur: {e}", exc_info=True)
        return False

if __name__ == "__main__":
    success = asyncio.run(test_gpt4o_conversation())
    if success:
        print("\nüéâ Test de conversation GPT-4o-mini r√©ussi!")
    else:
        print("\nüí• √âchec du test de conversation")