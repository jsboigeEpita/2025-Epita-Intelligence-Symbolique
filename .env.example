# Configuration pour le projet d'analyse argumentative

# Service LLM à utiliser (OpenAI, Azure, etc.)
GLOBAL_LLM_SERVICE="OpenAI"

# Clé API pour OpenAI
OPENAI_API_KEY="sk-proj-YOUR_OPENAI_API_KEY_HERE"

# SOLUTION ALTERNATIVE : Utiliser OpenRouter avec votre clé OpenRouter
# OPENAI_API_KEY="sk-or-v1-YOUR_OPENROUTER_KEY_HERE"
# OPENAI_BASE_URL="https://openrouter.ai/api/v1"
# OPENAI_ORG_ID="your_openai_org_id_here"

# Modèle de chat OpenAI à utiliser
OPENAI_CHAT_MODEL_ID="gpt-4o-mini"

# Phrase secrète pour le chiffrement des configurations
TEXT_CONFIG_PASSPHRASE="YourSecretPassphrase"

# Configuration pour le serveur Tika distant
TIKA_SERVER_ENDPOINT="https://your-tika-server.example.com/"
TIKA_SERVER_TIMEOUT=30

# Clé Open-Router
OPENROUTER_API_KEY="sk-or-v1-YOUR_OPENROUTER_API_KEY_HERE"

# Configuration pour les modèles hébergés
SD_BASE_URL="https://your-stable-diffusion-server.example.com"

OPENAI_ENDPOINT_NAME_2="Local Model - Micro"
OPENAI_API_KEY_2="YOUR_LOCAL_API_KEY_2"
OPENAI_BASE_URL_2="https://your-micro-model-api.example.com/v1"

OPENAI_ENDPOINT_NAME_3="Local Model - Mini"
OPENAI_API_KEY_3="YOUR_LOCAL_API_KEY_3"
OPENAI_BASE_URL_3="https://your-mini-model-api.example.com/v1"

OPENAI_ENDPOINT_NAME_4="Local Model - Medium"
OPENAI_API_KEY_4="YOUR_LOCAL_API_KEY_4"
OPENAI_BASE_URL_4="https://your-medium-model-api.example.com/v1"

# Clés Azure OpenAI
AZURE_OPENAI_ENDPOINT="https://your-azure-endpoint.openai.azure.com/"
AZURE_OPENAI_API_KEY="your-azure-api-key"
AZURE_OPENAI_API_VERSION="2024-02-15-preview"

# Configuration Java (optionnel)
JAVA_HOME=./portable_jdk/jdk-17.0.11+9
# JPYPE_JVM_PATH=C:\Program Files\Java\jdk-11.0.x\bin\server\jvm.dll

# Configuration de développement (optionnel)
# DEBUG=true
# LOG_LEVEL=INFO