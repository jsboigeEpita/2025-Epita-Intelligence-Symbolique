# Fichier d'exemple pour la configuration de l'environnement.
# Renommez ce fichier en .env et remplissez les valeurs appropriées.

# --- Configuration Générale ---
# Service LLM par défaut (OpenAI, Azure, OpenRouter)
GLOBAL_LLM_SERVICE="OpenAI"

# Phrase secrète pour le chiffrement
TEXT_CONFIG_PASSPHRASE="une_phrase_secrete_robuste"

# --- Clés API ---
# Remplissez UNIQUEMENT les clés pour les services que vous utilisez.

# Pour OpenAI (primary)
OPENAI_API_KEY="sk-..."
OPENAI_CHAT_MODEL_ID="gpt-5-mini"
# BASE_URL="" # Override OpenAI base URL if needed

# Pour OpenRouter (alternative provider)
# OPENROUTER_API_KEY="sk-or-v1-..."

# Pour Azure OpenAI
# AZURE_OPENAI_ENDPOINT="https://your-azure-endpoint.openai.azure.com/"
# AZURE_OPENAI_API_KEY="your-azure-api-key"
# AZURE_OPENAI_API_VERSION="2024-02-15-preview"

# --- Endpoints locaux (pour text-generation-webui, vLLM ou similaire) ---
# OPENAI_ENDPOINT_NAME_2="Local Model - Micro"
# OPENAI_API_KEY_2="votre_cle_locale"
# OPENAI_BASE_URL_2="http://127.0.0.1:5001/v1"
# OPENAI_ENDPOINT_NAME_3="Local Model - Medium"
# OPENAI_API_KEY_3="votre_cle_locale"
# OPENAI_BASE_URL_3="http://127.0.0.1:5002/v1"
# OPENAI_ENDPOINT_NAME_4="Local Model - Large"
# OPENAI_API_KEY_4="votre_cle_locale"
# OPENAI_BASE_URL_4="http://127.0.0.1:5003/v1"

# --- Services externes ---
# Apache Tika (extraction de texte depuis PDF/DOCX)
# TIKA_SERVER_ENDPOINT="http://localhost:9998"
# TIKA_SERVER_TIMEOUT="30"

# Stable Diffusion (génération d'images)
# SD_BASE_URL="http://localhost:7860"

# --- Dépendances Systèmes ---
# Laisser vide pour utiliser le JDK portable ou si Java est dans le PATH
JAVA_HOME=""

# Environnement Conda (utilisé par les scripts)
CONDA_ENV_NAME="projet-is-roo-new"
# CONDA_PATH="" # Override path vers Conda si non dans le PATH

# --- Tests E2E ---
# Utilisé par Playwright, peut être laissé par défaut.
FRONTEND_URL="http://localhost:3000"
BACKEND_URL="http://localhost:8000"
