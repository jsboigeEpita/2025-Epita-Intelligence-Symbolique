# ğŸ—£ï¸ Speech-to-Text Argument Analyzer

Welcome to the **Speech-to-Text Argument Analyzer**!  
This project lets you upload or transcribe audio, analyze the resulting text for logical fallacies, argument structure, and moreâ€”all in a beautiful, interactive web interface.

---

## ğŸš€ Features

- ğŸ¤ **Audio Upload & Transcription**: Upload audio files or provide a YouTube link for transcription using Whisper WebUI.
- ğŸ§  **Argument Analysis**: Detects logical fallacies, evaluates argument structure, coherence, strength, and more.
- ğŸ“Š **Visual Results**: Clean, sectioned display of analysis results with color-coded quality indicators.
- ğŸ“„ **Export**: Download your analysis as JSON or a nicely formatted PDF.
- ğŸ”’ **Authentication**: Secure connection to the Whisper WebUI API with credentials.

---

## ğŸ› ï¸ Getting Started

### 1. **Clone the Repository**

```sh
git clone https://github.com/jsboigeEpita/2025-Epita-Intelligence-Symbolique.git
```

### 2. **Setup your environment**
â„¹ï¸ Please refer to the other documentation in the repository to set up your environment.


### 3. **Run the argumentation analysis python Web Api**
```sh
python -m argumentation_analysis.services.web_api.app
```

### 4. **Install Frontend Dependencies**

```sh
cd speech-to-text/frontend
npm install
```


### 5. **Configure API Credentials**

Copy the `.env.example` file variables into you `.env` file. Set the following variables:
- `WHISPER_API_URL` (default: `https://whisper-webui.myia.io/`)
- Your API username, password, and API key.

### 6. **Run the Frontend**

```sh
npm run serve
```
or
```sh
npm run dev
```

Visit [http://localhost:3000](http://localhost:3000) in your browser.

---

## ğŸ¬ Usage

1. **Upload an audio file** (e.g., `.mp3`, `.wav`) (In progress...) or paste a YouTube link.
2. Click **Transcribe** to convert speech to text.
3. Click **Analyze** to run the argument analysis.
4. View results: logical fallacies, argument structure, coherence, strength, and more.
5. **Export** your results as JSON or PDF.

---

## ğŸ“¦ Project Structure

```
frontend/
  â”œâ”€â”€ src/
  â”‚   â”œâ”€â”€ components/
  â”‚   â”‚   â””â”€â”€ MainComponent.vue   # Main UI and logic
  â”‚   â”œâ”€â”€ api/
  â”‚   â”‚   â””â”€â”€ whisperApiClient.js # API client for Whisper WebUI
  â”‚   â””â”€â”€ ...
  â””â”€â”€ ... # Main VueJS code
```

---

## ğŸ“ Customization

- **API Endpoint**: Change the Whisper WebUI endpoint in `whisperApiClient.js`.
- **Analysis Options**: Adjust analysis parameters in the UI or code.
- **PDF Export**: Tweak formatting in `exportResults` method in `MainComponent.vue`.

---

## ğŸ§© Dependencies

- [Vue.js](https://vuejs.org/) (Frontend framework)
- [Vuetify](https://vuetifyjs.com/) (UI components)
- [jsPDF](https://github.com/parallax/jsPDF) (PDF export)
- [@gradio/client](https://www.npmjs.com/package/@gradio/client) (API client)

---

## ğŸ Troubleshooting

- **CORS Errors**: If fetching remote files, use your own backend proxy or ensure the remote server sends proper CORS headers.
- **File Type Errors**: Only upload supported audio formats (see error message for allowed extensions).
- **API Errors**: Check your credentials and API endpoint.

---

## ğŸ¤ Contributing

Pull requests and suggestions are welcome!  
Please open an issue or discussion for feedback or feature requests.

---

## ğŸ“„ License

MIT License (c.f. project root license)

---

## ğŸ™ Acknowledgements

- [OpenAI Whisper](https://github.com/openai/whisper)
- [Gradio](https://gradio.app/)
- [jsPDF](https://github.com/parallax/jsPDF)

---

Enjoy analyzing arguments! ğŸ‰