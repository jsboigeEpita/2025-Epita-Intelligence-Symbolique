# ğŸ§  Semantic Index of Arguments

This project focuses on semantic indexing of arguments from large historical texts and political speeches (e.g., Lincoln-Douglas debates). It allows users to search and ask questions over the content using OpenAI embeddings, leveraging [Kernel Memory](https://github.com/microsoft/kernel-memory) as the semantic search engine.

## ğŸ”§ Features

- ğŸ” Semantic search across historical speeches
- ğŸ¤– RAG-based question answering using contextual document retrieval
- ğŸ§  Automatic indexing with OpenAI embeddings
- ğŸ–¥ï¸ Interactive demo interface built with Streamlit (`UI_streamlit.py`)

---

## âš™ï¸ Requirements

- Python 3.8+
- Valid OpenAI API Key (**required**)
- Docker installed

---

## ğŸ“¦ Installation

1. **Clone the repository:**

   ```bash
   git clone <REPO_URL>
   cd Arg_Semantic_Index
   ```

2. **Create and activate a virtual environment:**

   ```bash
   python -m venv venv
   source venv/bin/activate     # On Windows: .\venv\Scripts\activate
   ```

3. **Install Python dependencies:**

   ```bash
   pip install -r requirements.txt
   ```

---

## ğŸš€ Run Kernel Memory with Docker

> **âš ï¸ IMPORTANT:** You must insert your OpenAI API key in `appsettings.Development.json` before starting.

Use the following Docker command to start the Kernel Memory service:

```bash
docker run --volume ./kernel_memory/appsettings.Development.json:/app/appsettings.Production.json \
           -it --rm -p 9001:9001 kernelmemory/service
```

This starts the Kernel Memory API on `http://localhost:9001`.

---

## ğŸ§  Load Documents into Kernel Memory

Once Kernel Memory is running, ingest the data using:

```bash
python kernel_memory/load_sources.py
```

---

## ğŸ’» Launch the Streamlit Interface

```bash
streamlit run UI_streamlit.py
```

Open your browser to [http://localhost:8501](http://localhost:8501) to interact with the app.

---

## ğŸ”‘ OpenAI API Key Configuration

To use OpenAI embeddings, you must provide your API key in the file:  
`kernel_memory/appsettings.Development.json`

Example structure:

```json
{
  "KernelMemory": {
    "Embedding": {
      "Service": "openai",
      "Model": "text-embedding-ada-002",
      "ApiKey": "YOUR_OPENAI_API_KEY_HERE"
    }
  }
}
```

---

## ğŸ“ Project Structure

```
Arg_Semantic_Index
â”œâ”€â”€ kernel_memory/
â”‚   â”œâ”€â”€ appsettings.Development.json     â† Add your OpenAI API key here
â”‚   â”œâ”€â”€ example.py                       â† Example usage of Kernel Memory
â”‚   â”œâ”€â”€ km_client.py                     â† API wrapper for KM
â”‚   â””â”€â”€ load_sources.py                  â† Loads and ingests discourse data
â”œâ”€â”€ prompts.txt
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ sources/
â”‚   â””â”€â”€ final_processed_config_unencrypted.json  â† Cleaned discourse dataset
â””â”€â”€ UI_streamlit.py                    â† Streamlit user interface
```

---

## ğŸ‘¥ Authors

- yanis.martin
- leo.lopes