# Fondements th√©oriques et techniques

Cette section pr√©sente les projets centr√©s sur les aspects formels, logiques et th√©oriques de l'argumentation.

> **Note importante pour les √©tudiants**: Pour chaque projet ci-dessous, vous trouverez une r√©f√©rence √† des exemples de code sp√©cifiques √† la fin de la description du projet. Ces exemples sont extraits du notebook `Tweety.ipynb` et organis√©s dans le document [Exemples TweetyProject par projet](./exemples_tweety_par_projet.md). Ils vous fourniront un point de d√©part concret pour impl√©menter votre projet.

## 1.1 Logiques formelles et raisonnement

### 1.1.1 Int√©gration des logiques propositionnelles avanc√©es
- **Contexte** : La logique propositionnelle constitue la base de nombreux syst√®mes de raisonnement automatique. Le module `logics.pl` de Tweety offre des fonctionnalit√©s avanc√©es encore peu exploit√©es dans le projet. Ce module permet non seulement de repr√©senter et manipuler des formules propositionnelles, mais aussi d'effectuer des op√©rations complexes comme la conversion en formes normales (DNF/CNF), la simplification, et l'utilisation de solveurs SAT pour le raisonnement efficace.
- **Objectifs** : Am√©liorer l'agent PL existant pour exploiter davantage les fonctionnalit√©s du module, notamment les solveurs SAT (SAT4J interne ou solveurs externes comme Lingeling, CaDiCaL), la conversion DIMACS, et les op√©rations avanc√©es sur les formules (DNF, CNF, simplification). Impl√©menter des requ√™tes plus sophistiqu√©es comme la v√©rification de satisfiabilit√©, la recherche de mod√®les, et l'analyse d'implications logiques.
- **Technologies cl√©s** :
  * Tweety `logics.pl` (syntaxe, s√©mantique, parsing)
  * Solveurs SAT modernes (SAT4J interne, int√©gration avec Lingeling, CaDiCaL)
  * Format DIMACS pour l'√©change avec solveurs externes
  * Java-Python bridge via JPype
- **Niveau de difficult√©** : ‚≠ê‚≠ê‚≠ê
- **Estimation d'effort** : 3-4 semaines-personnes
- **Port√©e ajust√©e** : Se concentrer sur l'int√©gration d'un seul solveur SAT et la conversion DNF/CNF
- **Interd√©pendances** : Base pour les projets de maintenance de la v√©rit√© (1.4) et d'argumentation formelle (1.2)
- **R√©f√©rences** :
  - "SAT_SMT_by_example.pdf" (2023)
  - "Handbook of Satisfiability, Second Edition" (2021)
  - "Artificial Intelligence: A Modern Approach" (4√®me √©dition, 2021)
- **Livrables attendus** :
  - Agent PL am√©lior√© avec support pour les solveurs SAT externes
  - Fonctions pour la manipulation avanc√©e de formules (conversion DNF/CNF, simplification)
  - Documentation et exemples d'utilisation
  - Tests unitaires et d'int√©gration

> **Exemple de code**: Voir [Exemples TweetyProject par projet](./exemples_tweety_par_projet.md#111-int√©gration-des-logiques-propositionnelles-avanc√©es) pour des snippets sur la cr√©ation de formules propositionnelles, l'utilisation de solveurs SAT et la conversion en formes normales.
### 1.1.2 Logique du premier ordre (FOL)
- **Contexte** : La logique du premier ordre permet d'exprimer des relations plus complexes que la logique propositionnelle, avec des quantificateurs et des pr√©dicats. Le module `logics.fol` de Tweety fournit une impl√©mentation compl√®te pour d√©finir des signatures logiques (types/sorts, constantes, pr√©dicats, fonctions), construire des formules quantifi√©es, et raisonner sur ces formules via des prouveurs int√©gr√©s ou externes.
- **Objectifs** : D√©velopper un nouvel agent utilisant le module `logics.fol` de Tweety pour analyser des arguments plus complexes impliquant des quantificateurs (`‚àÄ`, `‚àÉ`) et des pr√©dicats. Cet agent pourrait tenter de traduire des arguments exprim√©s en langage naturel (avec quantificateurs) en formules FOL, d√©finir des signatures logiques (types/sorts, constantes, pr√©dicats, fonctions), et utiliser les raisonneurs int√©gr√©s.
- **Technologies cl√©s** :
  * Tweety `logics.fol` (signatures, formules, parsing)
  * Prouveurs FOL modernes (int√©gration avec Vampire, E-prover, Z3)
  * Techniques de traduction langage naturel vers FOL
  * Manipulation de formules quantifi√©es
- **Niveau de difficult√©** : ‚≠ê‚≠ê‚≠ê
- **Estimation d'effort** : 4 semaines-personnes
- **Port√©e ajust√©e** : Se concentrer sur la traduction d'arguments simples en FOL sans int√©gration de prouveurs externes
- **Interd√©pendances** : Extension de 1.1.1, base pour 1.2.4 (ABA)
- **R√©f√©rences** :
  - "Automated Theorem Proving: Theory and Practice" (2022)
  - "Handbook of Practical Logic and Automated Reasoning" (2023)
  - "From Natural Language to First-Order Logic: Mapping Techniques and Challenges" (2021)
- **Livrables attendus** :
  - Agent FOL pour l'analyse d'arguments quantifi√©s
  - Module de traduction langage naturel vers FOL
  - Int√©gration avec au moins un prouveur externe
  - Documentation et exemples d'utilisation

> **Exemple de code**: Voir [Exemples TweetyProject par projet](./exemples_tweety_par_projet.md#112-logique-du-premier-ordre-fol) pour des snippets sur la d√©finition de signatures FOL et la cr√©ation de formules avec quantificateurs.

### 1.1.3 Logique modale
- **Contexte** : Les logiques modales permettent de raisonner sur des notions comme la n√©cessit√©, la possibilit√©, les croyances ou les connaissances. Le module `logics.ml` de Tweety impl√©mente les concepts fondamentaux des logiques modales, permettant de repr√©senter et raisonner avec des op√©rateurs modaux comme la n√©cessit√© (`[]`) et la possibilit√© (`<>`), ainsi que d'utiliser diff√©rents syst√®mes modaux (K, T, S4, S5).
- **Objectifs** : Cr√©er un agent sp√©cialis√© utilisant le module `logics.ml` de Tweety pour raisonner sur des modalit√©s comme la n√©cessit√© (`[]`), la possibilit√© (`<>`), les croyances ou les connaissances. Cet agent pourrait analyser des arguments impliquant des notions de possibilit√©, n√©cessit√©, obligation ou permission.
- **Technologies cl√©s** :
  * Tweety `logics.ml`
  * Raisonneurs modaux (SPASS-XDB, MleanCoP)
  * S√©mantique des mondes possibles de Kripke
- **Niveau de difficult√©** : ‚≠ê‚≠ê‚≠ê
- **Estimation d'effort** : 4 semaines-personnes
- **Port√©e ajust√©e** : Se concentrer sur la repr√©sentation des modalit√©s de base (n√©cessit√©, possibilit√©) sans int√©gration de raisonneurs externes
- **Interd√©pendances** : Peut √™tre combin√© avec 1.4 (maintenance de la v√©rit√©)
- **R√©f√©rences** :
  - "Handbook of Modal Logic" (2022)
  - "Modal Logic for Open Minds" (2023)
  - "Reasoning About Knowledge" (2021)
- **Livrables attendus** :
  - Agent de logique modale
  - Int√©gration avec SPASS ou autre raisonneur modal
  - Documentation et exemples d'utilisation
  - Tests unitaires et d'int√©gration

> **Exemple de code**: Voir [Exemples TweetyProject par projet](./exemples_tweety_par_projet.md#113-logique-modale) pour des snippets sur la cr√©ation de formules modales et le raisonnement avec SimpleMlReasoner.
### 1.1.4 Logique de description (DL)
- **Contexte** : Les logiques de description sont utilis√©es pour repr√©senter des connaissances structur√©es sous forme de concepts, r√¥les et individus. Le module `logics.dl` de Tweety permet de d√©finir des TBox (axiomes terminologiques) et ABox (assertions sur les individus), et de raisonner sur la subsomption, l'instanciation et la consistance. Cette logique est particuli√®rement pertinente pour les ontologies et le web s√©mantique.
- **Objectifs** : D√©velopper un agent utilisant le module `logics.dl` de Tweety pour mod√©liser des connaissances structur√©es. Cet agent pourrait construire des TBox (axiomes terminologiques) et ABox (assertions sur les individus), et raisonner sur la subsomption, l'instanciation et la consistance.
- **Technologies cl√©s** :
  * Tweety `logics.dl`
  * Ontologies OWL
  * Raisonneurs DL (HermiT, ELK, Pellet)
- **Niveau de difficult√©** : ‚≠ê‚≠ê‚≠ê
- **Estimation d'effort** : 4 semaines-personnes
- **Port√©e ajust√©e** : Se concentrer sur la d√©finition de TBox et ABox simples sans int√©gration de raisonneurs externes
- **Interd√©pendances** : Peut √™tre combin√© avec 1.3 (taxonomies de sophismes)
- **R√©f√©rences** :
  - "The Description Logic Handbook" (2022)
  - "OWL 2 Web Ontology Language Primer" (2023)
  - "Description Logic: A Practical Introduction" (2023)
- **Livrables attendus** :
  - Agent de logique de description
  - Int√©gration avec au moins un raisonneur DL
  - Documentation et exemples d'utilisation
  - Tests unitaires et d'int√©gration

> **Exemple de code**: Voir [Exemples TweetyProject par projet](./exemples_tweety_par_projet.md#114-logique-de-description-dl) pour des snippets sur la d√©finition de concepts, r√¥les et axiomes DL.

### 1.1.5 Formules bool√©ennes quantifi√©es (QBF)
- **Contexte** : Les QBF √©tendent la logique propositionnelle avec des quantificateurs, permettant de mod√©liser des probl√®mes PSPACE-complets.
- **Objectifs** : Explorer l'utilisation du module `logics.qbf` de Tweety pour mod√©liser et r√©soudre des probl√®mes PSPACE-complets. Cet agent pourrait traiter des probl√®mes de planification conditionnelle, de jeux √† deux joueurs, ou de v√©rification formelle qui d√©passent la port√©e de SAT.
- **Technologies cl√©s** :
  * Tweety `logics.qbf`
  * Solveurs QBF
  * Format QDIMACS
- **Niveau de difficult√©** : ‚≠ê‚≠ê‚≠ê‚≠ê
- **Estimation d'effort** : 4 semaines-personnes
- **Port√©e ajust√©e** : Se concentrer sur la mod√©lisation de probl√®mes simples sans int√©gration de solveurs externes
- **Interd√©pendances** : Extension de 1.1.1, peut √™tre utilis√© dans 1.5.2 (v√©rification formelle)
- **R√©f√©rences** :
  - "SAT_SMT_by_example.pdf" (2023)
  - "Handbook of Satisfiability"
  - Documentation Tweety `logics.qbf`
- **Livrables attendus** :
  - Agent QBF pour la mod√©lisation et r√©solution de probl√®mes complexes
  - Int√©gration avec au moins un solveur QBF
  - Documentation et exemples d'utilisation

> **Exemple de code**: Voir [Exemples TweetyProject par projet](./exemples_tweety_par_projet.md#115-formules-bool√©ennes-quantifi√©es-qbf) pour des snippets sur la cr√©ation et manipulation de formules QBF.
### 1.1.6 Logique conditionnelle (CL)
- **Contexte** : Les logiques conditionnelles permettent de raisonner sur des √©nonc√©s de la forme "Si A est vrai, alors B est typiquement vrai". Elles constituent un formalisme puissant pour repr√©senter des connaissances incertaines et des r√®gles par d√©faut. Le module `logics.cl` de Tweety impl√©mente les fonctions de classement (ranking) ou OCF (Ordinal Conditional Functions) pour √©valuer ces conditionnels et raisonner de mani√®re non-monotone.
- **Objectifs** : Impl√©menter un agent utilisant le module `logics.cl` de Tweety pour raisonner sur des conditionnels. Le notebook Tweety d√©montre comment cr√©er une base conditionnelle avec des conditionnels comme (f|b), (b|p), (¬¨f|p), et comment calculer une fonction de classement (ranking) pour √©valuer ces conditionnels. L'agent devra permettre la cr√©ation de bases de connaissances conditionnelles, l'√©valuation de requ√™tes conditionnelles, et la visualisation des fonctions de classement.
- **Technologies cl√©s** :
  * Tweety `logics.cl`
  * Raisonnement non-monotone
  * Fonctions de classement (ranking) ou OCF (Ordinal Conditional Functions)
  * S√©mantique des mondes possibles
- **Niveau de difficult√©** : ‚≠ê‚≠ê‚≠ê
- **Estimation d'effort** : 4 semaines-personnes
- **Port√©e ajust√©e** : Se concentrer sur la cr√©ation de bases conditionnelles simples et l'√©valuation de requ√™tes basiques
- **Interd√©pendances** : Peut √™tre combin√© avec 1.2 (frameworks d'argumentation) et 1.4.3 (raisonnement non-monotone)
- **R√©f√©rences** :
  - "Conditionals in Nonmonotonic Reasoning and Belief Revision" de Gabriele Kern-Isberner (2001)
  - "A Ranking Semantics for First-Order Conditionals" de Wilhelm K√∂tter et al. (2019)
  - "Reasoning-with-probabilistic-and-deterministic-graphical-models-exact-algorithms" (2013)
  - Documentation Tweety `logics.cl`
- **Livrables attendus** :
  - Agent de logique conditionnelle
  - Fonctions pour la cr√©ation et l'√©valuation de bases conditionnelles
  - Visualisation des fonctions de classement (OCF)
  - Interface pour la formulation de requ√™tes conditionnelles
  - Documentation et exemples d'utilisation
  - Tests unitaires et d'int√©gration

> **Exemple de code**: Voir [Exemples TweetyProject par projet](./exemples_tweety_par_projet.md#116-logique-conditionnelle-cl) pour des snippets sur la cr√©ation et l'√©valuation de bases conditionnelles.

## 1.2 Frameworks d'argumentation

### 1.2.1 Argumentation abstraite de Dung
- **Contexte** : Les frameworks d'argumentation abstraite de Dung (AF) fournissent un cadre math√©matique pour repr√©senter et √©valuer des arguments en conflit. Le module `arg.dung` de Tweety offre une impl√©mentation compl√®te de ce formalisme, permettant de construire des graphes d'arguments et d'attaques (`DungTheory`), et de calculer l'acceptabilit√© des arguments selon diff√©rentes s√©mantiques (admissible, compl√®te, pr√©f√©r√©e, stable, fond√©e, id√©ale, semi-stable, CF2, etc.).
- **Objectifs** : Impl√©menter un agent sp√©cialis√© utilisant le module `arg.dung` de Tweety pour repr√©senter et √©valuer des arguments abstraits. Cet agent devrait permettre de construire des graphes d'arguments et d'attaques (`DungTheory`), et surtout de calculer l'acceptabilit√© des arguments selon diff√©rentes s√©mantiques (admissible, compl√®te, pr√©f√©r√©e, stable, fond√©e, id√©ale, semi-stable, CF2...).
- **Technologies cl√©s** :
  * Tweety `arg.dung` (construction, manipulation, visualisation)
  * Algorithmes de calcul d'extensions pour diff√©rentes s√©mantiques
  * Techniques d'apprentissage et de g√©n√©ration de frameworks
  * Visualisation de graphes d'argumentation
- **Niveau de difficult√©** : ‚≠ê‚≠ê‚≠ê
- **Estimation d'effort** : 3-4 semaines-personnes
- **Port√©e ajust√©e** : Se concentrer sur les s√©mantiques principales (admissible, compl√®te, pr√©f√©r√©e) et une visualisation simple
- **Interd√©pendances** : Base pour les autres frameworks d'argumentation (1.2.x)
- **R√©f√©rences** :
  - "On the Acceptability of Arguments and its Fundamental Role in Nonmonotonic Reasoning" (Dung, 1995)
  - "Abstract Argumentation Frameworks" (2022)
  - "Computational Problems in Abstract Argumentation" (2023)
- **Livrables attendus** :
  - Agent d'argumentation abstraite
  - Impl√©mentation des principales s√©mantiques d'acceptabilit√©
  - Visualisation des graphes d'argumentation
  - Documentation et exemples d'utilisation
  - Cas d'√©tude d√©montrant l'application √† un probl√®me concret

> **Exemple de code**: Voir [Exemples TweetyProject par projet](./exemples_tweety_par_projet.md#121-argumentation-abstraite-de-dung) pour des snippets sur la cr√©ation de frameworks d'argumentation et le calcul d'extensions selon diff√©rentes s√©mantiques.
### 1.2.2 Argumentation bipolaire
- **Contexte** : L'argumentation bipolaire √©tend les frameworks de Dung en distinguant deux types de relations entre arguments : l'attaque et le support. Le module `arg.bipolar` de Tweety impl√©mente plusieurs variantes de frameworks bipolaires, avec diff√©rentes interpr√©tations du support (d√©ductif, n√©cessaire, √©videntiel) et leurs s√©mantiques associ√©es. Ces frameworks permettent de mod√©liser des relations plus nuanc√©es entre arguments.
- **Objectifs** : D√©velopper un agent utilisant le module `arg.bipolar` de Tweety pour repr√©senter et √©valuer des arguments avec relations d'attaque et de support. Comprendre les diff√©rentes interpr√©tations du support (d√©ductif, n√©cessaire, √©videntiel...) et les s√©mantiques associ√©es propos√©es dans la litt√©rature et impl√©ment√©es dans Tweety.
- **Technologies cl√©s** :
  * Tweety `arg.bipolar`
  * S√©mantiques pour l'argumentation bipolaire
  * Extraction de relations de support
- **Niveau de difficult√©** : ‚≠ê‚≠ê‚≠ê
- **Estimation d'effort** : 3-4 semaines-personnes
- **Port√©e ajust√©e** : Se concentrer sur une seule interpr√©tation du support (d√©ductif ou n√©cessaire)
- **Interd√©pendances** : Extension de 1.2.1 (Dung AF)
- **R√©f√©rences** :
  - "Bipolar Argumentation Frameworks" (2022)
  - "A Logical Account of Formal Argumentation" (2023)
  - "Semantics for Support Relations in Abstract Argumentation" (2022)
- **Livrables attendus** :
  - Agent d'argumentation bipolaire
  - Impl√©mentation des principales s√©mantiques pour BAF
  - Visualisation des graphes bipolaires
  - Documentation et exemples d'utilisation

> **Exemple de code**: Voir [Exemples TweetyProject par projet](./exemples_tweety_par_projet.md#123-argumentation-bipolaire) pour des snippets sur la cr√©ation de frameworks bipolaires avec relations d'attaque et de support.

### 1.2.3 Argumentation pond√©r√©e
- **Contexte** : L'argumentation pond√©r√©e associe des poids num√©riques aux arguments ou aux attaques pour repr√©senter leur force relative. Les modules `arg.prob` et `arg.social` de Tweety permettent de manipuler des frameworks d'argumentation avec poids, en utilisant diff√©rents semi-anneaux (WeightedSemiring, FuzzySemiring, ProbabilisticSemiring) pour l'agr√©gation des poids et le calcul de l'acceptabilit√©.
- **Objectifs** : Cr√©er un agent utilisant le module `arg.prob` ou `arg.social` de Tweety pour manipuler des frameworks d'argumentation avec poids. Cet agent pourrait utiliser diff√©rents semi-anneaux (WeightedSemiring, FuzzySemiring, ProbabilisticSemiring) et raisonneurs pond√©r√©s.
- **Technologies cl√©s** :
  * Tweety `arg.prob` et `arg.social`
  * M√©thodes d'agr√©gation de poids
  * Estimation automatique de la force des arguments
- **Niveau de difficult√©** : ‚≠ê‚≠ê‚≠ê
- **Estimation d'effort** : 4 semaines-personnes
- **Port√©e ajust√©e** : Se concentrer sur un seul type de semi-anneau (WeightedSemiring ou ProbabilisticSemiring)
- **Interd√©pendances** : Extension de 1.2.1 (Dung AF)
- **R√©f√©rences** :
  - "Weighted Argument Systems" (2022)
  - "Gradual Argumentation: A Comprehensive Survey" (2023)
  - "Learning Weights in Abstract Argumentation" (2022)
- **Livrables attendus** :
  - Agent d'argumentation pond√©r√©e
  - Impl√©mentation de diff√©rents semi-anneaux et raisonneurs
  - Visualisation des graphes pond√©r√©s
  - Documentation et exemples d'utilisation

> **Exemple de code**: Voir [Exemples TweetyProject par projet](./exemples_tweety_par_projet.md#125-argumentation-pond√©r√©e-waf) pour des snippets sur la cr√©ation de frameworks pond√©r√©s avec attaques de diff√©rentes forces.

### 1.2.4 Argumentation bas√©e sur les hypoth√®ses (ABA)
- **Contexte** : L'argumentation bas√©e sur les hypoth√®ses (ABA) est un framework qui repr√©sente les arguments comme des d√©ductions √† partir d'hypoth√®ses.
- **Objectifs** : D√©velopper un agent utilisant le module `arg.aba` de Tweety pour repr√©senter et √©valuer des arguments bas√©s sur des hypoth√®ses. Cet agent pourrait analyser les attaques entre arguments d√©riv√©s de ces hypoth√®ses et d√©terminer leur acceptabilit√©.
- **Technologies cl√©s** :
  * Tweety `arg.aba`
  * Logiques non-monotones
  * Traduction langage naturel vers ABA
- **Niveau de difficult√©** : ‚≠ê‚≠ê‚≠ê‚≠ê
- **Estimation d'effort** : 4 semaines-personnes
- **Port√©e ajust√©e** : Se concentrer sur des cas simples d'ABA sans traduction depuis le langage naturel
- **Interd√©pendances** : Li√© √† 1.1.2 (FOL) et 1.2.1 (Dung AF)
- **R√©f√©rences** :
  - "Assumption-Based Argumentation" (2022)
  - "Computational Aspects of Assumption-Based Argumentation" (2023)
  - "ABA+: Assumption-Based Argumentation with Preferences" (2022)
- **Livrables attendus** :
  - Agent ABA
  - Module de traduction langage naturel vers ABA
  - Documentation et exemples d'utilisation

> **Exemple de code**: Voir [Exemples TweetyProject par projet](./exemples_tweety_par_projet.md#124-argumentation-bas√©e-sur-les-hypoth√®ses-aba) pour des snippets sur la cr√©ation de frameworks ABA avec r√®gles, hypoth√®ses et contraires.
### 1.2.5 Argumentation bas√©e sur les valeurs (VAF)
- **Contexte** : L'argumentation bas√©e sur les valeurs (VAF) √©tend les frameworks abstraits en associant des valeurs aux arguments.
- **Objectifs** : Cr√©er un agent sp√©cialis√© pour repr√©senter et √©valuer des arguments bas√©s sur des valeurs. Cet agent devrait permettre de mod√©liser des pr√©f√©rences sur les valeurs et d'√©valuer l'acceptabilit√© des arguments en fonction de ces pr√©f√©rences.
- **Technologies cl√©s** :
  * Frameworks d'argumentation bas√©s sur les valeurs
  * Identification automatique de valeurs
  * Mod√©lisation de pr√©f√©rences sur les valeurs
- **Niveau de difficult√©** : ‚≠ê‚≠ê‚≠ê
- **Estimation d'effort** : 4 semaines-personnes
- **Port√©e ajust√©e** : Se concentrer sur la mod√©lisation de pr√©f√©rences simples sur les valeurs
- **Interd√©pendances** : Extension de 1.2.1 (Dung AF)
- **R√©f√©rences** :
  - "Argumentation Based on Value" (2022)
  - "Value-Based Argumentation Frameworks" (2023)
  - "Ethical Argumentation" (2022)
- **Livrables attendus** :
  - Agent VAF
  - Module d'identification de valeurs dans les arguments
  - Visualisation des graphes VAF
  - Documentation et exemples d'utilisation

### 1.2.6 Argumentation structur√©e (ASPIC+)
- **Contexte** : ASPIC+ est un framework d'argumentation structur√©e qui combine la logique formelle avec des m√©canismes de gestion des conflits et des pr√©f√©rences.
- **Objectifs** : D√©velopper un agent impl√©mentant le framework ASPIC+ pour construire et √©valuer des arguments structur√©s. Cet agent pourrait mod√©liser des bases de connaissances avec axiomes et r√®gles, g√©rer les pr√©f√©rences entre r√®gles, et analyser les attaques (rebutting, undercutting, undermining).
- **Technologies cl√©s** :
  * Framework ASPIC+
  * R√®gles strictes et d√©faisables
  * Gestion des pr√©f√©rences
- **Niveau de difficult√©** : ‚≠ê‚≠ê‚≠ê‚≠ê
- **Estimation d'effort** : 4 semaines-personnes
- **Port√©e ajust√©e** : Se concentrer sur un sous-ensemble du framework avec des r√®gles strictes uniquement
- **Interd√©pendances** : Li√© √† 1.1 (logiques formelles) et 1.2.1 (Dung AF)
- **R√©f√©rences** :
  - "ASPIC+: An Argumentation Framework for Structured Argumentation" (2022)
  - "Rationality Postulates for Structured Argumentation" (2023)
  - "From Natural Language to ASPIC+" (2022)
- **Livrables attendus** :
  - Agent ASPIC+
  - Module de traduction langage naturel vers ASPIC+
  - Visualisation des arguments structur√©s
  - Documentation et exemples d'utilisation

### 1.2.7 Argumentation dialogique
- **Contexte** : L'argumentation dialogique mod√©lise les d√©bats comme des √©changes structur√©s entre participants, avec des r√®gles sp√©cifiques.
- **Objectifs** : Cr√©er un agent capable de participer √† des dialogues argumentatifs suivant diff√©rents protocoles. Cet agent devrait pouvoir g√©n√©rer des arguments, des contre-arguments, et des questions critiques en fonction du contexte du dialogue.
- **Technologies cl√©s** :
  * Protocoles de dialogue argumentatif
  * Strat√©gies argumentatives
  * Apprentissage par renforcement
- **Niveau de difficult√©** : ‚≠ê‚≠ê‚≠ê
- **Estimation d'effort** : 4 semaines-personnes
- **Port√©e ajust√©e** : Se concentrer sur un seul protocole de dialogue simple
- **Interd√©pendances** : Peut utiliser n'importe quel framework d'argumentation (1.2.x)
- **R√©f√©rences** :
  - "Dialogue-Based Argumentation" (2022)
  - "Protocols for Argumentative Dialogue" (2023)
  - "Strategic Argumentation" (2022)
- **Livrables attendus** :
  - Agent de dialogue argumentatif
  - Impl√©mentation de plusieurs protocoles de dialogue
  - Interface pour l'interaction avec l'agent
  - Documentation et exemples d'utilisation

> **üìñ Guide p√©dagogique d√©taill√©** : [1.2.7 Argumentation Dialogique](./sujets/1.2.7_Argumentation_Dialogique.md)

### 1.2.8 Abstract Dialectical Frameworks (ADF)
- **Contexte** : Les ADF g√©n√©ralisent les AAF de Dung en associant √† chaque argument une condition d'acceptation. Le module `arg.adf` de Tweety impl√©mente ce formalisme avanc√© o√π chaque argument est associ√© √† une formule propositionnelle (sa condition d'acceptation) qui d√©termine son statut en fonction de l'√©tat des autres arguments. Cette approche permet de mod√©liser des d√©pendances complexes comme le support, l'attaque conjointe, ou des combinaisons arbitraires de relations.
- **Objectifs** : Impl√©menter un agent utilisant le module `arg.adf` de Tweety. Les ADF g√©n√©ralisent les AAF de Dung en associant √† chaque argument une condition d'acceptation (une formule propositionnelle sur l'√©tat des autres arguments), permettant de mod√©liser des d√©pendances plus complexes que la simple attaque (ex: support, attaque conjointe).
- **Technologies cl√©s** :
  * Tweety `arg.adf`
  * Solveurs SAT incr√©mentaux
  * Formules propositionnelles
- **Niveau de difficult√©** : ‚≠ê‚≠ê‚≠ê‚≠ê
- **Estimation d'effort** : 4 semaines-personnes
- **Port√©e ajust√©e** : Se concentrer sur des ADF simples avec des conditions d'acceptation basiques
- **Interd√©pendances** : Extension de 1.2.1 (Dung), utilise 1.1.1 (logique propositionnelle)
- **R√©f√©rences** :
  - Article fondateur de Brewka et al. (2013) "Abstract Dialectical Frameworks"
  - "Implementing KR Approaches with Tweety" (2018)
  - Documentation Tweety `arg.adf`
- **Livrables attendus** :
  - Agent ADF
  - Int√©gration avec solveurs SAT incr√©mentaux
  - Visualisation des ADF
  - Documentation et exemples d'utilisation

> **Exemple de code**: Voir [Exemples TweetyProject par projet](./exemples_tweety_par_projet.md#122-frameworks-dialectiques-abstraits-adf) pour des snippets sur la cr√©ation d'ADF avec conditions d'acceptation personnalis√©es.

### 1.2.9 Analyse probabiliste d'arguments
- **Contexte** : L'argumentation probabiliste permet de g√©rer l'incertitude dans les frameworks d'argumentation. Le module `arg.prob` de Tweety impl√©mente l'approche de Li, Hunter et Thimm, o√π des probabilit√©s sont associ√©es aux arguments ou aux sous-ensembles d'arguments. Cette approche permet d'√©valuer la robustesse des conclusions face √† l'incertitude et de calculer des degr√©s de croyance dans l'acceptabilit√© des arguments.
- **Objectifs** : D√©velopper un agent utilisant le module `arg.prob` de Tweety pour analyser des arguments avec incertitude. Impl√©menter diff√©rentes distributions de probabilit√© sur les arguments, calculer des degr√©s d'acceptabilit√©, et visualiser l'impact de l'incertitude sur les conclusions argumentatives.
- **Technologies cl√©s** :
  * Tweety `arg.prob`
  * Distributions de probabilit√© sur les arguments
  * Calcul de degr√©s d'acceptabilit√©
  * Visualisation de l'incertitude argumentative
- **Niveau de difficult√©** : ‚≠ê‚≠ê‚≠ê
- **Estimation d'effort** : 4 semaines-personnes
- **Port√©e ajust√©e** : Se concentrer sur un mod√®le probabiliste simple avec visualisation basique
- **Interd√©pendances** : Extension de 1.2.1 (Dung AF) et 1.2.3 (Argumentation pond√©r√©e)
- **R√©f√©rences** :
  - "A Probabilistic Framework for Modelling Legal Argument" (2022)
  - "Probabilistic Argumentation: An Approach Based on a Conditional Logics" (2023)
  - "Handling Uncertainty in Argumentation Frameworks" (2022)
- **Livrables attendus** :
  - Agent d'argumentation probabiliste
  - Impl√©mentation de diff√©rentes distributions de probabilit√©
  - Visualisation des degr√©s d'acceptabilit√©
  - Documentation et exemples d'utilisation
  - Tests unitaires et d'int√©gration
## 1.3 Taxonomies et classification

### 1.3.1 Taxonomie des sch√©mas argumentatifs
- **Contexte** : Les sch√©mas argumentatifs sont des mod√®les r√©currents de raisonnement utilis√©s dans l'argumentation quotidienne.
- **Objectifs** : D√©velopper une taxonomie compl√®te des sch√©mas argumentatifs, en s'appuyant sur les travaux de Walton et d'autres chercheurs. Cette taxonomie devrait inclure les questions critiques associ√©es √† chaque sch√©ma et des exemples concrets.
- **Technologies cl√©s** :
  * Sch√©mas argumentatifs de Walton
  * Classification automatique de sch√©mas
  * Questions critiques associ√©es aux sch√©mas
- **Niveau de difficult√©** : ‚≠ê‚≠ê‚≠ê
- **Estimation d'effort** : 3-4 semaines-personnes
- **Port√©e ajust√©e** : Se concentrer sur un sous-ensemble de sch√©mas argumentatifs courants
- **Interd√©pendances** : Base pour 2.3.1 (extraction d'arguments)
- **R√©f√©rences** :
  - "Argumentation Schemes" de Walton, Reed & Macagno (√©dition mise √† jour, 2022)
  - "Automatic Identification of Argument Schemes" (2023)
  - "A Computational Model of Argument Schemes" (2022)
- **Livrables attendus** :
  - Taxonomie structur√©e des sch√©mas argumentatifs
  - Base de donn√©es d'exemples pour chaque sch√©ma
  - Module de classification automatique
  - Documentation et guide d'utilisation

### 1.3.2 Classification des sophismes
- **Contexte** : Les sophismes sont des erreurs de raisonnement qui peuvent sembler valides mais qui violent les principes de la logique.
- **Objectifs** : Enrichir et structurer la taxonomie des sophismes utilis√©e dans le projet, en int√©grant des classifications historiques et contemporaines. Cette taxonomie devrait inclure des d√©finitions pr√©cises, des exemples, et des m√©thodes de d√©tection pour chaque type de sophisme.
- **Technologies cl√©s** :
  * Taxonomies de sophismes
  * D√©tection automatique de sophismes
  * Apprentissage automatique pour la classification
- **Niveau de difficult√©** : ‚≠ê‚≠ê‚≠ê
- **Estimation d'effort** : 3-4 semaines-personnes
- **Port√©e ajust√©e** : Se concentrer sur une cat√©gorie sp√©cifique de sophismes
- **Interd√©pendances** : Base pour 2.3.2 (d√©tection de sophismes)
- **R√©f√©rences** :
  - "Fallacies: Classical and Contemporary Readings" (√©dition mise √† jour, 2022)
  - "Logical Fallacies: The Definitive Guide" (2023)
  - "Automated Detection of Fallacies in Arguments" (2022)
- **Livrables attendus** :
  - Taxonomie structur√©e des sophismes
  - Base de donn√©es d'exemples pour chaque sophisme
  - Module de d√©tection automatique
  - Documentation et guide d'utilisation

### 1.3.3 Ontologie de l'argumentation
- **Contexte** : Une ontologie formelle de l'argumentation permet de structurer et d'interconnecter les concepts li√©s √† l'analyse argumentative.
- **Objectifs** : D√©velopper une ontologie compl√®te de l'argumentation, int√©grant les diff√©rents frameworks, sch√©mas, et taxonomies. Cette ontologie devrait √™tre formalis√©e en OWL et permettre des inf√©rences sur les structures argumentatives.
- **Technologies cl√©s** :
  * Ontologies OWL
  * Prot√©g√©
  * Raisonneurs ontologiques
- **Niveau de difficult√©** : ‚≠ê‚≠ê‚≠ê
- **Estimation d'effort** : 4 semaines-personnes
- **Port√©e ajust√©e** : Se concentrer sur une ontologie simple couvrant les concepts de base
- **Interd√©pendances** : Int√®gre 1.1.4 (DL), 1.3.1 (sch√©mas), 1.3.2 (sophismes)
- **R√©f√©rences** :
  - "Building Ontologies with Basic Formal Ontology" (2022)
  - "The Argument Interchange Format" (2023)
  - "Ontological Foundations for Argumentation" (2022)
- **Livrables attendus** :
  - Ontologie OWL de l'argumentation
  - Documentation de l'ontologie
  - Exemples d'utilisation et de requ√™tes
  - Int√©gration avec les agents d'analyse argumentative
## 1.4 Maintenance de la v√©rit√© et r√©vision de croyances

### 1.4.1 Syst√®mes de maintenance de la v√©rit√© (TMS)
- **Contexte** : Les TMS permettent de g√©rer les d√©pendances entre croyances et de maintenir la coh√©rence lors de l'ajout ou du retrait d'informations.
- **Objectifs** : Impl√©menter un syst√®me de maintenance de la v√©rit√© pour g√©rer les d√©pendances entre arguments et assurer la coh√©rence des conclusions. Ce syst√®me devrait pouvoir g√©rer les justifications des croyances et propager les changements de mani√®re efficace.
- **Technologies cl√©s** :
  * JTMS (Justification-based TMS)
  * ATMS (Assumption-based TMS)
  * Graphes de d√©pendances
- **Niveau de difficult√©** : ‚≠ê‚≠ê‚≠ê
- **Estimation d'effort** : 4 semaines-personnes
- **Port√©e ajust√©e** : Se concentrer sur l'impl√©mentation d'un JTMS simple
- **Interd√©pendances** : Peut √™tre combin√© avec 1.1 (logiques formelles) et 1.2 (frameworks d'argumentation)
- **R√©f√©rences** :
  - "Building Problem Solvers" (√©dition mise √† jour, 2022)
  - "Truth Maintenance Systems: A New Perspective" (2023)
  - "Dependency-Directed Reasoning for Complex Knowledge Bases" (2022)
- **Livrables attendus** :
  - Impl√©mentation d'un TMS (JTMS ou ATMS)
  - Int√©gration avec l'√©tat partag√© du syst√®me
  - Documentation et exemples d'utilisation
  - Tests unitaires et d'int√©gration

> **üìñ Guide p√©dagogique d√©taill√©** : [1.4.1 Syst√®mes de Maintenance de la V√©rit√© (TMS)](./sujets/1.4.1_Systemes_Maintenance_Verite_TMS.md)

### 1.4.2 R√©vision de croyances
- **Contexte** : La r√©vision de croyances √©tudie comment mettre √† jour un ensemble de croyances de mani√®re coh√©rente face √† de nouvelles informations.
- **Objectifs** : D√©velopper des m√©canismes de r√©vision de croyances pour adapter les conclusions argumentatives face √† de nouvelles informations. Impl√©menter diff√©rents op√©rateurs de r√©vision et contraction bas√©s sur la th√©orie AGM.
- **Technologies cl√©s** :
  * AGM (Alchourr√≥n-G√§rdenfors-Makinson)
  * Op√©rateurs de r√©vision et contraction
  * Ordres √©pist√©miques
- **Niveau de difficult√©** : ‚≠ê‚≠ê‚≠ê
- **Estimation d'effort** : 4 semaines-personnes
- **Port√©e ajust√©e** : Se concentrer sur un op√©rateur de r√©vision simple
- **Interd√©pendances** : Li√© √† 1.4.1 (TMS) et 1.2 (frameworks d'argumentation)
- **R√©f√©rences** :
  - "Belief Revision" (G√§rdenfors, √©dition mise √† jour, 2022)
  - "Knowledge in Flux" (2023)
  - "Belief Change: A Computational Approach" (2022)
- **Livrables attendus** :
  - Impl√©mentation d'op√©rateurs de r√©vision et contraction
  - Int√©gration avec l'√©tat partag√© du syst√®me
  - Documentation et exemples d'utilisation
  - Tests unitaires et d'int√©gration

### 1.4.3 Raisonnement non-monotone
- **Contexte** : Le raisonnement non-monotone permet de tirer des conclusions provisoires qui peuvent √™tre r√©vis√©es √† la lumi√®re de nouvelles informations. Contrairement √† la logique classique o√π l'ajout d'informations pr√©serve les conclusions (monotonie), le raisonnement non-monotone permet de mod√©liser des situations o√π de nouvelles informations peuvent invalider des conclusions pr√©c√©dentes.
- **Objectifs** : Impl√©menter des m√©canismes de raisonnement non-monotone pour g√©rer l'incertitude et l'incompl√©tude dans l'analyse argumentative. Explorer diff√©rentes approches comme la logique par d√©faut, la circonscription, la logique auto√©pist√©mique, et les conditionnels non-monotones bas√©s sur les fonctions de classement (OCF).
- **Technologies cl√©s** :
  * Logique par d√©faut (Reiter)
  * Circonscription (McCarthy)
  * Logique auto√©pist√©mique (Moore)
  * Fonctions de classement (OCF) de Spohn
  * Module `logics.cl` de TweetyProject
- **Niveau de difficult√©** : ‚≠ê‚≠ê‚≠ê‚≠ê
- **Estimation d'effort** : 4 semaines-personnes
- **Port√©e ajust√©e** : Se concentrer sur une approche sp√©cifique (logique par d√©faut ou conditionnels)
- **Interd√©pendances** : Li√© √† 1.1 (logiques formelles), 1.1.6 (logique conditionnelle) et 1.4.2 (r√©vision de croyances)
- **R√©f√©rences** :
  - "Nonmonotonic Reasoning: Logical Foundations of Commonsense" (2022)
  - "Default Logic and Its Applications" (2023)
  - "Autoepistemic Logic and Its Applications" (2022)
  - "Ordinal conditional functions: a dynamic theory of epistemic states" de W. Spohn (1988)
  - "A Comparative Study of Nonmonotonic Inference Systems" de Brewka et al. (2019)
- **Livrables attendus** :
  - Impl√©mentation d'au moins une approche de raisonnement non-monotone
  - Comparaison des diff√©rentes approches sur des exemples classiques (Yale Shooting Problem, Nixon Diamond, etc.)
  - Visualisation des processus de raisonnement non-monotone
  - Int√©gration avec l'√©tat partag√© du syst√®me
  - Documentation et exemples d'utilisation
  - Tests unitaires et d'int√©gration

### 1.4.4 Mesures d'incoh√©rence et r√©solution
- **Contexte** : Quantifier et r√©soudre les incoh√©rences est crucial pour maintenir la qualit√© des bases de connaissances.
- **Objectifs** : Int√©grer les mesures d'incoh√©rence de Tweety (`logics.pl.analysis`) pour quantifier le degr√© d'incoh√©rence d'un ensemble d'informations, et impl√©menter des m√©thodes de r√©solution comme l'√©num√©ration de MUS (Minimal Unsatisfiable Subsets) et MaxSAT.
- **Technologies cl√©s** :
  * Tweety `logics.pl.analysis`
  * MUS (Minimal Unsatisfiable Subsets)
  * MaxSAT
- **Niveau de difficult√©** : ‚≠ê‚≠ê‚≠ê‚≠ê
- **Estimation d'effort** : 4 semaines-personnes
- **Port√©e ajust√©e** : Se concentrer sur l'impl√©mentation d'une mesure d'incoh√©rence simple
- **Interd√©pendances** : Utilise 1.1.1 (logique propositionnelle), li√© √† 1.4.1 (maintenance de la v√©rit√©)
- **R√©f√©rences** :
  - Survey de Hunter et Konieczny sur les mesures d'incoh√©rence
  - "Reasoning-with-probabilistic-and-deterministic-graphical-models-exact-algorithms" (2013)
  - "SAT_SMT_by_example.pdf" (2023)
- **Livrables attendus** :
  - Impl√©mentation de plusieurs mesures d'incoh√©rence
  - Algorithmes d'√©num√©ration de MUS
  - R√©solution d'incoh√©rences via MaxSAT
  - Documentation et exemples d'utilisation

> **Exemple de code**: Voir [Exemples TweetyProject par projet](./exemples_tweety_par_projet.md#144-mesures-dincoh√©rence-et-r√©solution) pour des snippets sur l'utilisation de mesures d'incoh√©rence et l'√©num√©ration de MUS.

### 1.4.5 R√©vision de croyances multi-agents
- **Contexte** : La r√©vision de croyances multi-agents √©tudie comment plusieurs agents peuvent mettre √† jour leurs croyances de mani√®re coh√©rente face √† de nouvelles informations, potentiellement contradictoires. Le module `beliefdynamics` de Tweety fournit des outils pour mod√©liser ce processus, en permettant de repr√©senter les croyances de diff√©rents agents et de simuler leur √©volution au fil du temps et des interactions.
- **Objectifs** : D√©velopper un syst√®me de r√©vision de croyances multi-agents bas√© sur le module `beliefdynamics` de Tweety. Impl√©menter diff√©rentes strat√©gies de r√©vision (cr√©dulit√©, scepticisme, consensus) et analyser leur impact sur la convergence des croyances dans un groupe d'agents.
- **Technologies cl√©s** :
  * Tweety `beliefdynamics`
  * Strat√©gies de r√©vision multi-agents
  * Mod√®les de confiance entre agents
  * Visualisation de l'√©volution des croyances
- **Niveau de difficult√©** : ‚≠ê‚≠ê‚≠ê
- **Estimation d'effort** : 4 semaines-personnes
- **Port√©e ajust√©e** : Se concentrer sur un sc√©nario simple avec deux agents
- **Interd√©pendances** : Li√© √† 1.4.2 (R√©vision de croyances) et 2.1.6 (Gouvernance multi-agents)
- **R√©f√©rences** :
  - "Belief Revision in Multi-Agent Systems" (2022)
  - "Social Choice Theory and Belief Merging" (2023)
  - "Trust-Based Belief Revision in Multi-Agent Settings" (2022)
- **Livrables attendus** :
  - Syst√®me de r√©vision de croyances multi-agents
  - Impl√©mentation de diff√©rentes strat√©gies de r√©vision
  - Visualisation de l'√©volution des croyances
  - Documentation et exemples d'utilisation

> **Exemple de code**: Voir [Exemples TweetyProject par projet](./exemples_tweety_par_projet.md#145-r√©vision-de-croyances-multi-agents) pour des snippets sur la cr√©ation de bases de croyances multi-agents et l'application d'op√©rateurs de r√©vision.
## 1.5 Planification et v√©rification formelle

### 1.5.1 Int√©gration d'un planificateur symbolique
- **Contexte** : La planification automatique permet de g√©n√©rer des s√©quences d'actions pour atteindre des objectifs.
- **Objectifs** : D√©velopper un agent capable de g√©n√©rer des plans d'action bas√©s sur des objectifs argumentatifs, en explorant le module `action` de Tweety pour la mod√©lisation des actions et la planification. Cet agent pourrait g√©n√©rer des plans pour atteindre des objectifs comme "faire accepter un argument sp√©cifique" ou "r√©futer un ensemble d'arguments adverses".
- **Technologies cl√©s** :
  * Tweety `action`
  * Planification automatique
  * PDDL (Planning Domain Definition Language)
- **Niveau de difficult√©** : ‚≠ê‚≠ê‚≠ê
- **Estimation d'effort** : 4 semaines-personnes
- **Port√©e ajust√©e** : Se concentrer sur un domaine de planification simple
- **Interd√©pendances** : Peut utiliser 1.1.5 (QBF) pour la planification conditionnelle
- **R√©f√©rences** :
  - "Automated planning" (2010)
  - "Automated planning and acting - book" (2016)
  - "Integrated Task and motion planning" (2020)
- **Livrables attendus** :
  - Agent de planification symbolique
  - Mod√©lisation PDDL des domaines argumentatifs
  - Documentation et exemples d'utilisation
  - Tests unitaires et d'int√©gration

### 1.5.2 V√©rification formelle d'arguments
- **Contexte** : La v√©rification formelle permet de garantir que les arguments respectent certaines propri√©t√©s.
- **Objectifs** : D√©velopper des m√©thodes de v√©rification formelle pour garantir la validit√© des arguments dans un contexte contractuel, en utilisant potentiellement les capacit√©s QBF ou FOL de Tweety. L'objectif est d'assurer que les arguments utilis√©s dans un contrat respectent certaines propri√©t√©s formelles (coh√©rence, non-circularit√©, etc.) avant leur ex√©cution.
- **Technologies cl√©s** :
  * V√©rification formelle
  * Model checking
  * Prouveurs de th√©or√®mes
- **Niveau de difficult√©** : ‚≠ê‚≠ê‚≠ê‚≠ê
- **Estimation d'effort** : 4 semaines-personnes
- **Port√©e ajust√©e** : Se concentrer sur la v√©rification de propri√©t√©s simples
- **Interd√©pendances** : Utilise 1.1.1-1.1.5 (logiques formelles), li√© √† 1.5.3 (contrats argumentatifs)
- **R√©f√©rences** :
  - "The Lean theorem prover" (2015)
  - "The Lean 4 Theorem Prover and Programming Language" (2021)
  - "SAT_SMT_by_example.pdf" (2023)
- **Livrables attendus** :
  - M√©thodes de v√©rification formelle pour arguments
  - Int√©gration avec au moins un prouveur de th√©or√®mes
  - Documentation et exemples d'utilisation
  - Cas d'√©tude d√©montrant l'application √† un probl√®me concret

### 1.5.3 Formalisation de contrats argumentatifs
- **Contexte** : Les smart contracts peuvent √™tre utilis√©s pour formaliser et ex√©cuter des protocoles d'argumentation.
- **Objectifs** : Explorer l'utilisation de smart contracts pour formaliser et ex√©cuter des protocoles d'argumentation, en s'appuyant sur les diff√©rents formalismes d'argumentation disponibles dans Tweety. Cette approche permettrait d'automatiser l'ex√©cution de d√©bats structur√©s ou de processus de r√©solution de conflits selon des r√®gles pr√©d√©finies et v√©rifiables.
- **Technologies cl√©s** :
  * Smart contracts
  * Blockchain
  * Protocoles d'argumentation
- **Niveau de difficult√©** : ‚≠ê‚≠ê‚≠ê
- **Estimation d'effort** : 4 semaines-personnes
- **Port√©e ajust√©e** : Se concentrer sur un protocole d'argumentation simple
- **Interd√©pendances** : Li√© √† 1.2 (frameworks d'argumentation) et 1.5.2 (v√©rification formelle)
- **R√©f√©rences** :
  - "Bitcoin and Beyond - Cryptocurrencies, blockchain and global governance" (2018)
  - "Survey on blockchain based smart contracts - Applications, opportunities and challenges" (2021)
  - Documentation sur les plateformes de smart contracts (Ethereum, etc.)
- **Livrables attendus** :
  - Mod√®les de contrats argumentatifs
  - Impl√©mentation d'au moins un protocole d'argumentation
  - Documentation et exemples d'utilisation
  - D√©monstration d'ex√©cution sur une blockchain de test