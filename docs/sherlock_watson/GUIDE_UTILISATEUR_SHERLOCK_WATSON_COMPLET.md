# ğŸ“ GUIDE UTILISATEUR COMPLET - SYSTÃˆME SHERLOCK/WATSON/MORIARTY
## Manuel d'Utilisation DÃ©taillÃ© et Cas d'Usage AvancÃ©s

**Guide Utilisateur Version 2.1.0**  
**Date** : 10/06/2025  
**Niveau** : DÃ©butant Ã  AvancÃ©  

---

## ğŸ“‹ **SOMMAIRE**

1. [ğŸš€ DÃ©marrage Rapide](#-dÃ©marrage-rapide)
2. [ğŸ¯ Configuration DÃ©taillÃ©e](#-configuration-dÃ©taillÃ©e)
3. [ğŸ­ Utilisation des DÃ©monstrations](#-utilisation-des-dÃ©monstrations)
4. [ğŸ”§ Personnalisation AvancÃ©e](#-personnalisation-avancÃ©e)
5. [ğŸ› ï¸ RÃ©solution de ProblÃ¨mes](#ï¸-rÃ©solution-de-problÃ¨mes)
6. [ğŸ“Š MÃ©triques et Analyse](#-mÃ©triques-et-analyse)
7. [ğŸ“ Cas d'Usage PÃ©dagogiques](#-cas-dusage-pÃ©dagogiques)

---

## ğŸš€ **DÃ‰MARRAGE RAPIDE**

### âš¡ **Installation Express (5 minutes)**

```bash
# 1. Clonage du projet
git clone https://github.com/votre-repo/2025-Epita-Intelligence-Symbolique.git
cd 2025-Epita-Intelligence-Symbolique

# 2. Environnement Python avec Conda (RECOMMANDÃ‰)
conda create --name projet-is python=3.9.18
conda activate projet-is

# 3. Installation des dÃ©pendances
pip install -r requirements.txt

# 4. VÃ©rification Java (requis pour TweetyProject)
java -version
# Sortie attendue: openjdk version "1.8.0_XXX" ou supÃ©rieur
```

### ğŸ”‘ **Configuration API Minimale**

```bash
# CrÃ©ation fichier .env avec vos clÃ©s API
cat > .env << EOF
# Configuration OpenRouter (RECOMMANDÃ‰ - moins cher)
OPENROUTER_API_KEY=sk-or-v1-votre-clÃ©-openrouter-ici
OPENROUTER_BASE_URL=https://openrouter.ai/api/v1
OPENROUTER_MODEL=gpt-4o-mini

# Alternative OpenAI (plus cher mais directe)
OPENAI_API_KEY=sk-votre-clÃ©-openai-ici
EOF
```

### âœ… **Test de Validation ImmÃ©diat**

```bash
# Test rapide du systÃ¨me (2 minutes)
python examples/Sherlock_Watson/sherlock_watson_authentic_demo.py

# Sortie attendue:
# ğŸš€ LANCEMENT CONVERSATION SHERLOCK-WATSON AUTHENTIQUE
# âœ… JVM TweetyProject initialisÃ©e (35+ JARs chargÃ©s)
# âœ… Service LLM configurÃ© (gpt-4o-mini)
# ğŸ­ Sherlock: "Excellente observation, Watson..."
# ğŸ§  Watson: "En effet Holmes, l'analyse logique rÃ©vÃ¨le..."
```

---

## ğŸ¯ **CONFIGURATION DÃ‰TAILLÃ‰E**

### ğŸ **Environnement Python Optimal**

#### **Option A: Conda (RECOMMANDÃ‰ - Plus Stable)**
```bash
# Installation Conda si nÃ©cessaire
wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh
bash Miniconda3-latest-Linux-x86_64.sh

# CrÃ©ation environnement optimisÃ©
conda create --name projet-is python=3.9.18 pip
conda activate projet-is

# Installation packages critiques via conda
conda install numpy=1.24.3 pandas=2.0.3 -c conda-forge

# Installation semantic-kernel via pip
pip install semantic-kernel>=1.29.0
pip install -r requirements.txt
```

#### **Option B: venv (Alternative)**
```bash
# CrÃ©ation environnement virtuel
python3.9 -m venv venv-projet-is
source venv-projet-is/bin/activate  # Linux/Mac
# ou
venv-projet-is\Scripts\activate     # Windows

# Installation complÃ¨te
pip install --upgrade pip
pip install -r requirements.txt
```

### â˜• **Configuration Java pour TweetyProject**

#### **VÃ©rification Installation Java**
```bash
# Test Java prÃ©sent
java -version
javac -version

# Si Java absent (Ubuntu/Debian)
sudo apt update
sudo apt install openjdk-8-jdk

# Si Java absent (CentOS/RHEL)
sudo yum install java-1.8.0-openjdk-devel

# Si Java absent (Windows)
# TÃ©lÃ©charger depuis: https://adoptopenjdk.net/
```

#### **Configuration Variables Environnement**
```bash
# Linux/Mac - Ajout Ã  ~/.bashrc ou ~/.zshrc
export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64
export PATH=$JAVA_HOME/bin:$PATH
export CLASSPATH=$JAVA_HOME/lib:$CLASSPATH

# Windows - Variables systÃ¨me
set JAVA_HOME=C:\Program Files\Java\jdk1.8.0_XXX
set PATH=%JAVA_HOME%\bin;%PATH%

# VÃ©rification configuration
echo $JAVA_HOME  # Doit afficher chemin Java
which java       # Doit trouver exÃ©cutable
```

### ğŸ” **Configuration APIs et Services**

#### **OpenRouter (RECOMMANDÃ‰ - Ã‰conomique)**
```bash
# 1. CrÃ©ation compte sur https://openrouter.ai
# 2. GÃ©nÃ©ration clÃ© API dans Settings > API Keys
# 3. Ajout crÃ©dits: $5 suffit pour exploration complÃ¨te

# Configuration .env
cat >> .env << EOF
OPENROUTER_API_KEY=sk-or-v1-votre-vraie-clÃ©-ici
OPENROUTER_BASE_URL=https://openrouter.ai/api/v1
OPENROUTER_MODEL=gpt-4o-mini

# ModÃ¨les alternatifs disponibles
# OPENROUTER_MODEL=claude-3-haiku-20240307
# OPENROUTER_MODEL=gpt-3.5-turbo
EOF
```

#### **OpenAI (Alternative Directe)**
```bash
# 1. CrÃ©ation compte sur https://platform.openai.com
# 2. GÃ©nÃ©ration clÃ© API dans API keys
# 3. Ajout crÃ©dits: $10 recommandÃ©

# Configuration .env  
cat >> .env << EOF
OPENAI_API_KEY=sk-votre-vraie-clÃ©-openai-ici
OPENAI_ORG_ID=org-votre-organisation-id    # Optionnel
EOF
```

#### **Test Configuration API**
```python
# Script de test API (test_api_config.py)
import os
from dotenv import load_dotenv
import openai

load_dotenv()

# Test OpenRouter
if os.getenv("OPENROUTER_API_KEY"):
    openai.api_key = os.getenv("OPENROUTER_API_KEY")
    openai.api_base = os.getenv("OPENROUTER_BASE_URL")
    
    try:
        response = openai.ChatCompletion.create(
            model="gpt-4o-mini",
            messages=[{"role": "user", "content": "Test connection"}],
            max_tokens=10
        )
        print("âœ… OpenRouter: Connexion rÃ©ussie")
    except Exception as e:
        print(f"âŒ OpenRouter: Erreur - {e}")

# Test OpenAI
elif os.getenv("OPENAI_API_KEY"):
    openai.api_key = os.getenv("OPENAI_API_KEY")
    
    try:
        response = openai.ChatCompletion.create(
            model="gpt-3.5-turbo",
            messages=[{"role": "user", "content": "Test connection"}],
            max_tokens=10
        )
        print("âœ… OpenAI: Connexion rÃ©ussie")
    except Exception as e:
        print(f"âŒ OpenAI: Erreur - {e}")
else:
    print("âŒ Aucune clÃ© API configurÃ©e")
```

---

## ğŸ­ **UTILISATION DES DÃ‰MONSTRATIONS**

### ğŸ•µï¸ **DÃ©mo 1: Conversation Sherlock-Watson Authentique**

#### **Objectif et Contexte**
Cette dÃ©monstration met en scÃ¨ne une conversation naturelle entre Sherlock Holmes et Dr Watson utilisant l'orchestrateur `CluedoExtendedOrchestrator` sans aucune simulation.

#### **ExÃ©cution Standard**
```bash
# Lancement simple
python examples/Sherlock_Watson/sherlock_watson_authentic_demo.py

# Avec logs dÃ©taillÃ©s
python examples/Sherlock_Watson/sherlock_watson_authentic_demo.py --verbose

# Avec sauvegarde personnalisÃ©e
python examples/Sherlock_Watson/sherlock_watson_authentic_demo.py --output ./mon_trace.json
```

#### **ParamÃ¨tres Configurables**
```python
# Configuration dans le script (ligne ~50)
ORCHESTRATION_CONFIG = {
    "max_iterations": 10,        # Nombre max tours conversation
    "temperature": 0.7,          # CrÃ©ativitÃ© LLM (0.1-1.0)
    "response_length": 150,      # Longueur max rÃ©ponses
    "personality_strength": 0.8, # Force personnalitÃ©s (0.1-1.0)
}
```

#### **InterprÃ©tation des RÃ©sultats**
```json
{
  "session_id": "sherlock_watson_20250610_040000",
  "total_messages": 7,
  "participants": ["Sherlock", "Watson"],
  "metrics": {
    "naturalness_score": 8.5,
    "personality_distinctiveness": 7.8,
    "conversation_flow": 8.2
  },
  "conversation": [
    {
      "agent": "Sherlock",
      "content": "Watson, observez ces indices curieux...",
      "timestamp": "2025-06-10T04:00:15.123Z",
      "analysis": {
        "personality_markers": ["observez", "curieux"],
        "leadership_indicators": true,
        "deductive_reasoning": true
      }
    }
  ]
}
```

### ğŸ² **DÃ©mo 2: Oracle Cluedo Complet**

#### **Validation Exhaustive du SystÃ¨me**
Cette dÃ©monstration exÃ©cute les 157 tests de validation du systÃ¨me Oracle sans aucune simulation.

#### **ExÃ©cution et Options**
```bash
# Test complet standard
python examples/Sherlock_Watson/cluedo_oracle_complete.py

# Test avec rapport dÃ©taillÃ©
python examples/Sherlock_Watson/cluedo_oracle_complete.py --detailed-report

# Test avec vÃ©rification intÃ©gritÃ© renforcÃ©e
python examples/Sherlock_Watson/cluedo_oracle_complete.py --strict-integrity

# Test performance (chronomÃ©trage)
python examples/Sherlock_Watson/cluedo_oracle_complete.py --benchmark
```

#### **MÃ©triques de Validation**
```bash
# RÃ©sultats attendus
âœ… Tests Oracle: 157/157 rÃ©ussis (100%)
âœ… Modules validÃ©s: 8/8
â”œâ”€â”€ Oracle Dataset: âœ… OpÃ©rationnel
â”œâ”€â”€ Permission Manager: âœ… SÃ©curisÃ©  
â”œâ”€â”€ Integrity Monitor: âœ… Actif
â”œâ”€â”€ Card Revelation System: âœ… ContrÃ´lÃ©
â”œâ”€â”€ Solution Validation: âœ… Fonctionnel
â”œâ”€â”€ Agent Access Control: âœ… RenforcÃ©
â”œâ”€â”€ Anti-Cheat System: âœ… ActivÃ©
â””â”€â”€ Performance Cache: âœ… OptimisÃ©

âœ… Temps total: 12.4 secondes
âœ… MÃ©moire utilisÃ©e: 245 MB
âœ… Violations dÃ©tectÃ©es: 0
```

### ğŸ¤– **DÃ©mo 3: Agents Logiques Production**

#### **Validation TweetyProject et Logique Formelle**
DÃ©monstration des capacitÃ©s logiques avancÃ©es avec `CustomDataProcessor` authentique.

#### **PrÃ©requis SpÃ©cifiques**
```bash
# VÃ©rification TweetyProject ready
ls libs/tweety/*.jar | wc -l  # Doit afficher 35+

# Test rapide JVM
python -c "
import jpype
print('JPype version:', jpype.__version__)
try:
    jpype.startJVM()
    print('âœ… JVM dÃ©marrage OK')
    jpype.shutdownJVM()
except Exception as e:
    print('âŒ Erreur JVM:', e)
"
```

#### **ExÃ©cution AvancÃ©e**
```bash
# Standard avec logique propositionnelle
python examples/Sherlock_Watson/agents_logiques_production.py

# Avec logique FOL (First-Order Logic)
python examples/Sherlock_Watson/agents_logiques_production.py --logic-type fol

# Avec validation contraintes complexes
python examples/Sherlock_Watson/agents_logiques_production.py --complex-constraints

# Mode debug avec traces TweetyProject
python examples/Sherlock_Watson/agents_logiques_production.py --debug-tweety
```

#### **Validation des Sorties**
```bash
# Sortie attendue dÃ©taillÃ©e
ğŸš€ LANCEMENT AGENTS LOGIQUES PRODUCTION
âœ… JVM TweetyProject prÃªte (35+ JARs chargÃ©s)
ğŸ“Š MÃ©moire JVM allouÃ©e: 512 MB
ğŸ§  Watson: Activation TweetyProject Bridge
ğŸ” Chargement classes critiques:
  â”œâ”€â”€ PlParser: âœ… org.tweetyproject.logics.pl.parser.PlParser
  â”œâ”€â”€ PlBeliefSet: âœ… org.tweetyproject.logics.pl.syntax.PlBeliefSet
  â”œâ”€â”€ Sat4jSolver: âœ… org.tweetyproject.logics.pl.sat.Sat4jSolver
  â””â”€â”€ FolParser: âœ… org.tweetyproject.logics.fol.parser.FolParser

ğŸ§® Test logique propositionnelle:
  Formule: "(a && b) || c"
  RÃ©sultat: âœ… Consistante
  Temps: 0.15s

ğŸ¯ CustomDataProcessor actif:
  Source: DonnÃ©es rÃ©elles (non simulÃ©es)
  Processeur: Authentique sans mocks
  Validation: 100% opÃ©rationnel
```

### ğŸ¼ **DÃ©mo 4: Orchestration Finale RÃ©elle**

#### **DÃ©monstration ComplÃ¨te du SystÃ¨me**
Script d'orchestration le plus avancÃ© intÃ©grant tous les composants avec Semantic Kernel.

#### **Configuration AvancÃ©e**
```python
# Configuration orchestration (editable dans le script)
ADVANCED_CONFIG = {
    "orchestration_strategy": "balanced_participation",
    "termination_strategy": "intelligent_conclusion",
    "max_agents_active": 3,
    "conversation_depth": "deep",         # shallow, medium, deep
    "logic_validation_level": "strict",   # loose, moderate, strict
    "personality_emphasis": "high",       # low, medium, high
    "performance_monitoring": True,
}
```

#### **Modes d'ExÃ©cution**
```bash
# Mode standard (recommandÃ©)
python examples/Sherlock_Watson/orchestration_finale_reelle.py

# Mode investigation complexe
python examples/Sherlock_Watson/orchestration_finale_reelle.py --mode complex

# Mode pÃ©dagogique avec explications
python examples/Sherlock_Watson/orchestration_finale_reelle.py --pedagogical

# Mode benchmark performance
python examples/Sherlock_Watson/orchestration_finale_reelle.py --benchmark

# Mode custom avec configuration
python examples/Sherlock_Watson/orchestration_finale_reelle.py --config custom_config.json
```

#### **Analyse des RÃ©sultats Complets**
```json
{
  "orchestration_session": {
    "session_id": "orch_finale_20250610_040000",
    "duration_seconds": 45.8,
    "total_cycles": 6,
    "agents_participated": 3,
    "resolution_achieved": true
  },
  "agent_performance": {
    "Sherlock": {
      "turns": 3,
      "avg_response_time": 2.1,
      "leadership_score": 8.7,
      "deduction_quality": 8.5
    },
    "Watson": {
      "turns": 2,
      "avg_response_time": 3.2,
      "logic_validation_score": 9.1,
      "tweety_queries": 4
    },
    "Moriarty": {
      "turns": 1,
      "avg_response_time": 1.8,
      "revelation_strategy": "progressive",
      "oracle_accuracy": 100
    }
  },
  "system_metrics": {
    "semantic_kernel_health": "excellent",
    "memory_usage_mb": 387,
    "api_calls_total": 12,
    "api_cost_estimated": "$0.08"
  }
}
```

---

## ğŸ”§ **PERSONNALISATION AVANCÃ‰E**

### ğŸ¨ **Modification des PersonnalitÃ©s d'Agents**

#### **Sherlock Holmes - Personnalisation**
```python
# Fichier: custom_personalities.py
SHERLOCK_CUSTOM_INSTRUCTIONS = """
Vous Ãªtes Sherlock Holmes avec les modifications suivantes:

STYLE MODIFIÃ‰:
- Plus collaboratif et moins autoritaire
- Explication dÃ©taillÃ©e de vos dÃ©ductions
- Encouragement actif des autres agents

SPÃ‰CIALISATIONS AJOUTÃ‰ES:
- Expertise en criminologie moderne
- Connaissance technologies actuelles
- Approche psychologique des suspects

CONTRAINTES SPÃ‰CIALES:
- Toujours demander confirmation Ã  Watson avant conclusion
- Partager systÃ©matiquement votre raisonnement
- Ã‰viter les accusations directes sans preuves
"""

# Application dans le code
sherlock_agent = SherlockEnqueteAgent(
    kernel=kernel,
    agent_name="Sherlock_Custom",
    service_id="openai_chat",
    instructions=SHERLOCK_CUSTOM_INSTRUCTIONS
)
```

#### **Watson - SpÃ©cialisation Logique**
```python
WATSON_ENHANCED_INSTRUCTIONS = """
Vous Ãªtes Dr Watson avec spÃ©cialisations techniques:

EXPERTISE RENFORCÃ‰E:
- MaÃ®trise logique formelle (TweetyProject expert)
- Analyse statistique et probabiliste
- Validation scientifique rigoureuse

COMPORTEMENT MODIFIÃ‰:
- Propositions proactives d'analyses
- Questions techniques pertinentes
- SynthÃ¨ses logiques structurÃ©es

OUTILS PRIVILÃ‰GIÃ‰S:
- Validation systÃ©matique via TweetyProject
- Calculs de probabilitÃ©s
- VÃ©rification cohÃ©rence logique
"""
```

### ğŸ”® **Extension du SystÃ¨me Oracle**

#### **Nouveau Dataset PersonnalisÃ©**
```python
# CrÃ©ation dataset custom
class CustomOracleDataset:
    """Oracle personnalisÃ© pour Ã©nigmes spÃ©cialisÃ©es"""
    
    def __init__(self, domain: str):
        self.domain = domain
        self.custom_data = self._load_domain_data(domain)
        
    def _load_domain_data(self, domain: str) -> Dict:
        """Chargement donnÃ©es spÃ©cialisÃ©es par domaine"""
        datasets = {
            "histoire": self._load_historical_mysteries(),
            "science": self._load_scientific_puzzles(),
            "litterature": self._load_literary_enigmas(),
            "mathematiques": self._load_math_problems()
        }
        return datasets.get(domain, {})
    
    def _load_historical_mysteries(self) -> Dict:
        """MystÃ¨res historiques authentiques"""
        return {
            "jack_the_ripper": {
                "suspects": ["Montague Druitt", "Aaron Kosminski", "Thomas Cutbush"],
                "indices": ["Lettre Dear Boss", "Graffiti Goulston Street", "TÃ©moignages"],
                "lieux": ["Whitechapel", "Spitalfields", "Mile End"]
            },
            "anastasia_romanov": {
                "prÃ©tendantes": ["Anna Anderson", "Eugenia Smith", "Nadezhda Vasilyeva"],
                "preuves": ["ADN", "Cicatrices", "Langues parlÃ©es"],
                "contexte": ["RÃ©volution russe", "Massacre Ekaterinbourg", "Exil"]
            }
        }
```

#### **StratÃ©gies de RÃ©vÃ©lation PersonnalisÃ©es**
```python
class ProgressiveHintStrategy:
    """StratÃ©gie de rÃ©vÃ©lation d'indices progressive personnalisable"""
    
    def __init__(self, difficulty_level: str = "medium"):
        self.difficulty = difficulty_level
        self.hint_schedule = self._calculate_hint_schedule()
        
    def _calculate_hint_schedule(self) -> List[Dict]:
        """Calcul planning rÃ©vÃ©lations selon difficultÃ©"""
        schedules = {
            "easy": [
                {"turn": 2, "type": "direct_clue", "strength": 0.8},
                {"turn": 4, "type": "elimination", "strength": 0.9},
                {"turn": 6, "type": "confirmation", "strength": 1.0}
            ],
            "medium": [
                {"turn": 3, "type": "indirect_clue", "strength": 0.6},
                {"turn": 6, "type": "partial_elimination", "strength": 0.7},
                {"turn": 9, "type": "directed_hint", "strength": 0.8}
            ],
            "hard": [
                {"turn": 5, "type": "subtle_hint", "strength": 0.4},
                {"turn": 10, "type": "contradiction", "strength": 0.6},
                {"turn": 15, "type": "final_nudge", "strength": 0.7}
            ]
        }
        return schedules.get(self.difficulty, schedules["medium"])
```

### âš™ï¸ **Configuration des StratÃ©gies d'Orchestration**

#### **StratÃ©gie de SÃ©lection PersonnalisÃ©e**
```python
class ExpertiseBasedSelectionStrategy(SelectionStrategy):
    """SÃ©lection agent basÃ©e sur expertise contextuelle"""
    
    def __init__(self):
        self.expertise_map = {
            "logical_reasoning": ["Watson"],
            "deductive_investigation": ["Sherlock"], 
            "information_revelation": ["Moriarty"],
            "collaborative_analysis": ["Sherlock", "Watson"],
            "contradiction_resolution": ["Watson", "Moriarty"]
        }
        
    async def next(self, agents: List[Agent], history: List[ChatMessage]) -> Agent:
        # Analyse contexte rÃ©cent
        recent_context = self._analyze_recent_context(history[-3:])
        
        # Identification expertise requise
        required_expertise = self._identify_required_expertise(recent_context)
        
        # SÃ©lection agent optimal
        suitable_agents = self.expertise_map.get(required_expertise, agents)
        
        return self._select_least_recently_used(suitable_agents, history)
```

---

## ğŸ› ï¸ **RÃ‰SOLUTION DE PROBLÃˆMES**

### âŒ **Erreurs FrÃ©quentes et Solutions DÃ©taillÃ©es**

#### **Erreur 1: JPype/TweetyProject Initialization**
```bash
# SYMPTÃ”ME
JPypeException: Unable to start JVM: No such file or directory

# DIAGNOSTIC
python -c "
import jpype
print('JPype Path:', jpype.getDefaultJVMPath())
import os
print('JAVA_HOME:', os.getenv('JAVA_HOME'))
"

# SOLUTIONS
# Solution 1: Java non installÃ©
sudo apt install openjdk-8-jdk  # Ubuntu/Debian
brew install openjdk@8          # macOS

# Solution 2: JAVA_HOME incorrect
export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64
export PATH=$JAVA_HOME/bin:$PATH

# Solution 3: Version Java incompatible
java -version  # Doit Ãªtre 1.8+ (Java 8+)
```

#### **Erreur 2: Semantic Kernel Module**
```bash
# SYMPTÃ”ME
ImportError: No module named 'semantic_kernel'

# DIAGNOSTIC
pip list | grep semantic

# SOLUTIONS
# Solution 1: Installation manquante
pip install semantic-kernel>=1.29.0

# Solution 2: Environnement incorrect
conda activate projet-is  # VÃ©rifier activation
which python              # VÃ©rifier environnement

# Solution 3: Version incompatible
pip install --upgrade semantic-kernel
pip list | grep semantic  # VÃ©rifier version >=1.29.0
```

#### **Erreur 3: API Authentication**
```bash
# SYMPTÃ”ME
openai.AuthenticationError: Invalid API key

# DIAGNOSTIC
cat .env | grep API_KEY
python -c "
import os
from dotenv import load_dotenv
load_dotenv()
print('OpenRouter Key:', os.getenv('OPENROUTER_API_KEY')[:10] + '...')
print('OpenAI Key:', os.getenv('OPENAI_API_KEY')[:10] + '...')
"

# SOLUTIONS
# Solution 1: ClÃ© API absente/incorrecte
# - VÃ©rifier .env existe et contient clÃ©
# - RÃ©gÃ©nÃ©rer clÃ© sur openrouter.ai ou platform.openai.com

# Solution 2: Permissions insuffisantes
# - VÃ©rifier crÃ©dits disponibles sur le compte
# - VÃ©rifier limites d'usage non dÃ©passÃ©es

# Solution 3: Configuration proxy/firewall
# - Tester connexion: curl https://openrouter.ai/api/v1/models
# - Configurer proxy si nÃ©cessaire
```

### ğŸ” **Debugging AvancÃ©**

#### **Mode Debug Complet**
```python
# Script de debug (debug_system.py)
import logging
import sys
import traceback
from pathlib import Path

# Configuration logging dÃ©taillÃ©
logging.basicConfig(
    level=logging.DEBUG,
    format='%(asctime)s [%(levelname)s] %(name)s: %(message)s',
    handlers=[
        logging.StreamHandler(sys.stdout),
        logging.FileHandler('debug_system.log')
    ]
)

def debug_system_components():
    """Diagnostic complet des composants systÃ¨me"""
    
    print("ğŸ” DIAGNOSTIC SYSTÃˆME COMPLET")
    print("=" * 50)
    
    # 1. Environnement Python
    print(f"Python: {sys.version}")
    print(f"Plateforme: {sys.platform}")
    
    # 2. Modules critiques
    critical_modules = [
        'semantic_kernel', 'jpype', 'openai', 
        'numpy', 'pandas', 'dotenv'
    ]
    
    for module in critical_modules:
        try:
            mod = __import__(module)
            version = getattr(mod, '__version__', 'Unknown')
            print(f"âœ… {module}: {version}")
        except ImportError as e:
            print(f"âŒ {module}: Non installÃ© - {e}")
    
    # 3. Configuration environnement
    from dotenv import load_dotenv
    load_dotenv()
    
    env_vars = [
        'JAVA_HOME', 'OPENROUTER_API_KEY', 'OPENAI_API_KEY'
    ]
    
    for var in env_vars:
        value = os.getenv(var)
        if value:
            masked = value[:10] + "..." if len(value) > 10 else value
            print(f"âœ… {var}: {masked}")
        else:
            print(f"âŒ {var}: Non dÃ©fini")
    
    # 4. TweetyProject JARs
    tweety_dir = Path("libs/tweety")
    if tweety_dir.exists():
        jars = list(tweety_dir.glob("*.jar"))
        print(f"âœ… TweetyProject JARs: {len(jars)} trouvÃ©s")
    else:
        print("âŒ TweetyProject JARs: Dossier libs/tweety non trouvÃ©")
    
    # 5. Test JVM
    try:
        import jpype
        jpype.startJVM()
        print("âœ… JVM: DÃ©marrage rÃ©ussi")
        jpype.shutdownJVM()
    except Exception as e:
        print(f"âŒ JVM: Erreur - {e}")

if __name__ == "__main__":
    debug_system_components()
```

#### **Profiling Performance**
```python
# Script profiling (profile_performance.py)
import time
import psutil
import cProfile
import pstats
from memory_profiler import profile

@profile
def profile_orchestration():
    """Profiling mÃ©moire orchestration"""
    # Import avec timing
    start_time = time.time()
    
    from examples.Sherlock_Watson.orchestration_finale_reelle import main
    import_time = time.time() - start_time
    print(f"Import time: {import_time:.2f}s")
    
    # ExÃ©cution avec profiling
    start_memory = psutil.virtual_memory().used / 1024 / 1024  # MB
    
    result = main()
    
    end_memory = psutil.virtual_memory().used / 1024 / 1024  # MB
    memory_used = end_memory - start_memory
    
    print(f"Memory used: {memory_used:.1f} MB")
    return result

def profile_cpu():
    """Profiling CPU dÃ©taillÃ©"""
    profiler = cProfile.Profile()
    profiler.enable()
    
    # ExÃ©cution code Ã  profiler
    profile_orchestration()
    
    profiler.disable()
    
    # Analyse rÃ©sultats
    stats = pstats.Stats(profiler)
    stats.sort_stats('cumulative')
    stats.print_stats(20)  # Top 20 fonctions
```

---

## ğŸ“Š **MÃ‰TRIQUES ET ANALYSE**

### ğŸ“ˆ **MÃ©triques de Performance SystÃ¨me**

#### **Monitoring Temps RÃ©el**
```python
# Script monitoring (monitor_system.py)
import time
import psutil
import threading
from dataclasses import dataclass
from typing import List, Dict

@dataclass
class SystemMetrics:
    timestamp: float
    cpu_percent: float
    memory_mb: float
    api_calls: int
    response_time: float

class SystemMonitor:
    """Monitoring systÃ¨me en temps rÃ©el"""
    
    def __init__(self):
        self.metrics_history: List[SystemMetrics] = []
        self.monitoring = False
        
    def start_monitoring(self):
        """DÃ©marrage monitoring en arriÃ¨re-plan"""
        self.monitoring = True
        monitor_thread = threading.Thread(target=self._monitor_loop)
        monitor_thread.daemon = True
        monitor_thread.start()
        
    def _monitor_loop(self):
        """Boucle monitoring continue"""
        while self.monitoring:
            metrics = SystemMetrics(
                timestamp=time.time(),
                cpu_percent=psutil.cpu_percent(),
                memory_mb=psutil.virtual_memory().used / 1024 / 1024,
                api_calls=self._count_api_calls(),
                response_time=self._measure_response_time()
            )
            self.metrics_history.append(metrics)
            time.sleep(1.0)  # Ã‰chantillonnage chaque seconde
            
    def generate_report(self) -> Dict:
        """GÃ©nÃ©ration rapport de performance"""
        if not self.metrics_history:
            return {"error": "Aucune mÃ©trique collectÃ©e"}
            
        cpu_avg = sum(m.cpu_percent for m in self.metrics_history) / len(self.metrics_history)
        memory_avg = sum(m.memory_mb for m in self.metrics_history) / len(self.metrics_history)
        memory_peak = max(m.memory_mb for m in self.metrics_history)
        
        return {
            "duration_seconds": len(self.metrics_history),
            "performance": {
                "cpu_average": round(cpu_avg, 1),
                "memory_average_mb": round(memory_avg, 1),
                "memory_peak_mb": round(memory_peak, 1)
            },
            "api_usage": {
                "total_calls": self._count_total_api_calls(),
                "average_response_time": self._calculate_avg_response_time()
            }
        }
```

#### **MÃ©triques QualitÃ© Conversation**
```python
class ConversationQualityAnalyzer:
    """Analyseur qualitÃ© conversation multi-agents"""
    
    def analyze_conversation(self, messages: List[Dict]) -> Dict:
        """Analyse qualitÃ© complÃ¨te conversation"""
        
        return {
            "personality_distinctiveness": self._measure_personality_distinction(messages),
            "conversation_naturalness": self._measure_naturalness(messages),
            "flow_continuity": self._measure_flow_continuity(messages),
            "logical_coherence": self._measure_logical_coherence(messages),
            "engagement_level": self._measure_engagement(messages)
        }
    
    def _measure_personality_distinction(self, messages: List[Dict]) -> float:
        """Mesure distinction personnalitÃ©s agents"""
        agent_characteristics = {}
        
        for msg in messages:
            agent = msg['agent']
            content = msg['content'].lower()
            
            # Analyse markers personnalitÃ©
            sherlock_markers = ['observe', 'dÃ©duction', 'Ã©vident', 'elementary']
            watson_markers = ['analyse', 'logique', 'mÃ©dical', 'validation']
            moriarty_markers = ['rÃ©vÃ¨le', 'oracle', 'mystÃ©rieux', 'secret']
            
            if agent not in agent_characteristics:
                agent_characteristics[agent] = []
                
            if agent.lower() == 'sherlock':
                score = sum(1 for marker in sherlock_markers if marker in content)
            elif agent.lower() == 'watson':
                score = sum(1 for marker in watson_markers if marker in content)
            elif agent.lower() == 'moriarty':
                score = sum(1 for marker in moriarty_markers if marker in content)
            else:
                score = 0
                
            agent_characteristics[agent].append(score)
        
        # Calcul score distinction
        total_distinction = 0
        for agent, scores in agent_characteristics.items():
            avg_score = sum(scores) / len(scores) if scores else 0
            total_distinction += min(avg_score, 1.0)  # Cap Ã  1.0 par agent
            
        return min(total_distinction / len(agent_characteristics), 10.0) if agent_characteristics else 0.0
```

---

## ğŸ“ **CAS D'USAGE PÃ‰DAGOGIQUES**

### ğŸ¯ **Pour Ã‰tudiants en Intelligence Artificielle**

#### **TP 1: DÃ©couverte SystÃ¨mes Multi-Agents**
```bash
# Objectif: Comprendre coordination agents
# DurÃ©e: 2 heures
# Niveau: DÃ©butant

# 1. ExÃ©cution conversation simple
python examples/Sherlock_Watson/sherlock_watson_authentic_demo.py

# 2. Analyse logs gÃ©nÃ©rÃ©s
cat logs/sherlock_watson_conversation_*.json | jq .

# 3. Questions d'analyse:
# - Comment les agents se coordonnent-ils?
# - Quels patterns de communication observe-t-on?
# - Comment les personnalitÃ©s se distinguent-elles?

# 4. Exercice: Modifier tempÃ©rature LLM et observer impact
# Editer le script, changer temperature de 0.7 Ã  0.3 puis 0.9
```

#### **TP 2: Logique Formelle avec TweetyProject**
```bash
# Objectif: MaÃ®triser raisonnement logique symbolique
# DurÃ©e: 3 heures  
# Niveau: IntermÃ©diaire

# 1. Test logique propositionnelle simple
python examples/Sherlock_Watson/agents_logiques_production.py --logic-type pl

# 2. Formulation contraintes Einstein
python examples/Sherlock_Watson/agents_logiques_production.py --scenario examples/Sherlock_Watson/einstein_scenario.json

# 3. Exercices progressifs:
# - Formuler "Si A alors B" en logique formelle
# - Tester cohÃ©rence: A, Aâ†’B, Â¬B
# - DÃ©duire conclusions via TweetyProject

# 4. Projet: CrÃ©er nouvelle Ã©nigme logique
# Utiliser template Watson pour validation formelle
```

#### **TP 3: Orchestration AvancÃ©e**
```bash
# Objectif: Comprendre patterns orchestration
# DurÃ©e: 4 heures
# Niveau: AvancÃ©

# 1. Orchestration standard
python examples/Sherlock_Watson/orchestration_finale_reelle.py

# 2. Modification stratÃ©gies sÃ©lection
# Editer et tester diffÃ©rentes SelectionStrategy

# 3. MÃ©triques personnalisÃ©es
# ImplÃ©menter nouveau MetricsCollector

# 4. Challenge: SystÃ¨me 4 agents
# Ajouter nouvel agent spÃ©cialisÃ©
```

### ğŸ”¬ **Pour Recherche AcadÃ©mique**

#### **Recherche 1: Performance Multi-Agents**
```python
# Protocole expÃ©rimental standardisÃ©
def experimental_protocol():
    """Protocole recherche performance multi-agents"""
    
    # Variables indÃ©pendantes
    configurations = [
        {"agents": 2, "strategy": "round_robin"},
        {"agents": 3, "strategy": "balanced"},
        {"agents": 3, "strategy": "expertise_based"},
        {"agents": 4, "strategy": "hierarchical"}
    ]
    
    # Variables dÃ©pendantes mesurÃ©es
    metrics = [
        "resolution_time",
        "message_count", 
        "solution_accuracy",
        "conversation_quality"
    ]
    
    # Protocole expÃ©rimental
    for config in configurations:
        for trial in range(10):  # 10 rÃ©pÃ©titions par configuration
            result = run_orchestration_trial(config)
            record_experimental_data(config, result, trial)
    
    # Analyse statistique
    perform_anova_analysis()
    generate_research_report()
```

#### **Recherche 2: Ã‰valuation QualitÃ© Dialogue**
```python
# Framework Ã©valuation dialogue IA
class DialogueEvaluationFramework:
    """Framework recherche qualitÃ© dialogue multi-agents"""
    
    def __init__(self):
        self.evaluation_dimensions = [
            "coherence_score",      # CohÃ©rence logique
            "informativeness",      # Richesse informative
            "naturalness",          # Naturel conversation
            "personality_consistency", # Consistance personnalitÃ©
            "goal_achievement"      # Atteinte objectifs
        ]
    
    def evaluate_session(self, conversation: List[Dict]) -> Dict:
        """Ã‰valuation complÃ¨te session dialogue"""
        
        scores = {}
        for dimension in self.evaluation_dimensions:
            scores[dimension] = getattr(self, f"_evaluate_{dimension}")(conversation)
        
        # Score composite
        scores["overall_quality"] = sum(scores.values()) / len(scores)
        
        return scores
    
    def _evaluate_coherence_score(self, conversation: List[Dict]) -> float:
        """Ã‰valuation cohÃ©rence via analyse sÃ©mantique"""
        # ImplÃ©mentation analyse cohÃ©rence avec NLP
        pass
    
    def _evaluate_personality_consistency(self, conversation: List[Dict]) -> float:
        """Ã‰valuation consistance personnalitÃ©s"""
        # Analyse marqueurs linguistiques caractÃ©ristiques
        pass
```

---

## ğŸ† **CONCLUSION**

Ce guide utilisateur complet vous donne tous les outils nÃ©cessaires pour maÃ®triser le systÃ¨me Sherlock/Watson/Moriarty, depuis l'installation de base jusqu'aux utilisations avancÃ©es en recherche. 

**ğŸ¯ Points ClÃ©s** :
- **Configuration robuste** avec gestion d'erreurs dÃ©taillÃ©e
- **DÃ©monstrations progressives** du simple au complexe  
- **Personnalisation complÃ¨te** pour adaptations spÃ©cifiques
- **MÃ©triques avancÃ©es** pour Ã©valuation rigoureuse
- **Cas d'usage pÃ©dagogiques** structurÃ©s et progressifs

**ğŸš€ Prochaines Ã‰tapes RecommandÃ©es** :
1. Commencer par le dÃ©marrage rapide (5 minutes)
2. Tester les 4 dÃ©monstrations principales  
3. Explorer la personnalisation selon vos besoins
4. ImplÃ©menter vos propres cas d'usage

---

*Guide mis Ã  jour - Version 2.1.0 - 10/06/2025*  
*Documentation exhaustive pour utilisation optimale du systÃ¨me*