# üìã Sp√©cification Technique - Migration vers Pipeline Unifi√© Central

## üéØ **Objectif**
Transformer les 3 scripts consolid√©s pour utiliser `unified_orchestration_pipeline.py` comme moteur central, en pr√©servant leurs interfaces et fonctionnalit√©s.

## üîå **API Pipeline Unifi√© - Points d'Entr√©e**

### **Fonction Principale**
```python
# Point d'entr√©e principal
async def run_unified_orchestration_pipeline(
    text: str, 
    config: ExtendedOrchestrationConfig
) -> Dict[str, Any]

# Alternative avec classe
pipeline = UnifiedOrchestrationPipeline(config)
result = await pipeline.analyze_text_extended(text)
```

### **Configuration Unifi√©e**
```python
class ExtendedOrchestrationConfig(UnifiedAnalysisConfig):
    def __init__(self,
        # === Configuration de base ===
        analysis_modes: List[str] = None,
        orchestration_mode: OrchestrationMode = OrchestrationMode.PIPELINE,
        logic_type: str = "fol",
        use_mocks: bool = False,
        use_advanced_tools: bool = True,
        output_format: str = "detailed",
        enable_conversation_logging: bool = True,
        
        # === Configuration orchestration √©tendue ===
        analysis_type: AnalysisType = AnalysisType.COMPREHENSIVE,
        enable_hierarchical: bool = True,
        enable_specialized_orchestrators: bool = True,
        enable_communication_middleware: bool = True,
        max_concurrent_analyses: int = 10,
        analysis_timeout: int = 300,
        auto_select_orchestrator: bool = True,
        hierarchical_coordination_level: str = "full",
        specialized_orchestrator_priority: List[str] = None,
        save_orchestration_trace: bool = True,
        middleware_config: Dict[str, Any] = None
    )
```

### **Enums Disponibles**
```python
class OrchestrationMode(Enum):
    # Modes de base
    PIPELINE = "pipeline"
    REAL = "real"
    CONVERSATION = "conversation"
    
    # Modes hi√©rarchiques
    HIERARCHICAL_FULL = "hierarchical_full"
    STRATEGIC_ONLY = "strategic_only"
    TACTICAL_COORDINATION = "tactical_coordination"
    OPERATIONAL_DIRECT = "operational_direct"
    
    # Modes sp√©cialis√©s
    CLUEDO_INVESTIGATION = "cluedo_investigation"
    LOGIC_COMPLEX = "logic_complex"
    ADAPTIVE_HYBRID = "adaptive_hybrid"
    AUTO_SELECT = "auto_select"

class AnalysisType(Enum):
    COMPREHENSIVE = "comprehensive"
    RHETORICAL = "rhetorical"
    LOGICAL = "logical"
    INVESTIGATIVE = "investigative"
    FALLACY_FOCUSED = "fallacy_focused"
    ARGUMENT_STRUCTURE = "argument_structure"
    DEBATE_ANALYSIS = "debate_analysis"
    CUSTOM = "custom"
```

---

## üîÑ **Transformations D√©taill√©es par Script**

### **1. unified_production_analyzer.py**

#### **AVANT - M√©thodes actuelles**
```python
async def analyze_text(self, text: str, analysis_type: str = "rhetorical") -> Dict[str, Any]:
    # 50+ lignes de logique interne avec retry, fallback, etc.

async def analyze_batch(self, texts: List[str]) -> List[Dict[str, Any]]:
    # Logique parall√©lisation manuelle avec semaphore
```

#### **APR√àS - D√©l√©gation au pipeline unifi√©**
```python
# Import unique
from argumentation_analysis.pipelines.unified_orchestration_pipeline import (
    run_unified_orchestration_pipeline,
    ExtendedOrchestrationConfig,
    OrchestrationMode,
    AnalysisType
)

class UnifiedProductionAnalyzer:
    def _map_orchestration_mode(self) -> OrchestrationMode:
        """Mappe orchestration_type CLI vers OrchestrationMode"""
        mapping = {
            "unified": OrchestrationMode.HIERARCHICAL_FULL,
            "conversation": OrchestrationMode.CONVERSATION,
            "micro": OrchestrationMode.OPERATIONAL_DIRECT,
            "real_llm": OrchestrationMode.REAL
        }
        return mapping.get(self.orchestration_type, OrchestrationMode.PIPELINE)
    
    def _map_analysis_type(self, analysis_type: str) -> AnalysisType:
        """Mappe analysis_mode CLI vers AnalysisType"""
        mapping = {
            "rhetorical": AnalysisType.RHETORICAL,
            "fallacies": AnalysisType.FALLACY_FOCUSED,
            "coherence": AnalysisType.ARGUMENT_STRUCTURE,
            "semantic": AnalysisType.COMPREHENSIVE,
            "unified": AnalysisType.COMPREHENSIVE,
            "advanced": AnalysisType.COMPREHENSIVE
        }
        return mapping.get(analysis_type, AnalysisType.COMPREHENSIVE)
    
    def _build_config(self, analysis_type: str = "rhetorical") -> ExtendedOrchestrationConfig:
        """Construit la configuration pour le pipeline unifi√©"""
        return ExtendedOrchestrationConfig(
            # Mapping des param√®tres CLI
            orchestration_mode=self._map_orchestration_mode(),
            analysis_type=self._map_analysis_type(analysis_type),
            logic_type=self.logic_type.value if hasattr(self.logic_type, 'value') else self.logic_type,
            use_mocks=(self.mock_level != MockLevel.NONE),
            use_advanced_tools=self.enable_advanced_tools,
            output_format=self.output_format,
            enable_conversation_logging=self.enable_conversation_logging,
            
            # Configuration orchestration
            enable_hierarchical=True,
            enable_specialized_orchestrators=True,
            max_concurrent_analyses=self.max_workers,
            analysis_timeout=self.timeout_seconds,
            auto_select_orchestrator=True,
            save_orchestration_trace=self.save_trace
        )
    
    async def analyze_text(self, text: str, analysis_type: str = "rhetorical") -> Dict[str, Any]:
        """Version simplifi√©e utilisant le pipeline unifi√©"""
        config = self._build_config(analysis_type)
        return await run_unified_orchestration_pipeline(text, config)
    
    async def analyze_batch(self, texts: List[str]) -> List[Dict[str, Any]]:
        """Version batch utilisant le pipeline unifi√©"""
        config = self._build_config()
        config.max_concurrent_analyses = min(self.max_workers, len(texts))
        
        # Le pipeline unifi√© g√®re le parall√©lisme
        results = []
        for text in texts:
            try:
                result = await run_unified_orchestration_pipeline(text, config)
                results.append(result)
            except Exception as e:
                results.append({
                    "status": "error",
                    "error": str(e),
                    "text_preview": text[:100] + "..." if len(text) > 100 else text
                })
        
        return results
```

### **2. educational_showcase_system.py**

#### **AVANT - Multiple imports et orchestrateurs**
```python
from argumentation_analysis.pipelines.unified_text_analysis import UnifiedTextAnalysisPipeline
from argumentation_analysis.orchestration.real_llm_orchestrator import RealLLMOrchestrator
from argumentation_analysis.orchestration.conversation_orchestrator import ConversationOrchestrator
# ... 12+ autres imports
```

#### **APR√àS - Configuration √©ducative unifi√©e**
```python
# Import simplifi√©
from argumentation_analysis.pipelines.unified_orchestration_pipeline import (
    run_unified_orchestration_pipeline,
    ExtendedOrchestrationConfig,
    OrchestrationMode,
    AnalysisType
)

class EducationalShowcaseSystem:
    def _build_educational_config(self, mode: str = "interactive") -> ExtendedOrchestrationConfig:
        """Configuration sp√©cialis√©e pour l'√©ducation"""
        return ExtendedOrchestrationConfig(
            # Mode conversationnel pour l'√©ducation
            orchestration_mode=OrchestrationMode.CONVERSATION,
            analysis_type=AnalysisType.COMPREHENSIVE,
            
            # Fonctionnalit√©s √©ducatives
            use_mocks=False,  # Toujours authentique en mode √©ducatif
            enable_conversation_logging=True,
            save_orchestration_trace=True,
            
            # Configuration orchestration √©ducative
            enable_hierarchical=True,
            enable_specialized_orchestrators=True,
            enable_communication_middleware=True,
            auto_select_orchestrator=True,
            hierarchical_coordination_level="full",
            specialized_orchestrator_priority=["conversation", "real_llm"],
            
            # Configuration middleware pour capture conversations
            middleware_config={
                "capture_agent_conversations": True,
                "detailed_logging": True,
                "educational_mode": True,
                "conversation_export_format": "markdown"
            }
        )
    
    async def run_educational_analysis(self, text: str, mode: str = "interactive") -> Dict[str, Any]:
        """Analyse √©ducative utilisant le pipeline unifi√©"""
        config = self._build_educational_config(mode)
        result = await run_unified_orchestration_pipeline(text, config)
        
        # Post-traitement √©ducatif
        if "orchestration_trace" in result:
            result["educational_insights"] = self._extract_educational_insights(result["orchestration_trace"])
        
        return result
    
    def _extract_educational_insights(self, trace: List[Dict]) -> Dict[str, Any]:
        """Extrait les insights p√©dagogiques de la trace d'orchestration"""
        return {
            "agents_involved": [step.get("agent", "unknown") for step in trace],
            "conversation_flow": self._build_conversation_flow(trace),
            "learning_points": self._identify_learning_points(trace),
            "complexity_metrics": self._calculate_complexity_metrics(trace)
        }
```

### **3. comprehensive_workflow_processor.py**

#### **AVANT - Workflow manuel complexe**
```python
# Imports multiples et workflow manuel
from argumentation_analysis.agents.core.informal.informal_agent import InformalAnalysisAgent
# Configuration manuelle des √©tapes...
```

#### **APR√àS - Mode workflow unifi√©**
```python
# Import simplifi√©
from argumentation_analysis.pipelines.unified_orchestration_pipeline import (
    run_unified_orchestration_pipeline,
    ExtendedOrchestrationConfig,
    OrchestrationMode,
    AnalysisType
)

class ComprehensiveWorkflowProcessor:
    def _build_workflow_config(self, mode: WorkflowMode) -> ExtendedOrchestrationConfig:
        """Configuration pour workflow complet"""
        mode_mapping = {
            WorkflowMode.FULL: OrchestrationMode.HIERARCHICAL_FULL,
            WorkflowMode.ANALYSIS_ONLY: OrchestrationMode.OPERATIONAL_DIRECT,
            WorkflowMode.TESTING_ONLY: OrchestrationMode.TACTICAL_COORDINATION,
            WorkflowMode.VALIDATION_ONLY: OrchestrationMode.STRATEGIC_ONLY,
            WorkflowMode.PERFORMANCE: OrchestrationMode.ADAPTIVE_HYBRID,
            WorkflowMode.BATCH: OrchestrationMode.HIERARCHICAL_FULL
        }
        
        return ExtendedOrchestrationConfig(
            orchestration_mode=mode_mapping.get(mode, OrchestrationMode.HIERARCHICAL_FULL),
            analysis_type=AnalysisType.COMPREHENSIVE,
            
            # Configuration workflow
            use_mocks=False,
            use_advanced_tools=True,
            enable_conversation_logging=True,
            save_orchestration_trace=True,
            
            # Configuration orchestration pour workflow
            enable_hierarchical=True,
            enable_specialized_orchestrators=True,
            enable_communication_middleware=True,
            max_concurrent_analyses=self.max_workers,
            analysis_timeout=self.timeout_seconds,
            auto_select_orchestrator=True,
            hierarchical_coordination_level="full",
            
            # Configuration workflow sp√©cialis√©e
            middleware_config={
                "workflow_mode": True,
                "batch_processing": (mode == WorkflowMode.BATCH),
                "performance_monitoring": True,
                "comprehensive_validation": True
            }
        )
    
    async def run_comprehensive_workflow(self, data: Dict[str, Any], mode: WorkflowMode) -> Dict[str, Any]:
        """Workflow complet utilisant le pipeline unifi√©"""
        config = self._build_workflow_config(mode)
        
        # Le pipeline unifi√© g√®re l'orchestration compl√®te
        if isinstance(data, dict) and "corpus_data" in data:
            # Mode corpus
            results = []
            for item in data["corpus_data"]:
                text = item.get("content", str(item))
                result = await run_unified_orchestration_pipeline(text, config)
                result["source_info"] = item.get("source_info", "unknown")
                results.append(result)
            
            return {
                "workflow_mode": mode.value,
                "results": results,
                "summary": self._build_workflow_summary(results)
            }
        else:
            # Mode texte simple
            text = str(data)
            return await run_unified_orchestration_pipeline(text, config)
```

---

## üß™ **Plan de Tests**

### **Tests de Non-R√©gression**
```python
# Test pour chaque script transform√©
async def test_production_analyzer_migration():
    """V√©rifie que l'interface CLI fonctionne toujours"""
    analyzer = UnifiedProductionAnalyzer()
    # Tester tous les param√®tres CLI existants
    
async def test_educational_system_migration():
    """V√©rifie que les fonctionnalit√©s p√©dagogiques sont pr√©serv√©es"""
    system = EducationalShowcaseSystem()
    # Tester capture conversations, rapports markdown, etc.
    
async def test_workflow_processor_migration():
    """V√©rifie que les workflows batch fonctionnent"""
    processor = ComprehensiveWorkflowProcessor()
    # Tester tous les modes de workflow
```

### **Tests de Performance**
```python
async def test_performance_comparison():
    """Compare performance avant/apr√®s migration"""
    # Mesurer temps d'ex√©cution
    # V√©rifier utilisation m√©moire
    # Valider parall√©lisme
```

---

## üìÖ **Plan d'Impl√©mentation D√©taill√©**

### **Jour 1 : unified_production_analyzer.py**
**Matin (2-3h)** :
1. ‚úÖ Ajouter import du pipeline unifi√©
2. ‚úÖ Cr√©er m√©thodes de mapping `_map_orchestration_mode()` et `_map_analysis_type()`
3. ‚úÖ Cr√©er `_build_config()` 
4. ‚úÖ Remplacer `analyze_text()` par appel pipeline unifi√©

**Apr√®s-midi (2-3h)** :
5. ‚úÖ Remplacer `analyze_batch()` par version pipeline unifi√©
6. ‚úÖ Tests de non-r√©gression CLI
7. ‚úÖ Validation avec tous les param√®tres existants

### **Jour 2 : educational_showcase_system.py**
**Matin (2-3h)** :
1. ‚úÖ Simplifier les imports multiples
2. ‚úÖ Cr√©er `_build_educational_config()`
3. ‚úÖ Transformer `run_educational_analysis()`

**Apr√®s-midi (2-3h)** :
4. ‚úÖ Adapter extraction des insights p√©dagogiques
5. ‚úÖ Tests des fonctionnalit√©s conversationnelles
6. ‚úÖ Validation g√©n√©ration rapports markdown

### **Jour 3 : comprehensive_workflow_processor.py**
**Matin (2-3h)** :
1. ‚úÖ Cr√©er `_build_workflow_config()` avec mapping modes
2. ‚úÖ Transformer `run_comprehensive_workflow()`
3. ‚úÖ Adapter gestion corpus et batch

**Apr√®s-midi (2-3h)** :
4. ‚úÖ Tests workflow complets
5. ‚úÖ Tests performance et parall√©lisme
6. ‚úÖ Validation int√©gration compl√®te

---

## ‚úÖ **Crit√®res de R√©ussite**

### **Fonctionnel**
- ‚úÖ Interface utilisateur inchang√©e (CLI, arguments, outputs)
- ‚úÖ Toutes les fonctionnalit√©s existantes pr√©serv√©es
- ‚úÖ Performance √©gale ou am√©lior√©e
- ‚úÖ Tests de non-r√©gression passent √† 100%

### **Technique**
- ‚úÖ Code simplifi√© et plus maintenable
- ‚úÖ R√©duction significative des imports
- ‚úÖ Logique centralis√©e dans le pipeline unifi√©
- ‚úÖ Tra√ßabilit√© et logging am√©lior√©s

### **Architecture**
- ‚úÖ Pipeline unifi√© devient le point central
- ‚úÖ Scripts transform√©s en fa√ßades l√©g√®res
- ‚úÖ R√©utilisation maximale des capacit√©s d'orchestration
- ‚úÖ √âvolutivit√© pour futures fonctionnalit√©s