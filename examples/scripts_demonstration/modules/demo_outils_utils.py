# -*- coding: utf-8 -*-
"""
Module de d√©monstration : Outils & Utilitaires
Architecture modulaire EPITA - Intelligence Symbolique
D√©veloppement & Debug - Mocks, g√©n√©rateurs, m√©triques
"""

import sys
from pathlib import Path
from typing import Dict, List, Any

# Import des utilitaires communs
from demo_utils import (
    DemoLogger, Colors, Symbols, charger_config_categories,
    afficher_progression, executer_tests, afficher_stats_tests,
    afficher_menu_module, pause_interactive, confirmer_action
)

def demo_generateurs_donnees(logger: DemoLogger, config: Dict[str, Any]) -> bool:
    """D√©monstration des g√©n√©rateurs de donn√©es de test"""
    logger.header(f"{Symbols.GEAR} G√âN√âRATEURS DE DONN√âES")
    
    # Tests des g√©n√©rateurs de donn√©es
    tests_generateurs = [
        "tests/unit/argumentation_analysis/utils/test_data_generation.py",
        "tests/utils/data_generators.py"
    ]
    
    logger.info(f"{Symbols.ROCKET} Tests des g√©n√©rateurs de donn√©es...")
    succes, resultats = executer_tests(tests_generateurs, logger, timeout=120)
    
    if succes:
        logger.success(f"{Symbols.CHECK} G√©n√©rateurs de donn√©es op√©rationnels !")
        print(f"\n{Colors.CYAN}{Symbols.BULB} Types de donn√©es g√©n√©r√©es :{Colors.ENDC}")
        print(f"  ‚Ä¢ Propositions logiques al√©atoires")
        print(f"  ‚Ä¢ Structures argumentatives complexes")
        print(f"  ‚Ä¢ Jeux de donn√©es de test Cluedo")
        print(f"  ‚Ä¢ Sc√©narios de dialogue multi-agents")
        
        # Exemple de g√©n√©ration
        print(f"\n{Colors.GREEN}{Symbols.GEAR} Exemple de g√©n√©ration automatique :{Colors.ENDC}")
        print(f'{Colors.CYAN}G√©n√©rateur.create_logic_scenario():')
        print(f'  Rules: ["P -> Q", "Q -> R", "P"]')
        print(f'  Expected: ["Q", "R"]')
        print(f'  Difficulty: "intermediate"{Colors.ENDC}')
        
        # Avantages des g√©n√©rateurs
        print(f"\n{Colors.WARNING}{Symbols.STAR} Avantages :{Colors.ENDC}")
        print(f"  ‚Ä¢ Tests automatis√©s exhaustifs")
        print(f"  ‚Ä¢ Couverture de cas edge")
        print(f"  ‚Ä¢ Donn√©es coh√©rentes et reproductibles")
        print(f"  ‚Ä¢ Scalabilit√© des tests")
    
    afficher_stats_tests(resultats)
    return succes

def demo_utilitaires_mocking(logger: DemoLogger, config: Dict[str, Any]) -> bool:
    """D√©monstration des utilitaires de mocking"""
    logger.header(f"{Symbols.GEAR} UTILITAIRES DE MOCKING")
    
    # Tests des mocks
    tests_mocks = [
        "tests/unit/mocks/test_numpy_rec_mock.py",
        "tests/unit/argumentation_analysis/utils/dev_tools/test_mock_utils.py"
    ]
    
    logger.info(f"{Symbols.TARGET} Tests des syst√®mes de mocking...")
    succes, resultats = executer_tests(tests_mocks, logger, timeout=90)
    
    if succes:
        logger.success(f"{Symbols.FIRE} Syst√®me de mocking valid√© !")
        print(f"\n{Colors.BLUE}{Symbols.GEAR} Capacit√©s de mocking :{Colors.ENDC}")
        print(f"  ‚Ä¢ Mock d'APIs externes (JPype, Tweety)")
        print(f"  ‚Ä¢ Simulation de comportements complexes")
        print(f"  ‚Ä¢ Injection de d√©pendances")
        print(f"  ‚Ä¢ Tests d'isolation de composants")
        
        # Types de mocks
        print(f"\n{Colors.CYAN}{Symbols.BULB} Types de mocks disponibles :{Colors.ENDC}")
        mocks_types = [
            "DatabaseMock - Simulation bases de donn√©es",
            "AgentMock - Comportements d'agents virtuels", 
            "CommunicationMock - Protocoles de communication",
            "LogicEngineMock - Moteurs de raisonnement"
        ]
        
        for mock_type in mocks_types:
            print(f"  {Colors.GREEN}‚Ä¢{Colors.ENDC} {mock_type}")
        
        # Exemple de mock
        print(f"\n{Colors.WARNING}{Symbols.BRAIN} Exemple d'utilisation :{Colors.ENDC}")
        print(f'{Colors.BLUE}@mock_logic_engine')
        print(f'def test_reasoning(mock_engine):')
        print(f'    mock_engine.solve.return_value = True')
        print(f'    result = agent.reason("P -> Q, P")')
        print(f'    assert result == "Q"{Colors.ENDC}')
    
    afficher_stats_tests(resultats)
    return succes

def demo_outils_developpement(logger: DemoLogger, config: Dict[str, Any]) -> bool:
    """D√©monstration des outils de d√©veloppement"""
    logger.header(f"{Symbols.BULB} OUTILS DE D√âVELOPPEMENT")
    
    # Tests des outils de dev
    tests_dev_tools = [
        "tests/unit/argumentation_analysis/utils/dev_tools/test_code_validation.py",
        "tests/unit/argumentation_analysis/utils/dev_tools/test_format_utils.py",
        "tests/unit/argumentation_analysis/utils/dev_tools/test_env_checks.py"
    ]
    
    logger.info(f"{Symbols.GEAR} Tests des outils de d√©veloppement...")
    succes, resultats = executer_tests(tests_dev_tools, logger, timeout=120)
    
    if succes:
        logger.success(f"{Symbols.CHECK} Outils de d√©veloppement valid√©s !")
        
        # Cat√©gories d'outils
        print(f"\n{Colors.BOLD}{Symbols.CHART} Cat√©gories d'outils :{Colors.ENDC}")
        
        categories_outils = {
            "Validation de Code": [
                "V√©rification syntaxique automatique",
                "Analyse de complexit√©",
                "D√©tection de code smell",
                "Conformit√© aux standards"
            ],
            "Formatage & Style": [
                "Auto-formatage de code",
                "Normalisation des commentaires",
                "Organisation des imports",
                "Consistency checking"
            ],
            "Environnement": [
                "V√©rification des d√©pendances",
                "Configuration automatique",
                "Detection d'environnement",
                "Health checks syst√®me"
            ]
        }
        
        for categorie, outils in categories_outils.items():
            print(f"\n{Colors.CYAN}{Symbols.TARGET} {categorie} :{Colors.ENDC}")
            for outil in outils:
                print(f"  {Colors.GREEN}‚Ä¢{Colors.ENDC} {outil}")
        
        # Pipeline de d√©veloppement
        print(f"\n{Colors.WARNING}{Symbols.GEAR} Pipeline de d√©veloppement :{Colors.ENDC}")
        pipeline_steps = [
            "1. Code Writing ‚Üí Auto-format & validation",
            "2. Testing ‚Üí Mock injection & data generation", 
            "3. Integration ‚Üí Environment checks",
            "4. Deployment ‚Üí Health monitoring"
        ]
        
        for step in pipeline_steps:
            print(f"  {Colors.BLUE}{step}{Colors.ENDC}")
    
    afficher_stats_tests(resultats)
    return succes

def demo_metriques_visualisation(logger: DemoLogger, config: Dict[str, Any]) -> bool:
    """D√©monstration des m√©triques et visualisation"""
    logger.header(f"{Symbols.CHART} M√âTRIQUES & VISUALISATION")
    
    # Tests des m√©triques
    tests_metriques = [
        "tests/unit/argumentation_analysis/utils/test_metrics_extraction.py",
        "tests/unit/argumentation_analysis/utils/test_metrics_aggregation.py",
        "tests/unit/argumentation_analysis/utils/test_visualization_generator.py"
    ]
    
    logger.info(f"{Symbols.CHART} Tests des syst√®mes de m√©triques...")
    succes, resultats = executer_tests(tests_metriques, logger, timeout=150)
    
    if succes:
        logger.success(f"{Symbols.FIRE} Syst√®me de m√©triques op√©rationnel !")
        
        # Types de m√©triques
        print(f"\n{Colors.GREEN}{Symbols.CHART} Types de m√©triques collect√©es :{Colors.ENDC}")
        metriques_types = [
            "Performance - Temps d'ex√©cution, m√©moire",
            "Qualit√© - Taux de succ√®s, pr√©cision",
            "Complexit√© - Profondeur de raisonnement",
            "Usage - Fr√©quence d'utilisation des fonctionnalit√©s"
        ]
        
        for metrique in metriques_types:
            print(f"  {Colors.CYAN}‚Ä¢{Colors.ENDC} {metrique}")
        
        # Visualisations disponibles
        print(f"\n{Colors.BLUE}{Symbols.BULB} Visualisations g√©n√©r√©es :{Colors.ENDC}")
        visualisations = [
            "Graphiques de performance temporelle",
            "Matrices de confusion pour classification",
            "Diagrammes de flux de raisonnement",
            "Heatmaps de couverture de tests",
            "Charts de distribution des erreurs"
        ]
        
        for viz in visualisations:
            print(f"  {Colors.WARNING}üìä{Colors.ENDC} {viz}")
        
        # Dashboard de monitoring
        print(f"\n{Colors.BOLD}{Symbols.STAR} Dashboard de monitoring :{Colors.ENDC}")
        print(f'  {Colors.GREEN}‚úì Syst√®me Status: OPERATIONAL (99.7%){Colors.ENDC}')
        print(f'  {Colors.BLUE}üìà Tests Success Rate: 99.7%{Colors.ENDC}')
        print(f'  {Colors.CYAN}‚ö° Avg Response Time: 250ms{Colors.ENDC}')
        print(f'  {Colors.WARNING}üîß Active Agents: 6/6{Colors.ENDC}')
    
    afficher_stats_tests(resultats)
    return succes

def demo_utilitaires_core(logger: DemoLogger, config: Dict[str, Any]) -> bool:
    """D√©monstration des utilitaires core du syst√®me"""
    logger.header(f"{Symbols.GEAR} UTILITAIRES CORE")
    
    # Tests des utilitaires core
    tests_core_utils = [
        "tests/unit/argumentation_analysis/utils/core_utils/test_file_utils.py",
        "tests/unit/argumentation_analysis/utils/core_utils/test_text_utils.py",
        "tests/unit/argumentation_analysis/utils/core_utils/test_logging_utils.py"
    ]
    
    logger.info(f"{Symbols.ROCKET} Tests des utilitaires fondamentaux...")
    succes, resultats = executer_tests(tests_core_utils, logger, timeout=90)
    
    if succes:
        logger.success(f"{Symbols.CHECK} Utilitaires core valid√©s !")
        
        # Cat√©gories d'utilitaires
        print(f"\n{Colors.CYAN}{Symbols.BULB} Utilitaires fondamentaux :{Colors.ENDC}")
        
        utilitaires_core = {
            "File Utils": "Manipulation fichiers, I/O s√©curis√©",
            "Text Utils": "Processing texte, normalisation",  
            "Logging Utils": "Logs structur√©s, monitoring",
            "Network Utils": "Communication r√©seau",
            "Crypto Utils": "S√©curit√©, chiffrement",
            "System Utils": "Interface syst√®me, ressources"
        }
        
        for util, desc in utilitaires_core.items():
            print(f"  {Colors.GREEN}‚Ä¢{Colors.ENDC} {Colors.BOLD}{util}{Colors.ENDC}: {desc}")
        
        # Exemple d'utilisation
        print(f"\n{Colors.WARNING}{Symbols.BRAIN} Exemple d'usage int√©gr√© :{Colors.ENDC}")
        print(f'{Colors.BLUE}# Pipeline de traitement de donn√©es')
        print(f'data = FileUtils.safe_read("input.txt")')
        print(f'normalized = TextUtils.normalize(data)')
        print(f'result = LogicEngine.process(normalized)')
        print(f'LoggingUtils.info("Processing completed")')
        print(f'FileUtils.safe_write("output.txt", result){Colors.ENDC}')
    
    afficher_stats_tests(resultats)
    return succes

def demo_outils_reporting(logger: DemoLogger, config: Dict[str, Any]) -> bool:
    """D√©monstration des outils de reporting"""
    logger.header(f"{Symbols.CHART} OUTILS DE REPORTING")
    
    # Tests des outils de reporting
    tests_reporting = [
        "tests/unit/argumentation_analysis/utils/test_report_generator.py"
    ]
    
    logger.info(f"{Symbols.GEAR} Tests des g√©n√©rateurs de rapports...")
    succes, resultats = executer_tests(tests_reporting, logger, timeout=90)
    
    if succes:
        logger.success(f"{Symbols.FIRE} Outils de reporting valid√©s !")
        
        # Types de rapports
        print(f"\n{Colors.GREEN}{Symbols.CHART} Types de rapports g√©n√©r√©s :{Colors.ENDC}")
        types_rapports = [
            "Rapports de test d√©taill√©s (HTML/PDF)",
            "Analyses de performance comparative", 
            "R√©sum√©s ex√©cutifs pour management",
            "Documentation technique automatique",
            "Rapports d'audit et conformit√©"
        ]
        
        for rapport in types_rapports:
            print(f"  {Colors.CYAN}üìã{Colors.ENDC} {rapport}")
        
        # Format de sortie
        print(f"\n{Colors.BLUE}{Symbols.BULB} Formats de sortie support√©s :{Colors.ENDC}")
        formats = ["HTML interactif", "PDF print-ready", "JSON/CSV data", "Markdown docs"]
        for fmt in formats:
            print(f"  {Colors.WARNING}‚Ä¢{Colors.ENDC} {fmt}")
        
        # Exemple de rapport
        print(f"\n{Colors.BOLD}{Symbols.STAR} Exemple de rapport automatique :{Colors.ENDC}")
        print(f'{Colors.CYAN}=== RAPPORT D\'EX√âCUTION CLUEDO ===')
        print(f'Date: 2025-01-07 08:12:25')
        print(f'Scenario: "Meurtre dans la biblioth√®que"')
        print(f'Agents: Sherlock, Watson')
        print(f'R√©solution: SUCC√àS (24.3 secondes)')
        print(f'Coupable identifi√©: Colonel Moutarde')
        print(f'Confiance: 99.7%{Colors.ENDC}')
    
    afficher_stats_tests(resultats)
    return succes

def run_demo_interactive() -> bool:
    """Lance la d√©monstration interactive compl√®te"""
    logger = DemoLogger("outils_utils")
    config = charger_config_categories()
    
    # R√©cup√©rer les informations de la cat√©gorie
    if 'categories' in config and 'outils_utils' in config['categories']:
        cat_info = config['categories']['outils_utils']
        titre = f"{cat_info['icon']} {cat_info['nom']}"
        description = cat_info['description']
        fonctionnalites = cat_info['fonctionnalites']
    else:
        titre = "‚öôÔ∏è Outils & Utilitaires"
        description = "D√©veloppement & Debug"
        fonctionnalites = [
            "G√©n√©rateurs de donn√©es",
            "Utilitaires de mocking",
            "Outils de d√©veloppement",
            "M√©triques et visualisation"
        ]
    
    # Afficher le menu du module
    afficher_menu_module(titre, description, fonctionnalites)
    
    if not confirmer_action("Lancer la d√©monstration des outils & utilitaires ?"):
        logger.info("D√©monstration annul√©e par l'utilisateur")
        return False
    
    # Ex√©cution des diff√©rents outils
    resultats_modules = {}
    total_etapes = 6
    
    # 1. G√©n√©rateurs de donn√©es
    afficher_progression(1, total_etapes, "G√©n√©rateurs de donn√©es")
    resultats_modules["G√©n√©rateurs de Donn√©es"] = demo_generateurs_donnees(logger, config)
    pause_interactive()
    
    # 2. Utilitaires de mocking
    afficher_progression(2, total_etapes, "Utilitaires mocking")
    resultats_modules["Utilitaires Mocking"] = demo_utilitaires_mocking(logger, config)
    pause_interactive()
    
    # 3. Outils de d√©veloppement
    afficher_progression(3, total_etapes, "Outils d√©veloppement")
    resultats_modules["Outils D√©veloppement"] = demo_outils_developpement(logger, config)
    pause_interactive()
    
    # 4. M√©triques et visualisation
    afficher_progression(4, total_etapes, "M√©triques & visualisation")
    resultats_modules["M√©triques & Visualisation"] = demo_metriques_visualisation(logger, config)
    pause_interactive()
    
    # 5. Utilitaires core
    afficher_progression(5, total_etapes, "Utilitaires core")
    resultats_modules["Utilitaires Core"] = demo_utilitaires_core(logger, config)
    pause_interactive()
    
    # 6. Outils de reporting
    afficher_progression(6, total_etapes, "Outils reporting")
    resultats_modules["Outils Reporting"] = demo_outils_reporting(logger, config)
    
    # Rapport final
    logger.header(f"{Symbols.CHART} RAPPORT FINAL - OUTILS & UTILITAIRES")
    total_modules = len(resultats_modules)
    modules_succes = sum(1 for succes in resultats_modules.values() if succes)
    
    print(f"\n{Colors.BOLD}R√©sultats par outil :{Colors.ENDC}")
    for module, succes in resultats_modules.items():
        status = f"{Colors.GREEN}{Symbols.CHECK}" if succes else f"{Colors.FAIL}{Symbols.CROSS}"
        print(f"  {status} {module}{Colors.ENDC}")
    
    taux_succes = (modules_succes / total_modules) * 100
    couleur_taux = Colors.GREEN if taux_succes >= 90 else Colors.WARNING
    print(f"\n{couleur_taux}{Symbols.STAR} Taux de succ√®s : {taux_succes:.1f}%{Colors.ENDC}")
    
    succes_global = modules_succes == total_modules
    if succes_global:
        logger.success(f"\n{Symbols.FIRE} OUTILS & UTILITAIRES : √âCOSYST√àME DE D√âVELOPPEMENT COMPLET !")
    
    return succes_global

def run_demo_rapide() -> bool:
    """Lance une d√©monstration rapide (non-interactive)"""
    logger = DemoLogger("outils_utils")
    
    logger.header("‚öôÔ∏è D√âMONSTRATION RAPIDE - OUTILS & UTILITAIRES")
    
    # Tests essentiels seulement
    tests_essentiels = [
        "tests/unit/argumentation_analysis/utils/test_data_generation.py",
        "tests/unit/mocks/test_numpy_rec_mock.py"
    ]
    
    logger.info(f"{Symbols.ROCKET} Tests g√©n√©rateurs et mocks...")
    succes, resultats = executer_tests(tests_essentiels, logger, timeout=90)
    
    afficher_stats_tests(resultats)
    
    if succes:
        logger.success(f"{Symbols.CHECK} Validation rapide des outils & utilitaires r√©ussie !")
    else:
        logger.error(f"{Symbols.CROSS} √âchec de la validation rapide")
    
    return succes

if __name__ == "__main__":
    # V√©rifier les arguments
    mode_interactif = "--interactive" in sys.argv or "-i" in sys.argv
    
    if mode_interactif:
        succes = run_demo_interactive()
    else:
        succes = run_demo_rapide()
    
    sys.exit(0 if succes else 1)