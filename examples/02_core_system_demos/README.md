# ‚öôÔ∏è Core System Demos

## Description

Ce r√©pertoire contient des d√©monstrations exhaustives des fonctionnalit√©s centrales du syst√®me d'argumentation. Ces d√©mos illustrent l'utilisation des services core, l'orchestration hi√©rarchique, l'int√©gration des agents, et les cas d'usage complets.

## Contenu

### Sous-R√©pertoires

| R√©pertoire | Description | Complexit√© | Scripts Cl√©s |
|------------|-------------|------------|--------------|
| **[phase2_demo/](./phase2_demo/)** | D√©monstrations des fonctionnalit√©s Phase 2 | Interm√©diaire | demo_authentic_llm_validation.py |
| **[scripts_demonstration/](./scripts_demonstration/)** | Scripts de d√©monstration exhaustifs et modulaires | Avanc√© | demonstration_epita.py, modules/ |

## üì¶ Phase 2 Demo

**Objectif** : D√©montrer les capacit√©s de validation et d'analyse avec LLM authentique

### Fichiers

| Fichier | Description | Lignes |
|---------|-------------|--------|
| [`demo_authentic_llm_validation.py`](./phase2_demo/demo_authentic_llm_validation.py) | Validation authentique avec LLM r√©el (230 lignes) | 230 |

### Fonctionnalit√©s D√©montr√©es

- ‚úÖ **Int√©gration LLM** : Utilisation de mod√®les de langage r√©els
- ‚úÖ **Validation authentique** : Tests avec donn√©es r√©elles
- ‚úÖ **Workflows Phase 2** : D√©monstration des workflows avanc√©s
- ‚úÖ **Gestion d'erreurs** : Robustesse et r√©silience

### Utilisation

```bash
# Naviguer vers le r√©pertoire
cd examples/02_core_system_demos/phase2_demo

# Configurer les cl√©s API (si n√©cessaire)
export OPENAI_API_KEY="votre-cl√©"

# Ex√©cuter la d√©mo
python demo_authentic_llm_validation.py
```

### Ce Que Vous Apprendrez

- ‚úÖ Int√©grer des LLM dans le syst√®me
- ‚úÖ Valider les r√©sultats d'analyse
- ‚úÖ G√©rer les appels API asynchrones
- ‚úÖ Optimiser l'utilisation des tokens

**üìñ [Code source](./phase2_demo/demo_authentic_llm_validation.py)**

## üéØ Scripts Demonstration

**Objectif** : Collection compl√®te de scripts modulaires d√©montrant toutes les fonctionnalit√©s du syst√®me

### Architecture

```
scripts_demonstration/
‚îú‚îÄ‚îÄ demonstration_epita.py      # Script principal orchestrateur (843 lignes)
‚îú‚îÄ‚îÄ demo_tweety_interaction_simple.py  # Int√©gration Tweety (240 lignes)
‚îú‚îÄ‚îÄ generate_complex_synthetic_data.py # G√©n√©ration donn√©es (379 lignes)
‚îú‚îÄ‚îÄ test_architecture.py        # Tests architecture (186 lignes)
‚îú‚îÄ‚îÄ configs/                    # Configurations YAML
‚îÇ   ‚îî‚îÄ‚îÄ demo_categories.yaml    # Cat√©gories de d√©mos (110 lignes)
‚îî‚îÄ‚îÄ modules/                    # Modules d√©monstration
    ‚îú‚îÄ‚îÄ demo_analyse_argumentation.py  # Analyse argumentative (120 lignes)
    ‚îú‚îÄ‚îÄ demo_cas_usage.py              # Cas d'usage (512 lignes)
    ‚îú‚îÄ‚îÄ demo_integrations.py           # Int√©grations (393 lignes)
    ‚îú‚îÄ‚îÄ demo_services_core.py          # Services core (314 lignes)
    ‚îú‚îÄ‚îÄ demo_tests_validation.py       # Tests validation (231 lignes)
    ‚îî‚îÄ‚îÄ demo_utils.py                  # Utilitaires (235 lignes)
```

### Scripts Principaux

#### 1. demonstration_epita.py (843 lignes)

**Script orchestrateur principal** pour d√©monstrations EPITA.

```bash
# Ex√©cution compl√®te
python scripts_demonstration/demonstration_epita.py

# Mode sp√©cifique
python scripts_demonstration/demonstration_epita.py --mode validation
python scripts_demonstration/demonstration_epita.py --mode integration
python scripts_demonstration/demonstration_epita.py --mode cas-usage
```

**Ce qu'il d√©montre** :
- Orchestration de toutes les d√©mos
- G√©n√©ration de rapports exhaustifs
- Tests de validation complets
- Cas d'usage r√©els

#### 2. demo_tweety_interaction_simple.py (240 lignes)

**D√©monstration d'int√©gration** avec la biblioth√®que Tweety pour la logique formelle.

```bash
python scripts_demonstration/demo_tweety_interaction_simple.py
```

**Ce qu'il d√©montre** :
- Int√©gration Tweety (Java bridge)
- Logique argumentative formelle
- Calcul d'extensions
- S√©mantiques de Dung

#### 3. generate_complex_synthetic_data.py (379 lignes)

**G√©n√©rateur de donn√©es synth√©tiques** complexes pour tests.

```bash
# G√©n√©rer 100 exemples
python scripts_demonstration/generate_complex_synthetic_data.py --count 100

# Avec sophismes sp√©cifiques
python scripts_demonstration/generate_complex_synthetic_data.py --fallacies "ad_hominem,straw_man"

# Export JSON
python scripts_demonstration/generate_complex_synthetic_data.py --output synthetic_data.json
```

**Ce qu'il g√©n√®re** :
- Textes argumentatifs vari√©s
- Sophismes de tous types
- Structures rh√©toriques complexes
- Donn√©es annot√©es pour ML

### Modules de D√©monstration

#### Analyse Argumentation

**Fichier** : `modules/demo_analyse_argumentation.py` (120 lignes)

**D√©montre** :
- Extraction d'arguments
- D√©tection de sophismes
- Analyse de coh√©rence
- √âvaluation de qualit√©

```python
from modules.demo_analyse_argumentation import demo_analyse_complete

# Analyser un texte
resultat = demo_analyse_complete("Texte argumentatif...")
print(resultat.sophismes)
print(resultat.structure)
```

#### Cas d'Usage

**Fichier** : `modules/demo_cas_usage.py` (512 lignes)

**D√©montre** :
- Analyse de discours politique
- √âvaluation d'article scientifique
- D√©bat contradictoire
- Argumentation juridique

```python
from modules.demo_cas_usage import demo_discours_politique

# Cas d'usage: discours politique
demo_discours_politique("discours.txt")
```

#### Int√©grations

**Fichier** : `modules/demo_integrations.py` (393 lignes)

**D√©montre** :
- Int√©gration API externe
- Workflows distribu√©s
- Microservices
- Event-driven architecture

#### Services Core

**Fichier** : `modules/demo_services_core.py` (314 lignes)

**D√©montre** :
- ExtractService
- AnalysisService
- ValidationService
- ReportingService

#### Tests & Validation

**Fichier** : `modules/demo_tests_validation.py` (231 lignes)

**D√©montre** :
- Tests unitaires
- Tests d'int√©gration
- Tests de performance
- Validation end-to-end

### Configuration

#### demo_categories.yaml (110 lignes)

D√©finit les cat√©gories de d√©monstrations :

```yaml
categories:
  - name: "Analyse Argumentative"
    demos:
      - id: "analyse_simple"
        description: "Analyse de base"
      - id: "analyse_avancee"
        description: "Analyse approfondie"
  
  - name: "Int√©grations"
    demos:
      - id: "tweety"
        description: "Int√©gration Tweety"
```

### Documentation Compl√©mentaire

| Document | Description | Lignes |
|----------|-------------|--------|
| [ARCHITECTURE_SUMMARY.md](./scripts_demonstration/ARCHITECTURE_SUMMARY.md) | R√©sum√© de l'architecture (160 lignes) | 160 |
| [README_DEMONSTRATION.md](./scripts_demonstration/README_DEMONSTRATION.md) | Guide d√©taill√© (200 lignes) | 200 |
| [GUIDE_VISUEL.md](./scripts_demonstration/GUIDE_VISUEL.md) | Guide visuel avec diagrammes (198 lignes) | 198 |

## Cas d'Usage Complets

### 1. Validation de Pipeline Complet

```bash
# Validation end-to-end
cd scripts_demonstration
python demonstration_epita.py --full-validation

# G√©n√®re un rapport complet
# - R√©sultats par module
# - M√©triques de performance
# - Logs d√©taill√©s
```

### 2. G√©n√©ration de Donn√©es de Test

```bash
# G√©n√©rer dataset pour ML
python generate_complex_synthetic_data.py \
  --count 1000 \
  --output ml_dataset.json \
  --balanced \
  --annotated
```

### 3. D√©mo Interactive

```bash
# Mode interactif pour pr√©sentation
python demonstration_epita.py --interactive

# Permet de:
# - S√©lectionner les d√©mos √† ex√©cuter
# - Voir les r√©sultats en temps r√©el
# - Exporter les rapports
```

## Performance

### M√©triques Typiques

| Script | Temps d'ex√©cution | M√©moire | Complexit√© |
|--------|-------------------|---------|------------|
| demo_authentic_llm_validation | 10-30 secondes | ~100 MB | Moyenne |
| demonstration_epita (complet) | 2-5 minutes | ~200 MB | √âlev√©e |
| generate_complex_synthetic_data | 5-10 secondes/100 exemples | ~50 MB | Variable |
| demo_tweety_interaction_simple | 5-15 secondes | ~150 MB | Moyenne |

### Optimisations

- **Caching** : Les r√©sultats LLM sont mis en cache
- **Parallel processing** : Certaines d√©mos s'ex√©cutent en parall√®le
- **Lazy loading** : Modules charg√©s √† la demande
- **Resource pooling** : Connexions r√©utilis√©es

## D√©veloppement

### Ajouter une Nouvelle D√©mo

1. **Cr√©er le module** dans `modules/`
   ```python
   # modules/demo_ma_feature.py
   def demo_ma_feature():
       """D√©montre ma nouvelle fonctionnalit√©"""
       # Impl√©mentation
       pass
   ```

2. **Enregistrer dans la config**
   ```yaml
   # configs/demo_categories.yaml
   - id: "ma_feature"
     description: "Ma nouvelle fonctionnalit√©"
     module: "demo_ma_feature"
   ```

3. **Int√©grer dans l'orchestrateur**
   ```python
   # demonstration_epita.py
   from modules.demo_ma_feature import demo_ma_feature
   
   def run_all_demos():
       # ...
       demo_ma_feature()
   ```

### Structure Recommand√©e

```python
#!/usr/bin/env python3
"""
Module: demo_ma_feature
Description: D√©montre ma fonctionnalit√©
"""

def demo_ma_feature(config=None):
    """
    Point d'entr√©e principal de la d√©mo
    
    Args:
        config: Configuration optionnelle
        
    Returns:
        R√©sultats de la d√©mo
    """
    print("=== Ma Feature Demo ===\n")
    
    # 1. Setup
    setup()
    
    # 2. Ex√©cution
    results = execute()
    
    # 3. Validation
    validate(results)
    
    # 4. Rapport
    return generate_report(results)

if __name__ == "__main__":
    demo_ma_feature()
```

## Bonnes Pratiques

### Pour les D√©mos

1. **Auto-contenu** : Chaque d√©mo doit fonctionner ind√©pendamment
2. **Documentation** : Docstrings claires et compl√®tes
3. **Logging** : Utiliser le logging pour tra√ßabilit√©
4. **Validation** : Valider les r√©sultats syst√©matiquement
5. **Rapport** : G√©n√©rer un r√©sum√© des r√©sultats

### Pour le Code

1. **Modulaire** : Un fichier = une responsabilit√©
2. **R√©utilisable** : Extraire les fonctions communes
3. **Testable** : √âcrire des tests pour chaque module
4. **Document√©** : README + docstrings + commentaires
5. **Type hints** : Annotations de types

## Ressources Connexes

- **[Logic & Riddles](../01_logic_and_riddles/)** : Exemples de logique
- **[Integrations](../03_integrations/)** : Int√©grations syst√®me
- **[Plugins](../04_plugins/)** : Architecture extensible
- **[Tutorials](../../tutorials/)** : Guides d'apprentissage
- **[Demos](../../demos/)** : Autres d√©monstrations

## Contribution

### Workflow

1. **Identifier le besoin** : Quelle d√©mo manque ?
2. **Cr√©er le module** : Suivre la structure recommand√©e
3. **Tester** : Valider le fonctionnement
4. **Documenter** : README + docstrings
5. **Int√©grer** : Ajouter √† l'orchestrateur
6. **PR** : Soumettre pour review

### Checklist

- [ ] Module cr√©√© dans `modules/`
- [ ] Tests √©crits et passants
- [ ] Documentation compl√®te
- [ ] Int√©gr√© dans `demonstration_epita.py`
- [ ] Ajout√© dans `demo_categories.yaml`
- [ ] README mis √† jour

---

**Derni√®re mise √† jour** : Phase D2.3  
**Mainteneur** : Intelligence Symbolique EPITA  
**Niveau** : Interm√©diaire √† Avanc√©  
**Technologies** : Python, Semantic Kernel, LLM, Tweety