#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
Script de d√©tection et √©limination des mocks pour garantir l'authenticit√© 100%.

Ce script identifie tous les mocks pr√©sents dans le syst√®me et propose
des remplacements par des impl√©mentations authentiques pour assurer
la tra√ßabilit√© compl√®te des analyses.

Objectifs :
- D√©tecter tous les mocks (classes, fonctions, services)
- Valider l'authenticit√© des services LLM
- V√©rifier l'utilisation de Tweety JAR r√©el
- Contr√¥ler la taxonomie compl√®te (1000 n≈ìuds)
- G√©n√©rer un rapport d'authenticit√©
"""

import os
import re
import ast
import logging
import asyncio
from pathlib import Path
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass, field

# Configuration du logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s [%(levelname)s] %(message)s')
logger = logging.getLogger("MockElimination")

@dataclass
class MockDetection:
    """R√©sultat de d√©tection d'un mock."""
    file_path: str
    line_number: int
    mock_type: str  # 'class', 'function', 'import', 'variable'
    mock_name: str
    context: str
    severity: str  # 'critical', 'high', 'medium', 'low'
    replacement_suggestion: str = ""

@dataclass
class AuthenticityReport:
    """Rapport complet d'authenticit√© du syst√®me."""
    total_mocks_detected: int = 0
    critical_mocks: List[MockDetection] = field(default_factory=list)
    high_priority_mocks: List[MockDetection] = field(default_factory=list)
    medium_priority_mocks: List[MockDetection] = field(default_factory=list)
    low_priority_mocks: List[MockDetection] = field(default_factory=list)
    authenticity_score: float = 0.0
    recommendations: List[str] = field(default_factory=list)
    validated_components: List[str] = field(default_factory=list)

class MockDetector:
    """D√©tecteur de mocks dans le code source."""
    
    def __init__(self, project_root: str):
        self.project_root = Path(project_root)
        self.mock_patterns = {
            'class_mocks': [
                r'class\s+(\w*Mock\w*)',
                r'class\s+(\w*Fake\w*)',
                r'class\s+(\w*Stub\w*)',
                r'class\s+(\w*Dummy\w*)',
                r'class\s+(\w*Simulated\w*)',
            ],
            'function_mocks': [
                r'def\s+(\w*mock\w*)',
                r'def\s+(\w*fake\w*)',
                r'def\s+(\w*stub\w*)',
                r'def\s+(\w*simulate\w*)',
            ],
            'import_mocks': [
                r'from\s+\w*\.?\w*\s+import\s+.*Mock',
                r'import\s+mock',
                r'from\s+unittest\s+import\s+mock',
                r'from\s+unittest\.mock\s+import',
            ],
            'variable_mocks': [
                r'(\w*mock\w*)\s*=',
                r'(\w*fake\w*)\s*=',
                r'(\w*stub\w*)\s*=',
            ]
        }
        
        # Patterns critiques pour services authentiques
        self.critical_patterns = {
            'llm_service_mocks': [
                r'MockLLMService',
                r'FakeLLMService',
                r'SimulatedLLMService',
                r'mock_llm',
                r'fake_llm',
            ],
            'tweety_mocks': [
                r'MockTweety',
                r'FakeTweety',
                r'SimulatedTweety',
                r'mock_tweety',
                r'fake_tweety',
            ],
            'taxonomy_mocks': [
                r'MockTaxonomy',
                r'FakeTaxonomy',
                r'mock_taxonomy',
                r'small_taxonomy',
                r'test_taxonomy',
            ]
        }

    def scan_project(self) -> AuthenticityReport:
        """
        Scanne tout le projet pour d√©tecter les mocks.
        
        Returns:
            AuthenticityReport: Rapport complet d'authenticit√©
        """
        logger.info(f"üîç D√©but du scan d'authenticit√© pour {self.project_root}")
        
        report = AuthenticityReport()
        python_files = self._find_python_files()
        
        logger.info(f"üìÅ {len(python_files)} fichiers Python √† analyser")
        
        for file_path in python_files:
            file_mocks = self._scan_file(file_path)
            self._categorize_mocks(file_mocks, report)
        
        # Calcul du score d'authenticit√©
        report.authenticity_score = self._calculate_authenticity_score(report)
        
        # G√©n√©ration des recommandations
        report.recommendations = self._generate_recommendations(report)
        
        logger.info(f"‚úÖ Scan termin√© - Score d'authenticit√©: {report.authenticity_score:.1%}")
        
        return report

    def _find_python_files(self) -> List[Path]:
        """Trouve tous les fichiers Python du projet."""
        python_files = []
        for pattern in ['**/*.py']:
            python_files.extend(self.project_root.glob(pattern))
        
        # Exclusion des fichiers de test et de cache
        excluded_patterns = [
            '**/__pycache__/**',
            '**/test_*',
            '**/tests/**',
            '**/.pytest_cache/**',
            '**/venv/**',
            '**/env/**',
        ]
        
        filtered_files = []
        for file_path in python_files:
            if not any(file_path.match(pattern) for pattern in excluded_patterns):
                filtered_files.append(file_path)
        
        return filtered_files

    def _scan_file(self, file_path: Path) -> List[MockDetection]:
        """
        Scanne un fichier pour d√©tecter les mocks.
        
        Args:
            file_path: Chemin du fichier √† scanner
            
        Returns:
            List[MockDetection]: Liste des mocks d√©tect√©s
        """
        mocks = []
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
                lines = content.splitlines()
            
            # Scan par patterns regex
            mocks.extend(self._scan_with_patterns(file_path, lines))
            
            # Scan AST pour une d√©tection plus pr√©cise
            mocks.extend(self._scan_with_ast(file_path, content))
            
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Erreur lors du scan de {file_path}: {e}")
        
        return mocks

    def _scan_with_patterns(self, file_path: Path, lines: List[str]) -> List[MockDetection]:
        """Scan par patterns regex."""
        mocks = []
        
        for line_num, line in enumerate(lines, 1):
            # Scan des patterns g√©n√©raux
            for category, patterns in self.mock_patterns.items():
                for pattern in patterns:
                    matches = re.finditer(pattern, line, re.IGNORECASE)
                    for match in matches:
                        mock_name = match.group(1) if match.groups() else match.group(0)
                        mocks.append(MockDetection(
                            file_path=str(file_path),
                            line_number=line_num,
                            mock_type=category,
                            mock_name=mock_name,
                            context=line.strip(),
                            severity='medium',
                            replacement_suggestion=self._suggest_replacement(mock_name, category)
                        ))
            
            # Scan des patterns critiques
            for category, patterns in self.critical_patterns.items():
                for pattern in patterns:
                    if re.search(pattern, line, re.IGNORECASE):
                        mocks.append(MockDetection(
                            file_path=str(file_path),
                            line_number=line_num,
                            mock_type=category,
                            mock_name=pattern,
                            context=line.strip(),
                            severity='critical',
                            replacement_suggestion=self._suggest_critical_replacement(pattern, category)
                        ))
        
        return mocks

    def _scan_with_ast(self, file_path: Path, content: str) -> List[MockDetection]:
        """Scan avec analyse AST pour d√©tection avanc√©e."""
        mocks = []
        
        try:
            tree = ast.parse(content)
            
            for node in ast.walk(tree):
                if isinstance(node, ast.ClassDef):
                    if self._is_mock_class(node.name):
                        mocks.append(MockDetection(
                            file_path=str(file_path),
                            line_number=node.lineno,
                            mock_type='class',
                            mock_name=node.name,
                            context=f"class {node.name}",
                            severity=self._determine_severity(node.name),
                            replacement_suggestion=self._suggest_replacement(node.name, 'class')
                        ))
                
                elif isinstance(node, ast.FunctionDef):
                    if self._is_mock_function(node.name):
                        mocks.append(MockDetection(
                            file_path=str(file_path),
                            line_number=node.lineno,
                            mock_type='function',
                            mock_name=node.name,
                            context=f"def {node.name}",
                            severity=self._determine_severity(node.name),
                            replacement_suggestion=self._suggest_replacement(node.name, 'function')
                        ))
        
        except SyntaxError:
            logger.warning(f"‚ö†Ô∏è Erreur de syntaxe dans {file_path} - scan AST ignor√©")
        
        return mocks

    def _is_mock_class(self, name: str) -> bool:
        """D√©termine si un nom de classe est un mock."""
        mock_indicators = ['mock', 'fake', 'stub', 'dummy', 'simulated', 'test']
        return any(indicator in name.lower() for indicator in mock_indicators)

    def _is_mock_function(self, name: str) -> bool:
        """D√©termine si un nom de fonction est un mock."""
        mock_indicators = ['mock', 'fake', 'stub', 'dummy', 'simulate', 'test']
        return any(indicator in name.lower() for indicator in mock_indicators)

    def _determine_severity(self, name: str) -> str:
        """D√©termine la s√©v√©rit√© d'un mock bas√©e sur son nom."""
        critical_keywords = ['llm', 'tweety', 'gpt', 'openai', 'taxonomy']
        high_keywords = ['agent', 'service', 'orchestrat']
        
        name_lower = name.lower()
        
        if any(keyword in name_lower for keyword in critical_keywords):
            return 'critical'
        elif any(keyword in name_lower for keyword in high_keywords):
            return 'high'
        else:
            return 'medium'

    def _suggest_replacement(self, mock_name: str, mock_type: str) -> str:
        """Sugg√®re un remplacement pour un mock."""
        suggestions = {
            'MockLLMService': 'RealLLMService avec GPT-4o-mini',
            'FakeTweetyBridge': 'TweetyBridge avec JAR authentique',
            'MockTaxonomy': 'FullTaxonomy avec 1000 n≈ìuds',
            'mock_agent': 'Agent authentique avec configuration r√©elle',
        }
        
        return suggestions.get(mock_name, f"Remplacer par impl√©mentation r√©elle de {mock_name}")

    def _suggest_critical_replacement(self, pattern: str, category: str) -> str:
        """Sugg√®re un remplacement pour un mock critique."""
        replacements = {
            'llm_service_mocks': 'Utiliser create_llm_service() avec API OpenAI r√©elle',
            'tweety_mocks': 'Utiliser TweetyBridge avec tweety-full.jar',
            'taxonomy_mocks': 'Charger la taxonomie compl√®te 1000 n≈ìuds',
        }
        
        return replacements.get(category, "Remplacer par service authentique")

    def _categorize_mocks(self, file_mocks: List[MockDetection], report: AuthenticityReport):
        """Cat√©gorise les mocks d√©tect√©s dans le rapport."""
        for mock in file_mocks:
            report.total_mocks_detected += 1
            
            if mock.severity == 'critical':
                report.critical_mocks.append(mock)
            elif mock.severity == 'high':
                report.high_priority_mocks.append(mock)
            elif mock.severity == 'medium':
                report.medium_priority_mocks.append(mock)
            else:
                report.low_priority_mocks.append(mock)

    def _calculate_authenticity_score(self, report: AuthenticityReport) -> float:
        """
        Calcule le score d'authenticit√© bas√© sur les mocks d√©tect√©s.
        
        Args:
            report: Rapport d'authenticit√©
            
        Returns:
            float: Score entre 0.0 et 1.0
        """
        if report.total_mocks_detected == 0:
            return 1.0
        
        # Pond√©ration des mocks par s√©v√©rit√©
        critical_weight = 10
        high_weight = 5
        medium_weight = 2
        low_weight = 1
        
        total_penalty = (
            len(report.critical_mocks) * critical_weight +
            len(report.high_priority_mocks) * high_weight +
            len(report.medium_priority_mocks) * medium_weight +
            len(report.low_priority_mocks) * low_weight
        )
        
        # Score bas√© sur la p√©nalit√©
        max_acceptable_penalty = 100  # Seuil arbitraire
        score = max(0.0, 1.0 - (total_penalty / max_acceptable_penalty))
        
        return score

    def _generate_recommendations(self, report: AuthenticityReport) -> List[str]:
        """G√©n√®re des recommandations bas√©es sur le rapport."""
        recommendations = []
        
        if report.critical_mocks:
            recommendations.append("üö® CRITIQUE: √âliminer imm√©diatement les mocks de services essentiels")
            recommendations.append("- Remplacer MockLLMService par service OpenAI r√©el")
            recommendations.append("- Utiliser TweetyBridge authentique avec JAR complet")
            recommendations.append("- Charger la taxonomie compl√®te (1000 n≈ìuds)")
        
        if report.high_priority_mocks:
            recommendations.append("‚ö†Ô∏è HAUTE PRIORIT√â: Remplacer les mocks d'agents")
            recommendations.append("- Utiliser des agents authentiques avec configuration r√©elle")
        
        if report.medium_priority_mocks:
            recommendations.append("üìã MOYENNE PRIORIT√â: Nettoyer les mocks utilitaires")
        
        if report.authenticity_score < 0.8:
            recommendations.append("üéØ OBJECTIF: Atteindre un score d'authenticit√© > 80%")
        
        recommendations.append("‚úÖ VALIDATION: Tester chaque remplacement avec traces compl√®tes")
        
        return recommendations


class MockEliminator:
    """√âlimine automatiquement les mocks d√©tect√©s."""
    
    def __init__(self, project_root: str):
        self.project_root = Path(project_root)
        self.backup_dir = self.project_root / "backups" / "mock_elimination"
        self.backup_dir.mkdir(parents=True, exist_ok=True)

    def eliminate_mocks(self, report: AuthenticityReport) -> Dict[str, Any]:
        """
        √âlimine automatiquement les mocks lorsque possible.
        
        Args:
            report: Rapport d'authenticit√© avec mocks d√©tect√©s
            
        Returns:
            Dict[str, Any]: R√©sultats de l'√©limination
        """
        logger.info("üßπ D√©but de l'√©limination automatique des mocks")
        
        results = {
            'eliminated_mocks': 0,
            'manual_intervention_required': [],
            'errors': [],
            'backups_created': []
        }
        
        # Traiter les mocks par priorit√©
        all_mocks = (
            report.critical_mocks + 
            report.high_priority_mocks + 
            report.medium_priority_mocks + 
            report.low_priority_mocks
        )
        
        for mock in all_mocks:
            try:
                if self._can_auto_eliminate(mock):
                    self._backup_file(mock.file_path)
                    success = self._eliminate_mock(mock)
                    if success:
                        results['eliminated_mocks'] += 1
                    else:
                        results['manual_intervention_required'].append(mock)
                else:
                    results['manual_intervention_required'].append(mock)
                    
            except Exception as e:
                logger.error(f"‚ùå Erreur √©limination {mock.mock_name}: {e}")
                results['errors'].append(f"{mock.mock_name}: {str(e)}")
        
        logger.info(f"‚úÖ √âlimination termin√©e - {results['eliminated_mocks']} mocks √©limin√©s")
        
        return results

    def _can_auto_eliminate(self, mock: MockDetection) -> bool:
        """D√©termine si un mock peut √™tre √©limin√© automatiquement."""
        # Pour l'instant, √©limination conservatrice
        safe_patterns = [
            'test_mock',
            'example_mock',
            'demo_mock'
        ]
        
        return any(pattern in mock.mock_name.lower() for pattern in safe_patterns)

    def _backup_file(self, file_path: str):
        """Cr√©e une sauvegarde du fichier avant modification."""
        import shutil
        from datetime import datetime
        
        source = Path(file_path)
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        backup_name = f"{source.name}.{timestamp}.backup"
        backup_path = self.backup_dir / backup_name
        
        shutil.copy2(source, backup_path)
        logger.info(f"üíæ Sauvegarde cr√©√©e: {backup_path}")

    def _eliminate_mock(self, mock: MockDetection) -> bool:
        """√âlimine un mock sp√©cifique."""
        # Impl√©mentation conservatrice - juste commentaire pour l'instant
        try:
            with open(mock.file_path, 'r', encoding='utf-8') as f:
                lines = f.readlines()
            
            # Commenter la ligne du mock
            line_index = mock.line_number - 1
            if line_index < len(lines):
                lines[line_index] = f"# MOCK ELIMINATED: {lines[line_index]}"
                
                with open(mock.file_path, 'w', encoding='utf-8') as f:
                    f.writelines(lines)
                
                logger.info(f"‚úÖ Mock √©limin√©: {mock.mock_name} dans {mock.file_path}")
                return True
        
        except Exception as e:
            logger.error(f"‚ùå Erreur √©limination {mock.mock_name}: {e}")
        
        return False


def generate_authenticity_report(report: AuthenticityReport, output_path: str):
    """G√©n√®re un rapport d'authenticit√© d√©taill√©."""
    
    with open(output_path, 'w', encoding='utf-8') as f:
        f.write("# Rapport d'Authenticit√© du Syst√®me\n\n")
        f.write(f"**Score d'authenticit√©: {report.authenticity_score:.1%}**\n\n")
        f.write(f"**Mocks d√©tect√©s: {report.total_mocks_detected}**\n\n")
        
        f.write("## R√©sum√© par S√©v√©rit√©\n\n")
        f.write(f"- üö® Critiques: {len(report.critical_mocks)}\n")
        f.write(f"- ‚ö†Ô∏è Haute priorit√©: {len(report.high_priority_mocks)}\n")
        f.write(f"- üìã Moyenne priorit√©: {len(report.medium_priority_mocks)}\n")
        f.write(f"- ‚ÑπÔ∏è Basse priorit√©: {len(report.low_priority_mocks)}\n\n")
        
        # D√©tail des mocks critiques
        if report.critical_mocks:
            f.write("## üö® Mocks Critiques (√âlimination Urgente)\n\n")
            for mock in report.critical_mocks:
                f.write(f"### {mock.mock_name}\n")
                f.write(f"- **Fichier**: `{mock.file_path}`\n")
                f.write(f"- **Ligne**: {mock.line_number}\n")
                f.write(f"- **Type**: {mock.mock_type}\n")
                f.write(f"- **Contexte**: `{mock.context}`\n")
                f.write(f"- **Remplacement sugg√©r√©**: {mock.replacement_suggestion}\n\n")
        
        # Recommandations
        f.write("## üìã Recommandations\n\n")
        for i, rec in enumerate(report.recommendations, 1):
            f.write(f"{i}. {rec}\n")
        
        f.write("\n## üéØ Objectif d'Authenticit√© 100%\n\n")
        f.write("Pour garantir l'authenticit√© compl√®te :\n")
        f.write("1. √âliminer tous les mocks critiques\n")
        f.write("2. Utiliser GPT-4o-mini r√©el exclusivement\n")
        f.write("3. Charger TweetyProject JAR authentique\n")
        f.write("4. Utiliser taxonomie 1000 n≈ìuds compl√®te\n")
        f.write("5. Valider toutes les traces g√©n√©r√©es\n")


async def main():
    """Fonction principale de d√©tection et √©limination des mocks."""
    project_root = Path(__file__).parent.parent.parent
    
    logger.info("üöÄ D√©marrage de l'audit d'authenticit√©")
    
    # 1. D√©tection des mocks
    detector = MockDetector(str(project_root))
    report = detector.scan_project()
    
    # 2. G√©n√©ration du rapport
    report_path = project_root / "reports" / "authenticity_report.md"
    report_path.parent.mkdir(exist_ok=True)
    generate_authenticity_report(report, str(report_path))
    
    logger.info(f"üìÑ Rapport g√©n√©r√©: {report_path}")
    
    # 3. √âlimination automatique (optionnelle)
    eliminator = MockEliminator(str(project_root))
    elimination_results = eliminator.eliminate_mocks(report)
    
    logger.info(f"‚úÖ Audit termin√© - Score: {report.authenticity_score:.1%}")
    
    # 4. R√©sum√© console
    print(f"\nüéØ SCORE D'AUTHENTICIT√â: {report.authenticity_score:.1%}")
    print(f"üìä MOCKS D√âTECT√âS: {report.total_mocks_detected}")
    print(f"üö® CRITIQUES: {len(report.critical_mocks)}")
    print(f"‚ö†Ô∏è HAUTE PRIORIT√â: {len(report.high_priority_mocks)}")
    print(f"üìã RAPPORT COMPLET: {report_path}")


if __name__ == "__main__":
    asyncio.run(main())