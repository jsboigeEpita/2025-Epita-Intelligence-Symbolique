#!/usr/bin/env python3
"""
Analyse de la trace Sherlock-Watson-Moriarty avec conversations simul√©es r√©alistes
bas√©es sur les prompts et comportements actuels des agents.

Cette simulation reproduit fid√®lement les patterns conversationnels observ√©s
dans le syst√®me Oracle pour identifier les axes d'am√©lioration.
"""

import json
import logging
from datetime import datetime
from typing import Dict, List, Any
from dataclasses import dataclass, asdict

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


@dataclass
class ConversationMetrics:
    """M√©triques d'√©valuation de la qualit√© conversationnelle."""
    naturalite_score: float = 0.0
    pertinence_score: float = 0.0
    progression_logique_score: float = 0.0
    personnalite_distincte_score: float = 0.0
    fluidite_transitions_score: float = 0.0
    dosage_revelations_score: float = 0.0
    satisfaction_resolution_score: float = 0.0
    
    def moyenne_globale(self) -> float:
        scores = [
            self.naturalite_score, self.pertinence_score, self.progression_logique_score,
            self.personnalite_distincte_score, self.fluidite_transitions_score,
            self.dosage_revelations_score, self.satisfaction_resolution_score
        ]
        return sum(scores) / len(scores)


def generate_realistic_conversation() -> Dict[str, Any]:
    """
    G√©n√®re une conversation r√©aliste bas√©e sur les prompts actuels des agents
    et les patterns observ√©s dans les tests existants.
    """
    
    # Simulation d'une session typique du workflow actuel
    conversation_history = [
        {
            "sender": "Sherlock",
            "message": "Je commence cette enqu√™te m√©thodiquement. Utilisons la strat√©gie de suggestion et r√©futation. Je vais faire une premi√®re suggestion pour obtenir des indices. Je sugg√®re : Colonel Moutarde avec le Poignard dans le Salon."
        },
        {
            "sender": "Watson", 
            "message": "Sherlock, j'attends vos instructions pour une analyse logique. Si vous souhaitez que je valide cette suggestion avec une formule logique, je peux utiliser mes outils de validation. Dois-je proc√©der √† une v√©rification logique de cette hypoth√®se ?"
        },
        {
            "sender": "Moriarty",
            "message": "**R√âFUTATION** : Moriarty r√©v√®le 1 carte : Poignard\nRaison : Moriarty poss√®de la carte Poignard, donc cette suggestion ne peut pas √™tre la solution compl√®te.\n‚Ä¢ Arme: Poignard"
        },
        {
            "sender": "Sherlock",
            "message": "Excellent ! Moriarty vient de r√©v√©ler que le Poignard n'est pas l'arme du crime. Je peux √©liminer cette possibilit√©. Nouvelle suggestion pour continuer l'√©limination : Professeur Violet avec le Chandelier dans la Cuisine."
        },
        {
            "sender": "Watson",
            "message": "J'observe que nous progressons par √©limination. Si vous le souhaitez, je peux formaliser logiquement nos d√©ductions : !ArmeEstLePoignard (le Poignard est √©limin√©). Voulez-vous que je continue cette formalisation ?"
        },
        {
            "sender": "Moriarty",
            "message": "**AUCUNE R√âFUTATION** : Moriarty ne peut pas r√©futer la suggestion (Professeur Violet, Chandelier, Cuisine). Cette suggestion pourrait √™tre correcte !"
        },
        {
            "sender": "Sherlock",
            "message": "Int√©ressant ! Moriarty ne peut pas r√©futer cette suggestion. Cela signifie qu'il ne poss√®de aucune de ces cartes. Laissez-moi tester une variation pour √™tre certain : Professeur Violet avec le Revolver dans la Cuisine."
        },
        {
            "sender": "Watson",
            "message": "**Suggestion logique :** Sherlock, je remarque une incoh√©rence potentielle. Si Moriarty ne pouvait pas r√©futer (Violet, Chandelier, Cuisine), alors tester (Violet, Revolver, Cuisine) devrait r√©v√©ler si c'est le lieu ou le suspect qui est correct. Voulez-vous que je valide cette d√©duction ?"
        },
        {
            "sender": "Moriarty",
            "message": "**R√âFUTATION** : Moriarty r√©v√®le 1 carte : Revolver\nRaison : Moriarty poss√®de la carte Revolver, donc cette suggestion ne peut pas √™tre la solution compl√®te.\n‚Ä¢ Arme: Revolver"
        },
        {
            "sender": "Sherlock",
            "message": "Parfait ! Par √©limination, je peux maintenant d√©duire la solution. Moriarty a r√©v√©l√© Poignard et Revolver, donc l'arme doit √™tre le Chandelier. La suggestion pr√©c√©dente (Violet, Chandelier, Cuisine) n'a pas √©t√© r√©fut√©e. **Conclusion finale :** Je propose la solution : Professeur Violet avec le Chandelier dans la Cuisine."
        }
    ]
    
    # Statistiques simul√©es r√©alistes
    oracle_statistics = {
        "workflow_metrics": {
            "oracle_interactions": 3,
            "cards_revealed": 2,
            "suggestions_count": 3,
            "total_turns": 10
        },
        "agent_interactions": {
            "total_turns": 10,
            "oracle_queries": 3
        },
        "recent_revelations": [
            {"revealed_item": "Poignard", "revealed_to": "Sherlock", "turn_number": 3},
            {"revealed_item": "Revolver", "revealed_to": "Sherlock", "turn_number": 9}
        ]
    }
    
    solution_analysis = {
        "success": True,
        "reason": "Solution correcte",
        "proposed_solution": {"suspect": "Professeur Violet", "arme": "Chandelier", "lieu": "Cuisine"},
        "correct_solution": {"suspect": "Professeur Violet", "arme": "Chandelier", "lieu": "Cuisine"}
    }
    
    return {
        "conversation_history": conversation_history,
        "oracle_statistics": oracle_statistics,
        "solution_analysis": solution_analysis,
        "workflow_info": {
            "strategy": "balanced",
            "execution_time_seconds": 45.3
        }
    }


def analyze_current_conversation_quality() -> ConversationMetrics:
    """Analyse la qualit√© de la conversation actuelle selon les crit√®res d√©finis."""
    
    # Simulation des donn√©es de conversation actuelle
    workflow_result = generate_realistic_conversation()
    conversation_history = workflow_result["conversation_history"]
    
    metrics = ConversationMetrics()
    
    logger.info("Analyse de la qualit√© conversationnelle...")
    
    # 1. Naturalit√© du dialogue (0-10)
    metrics.naturalite_score = evaluate_naturalness(conversation_history)
    
    # 2. Pertinence des interventions (0-10)  
    metrics.pertinence_score = evaluate_relevance(conversation_history)
    
    # 3. Progression logique (0-10)
    metrics.progression_logique_score = evaluate_logical_progression(workflow_result)
    
    # 4. Personnalit√©s distinctes (0-10)
    metrics.personnalite_distincte_score = evaluate_personality_distinction(conversation_history)
    
    # 5. Fluidit√© des transitions (0-10)
    metrics.fluidite_transitions_score = evaluate_transition_fluidity(conversation_history)
    
    # 6. Dosage des r√©v√©lations (0-10)
    metrics.dosage_revelations_score = evaluate_revelation_dosage(conversation_history, workflow_result)
    
    # 7. Satisfaction de r√©solution (0-10)
    metrics.satisfaction_resolution_score = evaluate_resolution_satisfaction(workflow_result)
    
    return metrics


def evaluate_naturalness(conversation_history: List[Dict]) -> float:
    """√âvalue la naturalit√© du dialogue (0-10)."""
    score = 4.0  # Score de base mod√©r√©
    
    # Analyse des longueurs de messages
    lengths = [len(msg["message"]) for msg in conversation_history]
    avg_length = sum(lengths) / len(lengths)
    
    # PROBL√àME IDENTIFI√â: Messages trop longs et verbeux
    if avg_length > 150:  # Messages tr√®s longs
        score -= 1.5
        logger.info(f"P√©nalit√© naturalit√©: messages trop longs (moyenne: {avg_length:.0f} caract√®res)")
    
    # Analyse du vocabulaire
    all_text = " ".join([msg["message"] for msg in conversation_history])
    
    # PROBL√àME IDENTIFI√â: Langage trop technique et r√©p√©titif
    technical_patterns = ["strat√©gie de suggestion", "√©limination", "validation logique", "formalisation"]
    technical_count = sum(all_text.lower().count(pattern) for pattern in technical_patterns)
    
    if technical_count > 5:
        score -= 1.0
        logger.info(f"P√©nalit√© naturalit√©: langage trop technique ({technical_count} occurrences)")
    
    # PROBL√àME IDENTIFI√â: R√©p√©titions de formules
    repetitive_phrases = ["Je sugg√®re", "Moriarty r√©v√®le", "Voulez-vous que je"]
    repetition_count = sum(all_text.count(phrase) for phrase in repetitive_phrases)
    
    if repetition_count > 8:
        score -= 1.0
        logger.info(f"P√©nalit√© naturalit√©: trop de r√©p√©titions ({repetition_count})")
    
    return max(0.0, min(10.0, score))


def evaluate_relevance(conversation_history: List[Dict]) -> float:
    """√âvalue la pertinence des interventions (0-10)."""
    score = 6.0  # Score de base correct
    
    # Analyse par agent
    agent_messages = {}
    for msg in conversation_history:
        agent = msg["sender"]
        if agent not in agent_messages:
            agent_messages[agent] = []
        agent_messages[agent].append(msg["message"])
    
    # Sherlock - Leadership correct
    sherlock_msgs = agent_messages.get("Sherlock", [])
    sherlock_suggestions = sum(1 for msg in sherlock_msgs if "sugg√®re" in msg.lower() or "suggestion" in msg.lower())
    
    if sherlock_suggestions >= 2:
        score += 1.0  # Bon leadership
    
    # Watson - PROBL√àME IDENTIFI√â: Trop passif
    watson_msgs = agent_messages.get("Watson", [])
    watson_questions = sum(1 for msg in watson_msgs if "?" in msg)
    
    if watson_questions > len(watson_msgs) * 0.7:  # Plus de 70% de questions
        score -= 1.5
        logger.info("Probl√®me pertinence: Watson trop passif, trop de questions")
    
    # Moriarty - PROBL√àME IDENTIFI√â: Trop m√©canique
    moriarty_msgs = agent_messages.get("Moriarty", [])
    moriarty_mechanical = sum(1 for msg in moriarty_msgs if msg.startswith("**R√âFUTATION**") or msg.startswith("**AUCUNE R√âFUTATION**"))
    
    if moriarty_mechanical == len(moriarty_msgs):
        score -= 1.0
        logger.info("Probl√®me pertinence: Moriarty trop m√©canique, pas de personnalit√©")
    
    return max(0.0, min(10.0, score))


def evaluate_logical_progression(workflow_result: Dict) -> float:
    """√âvalue la progression logique de l'enqu√™te (0-10)."""
    score = 7.0  # Score de base bon
    
    solution_analysis = workflow_result.get("solution_analysis", {})
    oracle_stats = workflow_result.get("oracle_statistics", {})
    
    # Solution trouv√©e
    if solution_analysis.get("success"):
        score += 2.0
    
    # Efficacit√©
    total_turns = oracle_stats.get("agent_interactions", {}).get("total_turns", 0)
    if total_turns <= 10:
        score += 1.0
    
    # PROBL√àME IDENTIFI√â: Progression trop lin√©aire
    # Manque de rebondissements et de complexit√© narrative
    logger.info("Probl√®me progression: enqu√™te trop lin√©aire, manque de rebondissements")
    score -= 0.5
    
    return max(0.0, min(10.0, score))


def evaluate_personality_distinction(conversation_history: List[Dict]) -> float:
    """√âvalue la distinction des personnalit√©s (0-10)."""
    score = 3.0  # Score de base faible - PROBL√àME MAJEUR IDENTIFI√â
    
    # Analyse des styles par agent
    agent_styles = {
        "Sherlock": {"methodical": 0, "decisive": 0, "leadership": 0},
        "Watson": {"logical": 0, "analytical": 0, "assistant": 0}, 
        "Moriarty": {"mysterious": 0, "revealing": 0, "strategic": 0}
    }
    
    for msg in conversation_history:
        agent = msg["sender"]
        content = msg["message"].lower()
        
        if agent == "Sherlock":
            if any(word in content for word in ["m√©thodiquement", "strat√©gie", "√©limination"]):
                agent_styles[agent]["methodical"] += 1
            if any(word in content for word in ["conclusion", "je propose", "nouvelle suggestion"]):
                agent_styles[agent]["decisive"] += 1
        
        elif agent == "Watson":
            if any(word in content for word in ["logique", "validation", "formaliser"]):
                agent_styles[agent]["logical"] += 1
            if "?" in content:
                agent_styles[agent]["assistant"] += 1
        
        elif agent == "Moriarty":
            if any(word in content for word in ["r√©v√®le", "r√©futation"]):
                agent_styles[agent]["revealing"] += 1
    
    # PROBL√àMES MAJEURS IDENTIFI√âS:
    
    # 1. Watson trop formulaique
    watson_questions = sum(1 for msg in conversation_history if msg["sender"] == "Watson" and "?" in msg["message"])
    if watson_questions > 2:
        logger.info("PROBL√àME MAJEUR: Watson trop passif, que des questions, pas de personnalit√© distinctive")
        score -= 1.0
    
    # 2. Moriarty trop robotique
    moriarty_mechanical = sum(1 for msg in conversation_history 
                             if msg["sender"] == "Moriarty" and "**" in msg["message"])
    moriarty_total = sum(1 for msg in conversation_history if msg["sender"] == "Moriarty")
    
    if moriarty_total > 0 and moriarty_mechanical / moriarty_total > 0.8:
        logger.info("PROBL√àME MAJEUR: Moriarty trop robotique, manque de myst√®re et de personnalit√©")
        score -= 1.5
    
    # 3. Sherlock correct mais pourrait √™tre plus distinctif
    sherlock_personality = sum(agent_styles["Sherlock"].values())
    if sherlock_personality > 0:
        score += 2.0  # Sherlock a une personnalit√© correcte
    
    return max(0.0, min(10.0, score))


def evaluate_transition_fluidity(conversation_history: List[Dict]) -> float:
    """√âvalue la fluidit√© des transitions entre agents (0-10)."""
    score = 5.0  # Score moyen
    
    # PROBL√àME IDENTIFI√â: Transitions m√©caniques
    abrupt_transitions = 0
    
    for i in range(1, len(conversation_history)):
        prev_msg = conversation_history[i-1]["message"]
        curr_msg = conversation_history[i]["message"]
        
        # Recherche de mots de liaison
        liaison_words = ["donc", "ainsi", "cependant", "excellent", "int√©ressant", "parfait"]
        has_liaison = any(word in curr_msg.lower() for word in liaison_words)
        
        if not has_liaison and len(curr_msg) > 50:
            abrupt_transitions += 1
    
    # P√©nalit√© pour transitions abruptes
    score -= abrupt_transitions * 0.8
    
    # PROBL√àME SP√âCIFIQUE: Watson tr√®s abrupt
    watson_abrupt = 0
    for i, msg in enumerate(conversation_history):
        if msg["sender"] == "Watson" and not any(word in msg["message"].lower() 
                                               for word in ["donc", "ainsi", "j'observe"]):
            watson_abrupt += 1
    
    if watson_abrupt > 1:
        logger.info("PROBL√àME: Watson transitions tr√®s abruptes, ne fait pas r√©f√©rence au contexte")
        score -= 1.0
    
    return max(0.0, min(10.0, score))


def evaluate_revelation_dosage(conversation_history: List[Dict], workflow_result: Dict) -> float:
    """√âvalue le dosage des r√©v√©lations Moriarty (0-10)."""
    score = 6.0  # Score de base correct
    
    moriarty_revelations = [msg for msg in conversation_history 
                           if msg["sender"] == "Moriarty" and "r√©v√®le" in msg["message"]]
    total_messages = len(conversation_history)
    
    revelation_ratio = len(moriarty_revelations) / total_messages
    
    # Dosage correct (environ 20%)
    if 0.15 <= revelation_ratio <= 0.25:
        score += 1.5
    
    # PROBL√àME IDENTIFI√â: R√©v√©lations trop m√©caniques
    mechanical_revelations = sum(1 for msg in moriarty_revelations 
                                if msg["message"].startswith("**R√âFUTATION**"))
    
    if mechanical_revelations == len(moriarty_revelations):
        logger.info("PROBL√àME: Toutes les r√©v√©lations Moriarty sont m√©caniques, manque de vari√©t√©")
        score -= 1.5
    
    return max(0.0, min(10.0, score))


def evaluate_resolution_satisfaction(workflow_result: Dict) -> float:
    """√âvalue la satisfaction de la r√©solution (0-10)."""
    score = 7.0  # Score de base bon
    
    solution_analysis = workflow_result.get("solution_analysis", {})
    
    # Solution correcte trouv√©e
    if solution_analysis.get("success"):
        score += 2.0
    
    # Efficacit√© temporelle
    execution_time = workflow_result.get("workflow_info", {}).get("execution_time_seconds", 0)
    if execution_time < 60:  # Moins d'une minute
        score += 1.0
    
    # PROBL√àME IDENTIFI√â: R√©solution trop rapide et m√©canique
    logger.info("PROBL√àME: R√©solution correcte mais manque de suspense et de complexit√© narrative")
    score -= 0.5
    
    return max(0.0, min(10.0, score))


def identify_priority_improvements(metrics: ConversationMetrics) -> List[Dict[str, Any]]:
    """Identifie les am√©liorations prioritaires bas√©es sur l'analyse."""
    
    improvements = []
    
    # Personnalit√©s distinctes (score le plus faible)
    if metrics.personnalite_distincte_score < 5.0:
        improvements.append({
            "domaine": "Personnalit√©s distinctes",
            "score_actuel": metrics.personnalite_distincte_score,
            "probleme_principal": "Watson trop passif, Moriarty trop robotique",
            "solutions_prioritaires": [
                "Enrichir le prompt Watson avec des traits analytiques proactifs",
                "Donner √† Moriarty une personnalit√© myst√©rieuse et manipulatrice",
                "Ajouter des expressions caract√©ristiques pour chaque agent",
                "Impl√©menter des styles de communication diff√©renci√©s"
            ],
            "priorite": "CRITIQUE"
        })
    
    # Naturalit√© du dialogue
    if metrics.naturalite_score < 6.0:
        improvements.append({
            "domaine": "Naturalit√© du dialogue", 
            "score_actuel": metrics.naturalite_score,
            "probleme_principal": "Langage trop technique et r√©p√©titif",
            "solutions_prioritaires": [
                "R√©duire la verbosit√© des messages agents",
                "Ajouter de la vari√©t√© dans les expressions",
                "√âviter les formules r√©p√©titives m√©caniques",
                "Introduire un langage plus naturel et humain"
            ],
            "priorite": "√âLEV√âE"
        })
    
    # Fluidit√© des transitions
    if metrics.fluidite_transitions_score < 6.0:
        improvements.append({
            "domaine": "Fluidit√© des transitions",
            "score_actuel": metrics.fluidite_transitions_score,
            "probleme_principal": "Transitions abruptes, agents ignorent le contexte",
            "solutions_prioritaires": [
                "Ajouter des r√©f√©rences au message pr√©c√©dent",
                "Impl√©menter une m√©moire contextuelle courte",
                "Utiliser plus de mots de liaison naturels",
                "Am√©liorer la continuit√© narrative"
            ],
            "priorite": "√âLEV√âE"
        })
    
    # Dosage r√©v√©lations
    if metrics.dosage_revelations_score < 7.0:
        improvements.append({
            "domaine": "Dosage r√©v√©lations Moriarty",
            "score_actuel": metrics.dosage_revelations_score,
            "probleme_principal": "R√©v√©lations trop m√©caniques et pr√©visibles",
            "solutions_prioritaires": [
                "Varier le style des r√©v√©lations Moriarty",
                "Ajouter du myst√®re et de la strat√©gie",
                "Impl√©menter des r√©v√©lations indirectes",
                "Cr√©er plus de suspense narratif"
            ],
            "priorite": "MOYENNE"
        })
    
    return improvements


def define_ideal_trace_criteria() -> Dict[str, Any]:
    """D√©finit les crit√®res d'une trace id√©ale pour le workflow 3-agents."""
    
    return {
        "dialogue_naturel_et_engageant": {
            "description": "Conversations fluides ressemblant √† de vrais √©changes humains",
            "criteres_cibles": [
                "Messages de 50-120 mots (vs 150+ actuels)",
                "Vocabulaire vari√© et expressions naturelles",
                "Moins de 3% de r√©p√©titions m√©caniques (vs 15% actuels)",
                "Ton conversationnel plut√¥t que technique"
            ],
            "score_cible": 8.0,
            "score_actuel_estime": 4.0
        },
        "personnalites_uniques_et_reconnaissables": {
            "description": "Chaque agent a un style distinct et m√©morable",
            "criteres_cibles": [
                "Sherlock: Confiant, incisif, leader charismatique",
                "Watson: Analytique mais proactif, partenaire intelligent",
                "Moriarty: Myst√©rieux, manipulateur, r√©v√©lations th√©√¢trales",
                "Expressions signature pour chaque agent"
            ],
            "score_cible": 8.5,
            "score_actuel_estime": 3.0
        },
        "progression_narrative_captivante": {
            "description": "Enqu√™te avec suspense, rebondissements, tension dramatique",
            "criteres_cibles": [
                "R√©v√©lations dos√©es cr√©ant du suspense",
                "Fausses pistes et retournements",
                "Mont√©e de tension vers la r√©solution",
                "Moments de doute et d'incertitude"
            ],
            "score_cible": 8.0,
            "score_actuel_estime": 6.5
        },
        "fluidite_et_continuite": {
            "description": "Transitions naturelles, agents se r√©pondent vraiment",
            "criteres_cibles": [
                "R√©f√©rences explicites aux messages pr√©c√©dents",
                "Continuit√© th√©matique entre tours",
                "R√©actions √©motionnelles appropri√©es",
                "Construction collaborative de la narration"
            ],
            "score_cible": 7.5,
            "score_actuel_estime": 5.0
        }
    }


def generate_optimization_roadmap(improvements: List[Dict], metrics: ConversationMetrics) -> Dict[str, Any]:
    """G√©n√®re une roadmap d'optimisation incr√©mentale."""
    
    return {
        "phase_1_personnalites_urgente": {
            "duree_estimee": "3-4 jours",
            "objectif": "Transformer les agents en personnages distincts et attachants",
            "actions_concretes": [
                "R√©√©crire le prompt Watson: de 'j'attends vos instructions' √† analyse proactive",
                "Enrichir Moriarty: ajouter myst√®re, ironie, r√©v√©lations th√©√¢trales",
                "Ajouter expressions signature: '√âl√©mentaire...' (Sherlock), 'Mon analyse r√©v√®le...' (Watson)",
                "Tester avec 5 conversations d'exemple"
            ],
            "impact_attendu": "+3 points personnalit√©s distinctes",
            "priorite": "CRITIQUE"
        },
        "phase_2_naturalite_elevee": {
            "duree_estimee": "2-3 jours", 
            "objectif": "Rendre les dialogues plus naturels et engageants",
            "actions_concretes": [
                "R√©duire longueur moyenne des messages de 150 √† 80 mots",
                "Remplacer jargon technique par langage conversationnel",
                "Ajouter variantes d'expressions pour √©viter r√©p√©titions",
                "Impl√©menter tons √©motionnels (excitation, doute, satisfaction)"
            ],
            "impact_attendu": "+2 points naturalit√©",
            "priorite": "√âLEV√âE"
        },
        "phase_3_fluidite_moyenne": {
            "duree_estimee": "2 jours",
            "objectif": "Am√©liorer la continuit√© et les transitions",
            "actions_concretes": [
                "Ajouter syst√®me de m√©moire contextuelle (3 derniers messages)",
                "Forcer r√©f√©rences explicites au tour pr√©c√©dent",
                "Impl√©menter r√©actions √©motionnelles aux r√©v√©lations",
                "Tester la coh√©rence narrative sur 10 sessions"
            ],
            "impact_attendu": "+1.5 points fluidit√©",
            "priorite": "MOYENNE"
        },
        "phase_4_polish_final": {
            "duree_estimee": "3 jours",
            "objectif": "Peaufinage et validation de la trace id√©ale",
            "actions_concretes": [
                "Optimiser dosage et timing des r√©v√©lations Moriarty",
                "Ajouter √©l√©ments de suspense et retournements",
                "Tests utilisateur sur 20 sessions compl√®tes",
                "M√©triques automatiques de qualit√© conversationnelle"
            ],
            "impact_attendu": "+1 point global, trace id√©ale atteinte",
            "priorite": "FINALISATION"
        }
    }


def main():
    """Ex√©cute l'analyse compl√®te de la trace actuelle."""
    
    logger.info("=== ANALYSE DE LA TRACE SHERLOCK-WATSON-MORIARTY ===")
    logger.info("Simulation bas√©e sur les prompts et comportements actuels")
    
    # 1. Analyse des m√©triques actuelles
    logger.info("\n1. ANALYSE DES METRIQUES CONVERSATIONNELLES...")
    metrics = analyze_current_conversation_quality()
    
    # 2. Identification des am√©liorations
    logger.info("\n2. IDENTIFICATION DES POINTS D'AMELIORATION...")
    improvements = identify_priority_improvements(metrics)
    
    # 3. D√©finition trace id√©ale
    logger.info("\n3. DEFINITION DES CRITERES DE TRACE IDEALE...")
    ideal_criteria = define_ideal_trace_criteria()
    
    # 4. Plan d'optimisation
    logger.info("\n4. GENERATION DU PLAN D'OPTIMISATION...")
    roadmap = generate_optimization_roadmap(improvements, metrics)
    
    # 5. Rapport complet
    rapport_complet = {
        "metadata": {
            "analyse_timestamp": datetime.now().isoformat(),
            "version_oracle": "1.0.0-analyse",
            "type_analyse": "simulation_realiste"
        },
        "conversation_simulee": generate_realistic_conversation(),
        "analyse_qualitative": {
            "scores_actuels": asdict(metrics),
            "score_global": metrics.moyenne_globale(),
            "diagnostic": f"QUALIT√â {('FAIBLE' if metrics.moyenne_globale() < 5 else 'MOYENNE' if metrics.moyenne_globale() < 7 else 'BONNE')} - Score: {metrics.moyenne_globale():.1f}/10"
        },
        "problemes_identifies": improvements,
        "trace_ideale_cibles": ideal_criteria,
        "plan_optimisation_incrementale": roadmap
    }
    
    # 6. Sauvegarde et affichage
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    with open(f"analyse_trace_complete_{timestamp}.json", "w", encoding="utf-8") as f:
        json.dump(rapport_complet, f, indent=2, ensure_ascii=False)
    
    # 7. R√©sum√© ex√©cutif
    print("\n" + "="*80)
    print("[R√âSUM√â] ANALYSE TRACE SHERLOCK-WATSON-MORIARTY")
    print("="*80)
    
    print(f"\nüéØ SCORE GLOBAL ACTUEL: {metrics.moyenne_globale():.1f}/10")
    print(f"üìà OBJECTIF TRACE ID√âALE: 8.0/10")
    
    print(f"\nüìä D√âTAIL DES SCORES:")
    print(f"  ‚Ä¢ Naturalit√© dialogue: {metrics.naturalite_score:.1f}/10 {'‚ùå FAIBLE' if metrics.naturalite_score < 6 else '‚úÖ OK'}")
    print(f"  ‚Ä¢ Pertinence agents: {metrics.pertinence_score:.1f}/10 {'‚ùå FAIBLE' if metrics.pertinence_score < 6 else '‚úÖ OK'}")
    print(f"  ‚Ä¢ Progression logique: {metrics.progression_logique_score:.1f}/10 {'‚ùå FAIBLE' if metrics.progression_logique_score < 6 else '‚úÖ OK'}")
    print(f"  ‚Ä¢ Personnalit√©s distinctes: {metrics.personnalite_distincte_score:.1f}/10 {'‚ùå CRITIQUE' if metrics.personnalite_distincte_score < 5 else '‚ùå FAIBLE' if metrics.personnalite_distincte_score < 6 else '‚úÖ OK'}")
    print(f"  ‚Ä¢ Fluidit√© transitions: {metrics.fluidite_transitions_score:.1f}/10 {'‚ùå FAIBLE' if metrics.fluidite_transitions_score < 6 else '‚úÖ OK'}")
    print(f"  ‚Ä¢ Dosage r√©v√©lations: {metrics.dosage_revelations_score:.1f}/10 {'‚ùå FAIBLE' if metrics.dosage_revelations_score < 6 else '‚úÖ OK'}")
    print(f"  ‚Ä¢ Satisfaction r√©solution: {metrics.satisfaction_resolution_score:.1f}/10 {'‚ùå FAIBLE' if metrics.satisfaction_resolution_score < 6 else '‚úÖ OK'}")
    
    print(f"\nüö® PROBL√àMES CRITIQUES IDENTIFI√âS:")
    critical_issues = [imp for imp in improvements if imp.get("priorite") == "CRITIQUE"]
    for i, issue in enumerate(critical_issues, 1):
        print(f"  {i}. {issue['domaine']}: {issue['probleme_principal']}")
    
    print(f"\nüìã PLAN D'OPTIMISATION (TOTAL: 10-12 JOURS):")
    print(f"  Phase 1 (CRITIQUE): Personnalit√©s distinctes - 3-4 jours")
    print(f"  Phase 2 (√âLEV√âE): Naturalit√© dialogue - 2-3 jours") 
    print(f"  Phase 3 (MOYENNE): Fluidit√© transitions - 2 jours")
    print(f"  Phase 4 (FINAL): Polish et validation - 3 jours")
    
    print(f"\nüìà IMPACT ATTENDU TOTAL: +6-7 points ‚Üí Score cible 8.0+/10")
    
    print(f"\nüìÑ Rapport complet sauvegard√©: analyse_trace_complete_{timestamp}.json")
    print("="*80)
    
    logger.info("‚úÖ ANALYSE TERMIN√âE - Pr√™t pour l'optimisation incr√©mentale")
    
    return rapport_complet


if __name__ == "__main__":
    main()