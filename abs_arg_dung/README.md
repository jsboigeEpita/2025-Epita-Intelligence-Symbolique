# Agent d'Argumentation Abstraite de Dung
**Ã‰tudiants inscrits** : wassim.badraoui, alexandre.da-silva, roshan.jeyakumar
![Python](https://img.shields.io/badge/python-3.8+-blue.svg)
![TweetyProject](https://img.shields.io/badge/TweetyProject-1.28-green.svg)
![License](https://img.shields.io/badge/license-MIT-blue.svg)

Ce projet implÃ©mente un agent d'argumentation complet basÃ© sur les frameworks d'argumentation abstraite de Dung, utilisant la bibliothÃ¨que TweetyProject pour Java.

## ğŸ¯ FonctionnalitÃ©s

- **Construction de frameworks** : CrÃ©ation interactive et programmatique
- **Calcul d'extensions** : Toutes les sÃ©mantiques principales (grounded, preferred, stable, complete, admissible, ideal, semi-stable)
- **Visualisation graphique** : Rendu des graphes d'argumentation avec mise en Ã©vidence des extensions
- **Analyse avancÃ©e** : PropriÃ©tÃ©s structurelles, statut des arguments, relations sÃ©mantiques
- **Import/Export** : Support JSON, TGF, DOT pour l'interopÃ©rabilitÃ©
- **GÃ©nÃ©ration alÃ©atoire** : Frameworks automatiques pour tests et benchmarks
- **Interface CLI** : Ligne de commande complÃ¨te pour toutes les opÃ©rations
- **Agent amÃ©liorÃ©** : Corrections pour cas problÃ©matiques spÃ©cifiques
- **Tests complets** : Suite de tests unitaires et avancÃ©s
- **Validation automatique** : Script de validation complÃ¨te du projet
- **DÃ©monstration interactive** : PrÃ©sentation guidÃ©e de toutes les fonctionnalitÃ©s

## ğŸ“¦ Installation

### PrÃ©requis
- Python 3.8+
- Java 8+ (pour TweetyProject)

### Installation rapide
```bash
# Cloner le projet
git clone <repository_url>
cd mon_agent_dung

# Installer les dÃ©pendances
pip install -r requirements.txt
```

### Structure du projet
```
mon_agent_dung/
â”œâ”€â”€ agent.py                 # Classe principale DungAgent
â”œâ”€â”€ enhanced_agent.py        # Agent avec corrections
â”œâ”€â”€ framework_generator.py   # GÃ©nÃ©ration de frameworks
â”œâ”€â”€ io_utils.py             # Import/export multi-formats
â”œâ”€â”€ cli.py                  # Interface ligne de commande
â”œâ”€â”€ config.py               # Configuration centralisÃ©e
â”œâ”€â”€ project_info.py         # MÃ©tadonnÃ©es du projet
â”œâ”€â”€ test_agent.py           # Tests unitaires de base
â”œâ”€â”€ advanced_tests.py       # Tests avancÃ©s et complexes
â”œâ”€â”€ benchmark.py            # Benchmarking de performance
â”œâ”€â”€ validate_project.py     # Validation complÃ¨te du projet
â”œâ”€â”€ demo_interactive.py     # DÃ©monstration interactive
â”œâ”€â”€ demo.ipynb              # Notebook Jupyter
â”œâ”€â”€ README.md               # Cette documentation
â”œâ”€â”€ requirements.txt        # DÃ©pendances Python
â”œâ”€â”€ libs/                   # BibliothÃ¨ques TweetyProject JAR
â”œâ”€â”€ data/                   # Dossier pour vos frameworks
â”œâ”€â”€ outputs/                # RÃ©sultats d'export
â””â”€â”€ examples/               # Exemples de frameworks
```

## ğŸš€ DÃ©marrage rapide

### ğŸ¬ DÃ©monstration complÃ¨te
```bash
# DÃ©monstration interactive de toutes les fonctionnalitÃ©s
python demo_interactive.py
```

### âœ… Validation du projet
```bash
# Valider que tout fonctionne correctement
python validate_project.py
```

### ğŸ“Š Informations du projet
```bash
# Voir les mÃ©tadonnÃ©es et statistiques
python cli.py info
python project_info.py
```

### Utilisation programmatique

```python
from agent import DungAgent

# CrÃ©er un agent
agent = DungAgent()

# Construire un framework
agent.add_argument("a")
agent.add_argument("b") 
agent.add_argument("c")

agent.add_attack("a", "b")
agent.add_attack("b", "c")

# Analyser
grounded = agent.get_grounded_extension()
preferred = agent.get_preferred_extensions()

print(f"Extension fondÃ©e: {grounded}")
print(f"Extensions prÃ©fÃ©rÃ©es: {preferred}")

# Analyse complÃ¨te
agent.analyze_semantics_relationships()
agent.print_all_arguments_status()

# Visualisation
agent.visualize_graph()
```

### Interface en ligne de commande

```bash
# CrÃ©er un framework interactivement
python cli.py create

# GÃ©nÃ©rer un framework alÃ©atoire
python cli.py random --size 10 --prob 0.4 --save my_framework.json

# Analyser un framework existant
python cli.py analyze my_framework.json --export analysis_report.json

# Voir les exemples classiques
python cli.py examples --list
python cli.py examples --run triangle

# Convertir entre formats
python cli.py convert framework.json framework.tgf --format tgf

# Informations du projet
python cli.py info
```

## ğŸ“Š Exemples d'utilisation

### Framework simple
```python
agent = DungAgent()
agent.add_argument("manger_viande")
agent.add_argument("etre_vegetarien") 
agent.add_argument("sante")

agent.add_attack("etre_vegetarien", "manger_viande")
agent.add_attack("sante", "manger_viande")

# Analyse du dÃ©bat
agent.analyze_semantics_relationships()
```

### GÃ©nÃ©ration et test de masse
```python
from framework_generator import FrameworkGenerator

# 100 frameworks alÃ©atoires pour analyse statistique
for i in range(100):
    agent = FrameworkGenerator.generate_random_framework(
        num_args=8, 
        attack_probability=0.3, 
        seed=i
    )
    properties = agent.get_framework_properties()
    print(f"Framework {i}: {properties['num_arguments']} args, cycles: {properties['has_cycles']}")
```

### Comparaison agent standard vs amÃ©liorÃ©
```python
from enhanced_agent import EnhancedDungAgent

# Cas problÃ©matique : self-attack
standard_agent = DungAgent()
enhanced_agent = EnhancedDungAgent()

for agent in [standard_agent, enhanced_agent]:
    agent.add_argument("a")
    agent.add_argument("b")
    agent.add_attack("a", "a")  # Self-attack
    agent.add_attack("a", "b")

print("Standard:", standard_agent.get_grounded_extension())
print("AmÃ©liorÃ©:", enhanced_agent.get_grounded_extension())
```

## ğŸ§ª Tests et Validation

### Tests de base
```bash
python test_agent.py
```

### Tests avancÃ©s (frameworks complexes)
```bash
python advanced_tests.py
```

### Benchmark de performance
```bash
python benchmark.py
```

### Validation complÃ¨te
```bash
# Script qui exÃ©cute tous les tests et validations
python validate_project.py
```

## ğŸ¯ DÃ©monstrations

### DÃ©monstration interactive
```bash
# PrÃ©sentation guidÃ©e de toutes les fonctionnalitÃ©s
python demo_interactive.py
```

### Notebook Jupyter
Ouvrez `demo.ipynb` pour une dÃ©monstration dÃ©taillÃ©e avec visualisations.

### Exemples via CLI
```bash
# Lister tous les exemples disponibles
python cli.py examples --list

# ExÃ©cuter un exemple spÃ©cifique
python cli.py examples --run triangle

# CrÃ©er un framework interactivement
python cli.py create --enhanced
```

## ğŸ› ï¸ Scripts utilitaires

| Script | Description | Usage |
|--------|-------------|-------|
| `validate_project.py` | Validation complÃ¨te | `python validate_project.py` |
| `demo_interactive.py` | DÃ©monstration guidÃ©e | `python demo_interactive.py` |
| `benchmark.py` | Tests de performance | `python benchmark.py` |
| `project_info.py` | Informations dÃ©taillÃ©es | `python project_info.py` |
| `cli.py` | Interface ligne de commande | `python cli.py --help` |

## ğŸ“ˆ RÃ©sultats de tests rÃ©cents

âœ… **Tests avancÃ©s** : 11/11 rÃ©ussis  
âœ… **CohÃ©rence sÃ©mantique** : 100%  
âœ… **Performance** : Passage Ã  l'Ã©chelle jusqu'Ã  16+ arguments  
âœ… **Agent amÃ©liorÃ©** : 12/15 corrections dÃ©tectÃ©es  

## ğŸ¨ Formats d'export Ã©tendus

| Format | Extension | Usage | Outil compatible |
|--------|-----------|-------|------------------|
| **JSON** | `.json` | Format principal | Universel |
| **TGF** | `.tgf` | Graphes simples | Gephi, yEd |
| **DOT** | `.dot` | Rendu professionnel | GraphViz |
| **Analyse** | `.json` | Rapports complets | Analyse statistique |

## ğŸ† Points forts du projet

- âœ… **ComplÃ©tude** : Toutes les sÃ©mantiques d'argumentation standard
- âœ… **Performance** : Cache optimisÃ©, passage Ã  l'Ã©chelle
- âœ… **Robustesse** : Tests exhaustifs, gestion des cas limites
- âœ… **UtilisabilitÃ©** : CLI intuitive, dÃ©monstrations interactives
- âœ… **ExtensibilitÃ©** : Architecture modulaire, formats multiples
- âœ… **QualitÃ©** : Documentation complÃ¨te, validation automatique

## ğŸ¯ Cas d'usage

1. **Recherche acadÃ©mique** : Validation d'algorithmes d'argumentation
2. **Enseignement** : Illustration des concepts d'argumentation formelle
3. **DÃ©veloppement** : Base pour applications d'argumentation
4. **Analyse** : Ã‰tude de dÃ©bats structurÃ©s
5. **Benchmarking** : Tests de performance d'implÃ©mentations

## ğŸš€ Pour commencer

```bash
# 1. Validation rapide
python validate_project.py

# 2. DÃ©monstration interactive
python demo_interactive.py

# 3. Premier framework
python cli.py create

# 4. Analyse d'exemples
python cli.py examples
```
