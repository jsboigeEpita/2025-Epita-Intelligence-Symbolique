{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Réparation des bornes défectueuses dans les extraits\n",
    "\n",
    "Ce notebook permet d'exécuter interactivement le script de réparation des bornes défectueuses dans les extraits définis dans `extract_sources.json`.\n",
    "\n",
    "## Contexte\n",
    "\n",
    "Notre application d'analyse d'argumentation utilise un système d'extraits définis par des marqueurs de début et de fin dans des textes sources. Certains extraits présentent des problèmes de bornes (marqueurs introuvables ou incorrects), notamment dans le corpus de discours d'Hitler qui est particulièrement volumineux.\n",
    "\n",
    "Ce notebook permet de :\n",
    "\n",
    "1. Analyser les extraits existants pour détecter les bornes défectueuses\n",
    "2. Proposer des corrections automatiques pour les bornes défectueuses\n",
    "3. Valider les corrections proposées\n",
    "4. Sauvegarder les définitions corrigées\n",
    "5. Générer un rapport détaillé des modifications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importation des modules nécessaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import logging\n",
    "import asyncio\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any, Tuple, Optional, Union\n",
    "import semantic_kernel as sk\n",
    "from semantic_kernel.contents import ChatMessageContent\n",
    "from semantic_kernel.agents import ChatCompletionAgent\n",
    "from semantic_kernel.functions.kernel_arguments import KernelArguments\n",
    "\n",
    "# Ajouter le répertoire parent au chemin d'importation\n",
    "import sys\n",
    "sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(\"__file__\"), '../..')))\n",
    "\n",
    "# Imports depuis les modules du projet\n",
    "try:\n",
    "    from argumentation_analysis.ui.config import ENCRYPTION_KEY, CONFIG_FILE, CONFIG_FILE_JSON\n",
    "    from argumentation_analysis.ui.utils import load_from_cache, reconstruct_url\n",
    "    from argumentation_analysis.ui.extract_utils import (\n",
    "        load_source_text, extract_text_with_markers, find_similar_text,\n",
    "        load_extract_definitions_safely, save_extract_definitions_safely\n",
    "    )\n",
    "    from argumentation_analysis.core.llm_service import create_llm_service\n",
    "except ImportError:\n",
    "    # Fallback pour les imports relatifs\n",
    "    from ...ui.config import ENCRYPTION_KEY, CONFIG_FILE, CONFIG_FILE_JSON\n",
    "    from ...ui.utils import load_from_cache, reconstruct_url\n",
    "    from ...ui.extract_utils import (\n",
    "        load_source_text, extract_text_with_markers, find_similar_text,\n",
    "        load_extract_definitions_safely, save_extract_definitions_safely\n",
    "    )\n",
    "    from ...core.llm_service import create_llm_service\n",
    "\n",
    "# Import du script de réparation\n",
    "from repair_extract_markers import (\n",
    "    ExtractRepairPlugin, setup_agents, analyze_extract,\n",
    "    repair_extract_markers, generate_report\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration du logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration du logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s [%(levelname)s] [%(name)s] %(message)s',\n",
    "    datefmt='%H:%M:%S'\n",
    ")\n",
    "logger = logging.getLogger(\"RepairExtractMarkers\")\n",
    "\n",
    "# Création d'un handler pour écrire les logs dans un fichier\n",
    "file_handler = logging.FileHandler(\"repair_extract_markers.log\")\n",
    "file_handler.setFormatter(logging.Formatter('%(asctime)s [%(levelname)s] [%(name)s] %(message)s', datefmt='%H:%M:%S'))\n",
    "logger.addHandler(file_handler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Chargement des définitions d'extraits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger les définitions d'extraits\n",
    "extract_definitions, error_message = load_extract_definitions_safely(CONFIG_FILE, ENCRYPTION_KEY, CONFIG_FILE_JSON)\n",
    "if error_message:\n",
    "    logger.error(f\"Erreur lors du chargement des définitions d'extraits: {error_message}\")\n",
    "else:\n",
    "    logger.info(f\"{len(extract_definitions)} sources chargées.\")\n",
    "    \n",
    "# Afficher un résumé des sources et extraits\n",
    "print(f\"\\n=== Résumé des sources et extraits ===\")\n",
    "total_extracts = 0\n",
    "for i, source in enumerate(extract_definitions):\n",
    "    source_name = source.get(\"source_name\", f\"Source #{i}\")\n",
    "    extracts = source.get(\"extracts\", [])\n",
    "    total_extracts += len(extracts)\n",
    "    print(f\"Source {i+1}: {source_name} - {len(extracts)} extraits\")\n",
    "print(f\"\\nTotal: {len(extract_definitions)} sources, {total_extracts} extraits\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Analyse des extraits existants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour analyser les extraits existants sans les modifier\n",
    "def analyze_extracts(extract_definitions):\n",
    "    results = {\n",
    "        \"valid\": [],\n",
    "        \"invalid\": []\n",
    "    }\n",
    "    \n",
    "    for source_idx, source_info in enumerate(extract_definitions):\n",
    "        source_name = source_info.get(\"source_name\", f\"Source #{source_idx}\")\n",
    "        print(f\"\\nAnalyse de la source '{source_name}'...\")\n",
    "        \n",
    "        # Chargement du texte source\n",
    "        source_text, url = load_source_text(source_info)\n",
    "        if not source_text:\n",
    "            print(f\"  ❌ Impossible de charger le texte source: {url}\")\n",
    "            continue\n",
    "        \n",
    "        print(f\"  ✅ Texte source chargé ({len(source_text)} caractères)\")\n",
    "        \n",
    "        extracts = source_info.get(\"extracts\", [])\n",
    "        for extract_idx, extract_info in enumerate(extracts):\n",
    "            extract_name = extract_info.get(\"extract_name\", f\"Extrait #{extract_idx}\")\n",
    "            start_marker = extract_info.get(\"start_marker\", \"\")\n",
    "            end_marker = extract_info.get(\"end_marker\", \"\")\n",
    "            template_start = extract_info.get(\"template_start\", \"\")\n",
    "            \n",
    "            # Extraction du texte avec les marqueurs actuels\n",
    "            extracted_text, status, start_found, end_found = extract_text_with_markers(\n",
    "                source_text, start_marker, end_marker, template_start\n",
    "            )\n",
    "            \n",
    "            # Afficher le résultat\n",
    "            if start_found and end_found:\n",
    "                print(f\"  ✅ Extrait '{extract_name}' valide\")\n",
    "                results[\"valid\"].append({\n",
    "                    \"source_name\": source_name,\n",
    "                    \"extract_name\": extract_name,\n",
    "                    \"status\": status\n",
    "                })\n",
    "            else:\n",
    "                print(f\"  ❌ Extrait '{extract_name}' invalide: {status}\")\n",
    "                results[\"invalid\"].append({\n",
    "                    \"source_name\": source_name,\n",
    "                    \"extract_name\": extract_name,\n",
    "                    \"status\": status,\n",
    "                    \"start_found\": start_found,\n",
    "                    \"end_found\": end_found\n",
    "                })\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Analyser les extraits existants\n",
    "analysis_results = analyze_extracts(extract_definitions)\n",
    "\n",
    "# Afficher un résumé des résultats\n",
    "print(f\"\\n=== Résumé de l'analyse ===\")\n",
    "print(f\"Extraits valides: {len(analysis_results['valid'])}\")\n",
    "print(f\"Extraits invalides: {len(analysis_results['invalid'])}\")\n",
    "\n",
    "# Afficher les extraits invalides\n",
    "if analysis_results['invalid']:\n",
    "    print(f\"\\n=== Extraits invalides ===\")\n",
    "    for i, invalid in enumerate(analysis_results['invalid']):\n",
    "        print(f\"{i+1}. {invalid['source_name']} -> {invalid['extract_name']}\")\n",
    "        print(f\"   Statut: {invalid['status']}\")\n",
    "        print(f\"   Marqueur début trouvé: {'Oui' if invalid['start_found'] else 'Non'}\")\n",
    "        print(f\"   Marqueur fin trouvé: {'Oui' if invalid['end_found'] else 'Non'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Réparation des bornes défectueuses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer le service LLM\n",
    "llm_service = create_llm_service()\n",
    "if not llm_service:\n",
    "    logger.error(\"Impossible de créer le service LLM.\")\n",
    "else:\n",
    "    logger.info(f\"Service LLM créé: {llm_service.service_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option pour filtrer les sources (corpus Hitler uniquement)\n",
    "filter_hitler_only = False  # Mettre à True pour traiter uniquement le corpus de discours d'Hitler\n",
    "\n",
    "# Filtrer les sources si l'option est activée\n",
    "filtered_definitions = extract_definitions\n",
    "if filter_hitler_only:\n",
    "    original_count = len(filtered_definitions)\n",
    "    filtered_definitions = [\n",
    "        source for source in filtered_definitions \n",
    "        if \"hitler\" in source.get(\"source_name\", \"\").lower()\n",
    "    ]\n",
    "    print(f\"Filtrage des sources: {len(filtered_definitions)}/{original_count} sources retenues (corpus Hitler).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Réparer les bornes défectueuses\n",
    "async def run_repair():\n",
    "    updated_definitions, results = await repair_extract_markers(filtered_definitions, llm_service)\n",
    "    return updated_definitions, results\n",
    "\n",
    "# Exécuter la réparation\n",
    "updated_definitions, repair_results = await run_repair()\n",
    "\n",
    "# Afficher un résumé des résultats\n",
    "status_counts = {\"valid\": 0, \"repaired\": 0, \"rejected\": 0, \"unchanged\": 0, \"error\": 0}\n",
    "for result in repair_results:\n",
    "    status = result.get(\"status\", \"error\")\n",
    "    if status in status_counts:\n",
    "        status_counts[status] += 1\n",
    "\n",
    "print(f\"\\n=== Résumé des réparations ===\")\n",
    "print(f\"Total des extraits analysés: {len(repair_results)}\")\n",
    "print(f\"Extraits valides: {status_counts['valid']}\")\n",
    "print(f\"Extraits réparés: {status_counts['repaired']}\")\n",
    "print(f\"Réparations rejetées: {status_counts['rejected']}\")\n",
    "print(f\"Extraits inchangés: {status_counts['unchanged']}\")\n",
    "print(f\"Erreurs: {status_counts['error']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Génération du rapport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Générer le rapport\n",
    "output_file = \"repair_report.html\"\n",
    "generate_report(repair_results, output_file)\n",
    "print(f\"Rapport généré dans '{output_file}'.\")\n",
    "\n",
    "# Afficher le rapport dans le notebook\n",
    "from IPython.display import IFrame\n",
    "IFrame(src=output_file, width=\"100%\", height=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Sauvegarde des modifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option pour sauvegarder les modifications\n",
    "save_changes = False  # Mettre à True pour sauvegarder les modifications\n",
    "\n",
    "if save_changes:\n",
    "    print(\"Sauvegarde des modifications...\")\n",
    "    success, error_message = save_extract_definitions_safely(\n",
    "        updated_definitions, CONFIG_FILE, ENCRYPTION_KEY, CONFIG_FILE_JSON\n",
    "    )\n",
    "    if success:\n",
    "        print(\"✅ Modifications sauvegardées avec succès.\")\n",
    "    else:\n",
    "        print(f\"❌ Erreur lors de la sauvegarde des modifications: {error_message}\")\n",
    "else:\n",
    "    print(\"Les modifications n'ont pas été sauvegardées (mettez save_changes=True pour sauvegarder).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Analyse des extraits après réparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyser les extraits après réparation\n",
    "if save_changes:\n",
    "    print(\"\\nAnalyse des extraits après réparation...\")\n",
    "    \n",
    "    # Recharger les définitions d'extraits\n",
    "    updated_extract_definitions, error_message = load_extract_definitions_safely(CONFIG_FILE, ENCRYPTION_KEY, CONFIG_FILE_JSON)\n",
    "    if error_message:\n",
    "        print(f\"Erreur lors du chargement des définitions d'extraits: {error_message}\")\n",
    "    else:\n",
    "        # Analyser les extraits mis à jour\n",
    "        updated_analysis_results = analyze_extracts(updated_extract_definitions)\n",
    "        \n",
    "        # Afficher un résumé des résultats\n",
    "        print(f\"\\n=== Résumé de l'analyse après réparation ===\")\n",
    "        print(f\"Extraits valides: {len(updated_analysis_results['valid'])}\")\n",
    "        print(f\"Extraits invalides: {len(updated_analysis_results['invalid'])}\")\n",
    "        \n",
    "        # Comparer avec l'analyse initiale\n",
    "        print(f\"\\n=== Comparaison avant/après réparation ===\")\n",
    "        print(f\"Extraits valides avant: {len(analysis_results['valid'])} -> après: {len(updated_analysis_results['valid'])}\")\n",
    "        print(f\"Extraits invalides avant: {len(analysis_results['invalid'])} -> après: {len(updated_analysis_results['invalid'])}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}