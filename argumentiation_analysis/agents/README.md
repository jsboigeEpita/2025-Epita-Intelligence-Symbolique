# ğŸ§  Agents IA (`agents/`)

Ce rÃ©pertoire contient les dÃ©finitions spÃ©cifiques Ã  chaque agent IA participant Ã  l'analyse rhÃ©torique collaborative. La structure a Ã©tÃ© rÃ©organisÃ©e pour une meilleure modularitÃ© et maintenabilitÃ©.

[Retour au README Principal](../README.md)

## Point d'entrÃ©e pour instance VSCode dÃ©diÃ©e

Ce README sert de point d'entrÃ©e pour une instance VSCode dÃ©diÃ©e au dÃ©veloppement et Ã  la maintenance des agents IA. Cette approche multi-instance permet de travailler spÃ©cifiquement sur les agents sans avoir Ã  gÃ©rer l'ensemble du projet.

## Structure

### Agents Principaux

* **[`core/`](./core/README.md)** : RÃ©pertoire contenant les agents principaux du systÃ¨me
  * **[`core/pm/`](./core/pm/README.md)** ğŸ§‘â€ğŸ« : Agent Project Manager - Orchestre l'analyse.
  * **[`core/informal/`](./core/informal/README.md)** ğŸ§ : Agent d'Analyse Informelle - Identifie arguments et sophismes.
  * **[`core/pl/`](./core/pl/README.md)** ğŸ“ : Agent de Logique Propositionnelle - GÃ¨re la formalisation et l'interrogation logique via Tweety.
  * **[`core/extract/`](./core/extract/README.md)** ğŸ“‘ : Agent d'Extraction - GÃ¨re l'extraction et la rÃ©paration des extraits de texte.

### Outils et Utilitaires

* **[`tools/`](./tools/README.md)** ğŸ› ï¸ : Outils et utilitaires utilisÃ©s par les agents
  * **[`tools/optimization/`](./tools/optimization/README.md)** âš™ï¸ : Outils d'optimisation des agents
  * **[`tools/analysis/`](./tools/analysis/README.md)** ğŸ“Š : Outils d'analyse des rÃ©sultats des agents
  * **[`tools/encryption/`](./tools/encryption/README.md)** ğŸ”’ : SystÃ¨me d'encryption pour sÃ©curiser les donnÃ©es sensibles

### Scripts d'ExÃ©cution

* **[`runners/`](./runners/README.md)** ğŸš€ : Scripts d'exÃ©cution pour les agents
  * **[`runners/test/`](./runners/test/README.md)** ğŸ§ª : Scripts pour l'exÃ©cution des tests
  * **[`runners/deploy/`](./runners/deploy/README.md)** ğŸ“¦ : Scripts de dÃ©ploiement
  * **[`runners/integration/`](./runners/integration/README.md)** ğŸ”„ : Scripts d'intÃ©gration

### DonnÃ©es et BibliothÃ¨ques

* **[`data/`](./data/)** ğŸ“ : DonnÃ©es utilisÃ©es par les agents
* **[`libs/`](./libs/)** ğŸ“¦ : BibliothÃ¨ques partagÃ©es

### Documentation et Traces

* **[`docs/`](./docs/README.md)** ğŸ“š : Documentation du projet
  * **[`docs/reports/`](./docs/reports/README.md)** ğŸ“ : Rapports d'analyse et de test

* **[`traces/`](./traces/README.md)** ğŸ“ : Traces d'exÃ©cution des agents (sÃ©parÃ©es du code)
  * **[`traces/informal/`](./traces/informal/README.md)** ğŸ§ : Traces de l'agent d'analyse informelle
  * **[`traces/orchestration/`](./traces/orchestration/README.md)** ğŸ® : Traces de l'orchestration

### Templates

* **[`templates/`](./templates/README.md)** ğŸ“‹ : Templates pour nouveaux agents
  * **[`templates/student_template/`](./templates/student_template/README.md)** ğŸ“ : Template pour les Ã©tudiants

## Structure des Agents

Chaque sous-rÃ©pertoire d'agent dans `core/` contient typiquement :
* `__init__.py`: Fichier vide ou avec des imports pour faciliter l'accÃ¨s aux fonctions.
* `*_definitions.py`: Classes Plugin (si besoin), fonction `setup_*_kernel`, constante `*_INSTRUCTIONS`.
* `prompts.py`: Constantes contenant les prompts sÃ©mantiques pour l'agent.
* `*_agent.py`: Classe principale de l'agent avec ses mÃ©thodes spÃ©cifiques.
* `README.md`: Documentation spÃ©cifique Ã  l'agent.

## DÃ©veloppement des agents

### CrÃ©ation d'un nouvel agent

Pour crÃ©er un nouvel agent, suivez ces Ã©tapes :

1. Utilisez le template Ã©tudiant comme base (`templates/student_template/`)
2. CrÃ©ez un nouveau sous-rÃ©pertoire dans `core/` avec le nom de l'agent (ex: `core/new_agent/`)
3. Copiez les fichiers du template et adaptez-les Ã  votre agent
4. ImplÃ©mentez les fonctionnalitÃ©s spÃ©cifiques Ã  l'agent
5. Mettez Ã  jour l'orchestrateur principal pour intÃ©grer le nouvel agent

### Test indÃ©pendant des agents

Pour tester un agent de maniÃ¨re indÃ©pendante, vous pouvez crÃ©er un script de test dans le rÃ©pertoire `runners/test/[agent_name]/`. Exemple :

```python
# runners/test/new_agent/test_new_agent.py
import asyncio
import sys
import os
from pathlib import Path

# Ajouter le rÃ©pertoire parent au chemin de recherche des modules
current_dir = Path(__file__).parent
parent_dir = current_dir.parent.parent.parent
if str(parent_dir) not in sys.path:
    sys.path.append(str(parent_dir))

from dotenv import load_dotenv
load_dotenv(override=True)

from core.llm_service import create_llm_service
from agents.core.new_agent.new_agent_definitions import setup_new_agent

async def test_agent():
    # CrÃ©er le service LLM
    llm_service = create_llm_service()
    
    # Initialiser l'agent
    kernel, agent = await setup_new_agent(llm_service)
    
    # Tester une fonctionnalitÃ© spÃ©cifique
    result = await agent.some_function("Texte de test")
    print(f"RÃ©sultat: {result}")

if __name__ == "__main__":
    asyncio.run(test_agent())
```

ExÃ©cutez le test avec :
```bash
python agents/runners/test/new_agent/test_new_agent.py
```

## IntÃ©gration avec l'orchestrateur principal

Pour intÃ©grer un nouvel agent dans l'analyse complÃ¨te, vous devez :

1. Ajouter l'importation de l'agent dans `orchestration/analysis_runner.py`
2. Initialiser l'agent dans la fonction `setup_agents()`
3. Ajouter l'agent Ã  la liste des agents disponibles
4. Mettre Ã  jour la logique d'orchestration pour utiliser le nouvel agent

## DÃ©veloppement avec l'approche multi-instance

1. Ouvrez ce rÃ©pertoire (`agents/`) comme dossier racine dans une instance VSCode dÃ©diÃ©e
2. Travaillez sur les agents sans Ãªtre distrait par les autres parties du projet
3. Testez vos modifications avec les scripts de test indÃ©pendants
4. Une fois les modifications validÃ©es, intÃ©grez-les dans le projet principal

## Bonnes pratiques

- Gardez les prompts dans des fichiers sÃ©parÃ©s pour faciliter leur maintenance
- Documentez clairement les fonctionnalitÃ©s et les paramÃ¨tres de chaque agent
- Utilisez des tests unitaires pour valider le comportement des agents
- Suivez une structure cohÃ©rente pour tous les agents
- Utilisez des noms explicites pour les fonctions et les variables
- CrÃ©ez des backups des fichiers avant de les modifier
- Documentez les modifications apportÃ©es aux agents dans des rapports dÃ©diÃ©s
- Utilisez les outils d'optimisation pour amÃ©liorer les performances des agents

## Nouveaux DÃ©veloppements

### Optimisation des Agents

Le dossier `tools/optimization/` contient des outils pour analyser et amÃ©liorer les performances des agents :

- **Analyse de la taxonomie** : Visualisation et analyse de la structure de la taxonomie des sophismes.
- **Optimisation des prompts** : AmÃ©lioration des instructions et des prompts de l'agent.
- **AmÃ©lioration des performances** : Scripts pour amÃ©liorer les performances de l'agent.
- **Comparaison des versions** : Outils pour comparer diffÃ©rentes versions de l'agent.

### Tests Ã  Grande Ã‰chelle

Les scripts dans `runners/integration/` permettent de tester l'orchestration des agents sur un grand nombre de textes, afin d'Ã©valuer :

- La robustesse du systÃ¨me
- Les performances des agents
- La qualitÃ© des analyses produites
- Les temps d'exÃ©cution

Les rÃ©sultats de ces tests sont documentÃ©s dans `docs/reports/`.

### Traces d'ExÃ©cution

Le dossier `traces/` contient les traces d'exÃ©cution des agents, permettant :

- D'analyser le comportement des agents
- D'identifier les points d'amÃ©lioration
- De comparer diffÃ©rentes versions des agents
- De documenter les performances sur diffÃ©rents types de textes