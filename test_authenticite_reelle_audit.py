#!/usr/bin/env python3
"""
TEST AUTHENTICIT√â R√âELLE - AUDIT COMPLET
========================================

Mission: Prouver l'authenticit√© du syst√®me par des tests r√©els avec gpt-4o-mini + TweetyProject
Objectif: √âliminer mocks de complaisance et g√©n√©rer traces auditables authentiques

Date: 09/06/2025
Auteur: Syst√®me d'Audit d'Authenticit√©
"""

import asyncio
import json
import time
import os
import uuid
import hashlib
from datetime import datetime
from typing import Dict, List, Any, Optional, Tuple
from pathlib import Path
import logging
import requests
import subprocess
import openai
import semantic_kernel as sk
from semantic_kernel.kernel import Kernel
from semantic_kernel.connectors.ai.open_ai import OpenAIChatCompletion

# Configuration logging avec traces d√©taill√©es
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s.%(msecs)03d - [%(levelname)s] %(name)s - %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S'
)
logger = logging.getLogger(__name__)

class MockEliminationEngine:
    """Moteur d'√©limination syst√©matique des mocks."""
    
    def __init__(self):
        self.mock_detections = []
        self.eliminated_mocks = []
        self.authentic_components = {}
        
    def scan_for_mocks(self) -> Dict[str, List[str]]:
        """Scan complet pour identifier tous les mocks."""
        logger.info("[SCAN] DEBUT SCAN ELIMINATION MOCKS")
        
        mock_patterns = [
            "unittest.mock", "Mock(", "AsyncMock", "MagicMock", 
            "mock_", "fake_", "dummy", "test_key", 
            "sk-test-", "example.com", "placeholder",
            "assert True", "return True", "pass.*#.*test"
        ]
        
        mock_files = {
            "config_files": [
                "config/.env",
                "config/test.env"
            ],
            "test_files": [
                "tests/validation_sherlock_watson/",
                "tests/unit/mocks/",
                "tests/utils/common_test_helpers.py"
            ],
            "orchestration_files": [
                "argumentation_analysis/orchestration/cluedo_orchestrator.py"
            ]
        }
        
        detected_mocks = {}
        
        for category, files in mock_files.items():
            detected_mocks[category] = []
            for file_path in files:
                if os.path.exists(file_path):
                    detected_mocks[category].append(file_path)
                    logger.warning(f"[MOCK] MOCK DETECTE: {file_path}")
        
        self.mock_detections = detected_mocks
        return detected_mocks
    
    def eliminate_env_mock(self) -> bool:
        """D√âSACTIV√â - Ne modifie plus le .env pour prot√©ger la vraie cl√© API."""
        env_path = "config/.env"
        
        if not os.path.exists(env_path):
            logger.error(f"Fichier {env_path} introuvable")
            return False
            
        logger.info("[SAFE] VERIFICATION CLE API (sans modification)")
        
        # Lire le fichier sans le modifier
        with open(env_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # V√©rifier si une vraie cl√© est pr√©sente
        if "sk-proj-" in content or ("sk-" in content and "test" not in content.lower() and "dummy" not in content.lower()):
            logger.info("[OK] VRAIE CLE API DETECTEE - Pas de modification n√©cessaire")
            self.eliminated_mocks.append("env_real_key_detected")
            return True
        elif "sk-test-dummy-key-for-testing" in content:
            logger.warning("[WARNING] Cl√© factice d√©tect√©e mais modification d√©sactiv√©e pour s√©curit√©")
            return False
        else:
            logger.warning("[WARNING] Aucune cl√© API d√©tect√©e")
            return False

class SyntheticDataGenerator:
    """G√©n√©rateur de donn√©es synth√©tiques uniques pour tests d'authenticit√©."""
    
    def __init__(self):
        self.test_id = str(uuid.uuid4())[:8]
        self.timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
    def generate_unique_cluedo_scenario(self) -> Dict[str, Any]:
        """G√©n√®re un sc√©nario Cluedo unique (pas les exemples classiques)."""
        unique_scenarios = [
            {
                "nom": f"Le Myst√®re du Laboratoire Quantique_{self.test_id}",
                "suspects": ["Dr. Heisenberg", "Prof. Schr√∂dinger", "Ing. Tesla"],
                "armes": ["Acc√©l√©rateur de particules", "Rayon gamma", "Champ magn√©tique"],
                "lieux": ["Chambre d'isolation", "Salle des serveurs", "Laboratoire cyr√©nique"],
                "contexte": f"Un incident inexpliqu√© s'est produit dans le laboratoire √† {self.timestamp}. Les √©quipements montrent des anomalies."
            },
            {
                "nom": f"L'Affaire du Symposium Philosophique_{self.test_id}",
                "suspects": ["Ma√Ætre Aristote", "Sage Confucius", "Penseur Descartes"],
                "armes": ["Sophisme mortel", "Paradoxe temporel", "Dialectique foudroyante"],
                "lieux": ["Amphith√©√¢tre des Id√©es", "Jardin des Concepts", "Tour d'Ivoire"],
                "contexte": f"Un d√©bat intellectuel a mal tourn√© le {self.timestamp}. Une contradiction fatale a √©t√© d√©tect√©e."
            }
        ]
        
        return unique_scenarios[hash(self.test_id) % len(unique_scenarios)]
    
    def generate_unique_sophisms(self) -> List[Dict[str, str]]:
        """G√©n√®re des sophismes nouveaux pour l'agent informel."""
        return [
            {
                "type": f"argumentum_ad_technologicum_{self.test_id}",
                "description": "Fallacieux d'appel √† la technologie moderne",
                "example": f"Cette IA est plus r√©cente donc forc√©ment meilleure (Test {self.timestamp})",
                "context": "Intelligence artificielle et modernit√©"
            },
            {
                "type": f"fallacia_temporalis_{self.test_id}",
                "description": "Sophisme de confusion temporelle",
                "example": f"Hier √©tait mieux qu'aujourd'hui, donc demain sera pire (G√©n√©r√© {self.test_id})",
                "context": "Perception du temps et progr√®s"
            }
        ]
    
    def generate_logic_problems(self) -> List[Dict[str, str]]:
        """G√©n√®re des probl√®mes logiques in√©dits pour FirstOrderLogicAgent."""
        return [
            {
                "problem_id": f"logic_puzzle_{self.test_id}",
                "premises": [
                    f"‚àÄx (Scientist(x) ‚Üí HasLab(x))",
                    f"‚àÄx (HasLab(x) ‚Üí CanExperiment(x))",
                    f"Scientist(DrQuantum_{self.test_id})"
                ],
                "query": f"CanExperiment(DrQuantum_{self.test_id})?",
                "expected": "True",
                "context": f"Probl√®me g√©n√©r√© le {self.timestamp}"
            },
            {
                "problem_id": f"modal_logic_{self.test_id}",
                "premises": [
                    f"‚óá(Exists(x) ‚àß AI(x))",
                    f"‚ñ°(AI(x) ‚Üí Reasoning(x))",
                    f"Exists(ChatGPT_{self.test_id})"
                ],
                "query": f"‚óáReasoning(ChatGPT_{self.test_id})?",
                "expected": "True",
                "context": f"Logique modale - Test {self.timestamp}"
            }
        ]

class AuthenticAPITracer:
    """Traceur d'appels API authentiques avec m√©triques d√©taill√©es."""
    
    def __init__(self):
        self.traces = []
        self.start_time = None
        self.api_calls = 0
        
    def start_tracing(self):
        """D√©marre le tra√ßage des appels API."""
        self.start_time = time.time()
        logger.info("üîç D√âBUT TRA√áAGE API AUTHENTIQUE")
        
    def trace_openai_call(self, prompt: str, response: str, metadata: Dict) -> Dict:
        """Trace un appel OpenAI avec toutes les m√©triques."""
        call_start = time.time()
        
        # Calculer hash du prompt pour v√©rifier unicit√©
        prompt_hash = hashlib.sha256(prompt.encode()).hexdigest()[:16]
        
        trace_entry = {
            "call_id": str(uuid.uuid4()),
            "timestamp": datetime.now().isoformat(),
            "prompt_hash": prompt_hash,
            "prompt_length": len(prompt),
            "response_length": len(response),
            "model": metadata.get('model', 'unknown'),
            "tokens_used": metadata.get('tokens', 0),
            "latency_ms": (time.time() - call_start) * 1000,
            "cost_estimate": metadata.get('cost', 0),
            "authenticity_markers": {
                "has_real_latency": metadata.get('latency', 0) > 100,  # > 100ms
                "has_token_usage": metadata.get('tokens', 0) > 0,
                "response_variations": len(set(response.split())) / len(response.split()) if response.split() else 0
            }
        }
        
        self.traces.append(trace_entry)
        self.api_calls += 1
        
        logger.info(f"üì° API CALL #{self.api_calls}: {prompt_hash} - {trace_entry['latency_ms']:.1f}ms")
        
        return trace_entry
    
    def validate_authenticity(self) -> Dict[str, Any]:
        """Valide l'authenticit√© des traces API."""
        if not self.traces:
            return {"authentic": False, "reason": "Aucune trace API"}
        
        # M√©triques d'authenticit√©
        avg_latency = sum(t['latency_ms'] for t in self.traces) / len(self.traces)
        total_tokens = sum(t['tokens_used'] for t in self.traces)
        unique_responses = len(set(t['prompt_hash'] for t in self.traces))
        
        authenticity_score = 0
        criteria = {}
        
        # Crit√®re 1: Latence r√©aliste (> 500ms en moyenne pour gpt-4o-mini)
        if avg_latency > 500:
            authenticity_score += 25
            criteria['realistic_latency'] = True
        else:
            criteria['realistic_latency'] = False
            
        # Crit√®re 2: Usage de tokens r√©el
        if total_tokens > 0:
            authenticity_score += 25
            criteria['real_tokens'] = True
        else:
            criteria['real_tokens'] = False
            
        # Crit√®re 3: Variations dans les r√©ponses
        if unique_responses == len(self.traces):
            authenticity_score += 25
            criteria['response_variations'] = True
        else:
            criteria['response_variations'] = False
            
        # Crit√®re 4: Nombre d'appels coh√©rent
        if len(self.traces) >= 3:
            authenticity_score += 25
            criteria['sufficient_calls'] = True
        else:
            criteria['sufficient_calls'] = False
        
        return {
            "authentic": authenticity_score >= 75,
            "authenticity_score": authenticity_score,
            "criteria": criteria,
            "metrics": {
                "total_calls": len(self.traces),
                "avg_latency_ms": avg_latency,
                "total_tokens": total_tokens,
                "unique_responses": unique_responses
            }
        }

class RealOrchestrationTester:
    """Testeur d'orchestration conversationnelle r√©elle."""
    
    def __init__(self):
        self.tracer = AuthenticAPITracer()
        self.data_generator = SyntheticDataGenerator()
        
    async def setup_real_kernel(self) -> Kernel:
        """Configure un Kernel avec vraie API OpenAI."""
        kernel = Kernel()
        
        # R√©cup√©rer la vraie cl√© API
        api_key = os.getenv('OPENAI_API_KEY')
        if not api_key or api_key.startswith('sk-test-'):
            raise ValueError("CL√â API R√âELLE REQUISE - Mocks d√©tect√©s!")
        
        # Configurer le service OpenAI r√©el
        openai_service = OpenAIChatCompletion(
            service_id="openai_real",
            ai_model_id="gpt-4o-mini",
            api_key=api_key
        )
        
        kernel.add_service(openai_service)
        logger.info("‚úÖ KERNEL R√âEL CONFIGUR√â avec gpt-4o-mini")
        
        return kernel
    
    async def test_real_cluedo_orchestration(self) -> Dict[str, Any]:
        """Teste l'orchestration Cluedo avec donn√©es synth√©tiques r√©elles."""
        logger.info("üé≠ D√âBUT TEST ORCHESTRATION R√âELLE")
        
        # G√©n√©rer sc√©nario unique
        scenario = self.data_generator.generate_unique_cluedo_scenario()
        logger.info(f"üìã Sc√©nario g√©n√©r√©: {scenario['nom']}")
        
        self.tracer.start_tracing()
        
        try:
            # Configurer le kernel r√©el
            kernel = await self.setup_real_kernel()
            
            # Importer l'orchestrateur r√©el
            from argumentation_analysis.orchestration.cluedo_orchestrator import run_cluedo_game
            
            # Question initiale unique
            initial_question = f"""
            ENQU√äTE UNIQUE {self.data_generator.test_id}:
            
            {scenario['contexte']}
            
            Suspects: {', '.join(scenario['suspects'])}
            Armes possibles: {', '.join(scenario['armes'])}
            Lieux: {', '.join(scenario['lieux'])}
            
            Sherlock, analysez cette situation in√©dite. Watson, aidez avec la logique.
            """
            
            # Capturer d√©but
            start_time = time.time()
            
            # EX√âCUTION R√âELLE avec traces
            history, final_state = await run_cluedo_game(
                kernel=kernel,
                initial_question=initial_question,
                max_turns=3  # Limit√© pour test rapide mais authentique
            )
            
            execution_time = time.time() - start_time
            
            # Analyser les r√©sultats
            result = {
                "test_id": self.data_generator.test_id,
                "scenario": scenario,
                "execution_time_seconds": execution_time,
                "conversation_turns": len(history),
                "final_state": {
                    "solution_proposed": getattr(final_state, 'solution_proposee', None),
                    "is_solution_found": getattr(final_state, 'is_solution_proposed', False)
                },
                "conversation_extract": [
                    {
                        "speaker": msg["sender"],
                        "message_length": len(msg["message"]),
                        "message_hash": hashlib.sha256(msg["message"].encode()).hexdigest()[:16]
                    }
                    for msg in history[-3:]  # Derniers 3 messages
                ],
                "authenticity_validation": self.tracer.validate_authenticity()
            }
            
            logger.info(f"‚úÖ ORCHESTRATION R√âELLE TERMIN√âE: {execution_time:.2f}s, {len(history)} tours")
            
            return result
            
        except Exception as e:
            logger.error(f"‚ùå ERREUR ORCHESTRATION R√âELLE: {e}")
            return {
                "test_id": self.data_generator.test_id,
                "error": str(e),
                "authenticity_validation": {"authentic": False, "reason": f"Execution failed: {e}"}
            }

class AuthenticityAuditor:
    """Auditeur principal d'authenticit√© compl√®te."""
    
    def __init__(self):
        self.mock_eliminator = MockEliminationEngine()
        self.orchestration_tester = RealOrchestrationTester()
        self.audit_results = {}
        self.audit_timestamp = datetime.now().isoformat()
        
    async def run_full_audit(self) -> Dict[str, Any]:
        """Ex√©cute l'audit complet d'authenticit√©."""
        logger.info("üöÄ D√âBUT AUDIT AUTHENTICIT√â COMPL√àTE")
        
        audit_results = {
            "audit_id": str(uuid.uuid4()),
            "timestamp": self.audit_timestamp,
            "phases": {}
        }
        
        # Phase 1: D√©tection des mocks
        logger.info("üìç PHASE 1: D√âTECTION MOCKS")
        mock_scan = self.mock_eliminator.scan_for_mocks()
        audit_results["phases"]["mock_detection"] = {
            "detected_mocks": mock_scan,
            "total_mock_files": sum(len(files) for files in mock_scan.values())
        }
        
        # Phase 2: √âlimination des mocks critiques
        logger.info("üìç PHASE 2: √âLIMINATION MOCKS")
        env_fixed = self.mock_eliminator.eliminate_env_mock()
        audit_results["phases"]["mock_elimination"] = {
            "env_key_fixed": env_fixed,
            "eliminated_components": self.mock_eliminator.eliminated_mocks
        }
        
        if not env_fixed:
            logger.error("‚ùå AUDIT ARR√äT√â: Cl√©s API r√©elles requises")
            audit_results["status"] = "FAILED_NO_REAL_API"
            return audit_results
        
        # Phase 3: Test orchestration r√©elle
        logger.info("üìç PHASE 3: TEST ORCHESTRATION R√âELLE")
        orchestration_result = await self.orchestration_tester.test_real_cluedo_orchestration()
        audit_results["phases"]["real_orchestration"] = orchestration_result
        
        # Phase 4: Validation finale d'authenticit√©
        logger.info("üìç PHASE 4: VALIDATION AUTHENTICIT√â")
        authenticity_score = self.calculate_final_authenticity_score(audit_results)
        audit_results["final_authenticity"] = authenticity_score
        
        # Status final
        if authenticity_score["score"] >= 80:
            audit_results["status"] = "AUTHENTIC_VERIFIED"
            logger.info("üéØ SYST√àME AUTHENTIQUE V√âRIFI√â!")
        elif authenticity_score["score"] >= 60:
            audit_results["status"] = "PARTIALLY_AUTHENTIC"
            logger.warning("‚ö†Ô∏è SYST√àME PARTIELLEMENT AUTHENTIQUE")
        else:
            audit_results["status"] = "MOCKS_DETECTED"
            logger.error("‚ùå MOCKS PERSISTANTS D√âTECT√âS")
        
        return audit_results
    
    def calculate_final_authenticity_score(self, audit_results: Dict) -> Dict[str, Any]:
        """Calcule le score final d'authenticit√©."""
        score = 0
        max_score = 100
        criteria = {}
        
        # Crit√®re 1: √âlimination des mocks (30 points)
        if audit_results["phases"]["mock_elimination"]["env_key_fixed"]:
            score += 30
            criteria["env_mocks_eliminated"] = True
        else:
            criteria["env_mocks_eliminated"] = False
        
        # Crit√®re 2: Orchestration r√©elle r√©ussie (40 points)
        orchestration = audit_results["phases"]["real_orchestration"]
        if "error" not in orchestration:
            score += 20
            criteria["orchestration_executed"] = True
            
            # Bonus pour conversation multi-tours
            if orchestration.get("conversation_turns", 0) >= 2:
                score += 20
                criteria["multi_turn_conversation"] = True
            else:
                criteria["multi_turn_conversation"] = False
        else:
            criteria["orchestration_executed"] = False
            criteria["multi_turn_conversation"] = False
        
        # Crit√®re 3: Validation API authentique (30 points)
        api_validation = orchestration.get("authenticity_validation", {})
        if api_validation.get("authentic", False):
            score += 30
            criteria["authentic_api_calls"] = True
        else:
            criteria["authentic_api_calls"] = False
        
        return {
            "score": score,
            "max_score": max_score,
            "percentage": (score / max_score) * 100,
            "criteria": criteria,
            "interpretation": self.interpret_score(score)
        }
    
    def interpret_score(self, score: int) -> str:
        """Interpr√®te le score d'authenticit√©."""
        if score >= 90:
            return "SYST√àME 100% AUTHENTIQUE - Aucun mock d√©tect√©"
        elif score >= 80:
            return "SYST√àME TR√àS AUTHENTIQUE - Mocks mineurs seulement"
        elif score >= 60:
            return "SYST√àME MOD√âR√âMENT AUTHENTIQUE - Quelques mocks persistants"
        elif score >= 40:
            return "SYST√àME LARGEMENT MOCK√â - Authenticit√© limit√©e"
        else:
            return "SYST√àME PRINCIPALEMENT MOCK√â - Authenticit√© tr√®s faible"
    
    def save_audit_report(self, audit_results: Dict[str, Any]):
        """Sauvegarde le rapport d'audit complet."""
        report_path = f"reports/audit_authenticite_{self.audit_timestamp.replace(':', '-')}.json"
        
        os.makedirs("reports", exist_ok=True)
        
        with open(report_path, 'w', encoding='utf-8') as f:
            json.dump(audit_results, f, indent=2, ensure_ascii=False)
        
        logger.info(f"üìÑ RAPPORT SAUVEGARD√â: {report_path}")
        
        # Cr√©er aussi un r√©sum√© lisible
        self.create_human_readable_report(audit_results, report_path.replace('.json', '_resume.md'))
    
    def create_human_readable_report(self, audit_results: Dict[str, Any], report_path: str):
        """Cr√©e un rapport lisible pour humains."""
        markdown_content = f"""# RAPPORT D'AUDIT D'AUTHENTICIT√â

## Informations G√©n√©rales
- **ID Audit**: {audit_results['audit_id']}
- **Timestamp**: {audit_results['timestamp']}
- **Status**: {audit_results['status']}

## Score d'Authenticit√©
- **Score Final**: {audit_results['final_authenticity']['score']}/{audit_results['final_authenticity']['max_score']} ({audit_results['final_authenticity']['percentage']:.1f}%)
- **Interpr√©tation**: {audit_results['final_authenticity']['interpretation']}

## D√©tection des Mocks
"""
        
        mock_detection = audit_results['phases']['mock_detection']
        markdown_content += f"- **Total fichiers avec mocks**: {mock_detection['total_mock_files']}\n"
        
        for category, files in mock_detection['detected_mocks'].items():
            if files:
                markdown_content += f"- **{category}**: {len(files)} fichiers d√©tect√©s\n"
        
        markdown_content += f"""
## √âlimination des Mocks
- **Cl√© API corrig√©e**: {audit_results['phases']['mock_elimination']['env_key_fixed']}
- **Composants √©limin√©s**: {audit_results['phases']['mock_elimination']['eliminated_components']}

## Test d'Orchestration R√©elle
"""
        
        orchestration = audit_results['phases']['real_orchestration']
        if 'error' in orchestration:
            markdown_content += f"- **Erreur**: {orchestration['error']}\n"
        else:
            markdown_content += f"""- **Test ID**: {orchestration['test_id']}
- **Temps d'ex√©cution**: {orchestration['execution_time_seconds']:.2f} secondes
- **Tours de conversation**: {orchestration['conversation_turns']}
- **Solution trouv√©e**: {orchestration['final_state']['is_solution_found']}
"""
        
        markdown_content += f"""
## Validation API Authentique
"""
        
        api_validation = orchestration.get('authenticity_validation', {})
        if api_validation:
            markdown_content += f"""- **API Authentique**: {api_validation.get('authentic', False)}
- **Score Authenticit√©**: {api_validation.get('authenticity_score', 0)}%
- **Appels Total**: {api_validation.get('metrics', {}).get('total_calls', 0)}
- **Latence Moyenne**: {api_validation.get('metrics', {}).get('avg_latency_ms', 0):.1f}ms
- **Tokens Total**: {api_validation.get('metrics', {}).get('total_tokens', 0)}
"""
        
        markdown_content += f"""
## Crit√®res d'Authenticit√©
"""
        
        criteria = audit_results['final_authenticity']['criteria']
        for criterion, passed in criteria.items():
            status = "‚úÖ" if passed else "‚ùå"
            markdown_content += f"- {status} **{criterion}**: {passed}\n"
        
        markdown_content += f"""
---
*Rapport g√©n√©r√© automatiquement par le syst√®me d'audit d'authenticit√©*
"""
        
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write(markdown_content)

async def main():
    """Point d'entr√©e principal de l'audit d'authenticit√©."""
    print("üöÄ D√âMARRAGE AUDIT AUTHENTICIT√â R√âELLE")
    print("=" * 50)
    
    auditor = AuthenticityAuditor()
    
    try:
        # Ex√©cuter l'audit complet
        audit_results = await auditor.run_full_audit()
        
        # Sauvegarder les r√©sultats
        auditor.save_audit_report(audit_results)
        
        # Afficher r√©sum√©
        print("\n" + "=" * 50)
        print("üìä R√âSULTATS AUDIT D'AUTHENTICIT√â")
        print("=" * 50)
        print(f"Status: {audit_results['status']}")
        print(f"Score: {audit_results['final_authenticity']['score']}/100 ({audit_results['final_authenticity']['percentage']:.1f}%)")
        print(f"Interpr√©tation: {audit_results['final_authenticity']['interpretation']}")
        
        if audit_results['status'] == 'AUTHENTIC_VERIFIED':
            print("\nüéØ MISSION ACCOMPLIE - SYST√àME AUTHENTIQUE V√âRIFI√â!")
            print("‚úÖ Tous les mocks de complaisance ont √©t√© √©limin√©s")
            print("‚úÖ API r√©elles fonctionnelles avec traces auditables")
            print("‚úÖ Orchestration conversationnelle authentique prouv√©e")
        else:
            print(f"\n‚ö†Ô∏è MISSION PARTIELLE - Status: {audit_results['status']}")
            print("Voir le rapport d√©taill√© pour les am√©liorations n√©cessaires")
        
        return audit_results['status'] == 'AUTHENTIC_VERIFIED'
        
    except Exception as e:
        logger.error(f"‚ùå √âCHEC AUDIT: {e}")
        print(f"\n‚ùå √âCHEC AUDIT: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    success = asyncio.run(main())
    exit(0 if success else 1)