{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ccc3bb9d",
   "metadata": {},
   "source": [
    "# Interface de Configuration et Préparation du Texte\n",
    "\n",
    "**Objectif:** Ce notebook définit l'interface utilisateur et la logique nécessaire pour :\n",
    "1.  Sélectionner une source de texte (Bibliothèque prédéfinie, URL, Fichier local, Texte direct).\n",
    "2.  Extraire le contenu textuel via Jina ou Tika si nécessaire.\n",
    "3.  Appliquer des marqueurs de début/fin pour isoler un extrait spécifique.\n",
    "4.  Gérer un cache fichier pour les textes complets des sources externes.\n",
    "5.  Charger/Sauvegarder la configuration des sources prédéfinies depuis/vers un fichier chiffré.\n",
    "6.  Retourner le texte final préparé au notebook exécuteur principal.\n",
    "\n",
    "**Fonction Principale:** Définit la fonction `configure_analysis_task()` qui sera appelée par le notebook exécuteur."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8806466",
   "metadata": {},
   "source": [
    "## 1. Imports Requis\n",
    "\n",
    "Importation des bibliothèques nécessaires pour l'UI, les requêtes HTTP, le cache, le chiffrement, et la gestion des fichiers/chemins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7021532a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports pour UI_Configuration chargés (incluant crypto KDF et base64).\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# Filename: UI_Configuration.ipynb\n",
    "\n",
    "# %% =====================================================\n",
    "# CELLULE 1: Imports Requis\n",
    "# =====================================================\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "import requests\n",
    "import time\n",
    "import random\n",
    "import io\n",
    "from jupyter_ui_poll import ui_events\n",
    "import traceback\n",
    "import re\n",
    "import os\n",
    "import json\n",
    "import gzip\n",
    "import hashlib\n",
    "from pathlib import Path\n",
    "# Imports Cryptography (Fernet pour chiffrement/déchiffrement)\n",
    "from cryptography.fernet import Fernet, InvalidToken\n",
    "from cryptography.exceptions import InvalidSignature\n",
    "# Imports Cryptography (PBKDF2 pour dérivation de clé depuis passphrase) CORRECTIF ICI\n",
    "from cryptography.hazmat.primitives import hashes\n",
    "from cryptography.hazmat.primitives.kdf.pbkdf2 import PBKDF2HMAC\n",
    "from cryptography.hazmat.backends import default_backend\n",
    "import base64 # Pour encoder la clé dérivée\n",
    "# ---\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "print(\"Imports pour UI_Configuration chargés (incluant crypto KDF et base64).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "114cc29b",
   "metadata": {},
   "source": [
    "## 2. Configuration, Constantes et Données Sources\n",
    "\n",
    "Définition des constantes (URLs des services, chemins des fichiers), chargement de la clé de chiffrement depuis `.env`, définition de la structure des sources prédéfinies (`EXTRACT_SOURCES`), et création du répertoire de cache."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5e08535d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vérification de la phrase secrète 'TEXT_CONFIG_PASSPHRASE' dans .env...\n",
      "✅ Phrase secrète trouvée. Dérivation de la clé...\n",
      "✅ Clé de chiffrement dérivée et encodée.\n",
      "Cache répertoire assuré : C:\\dev\\CoursIA\\MyIA.AI.Notebooks\\SymbolicAI\\Argument_Analysis\\text_cache\n",
      "Configuration UI chargée. 4 sources initiales définies.\n"
     ]
    }
   ],
   "source": [
    "# --- Chargement et Dérivation Clé de Chiffrement ---\n",
    "load_dotenv(find_dotenv())\n",
    "PASSPHRASE_VAR_NAME = \"TEXT_CONFIG_PASSPHRASE\"\n",
    "passphrase = os.getenv(PASSPHRASE_VAR_NAME)\n",
    "ENCRYPTION_KEY = None # Sera défini si la dérivation réussit\n",
    "\n",
    "FIXED_SALT = b'q\\x8b\\t\\x97\\x8b\\xe9\\xa3\\xf2\\xe4\\x8e\\xea\\xf5\\xe8\\xb7\\xd6\\x8c' # Exemple de sel fixe (16 bytes)\n",
    "\n",
    "print(f\"Vérification de la phrase secrète '{PASSPHRASE_VAR_NAME}' dans .env...\")\n",
    "\n",
    "if passphrase:\n",
    "    print(f\"✅ Phrase secrète trouvée. Dérivation de la clé...\")\n",
    "    try:\n",
    "        kdf = PBKDF2HMAC(\n",
    "            algorithm=hashes.SHA256(), length=32, salt=FIXED_SALT,\n",
    "            iterations=480000, backend=default_backend()\n",
    "        )\n",
    "        derived_key_raw = kdf.derive(passphrase.encode('utf-8'))\n",
    "        ENCRYPTION_KEY = base64.urlsafe_b64encode(derived_key_raw)\n",
    "        # Optionnel: commenter le test si la clé dérivée pose problème avec Fernet(key) directement\n",
    "        # try:\n",
    "        #     Fernet(ENCRYPTION_KEY)\n",
    "        #     print(\"✅ Clé de chiffrement dérivée avec succès et valide.\")\n",
    "        # except Exception as e_fernet:\n",
    "        #     print(f\"⚠️ Clé dérivée semble invalide pour Fernet : {e_fernet}.\")\n",
    "        #     ENCRYPTION_KEY = None # Invalider si test échoue\n",
    "        if ENCRYPTION_KEY: print(\"✅ Clé de chiffrement dérivée et encodée.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Erreur dérivation clé : {e}. Chiffrement désactivé.\")\n",
    "        ENCRYPTION_KEY = None\n",
    "else:\n",
    "    print(f\"⚠️ Variable '{PASSPHRASE_VAR_NAME}' non trouvée dans .env. Chiffrement désactivé.\")\n",
    "\n",
    "# --- URLs et Chemins ---\n",
    "TIKA_URL_PARTS = [\"https:\", \"\", \"tika\", \"open-webui\", \"myia\", \"io\", \"tika\"]\n",
    "# --- LIGNE DÉCOMMENTÉE ---\n",
    "# Reconstruit l'URL Tika une seule fois ici pour être utilisée globalement\n",
    "TIKA_SERVER_URL = f\"{TIKA_URL_PARTS[0]}//{'.'.join(TIKA_URL_PARTS[2:-1])}/{TIKA_URL_PARTS[-1]}\"\n",
    "# -------------------------\n",
    "JINA_READER_PREFIX = \"https://r.jina.ai/\"\n",
    "CACHE_DIR = Path(\"./text_cache\")\n",
    "CONFIG_FILE = Path(\"./extract_sources.json.gz.enc\")\n",
    "\n",
    "# --- Création Cache Dir ---\n",
    "try:\n",
    "    CACHE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    print(f\"Cache répertoire assuré : {CACHE_DIR.resolve()}\")\n",
    "except Exception as e:\n",
    "    print(f\"Erreur création répertoire cache {CACHE_DIR}: {e}\")\n",
    "\n",
    "# --- Structure par Défaut (avec nouvelle structure URL) ---\n",
    "DEFAULT_EXTRACT_SOURCES = [\n",
    "    {\"source_name\": \"Exemple Vide (Config manquante)\", \"source_type\": \"jina\",\n",
    "     \"schema\": \"https:\", \"host_parts\": [\"example\", \"com\"], \"path\": \"/\",\n",
    "     \"extracts\": []}\n",
    "]\n",
    "\n",
    "# --- Définition Initiale des Sources & Extraits (Structure Corrigée) ---\n",
    "# (Cette structure est utilisée comme fallback si le fichier .enc n'existe pas/n'est pas lisible)\n",
    "EXTRACT_SOURCES = [\n",
    "     {\n",
    "        \"source_name\": \"Lincoln-Douglas Débat 1 (NPS)\", \"source_type\": \"jina\",\n",
    "        \"schema\": \"https:\", \"host_parts\": [\"www\", \"nps\", \"gov\"], \"path\": \"/liho/learn/historyculture/debate1.htm\",\n",
    "        \"extracts\": [\n",
    "            {\"extract_name\": \"1. Débat Complet (Ottawa, 1858)\", \"start_marker\": \"**August 21, 1858**\", \"end_marker\": \"(Three times three cheers were here given for Senator Douglas.)\"},\n",
    "            {\"extract_name\": \"2. Discours Principal de Lincoln\", \"start_marker\": \"MY FELLOW-CITIZENS: When a man hears himself\", \"end_marker\": \"The Judge can take his half hour.\"},\n",
    "            {\"extract_name\": \"3. Discours d'Ouverture de Douglas\", \"start_marker\": \"Ladies and gentlemen: I appear before you\", \"end_marker\": \"occupy an half hour in replying to him.\"},\n",
    "            {\"extract_name\": \"4. Lincoln sur Droits Naturels/Égalité\", \"start_marker\": \"I will say here, while upon this subject,\", \"end_marker\": \"equal of every living man._ [Great applause.]\"},\n",
    "            {\"extract_name\": \"5. Douglas sur Race/Dred Scott\", \"start_marker\": \"utterly opposed to the Dred Scott decision,\", \"end_marker\": \"equality with the white man. (\\\"Good.\\\")\"},\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"source_name\": \"Lincoln-Douglas Débat 2 (NPS)\", \"source_type\": \"jina\",\n",
    "        \"schema\": \"https:\", \"host_parts\": [\"www\", \"nps\", \"gov\"], \"path\": \"/liho/learn/historyculture/debate2.htm\",\n",
    "        \"extracts\": [\n",
    "             {\"extract_name\": \"1. Débat Complet (Freeport, 1858)\", \"start_marker\": \"It was a cloudy, cool, and damp day.\", \"end_marker\": \"I cannot, gentlemen, my time has expired.\"},\n",
    "             {\"extract_name\": \"2. Discours Principal de Douglas\", \"start_marker\": \"**Mr. Douglas' Speech**\\n\\nLadies and Gentlemen-\", \"end_marker\": \"stopped on the moment.\"},\n",
    "             {\"extract_name\": \"3. Discours d'Ouverture de Lincoln\", \"start_marker\": \"LADIES AND GENTLEMEN - On Saturday last,\", \"end_marker\": \"Go on, Judge Douglas.\"},\n",
    "             {\"extract_name\": \"4. Doctrine de Freeport (Douglas)\", \"start_marker\": \"The next question propounded to me by Mr. Lincoln is,\", \"end_marker\": \"satisfactory on that point.\"},\n",
    "             {\"extract_name\": \"5. Lincoln répond aux 7 questions\", \"start_marker\": \"The first one of these interrogatories is in these words:,\", \"end_marker\": \"aggravate the slavery question among ourselves. [Cries of good, good.]\"},\n",
    "        ]\n",
    "    },\n",
    "     {\n",
    "        \"source_name\": \"Kremlin Discours 21/02/2022\", \"source_type\": \"jina\",\n",
    "        \"schema\": \"http:\", \"host_parts\": [\"en\", \"kremlin\", \"ru\"], \"path\": \"/events/president/transcripts/67828\",\n",
    "        \"extracts\": [\n",
    "            {\"extract_name\": \"1. Discours Complet\", \"start_marker\": \"Citizens of Russia, friends,\", \"end_marker\": \"Thank you.\"},\n",
    "            {\"extract_name\": \"2. Argument Historique Ukraine\", \"start_marker\": \"So, I will start with the fact that modern Ukraine\", \"end_marker\": \"He was its creator and architect.\"},\n",
    "            {\"extract_name\": \"3. Menace OTAN\", \"start_marker\": \"Ukraine is home to NATO training missions\", \"end_marker\": \"These principled proposals of ours have been ignored.\"},\n",
    "            {\"extract_name\": \"4. Décommunisation selon Poutine\", \"start_marker\": \"And today the “grateful progeny”\", \"end_marker\": \"what real decommunizations would mean for Ukraine.\"},\n",
    "            {\"extract_name\": \"5. Décision Reconnaissance Donbass\", \"start_marker\": \"Everything was in vain.\", \"end_marker\": \"These two documents will be prepared and signed shortly.\"},\n",
    "         ]\n",
    "    },\n",
    "    {\n",
    "        \"source_name\": \"Hitler Discours Collection (PDF)\", \"source_type\": \"direct_download\",\n",
    "        # \"schema\": \"https:\", \"host_parts\": [\"www\", \"nommeraadio\", \"ee\"], \"path\": \"/meedia/pdf/RRS/Adolf%20Hitler%20-%20Collection%20of%20Speeches%20-%201922-1945.pdf\",\n",
    "        \"schema\": \"https:\",\n",
    "        \"host_parts\": [\"drive\", \"google\", \"com\"],\n",
    "        \"path\": \"/uc?export=download&id=1D6ZESrdeuWvlPlsNq0rbVaUyxqUOB-KQ\", # Chemin GDrive direct\n",
    "        \"extracts\": [\n",
    "            {\"extract_name\": \"1. 1923.04.13 - Munich\", \"start_marker\": \"n our view, the times when\", \"end_marker\": \"build a new Germany!36\"},\n",
    "            {\"extract_name\": \"2. 1923.04.24 - Munich\", \"start_marker\": \"reject the word 'Proletariat.'\", \"end_marker\": \"the greatest social achievement.38\"},\n",
    "            {\"extract_name\": \"3. 1923.04.27 - Munich\", \"start_marker\": \"hat we need if we are to have\", \"end_marker\": \"the Germany of fighters which yet shall be.\"},\n",
    "            {\"extract_name\": \"4. 1933.03.23 - Duel Otto Wels\", \"start_marker\": \"You are talking today about your achievements\", \"end_marker\": \"Germany will be liberated, but not by you!125\"},\n",
    "            {\"extract_name\": \"5. 1933.05.01 - Lustgarten\", \"start_marker\": \"hree cheers for our Reich President,\", \"end_marker\": \"thus our German Volk und Vaterland!”\"},\n",
    "            {\"extract_name\": \"6. 1936.03.09 - Interview Ward Price\", \"start_marker\": \"irst question: Does the Fuhrer’s offer\", \"end_marker\": \"service to Europe and to the cause of peace.313\"},\n",
    "            {\"extract_name\": \"7. 1936.03.12 - Karlsruhe\", \"start_marker\": \"know no regime of the bourgeoisie,\", \"end_marker\": \"now and for all time to come!316\"},\n",
    "            {\"extract_name\": \"8. 1936.03.20 - Hambourg\", \"start_marker\": \"t is a pity that the statesmen-\", \"end_marker\": \"now give me your faith!\"},\n",
    "            {\"extract_name\": \"9. 1939.01.30 - Reichstag (Prophétie)\", \"start_marker\": \"Once again I will be a prophet:\", \"end_marker\": \"complementary nature of these economies to the German one.549\"},\n",
    "            {\"extract_name\": \"10. 1942.11.09 - Löwenbräukeller\", \"start_marker\": \"care of this. This danger has been recognized\", \"end_marker\": \"will always be a prayer for our Germany!\"},\n",
    "        ]\n",
    "    },\n",
    "]\n",
    "\n",
    "\n",
    "# --- Initialisation variable globale ---\n",
    "# Sera mise à jour par load_extract_definitions lors de l'appel à configure_analysis_task\n",
    "current_extract_definitions = []\n",
    "\n",
    "print(f\"Configuration UI chargée. {len(EXTRACT_SOURCES)} sources initiales définies.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abda6271",
   "metadata": {},
   "source": [
    "## 3. Fonctions Utilitaires\n",
    "\n",
    "Définition des fonctions pour :\n",
    "* Gérer le cache fichier (créer nom de fichier, lire, écrire).\n",
    "* Chiffrer et déchiffrer les données de configuration.\n",
    "* Charger et sauvegarder le fichier de configuration chiffré.\n",
    "* Reconstruire les URLs à partir des parties obfusquées.\n",
    "* Récupérer le texte via Jina (avec cache).\n",
    "* Récupérer le texte via Tika (téléchargement si URL, puis envoi au serveur Tika, avec cache)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ff6ba3ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fonctions utilitaires UI_Configuration définies.\n"
     ]
    }
   ],
   "source": [
    "def reconstruct_url(schema: str, host_parts: list, path: str) -> str | None:\n",
    "    \"\"\"Reconstruit une URL à partir de schema, host_parts, et path.\"\"\"\n",
    "    if not schema or not host_parts or not path: return None\n",
    "    host = \".\".join(part for part in host_parts if part)\n",
    "    # S'assurer que le path commence par / s'il n'est pas vide\n",
    "    path = path if path.startswith('/') or not path else '/' + path\n",
    "    return f\"{schema}//{host}{path}\"\n",
    "\n",
    "# --- Définitions des autres fonctions utilitaires ---\n",
    "# (get_cache_filepath, load_from_cache, save_to_cache, encrypt_data, decrypt_data,\n",
    "#  load_extract_definitions (modifiée pour utiliser la nouvelle structure interne),\n",
    "#  save_extract_definitions, fetch_with_jina, fetch_with_tika)\n",
    "# ... (Copiez ici le code complet de ces fonctions depuis la CELLULE 3 / Bloc Python 3 de ma réponse précédente) ...\n",
    "# ... Assurez-vous que load_extract_definitions utilise la nouvelle structure\n",
    "#     et que fetch_with_jina/tika appellent la nouvelle reconstruct_url si nécessaire ...\n",
    "\n",
    "# Exemple de load_extract_definitions (ajusté légèrement pour fallback)\n",
    "def load_extract_definitions(config_file: Path, key: bytes) -> list:\n",
    "    \"\"\"Charge, déchiffre et décompresse les définitions depuis le fichier.\"\"\"\n",
    "    global EXTRACT_SOURCES, DEFAULT_EXTRACT_SOURCES # Utiliser les structures définies globalement\n",
    "    fallback_definitions = EXTRACT_SOURCES if EXTRACT_SOURCES else DEFAULT_EXTRACT_SOURCES\n",
    "\n",
    "    if not config_file.exists():\n",
    "        print(f\"Fichier config '{config_file}' non trouvé. Utilisation définitions en mémoire.\")\n",
    "        return fallback_definitions[:]\n",
    "    if not key:\n",
    "        print(\"Clé chiffrement absente. Chargement config impossible. Utilisation définitions en mémoire.\")\n",
    "        return fallback_definitions[:]\n",
    "\n",
    "    print(f\"Chargement et déchiffrement de '{config_file}'...\")\n",
    "    try:\n",
    "        with open(config_file, 'rb') as f: encrypted_data = f.read()\n",
    "        decrypted_compressed_data = decrypt_data(encrypted_data, key)\n",
    "        if not decrypted_compressed_data: raise ValueError(\"Échec déchiffrement.\")\n",
    "        decompressed_data = gzip.decompress(decrypted_compressed_data)\n",
    "        definitions = json.loads(decompressed_data.decode('utf-8'))\n",
    "        print(\"✅ Définitions chargées et déchiffrées.\")\n",
    "        # Validation plus robuste\n",
    "        if not isinstance(definitions, list) or not all(\n",
    "            isinstance(item, dict) and\n",
    "            \"source_name\" in item and\n",
    "            \"source_type\" in item and\n",
    "            \"schema\" in item and\n",
    "            \"host_parts\" in item and\n",
    "            \"path\" in item and\n",
    "            isinstance(item.get(\"extracts\"), list)\n",
    "            for item in definitions\n",
    "        ):\n",
    "             print(\"⚠️ Format définitions invalide après chargement. Utilisation définitions en mémoire.\")\n",
    "             return fallback_definitions[:]\n",
    "        # Mettre à jour EXTRACT_SOURCES global si chargement OK\n",
    "        EXTRACT_SOURCES = definitions\n",
    "        print(f\"-> {len(EXTRACT_SOURCES)} définitions chargées depuis fichier.\")\n",
    "        return definitions # Retourner les définitions chargées\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Erreur chargement/traitement '{config_file}': {e}. Utilisation définitions en mémoire.\")\n",
    "        return fallback_definitions[:]\n",
    "\n",
    "# --- Assurez-vous que toutes les autres fonctions utilitaires sont collées ici ---\n",
    "def get_cache_filepath(url: str) -> Path:\n",
    "    url_hash = hashlib.sha256(url.encode()).hexdigest()\n",
    "    if 'CACHE_DIR' not in globals() or not isinstance(CACHE_DIR, Path): raise NameError(\"CACHE_DIR non définie.\")\n",
    "    return CACHE_DIR / f\"{url_hash}.txt\"\n",
    "def load_from_cache(url: str) -> str | None:\n",
    "    filepath = get_cache_filepath(url)\n",
    "    if filepath.exists():\n",
    "        try:\n",
    "            print(f\"   -> Lecture depuis cache : {filepath.name}\")\n",
    "            return filepath.read_text(encoding='utf-8')\n",
    "        except Exception as e: print(f\"   -> Erreur lecture cache {filepath.name}: {e}\"); return None\n",
    "    return None\n",
    "def save_to_cache(url: str, text: str):\n",
    "    if not text: print(\"   -> Texte vide, non sauvegardé.\"); return\n",
    "    filepath = get_cache_filepath(url)\n",
    "    try:\n",
    "        filepath.write_text(text, encoding='utf-8'); print(f\"   -> Texte sauvegardé : {filepath.name}\")\n",
    "    except Exception as e: print(f\"   -> Erreur sauvegarde cache {filepath.name}: {e}\")\n",
    "def encrypt_data(data: bytes, key: bytes) -> bytes | None:\n",
    "    if not key: print(\"Erreur: Clé chiffrement manquante.\"); return None\n",
    "    try: f = Fernet(key); return f.encrypt(data)\n",
    "    except Exception as e: print(f\"Erreur chiffrement: {e}\"); return None\n",
    "def decrypt_data(encrypted_data: bytes, key: bytes) -> bytes | None:\n",
    "    if not key: print(\"Erreur: Clé chiffrement manquante.\"); return None\n",
    "    try: f = Fernet(key); return f.decrypt(encrypted_data)\n",
    "    except (InvalidToken, InvalidSignature, Exception) as e: print(f\"Erreur déchiffrement: {e}\"); return None\n",
    "def save_extract_definitions(definitions: list, config_file: Path, key: bytes):\n",
    "    if not key: print(\"Clé chiffrement absente. Sauvegarde annulée.\"); return False\n",
    "    if not isinstance(definitions, list): print(\"Erreur: définitions non valides.\"); return False\n",
    "    print(f\"Préparation sauvegarde vers '{config_file}'...\")\n",
    "    try:\n",
    "        json_data = json.dumps(definitions, indent=2, ensure_ascii=False).encode('utf-8'); compressed_data = gzip.compress(json_data); encrypted_data = encrypt_data(compressed_data, key)\n",
    "        if not encrypted_data: raise ValueError(\"Échec chiffrement.\")\n",
    "        with open(config_file, 'wb') as f: f.write(encrypted_data)\n",
    "        print(f\"✅ Définitions sauvegardées dans '{config_file}'.\")\n",
    "        return True\n",
    "    except Exception as e: print(f\"❌ Erreur sauvegarde chiffrée: {e}\"); return False\n",
    "PLAINTEXT_EXTENSIONS = ['.txt', '.md', '.json', '.csv', '.xml', '.py', '.js', '.html', '.htm'] # Extensions à traiter comme texte simple\n",
    "\n",
    "def fetch_direct_text(source_url, timeout=60):\n",
    "    \"\"\"Récupère contenu texte brut d'URL, utilise cache fichier.\"\"\"\n",
    "    # ... (Code INCHANGÉ) ...\n",
    "    cached_text = load_from_cache(source_url)\n",
    "    if cached_text is not None: return cached_text\n",
    "    print(f\"-> Téléchargement direct depuis : {source_url}...\")\n",
    "    headers = {'User-Agent': 'Agent-Analysis-Notebook/1.0'}\n",
    "    try:\n",
    "        response = requests.get(source_url, headers=headers, timeout=timeout)\n",
    "        response.raise_for_status()\n",
    "        # Décoder en UTF-8, ignorer les erreurs potentielles\n",
    "        texte_brut = response.content.decode('utf-8', errors='ignore')\n",
    "        print(f\"   -> Contenu direct récupéré (longueur {len(texte_brut)}).\")\n",
    "        save_to_cache(source_url, texte_brut)\n",
    "        return texte_brut\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        raise ConnectionError(f\"Erreur téléchargement direct ({source_url}): {e}\") from e\n",
    "\n",
    "def fetch_with_jina(source_url, timeout=90):\n",
    "     \"\"\"Récupère et extrait via Jina, utilise cache fichier.\"\"\"\n",
    "     # ... (Code INCHANGÉ) ...\n",
    "     cached_text = load_from_cache(source_url);\n",
    "     if cached_text is not None: return cached_text\n",
    "     jina_url = f\"{JINA_READER_PREFIX}{source_url}\"; print(f\"-> Récupération via Jina : {jina_url}...\")\n",
    "     headers = {'Accept': 'text/markdown', 'User-Agent': 'Agent-Analysis-Notebook/1.0'}\n",
    "     try: response = requests.get(jina_url, headers=headers, timeout=timeout); response.raise_for_status()\n",
    "     except requests.exceptions.RequestException as e: raise ConnectionError(f\"Erreur Jina ({jina_url}): {e}\") from e\n",
    "     content = response.text; md_start_marker = \"Markdown Content:\"; md_start_index = content.find(md_start_marker)\n",
    "     texte_brut = content[md_start_index + len(md_start_marker):].strip() if md_start_index != -1 else content\n",
    "     print(f\"   -> Contenu Jina récupéré (longueur {len(texte_brut)}).\"); save_to_cache(source_url, texte_brut); return texte_brut\n",
    "\n",
    "\n",
    "# --- fetch_with_tika MODIFIÉE ---\n",
    "def fetch_with_tika(source_url=None, file_content=None, file_name=\"fichier\",\n",
    "                    raw_file_cache_path: Path | str | None = None, # Chemin cache brut\n",
    "                    timeout_dl=60, timeout_tika=600):\n",
    "    \"\"\"\n",
    "    Traite une source via Tika. Tente d'abord de lire le cache texte.\n",
    "    Si URL fournie, vérifie le cache brut puis télécharge si besoin.\n",
    "    Vérifie l'extension: si texte simple, utilise fetch_direct_text au lieu de Tika.\n",
    "    Sinon, envoie le contenu brut (téléchargé ou fourni) à Tika.\n",
    "    \"\"\"\n",
    "    cache_key = source_url if source_url else f\"file://{file_name}\"\n",
    "    # 1. Vérifier cache TEXTE FINAL\n",
    "    cached_text = load_from_cache(cache_key)\n",
    "    if cached_text is not None: return cached_text\n",
    "\n",
    "    global TIKA_SERVER_URL\n",
    "    content_to_send = None\n",
    "    original_filename_or_path = file_name # Par défaut (pour upload)\n",
    "\n",
    "    # 2. Obtenir contenu BRUT (si URL) et vérifier extension\n",
    "    if source_url:\n",
    "        original_filename_or_path = Path(source_url).name # Pour check extension et cache brut\n",
    "        # Vérifier si c'est un type texte simple connu basé sur l'URL\n",
    "        if any(source_url.lower().endswith(ext) for ext in PLAINTEXT_EXTENSIONS):\n",
    "            print(f\"   -> URL détectée comme texte simple ({source_url}). Utilisation fetch direct au lieu de Tika.\")\n",
    "            # On ne passe pas par Tika, on télécharge directement le texte\n",
    "            # La fonction fetch_direct_text gère son propre cache .txt\n",
    "            return fetch_direct_text(source_url)\n",
    "\n",
    "        # Si pas texte simple, gérer cache brut et téléchargement\n",
    "        if raw_file_cache_path:\n",
    "            raw_path = Path(raw_file_cache_path)\n",
    "            if raw_path.exists() and raw_path.stat().st_size > 0:\n",
    "                try:\n",
    "                    print(f\"   -> Lecture fichier brut depuis cache local : {raw_path.name}\")\n",
    "                    content_to_send = raw_path.read_bytes()\n",
    "                except Exception as e_read_raw:\n",
    "                    print(f\"   -> ⚠️ Erreur lecture cache brut {raw_path.name}: {e_read_raw}. Re-téléchargement...\")\n",
    "                    content_to_send = None\n",
    "\n",
    "        if content_to_send is None: # Si cache brut absent ou erreur lecture\n",
    "            print(f\"-> Téléchargement (pour Tika) depuis : {source_url}...\")\n",
    "            try:\n",
    "                response_dl = requests.get(source_url, stream=True, timeout=timeout_dl); response_dl.raise_for_status()\n",
    "                content_to_send = response_dl.content; print(f\"   -> Doc téléchargé ({len(content_to_send)} bytes).\")\n",
    "                if raw_file_cache_path: # Sauvegarder si chemin fourni\n",
    "                     try: save_path = Path(raw_file_cache_path); save_path.parent.mkdir(parents=True, exist_ok=True); save_path.write_bytes(content_to_send); print(f\"   -> Doc brut sauvegardé: {save_path.resolve()}\")\n",
    "                     except Exception as e_save: print(f\"   -> ⚠️ Erreur sauvegarde brut: {e_save}\")\n",
    "            except requests.exceptions.RequestException as e: raise ConnectionError(f\"Erreur téléchargement {source_url}: {e}\") from e\n",
    "\n",
    "    elif file_content:\n",
    "         # Cas: Fichier uploadé (pas d'URL source)\n",
    "         print(f\"-> Utilisation contenu fichier '{file_name}' ({len(file_content)} bytes)...\")\n",
    "         content_to_send = file_content\n",
    "         # Vérifier si upload est texte simple\n",
    "         if any(file_name.lower().endswith(ext) for ext in PLAINTEXT_EXTENSIONS):\n",
    "              print(\"   -> Fichier uploadé détecté comme texte simple. Lecture directe.\")\n",
    "              try:\n",
    "                  texte_brut = file_content.decode('utf-8', errors='ignore')\n",
    "                  save_to_cache(cache_key, texte_brut) # Sauver dans cache texte\n",
    "                  return texte_brut\n",
    "              except Exception as e_decode:\n",
    "                  print(f\"   -> ⚠️ Erreur décodage fichier texte '{file_name}': {e_decode}. Tentative avec Tika...\")\n",
    "                  # Si erreur décodage, on laisse Tika essayer\n",
    "    else:\n",
    "         raise ValueError(\"fetch_with_tika: Il faut soit source_url soit file_content.\")\n",
    "\n",
    "    # 3. Envoyer à Tika (seulement si nécessaire et contenu valide)\n",
    "    if not content_to_send:\n",
    "         print(\"   -> ⚠️ Contenu brut vide ou non récupéré. Impossible d'envoyer à Tika.\")\n",
    "         save_to_cache(cache_key, \"\") # Sauver cache vide pour éviter retry\n",
    "         return \"\"\n",
    "\n",
    "    print(f\"-> Envoi contenu à Tika ({TIKA_SERVER_URL})... (Timeout={timeout_tika}s)\")\n",
    "    headers = { 'Accept': 'text/plain', 'Content-Type': 'application/octet-stream', 'X-Tika-OCRLanguage': 'fra+eng' }\n",
    "    try:\n",
    "        response_tika = requests.put(TIKA_SERVER_URL, data=content_to_send, headers=headers, timeout=timeout_tika)\n",
    "        response_tika.raise_for_status()\n",
    "        texte_brut = response_tika.text\n",
    "        if not texte_brut: print(f\"   -> Warning: Tika status {response_tika.status_code} sans texte.\")\n",
    "        else: print(f\"   -> Texte Tika extrait (longueur {len(texte_brut)}).\")\n",
    "\n",
    "        # 4. Sauvegarder le TEXTE EXTRAIT dans le cache .txt\n",
    "        save_to_cache(cache_key, texte_brut)\n",
    "        return texte_brut\n",
    "\n",
    "    except requests.exceptions.Timeout: print(f\"   -> ❌ Timeout Tika ({timeout_tika}s).\"); raise ConnectionError(f\"Timeout Tika\")\n",
    "    except requests.exceptions.RequestException as e: raise ConnectionError(f\"Erreur Tika: {e}\") from e\n",
    "\n",
    "def verify_extract_definitions(definitions_list: list):\n",
    "    \"\"\"\n",
    "    Vérifie la présence des marqueurs start/end pour chaque extrait défini.\n",
    "    Récupère le texte complet (via cache ou fetch) pour chaque source.\n",
    "    Retourne un résumé des vérifications.\n",
    "    \"\"\"\n",
    "    print(\"\\n🔬 Lancement de la vérification des marqueurs d'extraits...\")\n",
    "    results = []\n",
    "    total_checks = 0\n",
    "    total_errors = 0\n",
    "\n",
    "    if not definitions_list or definitions_list == DEFAULT_EXTRACT_SOURCES:\n",
    "         return \"Aucune définition valide à vérifier.\"\n",
    "\n",
    "    for source_idx, source_info in enumerate(definitions_list):\n",
    "        source_name = source_info.get(\"source_name\", f\"Source Inconnue #{source_idx+1}\")\n",
    "        print(f\"\\n--- Vérification Source: '{source_name}' ---\")\n",
    "        source_errors = 0\n",
    "        source_checks = 0\n",
    "        texte_brut_source = None\n",
    "        reconstructed_url = None\n",
    "\n",
    "        try:\n",
    "            # Reconstruire l'URL\n",
    "            reconstructed_url = reconstruct_url(\n",
    "                source_info.get(\"schema\"), source_info.get(\"host_parts\", []), source_info.get(\"path\")\n",
    "            )\n",
    "            if not reconstructed_url:\n",
    "                print(\"   -> ❌ Erreur: URL Invalide.\")\n",
    "                results.append(f\"<li>{source_name}: URL invalide</li>\")\n",
    "                total_errors += len(source_info.get(\"extracts\", [])) # Compter tous les extraits comme erreurs\n",
    "                total_checks += len(source_info.get(\"extracts\", []))\n",
    "                continue\n",
    "\n",
    "            # Récupérer le texte complet (via cache ou fetch)\n",
    "            source_type = source_info.get(\"source_type\")\n",
    "            cache_key = reconstructed_url # Clé cache pour le texte complet\n",
    "            texte_brut_source = load_from_cache(cache_key)\n",
    "\n",
    "            if texte_brut_source is None:\n",
    "                print(f\"   -> Cache texte absent. Récupération (type: {source_type})...\")\n",
    "                if source_type == \"jina\": texte_brut_source = fetch_with_jina(reconstructed_url)\n",
    "                elif source_type == \"direct_download\": texte_brut_source = fetch_direct_text(reconstructed_url)\n",
    "                elif source_type == \"tika\":\n",
    "                    is_plaintext = any(source_info.get(\"path\", \"\").lower().endswith(ext) for ext in PLAINTEXT_EXTENSIONS)\n",
    "                    if is_plaintext: texte_brut_source = fetch_direct_text(reconstructed_url)\n",
    "                    else:\n",
    "                        # On ne peut pas raisonnablement vérifier les marqueurs si Tika échoue ici\n",
    "                        print(\"   -> ⚠️ Impossible de vérifier les marqueurs car nécessite Tika (potentiellement long/échoué).\")\n",
    "                        texte_brut_source = None # Marquer comme non vérifiable\n",
    "                else:\n",
    "                     print(f\"   -> ⚠️ Type source inconnu '{source_type}'. Vérification impossible.\")\n",
    "                     texte_brut_source = None\n",
    "\n",
    "            # Vérifier les marqueurs si le texte a été obtenu\n",
    "            if texte_brut_source is not None:\n",
    "                print(f\"   -> Texte complet récupéré (longueur: {len(texte_brut_source)}). Vérification des extraits...\")\n",
    "                extracts = source_info.get(\"extracts\", [])\n",
    "                if not extracts: print(\"      -> Aucun extrait défini pour cette source.\")\n",
    "\n",
    "                for extract_idx, extract_info in enumerate(extracts):\n",
    "                    extract_name = extract_info.get(\"extract_name\", f\"Extrait #{extract_idx+1}\")\n",
    "                    start_marker = extract_info.get(\"start_marker\")\n",
    "                    end_marker = extract_info.get(\"end_marker\")\n",
    "                    total_checks += 1\n",
    "                    source_checks += 1\n",
    "                    marker_errors = []\n",
    "\n",
    "                    if not start_marker or not end_marker:\n",
    "                        marker_errors.append(\"Marqueur(s) Manquant(s)\")\n",
    "                    else:\n",
    "                        start_found = start_marker in texte_brut_source\n",
    "                        end_found_after_start = False\n",
    "                        if start_found:\n",
    "                            try:\n",
    "                                start_pos = texte_brut_source.index(start_marker)\n",
    "                                end_found_after_start = end_marker in texte_brut_source[start_pos + len(start_marker):]\n",
    "                            except ValueError: # Ne devrait pas arriver si start_found est True\n",
    "                                 start_found = False\n",
    "\n",
    "                        if not start_found: marker_errors.append(\"Début NON TROUVÉ\")\n",
    "                        if not end_found_after_start: marker_errors.append(\"Fin NON TROUVÉE (après début)\")\n",
    "\n",
    "                    if marker_errors:\n",
    "                        print(f\"      -> ❌ Problème Extrait '{extract_name}': {', '.join(marker_errors)}\")\n",
    "                        results.append(f\"<li>{source_name} -> {extract_name}: <strong style='color:red;'>{', '.join(marker_errors)}</strong></li>\")\n",
    "                        source_errors += 1\n",
    "                        total_errors += 1\n",
    "                    else:\n",
    "                         print(f\"      -> ✅ OK: Extrait '{extract_name}'\")\n",
    "                         # results.append(f\"<li>{source_name} -> {extract_name}: OK</li>\") # Optionnel: lister aussi les OK\n",
    "\n",
    "            else: # Cas où le texte brut n'a pas pu être récupéré (ex: erreur Tika pendant la vérif)\n",
    "                 num_extracts = len(source_info.get(\"extracts\",[]))\n",
    "                 results.append(f\"<li>{source_name}: Vérification impossible (texte source non obtenu)</li>\")\n",
    "                 total_errors += num_extracts\n",
    "                 total_checks += num_extracts\n",
    "\n",
    "\n",
    "        except Exception as e_verify:\n",
    "            print(f\"   -> ❌ Erreur inattendue vérification source '{source_name}': {e_verify}\")\n",
    "            num_extracts = len(source_info.get(\"extracts\",[]))\n",
    "            results.append(f\"<li>{source_name}: Erreur Vérification Générale ({type(e_verify).__name__})</li>\")\n",
    "            total_errors += num_extracts\n",
    "            total_checks += num_extracts # Compter comme échec si erreur globale\n",
    "\n",
    "    summary = f\"--- Résultat Vérification ---<br/>{total_checks} extraits vérifiés. <strong style='color: {'red' if total_errors > 0 else 'green'};'>{total_errors} erreur(s) trouvée(s).</strong>\"\n",
    "    if results:\n",
    "        summary += \"<br/>Détails erreurs :<ul>\" + \"\".join(results) + \"</ul>\"\n",
    "    else:\n",
    "        summary += \"<br/>Tous les marqueurs semblent corrects.\"\n",
    "\n",
    "    print(f\"\\n{summary.replace('<br/>', '\\n').replace('<li>', '- ').replace('</li>', '').replace('<ul>', '').replace('</ul>', '').replace('<strong>', '').replace('</strong>', '')}\") # Affichage console simple\n",
    "    return summary\n",
    "\n",
    "\n",
    "print(\"Fonctions utilitaires UI_Configuration définies.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c738562",
   "metadata": {},
   "source": [
    "## 4. Initialisation du Cache (Optionnel)\n",
    "\n",
    "Vérification et pré-remplissage du cache fichier pour les textes complets des sources définies (celles définies initialement ou chargées depuis le fichier chiffré à l'étape précédente)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0e2d2004",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Initialisation du Cache des Textes Complets ---\n",
      "Vérification du cache pour 4 source(s)...\n",
      "\n",
      "--- Fin Initialisation du Cache ---\n",
      "✅ Cache initialisé/vérifié.\n"
     ]
    }
   ],
   "source": [
    "# --- Bloc Python 4 (Initialisation Cache - MODIFIÉ pour extensions texte) ---\n",
    "\n",
    "print(\"\\n--- Initialisation du Cache des Textes Complets ---\")\n",
    "\n",
    "definitions_to_check = current_extract_definitions if 'current_extract_definitions' in locals() and current_extract_definitions else EXTRACT_SOURCES\n",
    "TEMP_DOWNLOAD_DIR = Path(\"./temp_downloads\") # S'assurer qu'il est défini\n",
    "\n",
    "if not definitions_to_check or definitions_to_check == DEFAULT_EXTRACT_SOURCES:\n",
    "     print(\" -> Aucune définition de source valide à vérifier/initialiser.\")\n",
    "else:\n",
    "    initialisation_errors = 0\n",
    "    print(f\"Vérification du cache pour {len(definitions_to_check)} source(s)...\")\n",
    "    for i, source_info in enumerate(definitions_to_check):\n",
    "        source_name = source_info.get(\"source_name\", f\"Source #{i+1}\")\n",
    "        try:\n",
    "            reconstructed_url = reconstruct_url(\n",
    "                source_info.get(\"schema\"), source_info.get(\"host_parts\", []), source_info.get(\"path\")\n",
    "            )\n",
    "            if not reconstructed_url: print(f\"   -> ⚠️ URL invalide pour '{source_name}'.\"); initialisation_errors += 1; continue\n",
    "\n",
    "            source_type = source_info.get(\"source_type\")\n",
    "            original_path_str = source_info.get(\"path\", \"\")\n",
    "            is_plaintext_url = any(original_path_str.lower().endswith(ext) for ext in PLAINTEXT_EXTENSIONS)\n",
    "\n",
    "            # Utiliser l'URL reconstruite comme clé pour le cache texte final\n",
    "            filepath = get_cache_filepath(reconstructed_url)\n",
    "            if not filepath.exists():\n",
    "                print(f\"   -> Cache texte absent pour '{source_name}'. Récupération (type: {source_type})...\")\n",
    "                try:\n",
    "                    if source_type == \"jina\":\n",
    "                        fetch_with_jina(reconstructed_url)\n",
    "                    elif source_type == \"direct_download\":\n",
    "                         fetch_direct_text(reconstructed_url)\n",
    "                    elif source_type == \"tika\":\n",
    "                        if is_plaintext_url:\n",
    "                             # Si type=tika mais URL est texte simple, utiliser fetch direct\n",
    "                             print(\"      (URL type texte détectée, utilisation fetch direct au lieu de Tika)\")\n",
    "                             fetch_direct_text(reconstructed_url)\n",
    "                        else:\n",
    "                            # Type Tika pour fichier binaire (PDF, DOCX...)\n",
    "                            url_hash = hashlib.sha256(reconstructed_url.encode()).hexdigest()\n",
    "                            file_extension = Path(original_path_str).suffix if Path(original_path_str).suffix else \".download\"\n",
    "                            temp_save_path = TEMP_DOWNLOAD_DIR / f\"{url_hash}{file_extension}\"\n",
    "                            fetch_with_tika(source_url=reconstructed_url, raw_file_cache_path=temp_save_path)\n",
    "                    else:\n",
    "                         print(f\"   -> ⚠️ Type source inconnu '{source_type}'.\")\n",
    "                         initialisation_errors += 1\n",
    "\n",
    "                except Exception as e_fetch: # Attraper erreur PENDANT le fetch\n",
    "                    print(f\"   -> ❌ Erreur fetch pour '{source_name}': {e_fetch}\")\n",
    "                    initialisation_errors += 1\n",
    "            # else: print(f\"   -> Cache texte trouvé pour '{source_name}'.\")\n",
    "\n",
    "        except Exception as e_loop: # Attraper erreur DANS la boucle (ex: reconstruct_url)\n",
    "            print(f\"   -> ❌ Erreur traitement source '{source_name}': {e_loop}\")\n",
    "            initialisation_errors += 1\n",
    "\n",
    "    print(\"\\n--- Fin Initialisation du Cache ---\")\n",
    "    if initialisation_errors > 0: print(f\"⚠️ {initialisation_errors} erreur(s) rencontrée(s).\")\n",
    "    else: print(\"✅ Cache initialisé/vérifié.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "355de48a",
   "metadata": {},
   "source": [
    "## 5. Définition de la Fonction Principale de l'UI (`configure_analysis_task`)\n",
    "\n",
    "Définition de la fonction qui sera appelée par le notebook exécuteur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "140c9f17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fonction configure_analysis_task() définie dans UI_Configuration.ipynb.\n"
     ]
    }
   ],
   "source": [
    "def configure_analysis_task():\n",
    "    \"\"\"Affiche l'UI, gère interactions et retourne texte préparé.\"\"\"\n",
    "\n",
    "    # --- Variables locales à la fonction pour l'état de l'UI ---\n",
    "    # Note: On utilise 'nonlocal' pour les modifier dans les callbacks\n",
    "    texte_analyse_prepare_local = \"\"\n",
    "    analyse_ready_to_run_local = False\n",
    "\n",
    "    # --- Récupération clé et chargement initial ---\n",
    "    # Utilise les variables globales définies dans les cellules précédentes\n",
    "    global ENCRYPTION_KEY, current_extract_definitions, CONFIG_FILE, EXTRACT_SOURCES\n",
    "    # Charger/Recharger les définitions au début de l'appel de la fonction\n",
    "    # pour refléter un éventuel chargement/sauvegarde via les boutons de l'UI\n",
    "    current_extract_definitions = load_extract_definitions(CONFIG_FILE, ENCRYPTION_KEY)\n",
    "\n",
    "    # --- Création des Widgets ---\n",
    "    # (Utilise current_extract_definitions chargée)\n",
    "\n",
    "    # Bibliothèque\n",
    "    source_mode_radio = widgets.RadioButtons(\n",
    "        options=['Source Aléatoire', 'Choisir Document & Extrait'],\n",
    "        description='Mode:', value='Source Aléatoire', disabled=False, style={'description_width': 'initial'}\n",
    "    )\n",
    "    # Vérification pour éviter l'erreur si current_extract_definitions est invalide au démarrage\n",
    "    valid_source_names = [s.get(\"source_name\", f\"Erreur Def #{i}\")\n",
    "                          for i, s in enumerate(current_extract_definitions) if isinstance(s, dict)]\n",
    "    if not valid_source_names: # Fournir une option par défaut si tout échoue\n",
    "         print(\"⚠️ Erreur: Aucune définition de source valide trouvée pour le dropdown.\")\n",
    "         valid_source_names = [\"Erreur Chargement Config\"]\n",
    "\n",
    "    source_doc_dropdown = widgets.Dropdown(\n",
    "        options=valid_source_names,\n",
    "        description='Document:', disabled=True, style={'description_width': 'initial'}, layout={'width': '90%'}\n",
    "    )\n",
    "    extract_dropdown = widgets.Dropdown(\n",
    "        options=[], description='Extrait:', disabled=True, style={'description_width': 'initial'}, layout={'width': '90%'}\n",
    "    )\n",
    "    tab_library = widgets.VBox([source_mode_radio, source_doc_dropdown, extract_dropdown])\n",
    "\n",
    "    # URL\n",
    "    url_input = widgets.Text(placeholder=\"Entrez l'URL\", description=\"URL:\", layout={'width': '90%'}, style={'description_width': 'initial'})\n",
    "    url_processing_type_radio = widgets.RadioButtons(options=[('Page Web (via Jina)', 'jina'), ('Document PDF/Office (via Tika)', 'tika')], description='Type:', value='jina', disabled=False, style={'description_width': 'initial'})\n",
    "    tab_url = widgets.VBox([widgets.Label(\"Entrez l'URL et choisissez le type:\"), url_input, url_processing_type_radio])\n",
    "\n",
    "    # Fichier\n",
    "    file_uploader = widgets.FileUpload(accept='.txt,.pdf,.doc,.docx,.html,.xml,.md', multiple=False, description=\"Fichier:\", style={'description_width': 'initial'})\n",
    "    tab_file = widgets.VBox([widgets.Label(\"Téléversez fichier (traité par Tika si besoin):\"), file_uploader]) # Texte Tika ajusté\n",
    "\n",
    "    # Texte Direct\n",
    "    direct_text_input = widgets.Textarea(placeholder=\"Collez texte ici...\", layout={'width': '90%', 'height': '200px'})\n",
    "    tab_direct = widgets.VBox([widgets.Label(\"Saisissez le texte :\"), direct_text_input])\n",
    "\n",
    "    # Tabs\n",
    "    tabs = widgets.Tab(children=[tab_library, tab_url, tab_file, tab_direct])\n",
    "    tabs.set_title(0, '📚 Bibliothèque'); tabs.set_title(1, '🌐 URL'); tabs.set_title(2, '📄 Fichier'); tabs.set_title(3, '✍️ Texte Direct')\n",
    "\n",
    "    # Extraction\n",
    "    start_marker_input = widgets.Text(placeholder=\"(Optionnel) Début (exclus)\", description=\"Début Extrait:\", layout={'width': '90%'}, style={'description_width': 'initial'})\n",
    "    end_marker_input = widgets.Text(placeholder=\"(Optionnel) Fin (exclue)\", description=\"Fin Extrait:\", layout={'width': '90%'}, style={'description_width': 'initial'})\n",
    "    extraction_box = widgets.VBox([\n",
    "        widgets.HTML(\"<hr><h4>Options d'Extraction (Optionnel)</h4>\"),\n",
    "        widgets.HTML(\"<p style='font-size:0.9em; color:grey;'>Marqueurs uniques. Exclus du résultat.</p>\"),\n",
    "        start_marker_input, end_marker_input\n",
    "    ])\n",
    "\n",
    "    # Gestion Config\n",
    "    config_output_area = widgets.HTML(value=\"<i>Chargement...</i>\", layout={'border': '1px solid #ccc', 'padding': '5px', 'margin_top': '5px', 'max_height': '200px', 'overflow_y':'auto'})\n",
    "    load_config_button = widgets.Button(description=\"Charger/Actualiser Déf.\", icon=\"refresh\", button_style='info', tooltip=\"Charge les définitions\")\n",
    "    save_config_button = widgets.Button(description=\"Sauvegarder Déf.\", icon=\"save\", button_style='warning', disabled=(not ENCRYPTION_KEY), tooltip=\"Sauvegarde les définitions\")\n",
    "    verify_button = widgets.Button(description=\"Vérifier Marqueurs\", icon=\"check\", button_style='primary', tooltip=\"Vérifie les marqueurs\") # Bouton Vérif\n",
    "    config_management_box = widgets.VBox([\n",
    "         widgets.HTML(\"<hr style='margin: 20px 0;'><h3>Gestion Configuration Sources</h3>\"),\n",
    "         widgets.HBox([load_config_button, save_config_button, verify_button]), # Bouton Vérif ajouté\n",
    "         config_output_area\n",
    "    ])\n",
    "\n",
    "    # Boutons Principaux et Sortie\n",
    "    prepare_button = widgets.Button(description=\"Préparer le Texte\", button_style='info', icon='cogs', tooltip=\"Charge, extrait et prépare texte.\")\n",
    "    run_button = widgets.Button(description=\"Lancer l'Analyse\", button_style='success', icon='play', disabled=True, tooltip=\"Démarre l'analyse.\")\n",
    "    main_output_area = widgets.Output(layout={'border': '1px solid #ccc', 'padding': '10px', 'margin_top': '10px', 'min_height': '100px'})\n",
    "\n",
    "    # --- Callbacks ---\n",
    "    def update_extract_options_ui(change):\n",
    "        nonlocal extract_dropdown # Référence widget\n",
    "        global current_extract_definitions # Accès définitions\n",
    "        selected_doc_name = change.get('new', source_doc_dropdown.value)\n",
    "        # Utiliser .get pour éviter KeyError si structure invalide\n",
    "        source_info = next((s for s in current_extract_definitions if isinstance(s, dict) and s.get(\"source_name\") == selected_doc_name), None)\n",
    "        if source_info:\n",
    "            extract_options = [\"Texte Complet\"] + [e.get(\"extract_name\", \"Sans Nom\") for e in source_info.get(\"extracts\", []) if isinstance(e, dict)]\n",
    "            current_extract_value = extract_dropdown.value\n",
    "            extract_dropdown.options = extract_options\n",
    "            if current_extract_value in extract_options:\n",
    "                extract_dropdown.value = current_extract_value\n",
    "            elif extract_options: # S'assurer qu'il y a des options avant d'accéder à [0]\n",
    "                 extract_dropdown.value = extract_options[0]\n",
    "            else: # Cas où il n'y a que \"Texte Complet\" et pas d'extraits\n",
    "                 extract_dropdown.value = None\n",
    "        else:\n",
    "            extract_dropdown.options = []\n",
    "            extract_dropdown.value = None\n",
    "    source_doc_dropdown.observe(update_extract_options_ui, names='value')\n",
    "\n",
    "    def handle_source_mode_change_ui(change):\n",
    "        nonlocal source_doc_dropdown, extract_dropdown\n",
    "        is_manual_choice = (change.get('new', source_mode_radio.value) == 'Choisir Document & Extrait')\n",
    "        source_doc_dropdown.disabled = not is_manual_choice\n",
    "        extract_dropdown.disabled = not is_manual_choice\n",
    "        # ATTENTION: Indentation cruciale ici\n",
    "        if is_manual_choice:\n",
    "            if source_doc_dropdown.options:\n",
    "                 # S'assurer qu'une valeur est sélectionnée avant de mettre à jour les extraits\n",
    "                 if source_doc_dropdown.value:\n",
    "                     update_extract_options_ui({'new': source_doc_dropdown.value})\n",
    "                 # Si aucune valeur n'est sélectionnée (cas initial ou après chargement liste vide), on vide les extraits\n",
    "                 else:\n",
    "                     extract_dropdown.options = []\n",
    "                     extract_dropdown.value = None\n",
    "            else: # Si pas d'options dans le premier dropdown, vider le second\n",
    "                 extract_dropdown.options = []\n",
    "                 extract_dropdown.value = None\n",
    "        else: # Cas 'Source Aléatoire'\n",
    "             extract_dropdown.options = []\n",
    "             extract_dropdown.value = None\n",
    "    source_mode_radio.observe(handle_source_mode_change_ui, names='value')\n",
    "\n",
    "    def display_definitions_in_ui(definitions_list):\n",
    "        # ... (Code identique, mais utilise .get pour sécurité) ...\n",
    "        if not definitions_list: return \"Aucune définition chargée.\"\n",
    "        MAX_EXTRACTS_DISPLAY = 5; html = \"<ul style='list-style-type: none; padding-left: 0;'>\";\n",
    "        for source in definitions_list:\n",
    "            if not isinstance(source, dict): continue # Ignorer éléments non valides\n",
    "            source_name_display = source.get('source_name', 'Erreur: Nom Manquant')\n",
    "            html += f\"<li style='margin-bottom: 10px;'><b>{source_name_display}</b> ({source.get('source_type', 'N/A')})\"\n",
    "            # Utilisation nouvelle structure URL\n",
    "            reconstructed = reconstruct_url(source.get(\"schema\"), source.get(\"host_parts\", []), source.get(\"path\"))\n",
    "            html += f\"<br/><small style='color:grey;'>{reconstructed or 'URL Invalide'}</small>\"\n",
    "            extracts = source.get('extracts', [])\n",
    "            if extracts and isinstance(extracts, list): # Vérifier que extracts est une liste\n",
    "                html += \"<ul style='margin-top: 4px; font-size: 0.9em; list-style-type: none; padding-left: 10px;'>\";\n",
    "                for i, extract in enumerate(extracts):\n",
    "                    if not isinstance(extract, dict): continue # Ignorer extraits non valides\n",
    "                    if i >= MAX_EXTRACTS_DISPLAY: html += f\"<li>... et {len(extracts) - MAX_EXTRACTS_DISPLAY} autre(s)</li>\"; break\n",
    "                    extract_name_display = extract.get('extract_name', 'Erreur: Nom Extrait Manquant')\n",
    "                    html += f\"<li>- {extract_name_display}</li>\";\n",
    "                html += \"</ul>\";\n",
    "            html += \"</li>\";\n",
    "        html += \"</ul>\"; return html\n",
    "\n",
    "    def on_load_config_click_ui(b):\n",
    "        nonlocal config_output_area, source_doc_dropdown, save_config_button # Widgets externes\n",
    "        global current_extract_definitions, ENCRYPTION_KEY, CONFIG_FILE # Variables globales\n",
    "        with main_output_area: clear_output(wait=True); print(\"⏳ Chargement définitions...\")\n",
    "        loaded_defs = load_extract_definitions(CONFIG_FILE, ENCRYPTION_KEY)\n",
    "        # ---- Validation robuste ----\n",
    "        valid_defs = [s for s in loaded_defs if isinstance(s, dict) and \"source_name\" in s]\n",
    "        if len(valid_defs) != len(loaded_defs):\n",
    "            print(\"⚠️ Attention: Certaines définitions chargées/par défaut étaient invalides et ont été ignorées.\")\n",
    "        current_extract_definitions = valid_defs # Utiliser seulement les valides\n",
    "        # ---------------------------\n",
    "        config_output_area.value = display_definitions_in_ui(current_extract_definitions)\n",
    "        # Mettre à jour dropdown bibliothèque\n",
    "        current_doc_selection = source_doc_dropdown.value # Sauver la sélection\n",
    "        source_doc_options = [s[\"source_name\"] for s in current_extract_definitions] # Utilise la liste filtrée\n",
    "        source_doc_dropdown.options = source_doc_options\n",
    "        # Essayer de restaurer la sélection ou prendre la première\n",
    "        if current_doc_selection in source_doc_options: source_doc_dropdown.value = current_doc_selection\n",
    "        elif source_doc_options: source_doc_dropdown.value = source_doc_options[0]\n",
    "        else: source_doc_dropdown.value = None\n",
    "        # Mettre à jour les extraits (appelle update_extract_options_ui via observe)\n",
    "        # Forcer l'appel au cas où la valeur n'a pas changé mais les options oui\n",
    "        if source_doc_dropdown.value: update_extract_options_ui({'new': source_doc_dropdown.value})\n",
    "        else: extract_dropdown.options = []\n",
    "\n",
    "        with main_output_area: clear_output(wait=True); print(\"✅ Définitions chargées/actualisées.\")\n",
    "        save_config_button.disabled = (not ENCRYPTION_KEY)\n",
    "\n",
    "    def on_save_config_click_ui(b):\n",
    "        nonlocal main_output_area # Widget externe\n",
    "        global current_extract_definitions, ENCRYPTION_KEY, CONFIG_FILE # Variables globales\n",
    "        with main_output_area: clear_output(wait=True); print(\"⏳ Sauvegarde définitions...\")\n",
    "        success = save_extract_definitions(current_extract_definitions, CONFIG_FILE, ENCRYPTION_KEY)\n",
    "        if success: print(\"✅ Définitions sauvegardées.\")\n",
    "        else: print(\"❌ Échec sauvegarde.\")\n",
    "\n",
    "    def on_verify_click_ui(b):\n",
    "        \"\"\"Lance la vérification et affiche le résultat.\"\"\"\n",
    "        nonlocal main_output_area # Widget externe\n",
    "        global current_extract_definitions # Variable globale\n",
    "        with main_output_area:\n",
    "            clear_output(wait=True)\n",
    "            print(\"Lancement de la vérification (peut prendre du temps)...\")\n",
    "            # Appelle la fonction de vérification définie dans la cellule précédente\n",
    "            # S'assurer que verify_extract_definitions est bien définie globalement\n",
    "            if 'verify_extract_definitions' in globals():\n",
    "                 summary = verify_extract_definitions(current_extract_definitions)\n",
    "                 clear_output(wait=True)\n",
    "                 display(widgets.HTML(summary)) # Afficher le résultat HTML\n",
    "                 print(\"\\nVérification terminée.\") # Message console\n",
    "            else:\n",
    "                 print(\"ERREUR: La fonction verify_extract_definitions n'est pas trouvée.\")\n",
    "\n",
    "\n",
    "    def on_prepare_click_ui(b):\n",
    "        nonlocal texte_analyse_prepare_local, analyse_ready_to_run_local\n",
    "        global current_extract_definitions\n",
    "        # ... (Logique complète et corrigée de on_prepare_click_ui de ma réponse précédente) ...\n",
    "        # ... Assurez-vous que cette logique utilise bien la structure URL corrigée ...\n",
    "        # ... et la gestion des extensions texte simple ...\n",
    "        analyse_ready_to_run_local = False; run_button.disabled = True\n",
    "        texte_brut_source = \"\"; source_description = \"\"; start_marker_final = \"\"; end_marker_final = \"\"; error_occured = False\n",
    "\n",
    "        with main_output_area:\n",
    "            clear_output(wait=True); print(\"⏳ Préparation texte...\")\n",
    "            selected_tab_index = tabs.selected_index\n",
    "            try:\n",
    "                if selected_tab_index == 0: # Bibliothèque\n",
    "                    source_info = None ; extract_info = None ; reconstructed_url = None\n",
    "                    if source_mode_radio.value == 'Source Aléatoire':\n",
    "                        if not current_extract_definitions: raise ValueError(\"Biblio vide!\")\n",
    "                        source_info = random.choice(current_extract_definitions)\n",
    "                        extracts_available = source_info.get(\"extracts\", []); potential_extracts = [{\"extract_name\": \"Texte Complet\"}] + extracts_available; extract_info = random.choice(potential_extracts); print(f\"-> Choix Aléatoire: Doc='{source_info.get('source_name', '?')}', Extrait='{extract_info['extract_name']}'\")\n",
    "                    else:\n",
    "                        selected_doc_name = source_doc_dropdown.value; selected_extract_name = extract_dropdown.value\n",
    "                        if not selected_doc_name: raise ValueError(\"Aucun document sélectionné.\")\n",
    "                        source_info = next((s for s in current_extract_definitions if s.get(\"source_name\") == selected_doc_name), None)\n",
    "                        if not source_info: raise ValueError(f\"Doc '{selected_doc_name}' non trouvé.\")\n",
    "                        if selected_extract_name == \"Texte Complet\": extract_info = {\"extract_name\": \"Texte Complet\"}\n",
    "                        else: extract_info = next((e for e in source_info.get(\"extracts\", []) if e.get(\"extract_name\") == selected_extract_name), None);\n",
    "                        if not extract_info: raise ValueError(f\"Extrait '{selected_extract_name}' non trouvé.\")\n",
    "                        print(f\"-> Choix Manuel: Doc='{source_info['source_name']}', Extrait='{extract_info['extract_name']}'\")\n",
    "\n",
    "                    start_marker_final = extract_info.get(\"start_marker\", \"\") if extract_info.get(\"extract_name\") != \"Texte Complet\" else \"\"\n",
    "                    end_marker_final = extract_info.get(\"end_marker\", \"\") if extract_info.get(\"extract_name\") != \"Texte Complet\" else \"\"\n",
    "                    reconstructed_url = reconstruct_url(source_info.get(\"schema\"), source_info.get(\"host_parts\", []), source_info.get(\"path\"))\n",
    "                    if not reconstructed_url: raise ValueError(\"URL source invalide.\")\n",
    "                    source_description = f\"Biblio: {source_info.get('source_name','?')} ({extract_info.get('extract_name','?')})\"\n",
    "\n",
    "                    cached_text = load_from_cache(reconstructed_url)\n",
    "                    if cached_text is not None: texte_brut_source = cached_text\n",
    "                    else:\n",
    "                        source_type = source_info.get(\"source_type\"); original_path_str = source_info.get(\"path\", \"\"); is_plaintext_url = any(original_path_str.lower().endswith(ext) for ext in PLAINTEXT_EXTENSIONS)\n",
    "                        print(f\"-> Cache vide. Récupération (Type: {source_type}, URL: ...)...\")\n",
    "                        if source_type == \"jina\": texte_brut_source = fetch_with_jina(reconstructed_url)\n",
    "                        elif source_type == \"direct_download\": texte_brut_source = fetch_direct_text(reconstructed_url)\n",
    "                        elif source_type == \"tika\":\n",
    "                             if is_plaintext_url: print(\"      (URL type texte, fetch direct)\"); texte_brut_source = fetch_direct_text(reconstructed_url)\n",
    "                             else: url_hash = hashlib.sha256(reconstructed_url.encode()).hexdigest(); temp_save_path = TEMP_DOWNLOAD_DIR / f\"{url_hash}.download_debug\"; texte_brut_source = fetch_with_tika(source_url=reconstructed_url, raw_file_cache_path=temp_save_path)\n",
    "                        else: raise ValueError(f\"Type source inconnu '{source_type}'.\")\n",
    "\n",
    "                elif selected_tab_index == 1: # URL\n",
    "                    url = url_input.value.strip(); processing_type = url_processing_type_radio.value\n",
    "                    if not url or not url.startswith(('http://', 'https://')): raise ValueError(\"URL invalide.\")\n",
    "                    source_description = f\"URL ({processing_type.upper()}): {url}\"; cached_text = load_from_cache(url)\n",
    "                    if cached_text is not None: texte_brut_source = cached_text\n",
    "                    else:\n",
    "                        is_plaintext_url = any(url.lower().endswith(ext) for ext in PLAINTEXT_EXTENSIONS)\n",
    "                        if processing_type == \"jina\": texte_brut_source = fetch_with_jina(url)\n",
    "                        elif processing_type == \"tika\":\n",
    "                             if is_plaintext_url: print(\"   -> URL type texte, fetch direct.\"); texte_brut_source = fetch_direct_text(url)\n",
    "                             else: texte_brut_source = fetch_with_tika(source_url=url)\n",
    "                        else: raise ValueError(f\"Type traitement inconnu: {processing_type}\")\n",
    "                    start_marker_final = start_marker_input.value.strip()\n",
    "                    end_marker_final = end_marker_input.value.strip()\n",
    "\n",
    "                elif selected_tab_index == 2: # Fichier\n",
    "                    if not file_uploader.value: raise ValueError(\"Veuillez téléverser un fichier.\")\n",
    "                    uploaded_file_info = file_uploader.value[0]; file_name = uploaded_file_info['name']; cache_key = f\"file://{file_name}\"; cached_text = load_from_cache(cache_key)\n",
    "                    if cached_text is not None: texte_brut_source = cached_text; source_description = f\"Fichier (Cache): {file_name}\"\n",
    "                    else:\n",
    "                        is_plaintext_file = any(file_name.lower().endswith(ext) for ext in PLAINTEXT_EXTENSIONS)\n",
    "                        file_content_bytes = uploaded_file_info['content']\n",
    "                        if is_plaintext_file:\n",
    "                            print(f\"-> Traitement fichier texte local : '{file_name}'\");\n",
    "                            try: texte_brut_source = file_content_bytes.decode('utf-8', errors='ignore'); print(f\"   -> Contenu lu direct.\"); save_to_cache(cache_key, texte_brut_source); source_description = f\"Fichier Texte: {file_name}\"\n",
    "                            except Exception as e_decode: print(f\"   -> ⚠️ Erreur décodage, tentative Tika: {e_decode}\"); texte_brut_source = fetch_with_tika(file_content=file_content_bytes, file_name=file_name); source_description = f\"Fichier (via Tika post-err): {file_name}\"\n",
    "                        else: print(f\"-> Traitement fichier '{file_name}' via Tika...\"); source_description = f\"Fichier (via Tika): {file_name}\"; texte_brut_source = fetch_with_tika(file_content=file_content_bytes, file_name=file_name)\n",
    "                    try: file_uploader.value = {}; file_uploader._counter = 0\n",
    "                    except Exception: pass\n",
    "                    start_marker_final = start_marker_input.value.strip()\n",
    "                    end_marker_final = end_marker_input.value.strip()\n",
    "\n",
    "                elif selected_tab_index == 3: # Texte Direct\n",
    "                    texte_brut_source = direct_text_input.value; source_description = \"Texte Direct\"\n",
    "                    if not texte_brut_source: raise ValueError(\"Veuillez saisir du texte.\")\n",
    "                    print(f\"-> Utilisation texte direct (longueur: {len(texte_brut_source)}).\"); start_marker_final = start_marker_input.value.strip(); end_marker_final = end_marker_input.value.strip()\n",
    "                else: raise ValueError(\"Onglet inconnu.\")\n",
    "\n",
    "                # --- Application finale des marqueurs ---\n",
    "                texte_final = texte_brut_source\n",
    "                if start_marker_final or end_marker_final:\n",
    "                    # ... (logique d'extraction identique) ...\n",
    "                    print(\"\\n-> Application marqueurs...\"); start_index = 0; end_index = len(texte_brut_source);\n",
    "                    if start_marker_final:\n",
    "                        try: found_start = texte_brut_source.index(start_marker_final); start_index = found_start + len(start_marker_final); print(f\"   -> Début trouvé.\")\n",
    "                        except ValueError: print(f\"   ⚠️ Début non trouvé.\"); start_index = 0\n",
    "                    if end_marker_final:\n",
    "                        try: found_end = texte_brut_source.index(end_marker_final, start_index); end_index = found_end; print(f\"   -> Fin trouvée.\")\n",
    "                        except ValueError: print(f\"   ⚠️ Fin non trouvée.\"); end_index = len(texte_brut_source)\n",
    "                    if start_index < end_index: texte_final = texte_brut_source[start_index:end_index].strip();\n",
    "                    else: print(f\"   ⚠️ Conflit/Vide.\"); texte_final = \"\"\n",
    "                    if texte_final and (start_marker_final or end_marker_final) : source_description += \" (Extrait)\"\n",
    "                    if not texte_final and texte_brut_source: print(\"   -> Extraction vide.\")\n",
    "\n",
    "                # --- Finalisation ---\n",
    "                texte_analyse_prepare_local = texte_final\n",
    "                if not texte_analyse_prepare_local: print(\"\\n⚠️ Texte préparé final vide !\")\n",
    "                print(\"\\n--- Aperçu Texte Préparé ---\")\n",
    "                preview = texte_analyse_prepare_local[:1500]; print(preview + ('\\n[...]' if len(texte_analyse_prepare_local) > 1500 else '')); print(\"-\" * 30)\n",
    "                print(f\"\\n✅ Texte préparé (Source: {source_description}, Longueur: {len(texte_analyse_prepare_local)}).\")\n",
    "                if len(texte_analyse_prepare_local) > 0: print(\"Cliquez sur 'Lancer l'Analyse'.\"); run_button.disabled = False\n",
    "                else: print(\"Texte vide.\"); run_button.disabled = True\n",
    "\n",
    "            except Exception as e:\n",
    "                 # ... (gestion d'erreur identique) ...\n",
    "                 error_occured = True ; texte_analyse_prepare_local = \"\"\n",
    "                 print(f\"\\n❌ Erreur Préparation : {type(e).__name__} - {e}\"); print(\"\\n--- Trace ---\"); print(traceback.format_exc()); print(\"-\" * 25); run_button.disabled = True\n",
    "\n",
    "    def on_run_click_ui(b):\n",
    "        nonlocal analyse_ready_to_run_local, texte_analyse_prepare_local\n",
    "        # ... (code identique) ...\n",
    "        if run_button.disabled or not texte_analyse_prepare_local:\n",
    "             with main_output_area: clear_output(wait=True); print(\"⚠️ Préparez un texte non vide.\")\n",
    "        else:\n",
    "            analyse_ready_to_run_local = True; prepare_button.disabled = True; run_button.disabled = True; tabs.disabled = True; start_marker_input.disabled = True; end_marker_input.disabled = True; load_config_button.disabled = True; save_config_button.disabled = True; source_mode_radio.disabled = True; source_doc_dropdown.disabled=True; extract_dropdown.disabled=True; url_input.disabled = True; url_processing_type_radio.disabled=True; file_uploader.disabled = True; direct_text_input.disabled = True\n",
    "            with main_output_area: clear_output(wait=True); print(f\"📝 Texte final prêt (Longueur: {len(texte_analyse_prepare_local)}).\"); print(\"\\n🚀 Lancement analyse...\")\n",
    "\n",
    "    # --- Lier Callbacks ---\n",
    "    prepare_button.on_click(on_prepare_click_ui)\n",
    "    run_button.on_click(on_run_click_ui)\n",
    "    load_config_button.on_click(on_load_config_click_ui)\n",
    "    save_config_button.on_click(on_save_config_click_ui)\n",
    "    verify_button.on_click(on_verify_click_ui) # <-- Lier nouveau bouton\n",
    "\n",
    "    # --- Affichage et Boucle ---\n",
    "    print(\"Initialisation interface...\")\n",
    "    ui_container = widgets.VBox([\n",
    "        widgets.HTML(\"<h2>Configuration Tâche Analyse</h2>\"),\n",
    "        widgets.HTML(\"<h3>1. Source Texte</h3>\"), tabs, extraction_box,\n",
    "        config_management_box, # <-- Boîte gestion config incluant nouveau bouton\n",
    "        widgets.HTML(\"<hr><h3>2. Préparation</h3>\"), prepare_button, main_output_area,\n",
    "        widgets.HTML(\"<hr><h3>3. Démarrage</h3>\"), run_button\n",
    "    ])\n",
    "    display(ui_container)\n",
    "\n",
    "    # Initialiser l'UI\n",
    "    handle_source_mode_change_ui({})\n",
    "    on_load_config_click_ui(None) # Charger config initiale\n",
    "\n",
    "    print(\"\\n⏳ En attente interaction...\")\n",
    "    with ui_events() as poll:\n",
    "        while not analyse_ready_to_run_local: poll(10); time.sleep(0.1)\n",
    "\n",
    "    print(\"\\n🏁 Configuration tâche terminée. Retour notebook principal...\")\n",
    "    return texte_analyse_prepare_local\n",
    "\n",
    "# --- Fin de la définition de configure_analysis_task ---\n",
    "print(\"Fonction configure_analysis_task() définie dans UI_Configuration.ipynb.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333e0c9c",
   "metadata": {},
   "source": [
    "## 6. Fin\n",
    "\n",
    "Le notebook `Argument_Analysis_UI_configuration.ipynb` est maintenant prêt. Il contient toute la logique nécessaire pour l'interface utilisateur, la gestion des sources, le cache et le chiffrement.\n",
    "\n",
    "Le notebook exécuteur principal peut maintenant utiliser la fonction `configure_analysis_task()` définie ici pour obtenir le texte préparé avant de lancer l'analyse par les agents."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
