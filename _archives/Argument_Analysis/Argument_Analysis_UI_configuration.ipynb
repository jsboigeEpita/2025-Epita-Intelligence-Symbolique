{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ccc3bb9d",
   "metadata": {},
   "source": [
    "# Interface de Configuration et Pr√©paration du Texte\n",
    "\n",
    "**Objectif:** Ce notebook d√©finit l'interface utilisateur et la logique n√©cessaire pour :\n",
    "1.  S√©lectionner une source de texte (Biblioth√®que pr√©d√©finie, URL, Fichier local, Texte direct).\n",
    "2.  Extraire le contenu textuel via Jina ou Tika si n√©cessaire.\n",
    "3.  Appliquer des marqueurs de d√©but/fin pour isoler un extrait sp√©cifique.\n",
    "4.  G√©rer un cache fichier pour les textes complets des sources externes.\n",
    "5.  Charger/Sauvegarder la configuration des sources pr√©d√©finies depuis/vers un fichier chiffr√©.\n",
    "6.  Retourner le texte final pr√©par√© au notebook ex√©cuteur principal.\n",
    "\n",
    "**Fonction Principale:** D√©finit la fonction `configure_analysis_task()` qui sera appel√©e par le notebook ex√©cuteur."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8806466",
   "metadata": {},
   "source": [
    "## 1. Imports Requis\n",
    "\n",
    "Importation des biblioth√®ques n√©cessaires pour l'UI, les requ√™tes HTTP, le cache, le chiffrement, et la gestion des fichiers/chemins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7021532a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports pour UI_Configuration charg√©s (incluant crypto KDF et base64).\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# Filename: UI_Configuration.ipynb\n",
    "\n",
    "# %% =====================================================\n",
    "# CELLULE 1: Imports Requis\n",
    "# =====================================================\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "import requests\n",
    "import time\n",
    "import random\n",
    "import io\n",
    "from jupyter_ui_poll import ui_events\n",
    "import traceback\n",
    "import re\n",
    "import os\n",
    "import json\n",
    "import gzip\n",
    "import hashlib\n",
    "from pathlib import Path\n",
    "# Imports Cryptography (Fernet pour chiffrement/d√©chiffrement)\n",
    "from cryptography.fernet import Fernet, InvalidToken\n",
    "from cryptography.exceptions import InvalidSignature\n",
    "# Imports Cryptography (PBKDF2 pour d√©rivation de cl√© depuis passphrase) CORRECTIF ICI\n",
    "from cryptography.hazmat.primitives import hashes\n",
    "from cryptography.hazmat.primitives.kdf.pbkdf2 import PBKDF2HMAC\n",
    "from cryptography.hazmat.backends import default_backend\n",
    "import base64 # Pour encoder la cl√© d√©riv√©e\n",
    "# ---\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "print(\"Imports pour UI_Configuration charg√©s (incluant crypto KDF et base64).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "114cc29b",
   "metadata": {},
   "source": [
    "## 2. Configuration, Constantes et Donn√©es Sources\n",
    "\n",
    "D√©finition des constantes (URLs des services, chemins des fichiers), chargement de la cl√© de chiffrement depuis `.env`, d√©finition de la structure des sources pr√©d√©finies (`EXTRACT_SOURCES`), et cr√©ation du r√©pertoire de cache."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5e08535d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V√©rification de la phrase secr√®te 'TEXT_CONFIG_PASSPHRASE' dans .env...\n",
      "‚úÖ Phrase secr√®te trouv√©e. D√©rivation de la cl√©...\n",
      "‚úÖ Cl√© de chiffrement d√©riv√©e et encod√©e.\n",
      "Cache r√©pertoire assur√© : C:\\dev\\CoursIA\\MyIA.AI.Notebooks\\SymbolicAI\\Argument_Analysis\\text_cache\n",
      "Configuration UI charg√©e. 4 sources initiales d√©finies.\n"
     ]
    }
   ],
   "source": [
    "# --- Chargement et D√©rivation Cl√© de Chiffrement ---\n",
    "load_dotenv(find_dotenv())\n",
    "PASSPHRASE_VAR_NAME = \"TEXT_CONFIG_PASSPHRASE\"\n",
    "passphrase = os.getenv(PASSPHRASE_VAR_NAME)\n",
    "ENCRYPTION_KEY = None # Sera d√©fini si la d√©rivation r√©ussit\n",
    "\n",
    "FIXED_SALT = b'q\\x8b\\t\\x97\\x8b\\xe9\\xa3\\xf2\\xe4\\x8e\\xea\\xf5\\xe8\\xb7\\xd6\\x8c' # Exemple de sel fixe (16 bytes)\n",
    "\n",
    "print(f\"V√©rification de la phrase secr√®te '{PASSPHRASE_VAR_NAME}' dans .env...\")\n",
    "\n",
    "if passphrase:\n",
    "    print(f\"‚úÖ Phrase secr√®te trouv√©e. D√©rivation de la cl√©...\")\n",
    "    try:\n",
    "        kdf = PBKDF2HMAC(\n",
    "            algorithm=hashes.SHA256(), length=32, salt=FIXED_SALT,\n",
    "            iterations=480000, backend=default_backend()\n",
    "        )\n",
    "        derived_key_raw = kdf.derive(passphrase.encode('utf-8'))\n",
    "        ENCRYPTION_KEY = base64.urlsafe_b64encode(derived_key_raw)\n",
    "        # Optionnel: commenter le test si la cl√© d√©riv√©e pose probl√®me avec Fernet(key) directement\n",
    "        # try:\n",
    "        #     Fernet(ENCRYPTION_KEY)\n",
    "        #     print(\"‚úÖ Cl√© de chiffrement d√©riv√©e avec succ√®s et valide.\")\n",
    "        # except Exception as e_fernet:\n",
    "        #     print(f\"‚ö†Ô∏è Cl√© d√©riv√©e semble invalide pour Fernet : {e_fernet}.\")\n",
    "        #     ENCRYPTION_KEY = None # Invalider si test √©choue\n",
    "        if ENCRYPTION_KEY: print(\"‚úÖ Cl√© de chiffrement d√©riv√©e et encod√©e.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Erreur d√©rivation cl√© : {e}. Chiffrement d√©sactiv√©.\")\n",
    "        ENCRYPTION_KEY = None\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è Variable '{PASSPHRASE_VAR_NAME}' non trouv√©e dans .env. Chiffrement d√©sactiv√©.\")\n",
    "\n",
    "# --- URLs et Chemins ---\n",
    "TIKA_URL_PARTS = [\"https:\", \"\", \"tika\", \"open-webui\", \"myia\", \"io\", \"tika\"]\n",
    "# --- LIGNE D√âCOMMENT√âE ---\n",
    "# Reconstruit l'URL Tika une seule fois ici pour √™tre utilis√©e globalement\n",
    "TIKA_SERVER_URL = f\"{TIKA_URL_PARTS[0]}//{'.'.join(TIKA_URL_PARTS[2:-1])}/{TIKA_URL_PARTS[-1]}\"\n",
    "# -------------------------\n",
    "JINA_READER_PREFIX = \"https://r.jina.ai/\"\n",
    "CACHE_DIR = Path(\"./text_cache\")\n",
    "CONFIG_FILE = Path(\"./extract_sources.json.gz.enc\")\n",
    "\n",
    "# --- Cr√©ation Cache Dir ---\n",
    "try:\n",
    "    CACHE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    print(f\"Cache r√©pertoire assur√© : {CACHE_DIR.resolve()}\")\n",
    "except Exception as e:\n",
    "    print(f\"Erreur cr√©ation r√©pertoire cache {CACHE_DIR}: {e}\")\n",
    "\n",
    "# --- Structure par D√©faut (avec nouvelle structure URL) ---\n",
    "DEFAULT_EXTRACT_SOURCES = [\n",
    "    {\"source_name\": \"Exemple Vide (Config manquante)\", \"source_type\": \"jina\",\n",
    "     \"schema\": \"https:\", \"host_parts\": [\"example\", \"com\"], \"path\": \"/\",\n",
    "     \"extracts\": []}\n",
    "]\n",
    "\n",
    "# --- D√©finition Initiale des Sources & Extraits (Structure Corrig√©e) ---\n",
    "# (Cette structure est utilis√©e comme fallback si le fichier .enc n'existe pas/n'est pas lisible)\n",
    "EXTRACT_SOURCES = [\n",
    "     {\n",
    "        \"source_name\": \"Lincoln-Douglas D√©bat 1 (NPS)\", \"source_type\": \"jina\",\n",
    "        \"schema\": \"https:\", \"host_parts\": [\"www\", \"nps\", \"gov\"], \"path\": \"/liho/learn/historyculture/debate1.htm\",\n",
    "        \"extracts\": [\n",
    "            {\"extract_name\": \"1. D√©bat Complet (Ottawa, 1858)\", \"start_marker\": \"**August 21, 1858**\", \"end_marker\": \"(Three times three cheers were here given for Senator Douglas.)\"},\n",
    "            {\"extract_name\": \"2. Discours Principal de Lincoln\", \"start_marker\": \"MY FELLOW-CITIZENS: When a man hears himself\", \"end_marker\": \"The Judge can take his half hour.\"},\n",
    "            {\"extract_name\": \"3. Discours d'Ouverture de Douglas\", \"start_marker\": \"Ladies and gentlemen: I appear before you\", \"end_marker\": \"occupy an half hour in replying to him.\"},\n",
    "            {\"extract_name\": \"4. Lincoln sur Droits Naturels/√âgalit√©\", \"start_marker\": \"I will say here, while upon this subject,\", \"end_marker\": \"equal of every living man._ [Great applause.]\"},\n",
    "            {\"extract_name\": \"5. Douglas sur Race/Dred Scott\", \"start_marker\": \"utterly opposed to the Dred Scott decision,\", \"end_marker\": \"equality with the white man. (\\\"Good.\\\")\"},\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"source_name\": \"Lincoln-Douglas D√©bat 2 (NPS)\", \"source_type\": \"jina\",\n",
    "        \"schema\": \"https:\", \"host_parts\": [\"www\", \"nps\", \"gov\"], \"path\": \"/liho/learn/historyculture/debate2.htm\",\n",
    "        \"extracts\": [\n",
    "             {\"extract_name\": \"1. D√©bat Complet (Freeport, 1858)\", \"start_marker\": \"It was a cloudy, cool, and damp day.\", \"end_marker\": \"I cannot, gentlemen, my time has expired.\"},\n",
    "             {\"extract_name\": \"2. Discours Principal de Douglas\", \"start_marker\": \"**Mr. Douglas' Speech**\\n\\nLadies and Gentlemen-\", \"end_marker\": \"stopped on the moment.\"},\n",
    "             {\"extract_name\": \"3. Discours d'Ouverture de Lincoln\", \"start_marker\": \"LADIES AND GENTLEMEN - On Saturday last,\", \"end_marker\": \"Go on, Judge Douglas.\"},\n",
    "             {\"extract_name\": \"4. Doctrine de Freeport (Douglas)\", \"start_marker\": \"The next question propounded to me by Mr. Lincoln is,\", \"end_marker\": \"satisfactory on that point.\"},\n",
    "             {\"extract_name\": \"5. Lincoln r√©pond aux 7 questions\", \"start_marker\": \"The first one of these interrogatories is in these words:,\", \"end_marker\": \"aggravate the slavery question among ourselves. [Cries of good, good.]\"},\n",
    "        ]\n",
    "    },\n",
    "     {\n",
    "        \"source_name\": \"Kremlin Discours 21/02/2022\", \"source_type\": \"jina\",\n",
    "        \"schema\": \"http:\", \"host_parts\": [\"en\", \"kremlin\", \"ru\"], \"path\": \"/events/president/transcripts/67828\",\n",
    "        \"extracts\": [\n",
    "            {\"extract_name\": \"1. Discours Complet\", \"start_marker\": \"Citizens of Russia, friends,\", \"end_marker\": \"Thank you.\"},\n",
    "            {\"extract_name\": \"2. Argument Historique Ukraine\", \"start_marker\": \"So, I will start with the fact that modern Ukraine\", \"end_marker\": \"He was its creator and architect.\"},\n",
    "            {\"extract_name\": \"3. Menace OTAN\", \"start_marker\": \"Ukraine is home to NATO training missions\", \"end_marker\": \"These principled proposals of ours have been ignored.\"},\n",
    "            {\"extract_name\": \"4. D√©communisation selon Poutine\", \"start_marker\": \"And today the ‚Äúgrateful progeny‚Äù\", \"end_marker\": \"what real decommunizations would mean for Ukraine.\"},\n",
    "            {\"extract_name\": \"5. D√©cision Reconnaissance Donbass\", \"start_marker\": \"Everything was in vain.\", \"end_marker\": \"These two documents will be prepared and signed shortly.\"},\n",
    "         ]\n",
    "    },\n",
    "    {\n",
    "        \"source_name\": \"Hitler Discours Collection (PDF)\", \"source_type\": \"direct_download\",\n",
    "        # \"schema\": \"https:\", \"host_parts\": [\"www\", \"nommeraadio\", \"ee\"], \"path\": \"/meedia/pdf/RRS/Adolf%20Hitler%20-%20Collection%20of%20Speeches%20-%201922-1945.pdf\",\n",
    "        \"schema\": \"https:\",\n",
    "        \"host_parts\": [\"drive\", \"google\", \"com\"],\n",
    "        \"path\": \"/uc?export=download&id=1D6ZESrdeuWvlPlsNq0rbVaUyxqUOB-KQ\", # Chemin GDrive direct\n",
    "        \"extracts\": [\n",
    "            {\"extract_name\": \"1. 1923.04.13 - Munich\", \"start_marker\": \"n our view, the times when\", \"end_marker\": \"build a new Germany!36\"},\n",
    "            {\"extract_name\": \"2. 1923.04.24 - Munich\", \"start_marker\": \"reject the word 'Proletariat.'\", \"end_marker\": \"the greatest social achievement.38\"},\n",
    "            {\"extract_name\": \"3. 1923.04.27 - Munich\", \"start_marker\": \"hat we need if we are to have\", \"end_marker\": \"the Germany of fighters which yet shall be.\"},\n",
    "            {\"extract_name\": \"4. 1933.03.23 - Duel Otto Wels\", \"start_marker\": \"You are talking today about your achievements\", \"end_marker\": \"Germany will be liberated, but not by you!125\"},\n",
    "            {\"extract_name\": \"5. 1933.05.01 - Lustgarten\", \"start_marker\": \"hree cheers for our Reich President,\", \"end_marker\": \"thus our German Volk und Vaterland!‚Äù\"},\n",
    "            {\"extract_name\": \"6. 1936.03.09 - Interview Ward Price\", \"start_marker\": \"irst question: Does the Fuhrer‚Äôs offer\", \"end_marker\": \"service to Europe and to the cause of peace.313\"},\n",
    "            {\"extract_name\": \"7. 1936.03.12 - Karlsruhe\", \"start_marker\": \"know no regime of the bourgeoisie,\", \"end_marker\": \"now and for all time to come!316\"},\n",
    "            {\"extract_name\": \"8. 1936.03.20 - Hambourg\", \"start_marker\": \"t is a pity that the statesmen-\", \"end_marker\": \"now give me your faith!\"},\n",
    "            {\"extract_name\": \"9. 1939.01.30 - Reichstag (Proph√©tie)\", \"start_marker\": \"Once again I will be a prophet:\", \"end_marker\": \"complementary nature of these economies to the German one.549\"},\n",
    "            {\"extract_name\": \"10. 1942.11.09 - L√∂wenbr√§ukeller\", \"start_marker\": \"care of this. This danger has been recognized\", \"end_marker\": \"will always be a prayer for our Germany!\"},\n",
    "        ]\n",
    "    },\n",
    "]\n",
    "\n",
    "\n",
    "# --- Initialisation variable globale ---\n",
    "# Sera mise √† jour par load_extract_definitions lors de l'appel √† configure_analysis_task\n",
    "current_extract_definitions = []\n",
    "\n",
    "print(f\"Configuration UI charg√©e. {len(EXTRACT_SOURCES)} sources initiales d√©finies.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abda6271",
   "metadata": {},
   "source": [
    "## 3. Fonctions Utilitaires\n",
    "\n",
    "D√©finition des fonctions pour :\n",
    "* G√©rer le cache fichier (cr√©er nom de fichier, lire, √©crire).\n",
    "* Chiffrer et d√©chiffrer les donn√©es de configuration.\n",
    "* Charger et sauvegarder le fichier de configuration chiffr√©.\n",
    "* Reconstruire les URLs √† partir des parties obfusqu√©es.\n",
    "* R√©cup√©rer le texte via Jina (avec cache).\n",
    "* R√©cup√©rer le texte via Tika (t√©l√©chargement si URL, puis envoi au serveur Tika, avec cache)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ff6ba3ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fonctions utilitaires UI_Configuration d√©finies.\n"
     ]
    }
   ],
   "source": [
    "def reconstruct_url(schema: str, host_parts: list, path: str) -> str | None:\n",
    "    \"\"\"Reconstruit une URL √† partir de schema, host_parts, et path.\"\"\"\n",
    "    if not schema or not host_parts or not path: return None\n",
    "    host = \".\".join(part for part in host_parts if part)\n",
    "    # S'assurer que le path commence par / s'il n'est pas vide\n",
    "    path = path if path.startswith('/') or not path else '/' + path\n",
    "    return f\"{schema}//{host}{path}\"\n",
    "\n",
    "# --- D√©finitions des autres fonctions utilitaires ---\n",
    "# (get_cache_filepath, load_from_cache, save_to_cache, encrypt_data, decrypt_data,\n",
    "#  load_extract_definitions (modifi√©e pour utiliser la nouvelle structure interne),\n",
    "#  save_extract_definitions, fetch_with_jina, fetch_with_tika)\n",
    "# ... (Copiez ici le code complet de ces fonctions depuis la CELLULE 3 / Bloc Python 3 de ma r√©ponse pr√©c√©dente) ...\n",
    "# ... Assurez-vous que load_extract_definitions utilise la nouvelle structure\n",
    "#     et que fetch_with_jina/tika appellent la nouvelle reconstruct_url si n√©cessaire ...\n",
    "\n",
    "# Exemple de load_extract_definitions (ajust√© l√©g√®rement pour fallback)\n",
    "def load_extract_definitions(config_file: Path, key: bytes) -> list:\n",
    "    \"\"\"Charge, d√©chiffre et d√©compresse les d√©finitions depuis le fichier.\"\"\"\n",
    "    global EXTRACT_SOURCES, DEFAULT_EXTRACT_SOURCES # Utiliser les structures d√©finies globalement\n",
    "    fallback_definitions = EXTRACT_SOURCES if EXTRACT_SOURCES else DEFAULT_EXTRACT_SOURCES\n",
    "\n",
    "    if not config_file.exists():\n",
    "        print(f\"Fichier config '{config_file}' non trouv√©. Utilisation d√©finitions en m√©moire.\")\n",
    "        return fallback_definitions[:]\n",
    "    if not key:\n",
    "        print(\"Cl√© chiffrement absente. Chargement config impossible. Utilisation d√©finitions en m√©moire.\")\n",
    "        return fallback_definitions[:]\n",
    "\n",
    "    print(f\"Chargement et d√©chiffrement de '{config_file}'...\")\n",
    "    try:\n",
    "        with open(config_file, 'rb') as f: encrypted_data = f.read()\n",
    "        decrypted_compressed_data = decrypt_data(encrypted_data, key)\n",
    "        if not decrypted_compressed_data: raise ValueError(\"√âchec d√©chiffrement.\")\n",
    "        decompressed_data = gzip.decompress(decrypted_compressed_data)\n",
    "        definitions = json.loads(decompressed_data.decode('utf-8'))\n",
    "        print(\"‚úÖ D√©finitions charg√©es et d√©chiffr√©es.\")\n",
    "        # Validation plus robuste\n",
    "        if not isinstance(definitions, list) or not all(\n",
    "            isinstance(item, dict) and\n",
    "            \"source_name\" in item and\n",
    "            \"source_type\" in item and\n",
    "            \"schema\" in item and\n",
    "            \"host_parts\" in item and\n",
    "            \"path\" in item and\n",
    "            isinstance(item.get(\"extracts\"), list)\n",
    "            for item in definitions\n",
    "        ):\n",
    "             print(\"‚ö†Ô∏è Format d√©finitions invalide apr√®s chargement. Utilisation d√©finitions en m√©moire.\")\n",
    "             return fallback_definitions[:]\n",
    "        # Mettre √† jour EXTRACT_SOURCES global si chargement OK\n",
    "        EXTRACT_SOURCES = definitions\n",
    "        print(f\"-> {len(EXTRACT_SOURCES)} d√©finitions charg√©es depuis fichier.\")\n",
    "        return definitions # Retourner les d√©finitions charg√©es\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Erreur chargement/traitement '{config_file}': {e}. Utilisation d√©finitions en m√©moire.\")\n",
    "        return fallback_definitions[:]\n",
    "\n",
    "# --- Assurez-vous que toutes les autres fonctions utilitaires sont coll√©es ici ---\n",
    "def get_cache_filepath(url: str) -> Path:\n",
    "    url_hash = hashlib.sha256(url.encode()).hexdigest()\n",
    "    if 'CACHE_DIR' not in globals() or not isinstance(CACHE_DIR, Path): raise NameError(\"CACHE_DIR non d√©finie.\")\n",
    "    return CACHE_DIR / f\"{url_hash}.txt\"\n",
    "def load_from_cache(url: str) -> str | None:\n",
    "    filepath = get_cache_filepath(url)\n",
    "    if filepath.exists():\n",
    "        try:\n",
    "            print(f\"   -> Lecture depuis cache : {filepath.name}\")\n",
    "            return filepath.read_text(encoding='utf-8')\n",
    "        except Exception as e: print(f\"   -> Erreur lecture cache {filepath.name}: {e}\"); return None\n",
    "    return None\n",
    "def save_to_cache(url: str, text: str):\n",
    "    if not text: print(\"   -> Texte vide, non sauvegard√©.\"); return\n",
    "    filepath = get_cache_filepath(url)\n",
    "    try:\n",
    "        filepath.write_text(text, encoding='utf-8'); print(f\"   -> Texte sauvegard√© : {filepath.name}\")\n",
    "    except Exception as e: print(f\"   -> Erreur sauvegarde cache {filepath.name}: {e}\")\n",
    "def encrypt_data(data: bytes, key: bytes) -> bytes | None:\n",
    "    if not key: print(\"Erreur: Cl√© chiffrement manquante.\"); return None\n",
    "    try: f = Fernet(key); return f.encrypt(data)\n",
    "    except Exception as e: print(f\"Erreur chiffrement: {e}\"); return None\n",
    "def decrypt_data(encrypted_data: bytes, key: bytes) -> bytes | None:\n",
    "    if not key: print(\"Erreur: Cl√© chiffrement manquante.\"); return None\n",
    "    try: f = Fernet(key); return f.decrypt(encrypted_data)\n",
    "    except (InvalidToken, InvalidSignature, Exception) as e: print(f\"Erreur d√©chiffrement: {e}\"); return None\n",
    "def save_extract_definitions(definitions: list, config_file: Path, key: bytes):\n",
    "    if not key: print(\"Cl√© chiffrement absente. Sauvegarde annul√©e.\"); return False\n",
    "    if not isinstance(definitions, list): print(\"Erreur: d√©finitions non valides.\"); return False\n",
    "    print(f\"Pr√©paration sauvegarde vers '{config_file}'...\")\n",
    "    try:\n",
    "        json_data = json.dumps(definitions, indent=2, ensure_ascii=False).encode('utf-8'); compressed_data = gzip.compress(json_data); encrypted_data = encrypt_data(compressed_data, key)\n",
    "        if not encrypted_data: raise ValueError(\"√âchec chiffrement.\")\n",
    "        with open(config_file, 'wb') as f: f.write(encrypted_data)\n",
    "        print(f\"‚úÖ D√©finitions sauvegard√©es dans '{config_file}'.\")\n",
    "        return True\n",
    "    except Exception as e: print(f\"‚ùå Erreur sauvegarde chiffr√©e: {e}\"); return False\n",
    "PLAINTEXT_EXTENSIONS = ['.txt', '.md', '.json', '.csv', '.xml', '.py', '.js', '.html', '.htm'] # Extensions √† traiter comme texte simple\n",
    "\n",
    "def fetch_direct_text(source_url, timeout=60):\n",
    "    \"\"\"R√©cup√®re contenu texte brut d'URL, utilise cache fichier.\"\"\"\n",
    "    # ... (Code INCHANG√â) ...\n",
    "    cached_text = load_from_cache(source_url)\n",
    "    if cached_text is not None: return cached_text\n",
    "    print(f\"-> T√©l√©chargement direct depuis : {source_url}...\")\n",
    "    headers = {'User-Agent': 'Agent-Analysis-Notebook/1.0'}\n",
    "    try:\n",
    "        response = requests.get(source_url, headers=headers, timeout=timeout)\n",
    "        response.raise_for_status()\n",
    "        # D√©coder en UTF-8, ignorer les erreurs potentielles\n",
    "        texte_brut = response.content.decode('utf-8', errors='ignore')\n",
    "        print(f\"   -> Contenu direct r√©cup√©r√© (longueur {len(texte_brut)}).\")\n",
    "        save_to_cache(source_url, texte_brut)\n",
    "        return texte_brut\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        raise ConnectionError(f\"Erreur t√©l√©chargement direct ({source_url}): {e}\") from e\n",
    "\n",
    "def fetch_with_jina(source_url, timeout=90):\n",
    "     \"\"\"R√©cup√®re et extrait via Jina, utilise cache fichier.\"\"\"\n",
    "     # ... (Code INCHANG√â) ...\n",
    "     cached_text = load_from_cache(source_url);\n",
    "     if cached_text is not None: return cached_text\n",
    "     jina_url = f\"{JINA_READER_PREFIX}{source_url}\"; print(f\"-> R√©cup√©ration via Jina : {jina_url}...\")\n",
    "     headers = {'Accept': 'text/markdown', 'User-Agent': 'Agent-Analysis-Notebook/1.0'}\n",
    "     try: response = requests.get(jina_url, headers=headers, timeout=timeout); response.raise_for_status()\n",
    "     except requests.exceptions.RequestException as e: raise ConnectionError(f\"Erreur Jina ({jina_url}): {e}\") from e\n",
    "     content = response.text; md_start_marker = \"Markdown Content:\"; md_start_index = content.find(md_start_marker)\n",
    "     texte_brut = content[md_start_index + len(md_start_marker):].strip() if md_start_index != -1 else content\n",
    "     print(f\"   -> Contenu Jina r√©cup√©r√© (longueur {len(texte_brut)}).\"); save_to_cache(source_url, texte_brut); return texte_brut\n",
    "\n",
    "\n",
    "# --- fetch_with_tika MODIFI√âE ---\n",
    "def fetch_with_tika(source_url=None, file_content=None, file_name=\"fichier\",\n",
    "                    raw_file_cache_path: Path | str | None = None, # Chemin cache brut\n",
    "                    timeout_dl=60, timeout_tika=600):\n",
    "    \"\"\"\n",
    "    Traite une source via Tika. Tente d'abord de lire le cache texte.\n",
    "    Si URL fournie, v√©rifie le cache brut puis t√©l√©charge si besoin.\n",
    "    V√©rifie l'extension: si texte simple, utilise fetch_direct_text au lieu de Tika.\n",
    "    Sinon, envoie le contenu brut (t√©l√©charg√© ou fourni) √† Tika.\n",
    "    \"\"\"\n",
    "    cache_key = source_url if source_url else f\"file://{file_name}\"\n",
    "    # 1. V√©rifier cache TEXTE FINAL\n",
    "    cached_text = load_from_cache(cache_key)\n",
    "    if cached_text is not None: return cached_text\n",
    "\n",
    "    global TIKA_SERVER_URL\n",
    "    content_to_send = None\n",
    "    original_filename_or_path = file_name # Par d√©faut (pour upload)\n",
    "\n",
    "    # 2. Obtenir contenu BRUT (si URL) et v√©rifier extension\n",
    "    if source_url:\n",
    "        original_filename_or_path = Path(source_url).name # Pour check extension et cache brut\n",
    "        # V√©rifier si c'est un type texte simple connu bas√© sur l'URL\n",
    "        if any(source_url.lower().endswith(ext) for ext in PLAINTEXT_EXTENSIONS):\n",
    "            print(f\"   -> URL d√©tect√©e comme texte simple ({source_url}). Utilisation fetch direct au lieu de Tika.\")\n",
    "            # On ne passe pas par Tika, on t√©l√©charge directement le texte\n",
    "            # La fonction fetch_direct_text g√®re son propre cache .txt\n",
    "            return fetch_direct_text(source_url)\n",
    "\n",
    "        # Si pas texte simple, g√©rer cache brut et t√©l√©chargement\n",
    "        if raw_file_cache_path:\n",
    "            raw_path = Path(raw_file_cache_path)\n",
    "            if raw_path.exists() and raw_path.stat().st_size > 0:\n",
    "                try:\n",
    "                    print(f\"   -> Lecture fichier brut depuis cache local : {raw_path.name}\")\n",
    "                    content_to_send = raw_path.read_bytes()\n",
    "                except Exception as e_read_raw:\n",
    "                    print(f\"   -> ‚ö†Ô∏è Erreur lecture cache brut {raw_path.name}: {e_read_raw}. Re-t√©l√©chargement...\")\n",
    "                    content_to_send = None\n",
    "\n",
    "        if content_to_send is None: # Si cache brut absent ou erreur lecture\n",
    "            print(f\"-> T√©l√©chargement (pour Tika) depuis : {source_url}...\")\n",
    "            try:\n",
    "                response_dl = requests.get(source_url, stream=True, timeout=timeout_dl); response_dl.raise_for_status()\n",
    "                content_to_send = response_dl.content; print(f\"   -> Doc t√©l√©charg√© ({len(content_to_send)} bytes).\")\n",
    "                if raw_file_cache_path: # Sauvegarder si chemin fourni\n",
    "                     try: save_path = Path(raw_file_cache_path); save_path.parent.mkdir(parents=True, exist_ok=True); save_path.write_bytes(content_to_send); print(f\"   -> Doc brut sauvegard√©: {save_path.resolve()}\")\n",
    "                     except Exception as e_save: print(f\"   -> ‚ö†Ô∏è Erreur sauvegarde brut: {e_save}\")\n",
    "            except requests.exceptions.RequestException as e: raise ConnectionError(f\"Erreur t√©l√©chargement {source_url}: {e}\") from e\n",
    "\n",
    "    elif file_content:\n",
    "         # Cas: Fichier upload√© (pas d'URL source)\n",
    "         print(f\"-> Utilisation contenu fichier '{file_name}' ({len(file_content)} bytes)...\")\n",
    "         content_to_send = file_content\n",
    "         # V√©rifier si upload est texte simple\n",
    "         if any(file_name.lower().endswith(ext) for ext in PLAINTEXT_EXTENSIONS):\n",
    "              print(\"   -> Fichier upload√© d√©tect√© comme texte simple. Lecture directe.\")\n",
    "              try:\n",
    "                  texte_brut = file_content.decode('utf-8', errors='ignore')\n",
    "                  save_to_cache(cache_key, texte_brut) # Sauver dans cache texte\n",
    "                  return texte_brut\n",
    "              except Exception as e_decode:\n",
    "                  print(f\"   -> ‚ö†Ô∏è Erreur d√©codage fichier texte '{file_name}': {e_decode}. Tentative avec Tika...\")\n",
    "                  # Si erreur d√©codage, on laisse Tika essayer\n",
    "    else:\n",
    "         raise ValueError(\"fetch_with_tika: Il faut soit source_url soit file_content.\")\n",
    "\n",
    "    # 3. Envoyer √† Tika (seulement si n√©cessaire et contenu valide)\n",
    "    if not content_to_send:\n",
    "         print(\"   -> ‚ö†Ô∏è Contenu brut vide ou non r√©cup√©r√©. Impossible d'envoyer √† Tika.\")\n",
    "         save_to_cache(cache_key, \"\") # Sauver cache vide pour √©viter retry\n",
    "         return \"\"\n",
    "\n",
    "    print(f\"-> Envoi contenu √† Tika ({TIKA_SERVER_URL})... (Timeout={timeout_tika}s)\")\n",
    "    headers = { 'Accept': 'text/plain', 'Content-Type': 'application/octet-stream', 'X-Tika-OCRLanguage': 'fra+eng' }\n",
    "    try:\n",
    "        response_tika = requests.put(TIKA_SERVER_URL, data=content_to_send, headers=headers, timeout=timeout_tika)\n",
    "        response_tika.raise_for_status()\n",
    "        texte_brut = response_tika.text\n",
    "        if not texte_brut: print(f\"   -> Warning: Tika status {response_tika.status_code} sans texte.\")\n",
    "        else: print(f\"   -> Texte Tika extrait (longueur {len(texte_brut)}).\")\n",
    "\n",
    "        # 4. Sauvegarder le TEXTE EXTRAIT dans le cache .txt\n",
    "        save_to_cache(cache_key, texte_brut)\n",
    "        return texte_brut\n",
    "\n",
    "    except requests.exceptions.Timeout: print(f\"   -> ‚ùå Timeout Tika ({timeout_tika}s).\"); raise ConnectionError(f\"Timeout Tika\")\n",
    "    except requests.exceptions.RequestException as e: raise ConnectionError(f\"Erreur Tika: {e}\") from e\n",
    "\n",
    "def verify_extract_definitions(definitions_list: list):\n",
    "    \"\"\"\n",
    "    V√©rifie la pr√©sence des marqueurs start/end pour chaque extrait d√©fini.\n",
    "    R√©cup√®re le texte complet (via cache ou fetch) pour chaque source.\n",
    "    Retourne un r√©sum√© des v√©rifications.\n",
    "    \"\"\"\n",
    "    print(\"\\nüî¨ Lancement de la v√©rification des marqueurs d'extraits...\")\n",
    "    results = []\n",
    "    total_checks = 0\n",
    "    total_errors = 0\n",
    "\n",
    "    if not definitions_list or definitions_list == DEFAULT_EXTRACT_SOURCES:\n",
    "         return \"Aucune d√©finition valide √† v√©rifier.\"\n",
    "\n",
    "    for source_idx, source_info in enumerate(definitions_list):\n",
    "        source_name = source_info.get(\"source_name\", f\"Source Inconnue #{source_idx+1}\")\n",
    "        print(f\"\\n--- V√©rification Source: '{source_name}' ---\")\n",
    "        source_errors = 0\n",
    "        source_checks = 0\n",
    "        texte_brut_source = None\n",
    "        reconstructed_url = None\n",
    "\n",
    "        try:\n",
    "            # Reconstruire l'URL\n",
    "            reconstructed_url = reconstruct_url(\n",
    "                source_info.get(\"schema\"), source_info.get(\"host_parts\", []), source_info.get(\"path\")\n",
    "            )\n",
    "            if not reconstructed_url:\n",
    "                print(\"   -> ‚ùå Erreur: URL Invalide.\")\n",
    "                results.append(f\"<li>{source_name}: URL invalide</li>\")\n",
    "                total_errors += len(source_info.get(\"extracts\", [])) # Compter tous les extraits comme erreurs\n",
    "                total_checks += len(source_info.get(\"extracts\", []))\n",
    "                continue\n",
    "\n",
    "            # R√©cup√©rer le texte complet (via cache ou fetch)\n",
    "            source_type = source_info.get(\"source_type\")\n",
    "            cache_key = reconstructed_url # Cl√© cache pour le texte complet\n",
    "            texte_brut_source = load_from_cache(cache_key)\n",
    "\n",
    "            if texte_brut_source is None:\n",
    "                print(f\"   -> Cache texte absent. R√©cup√©ration (type: {source_type})...\")\n",
    "                if source_type == \"jina\": texte_brut_source = fetch_with_jina(reconstructed_url)\n",
    "                elif source_type == \"direct_download\": texte_brut_source = fetch_direct_text(reconstructed_url)\n",
    "                elif source_type == \"tika\":\n",
    "                    is_plaintext = any(source_info.get(\"path\", \"\").lower().endswith(ext) for ext in PLAINTEXT_EXTENSIONS)\n",
    "                    if is_plaintext: texte_brut_source = fetch_direct_text(reconstructed_url)\n",
    "                    else:\n",
    "                        # On ne peut pas raisonnablement v√©rifier les marqueurs si Tika √©choue ici\n",
    "                        print(\"   -> ‚ö†Ô∏è Impossible de v√©rifier les marqueurs car n√©cessite Tika (potentiellement long/√©chou√©).\")\n",
    "                        texte_brut_source = None # Marquer comme non v√©rifiable\n",
    "                else:\n",
    "                     print(f\"   -> ‚ö†Ô∏è Type source inconnu '{source_type}'. V√©rification impossible.\")\n",
    "                     texte_brut_source = None\n",
    "\n",
    "            # V√©rifier les marqueurs si le texte a √©t√© obtenu\n",
    "            if texte_brut_source is not None:\n",
    "                print(f\"   -> Texte complet r√©cup√©r√© (longueur: {len(texte_brut_source)}). V√©rification des extraits...\")\n",
    "                extracts = source_info.get(\"extracts\", [])\n",
    "                if not extracts: print(\"      -> Aucun extrait d√©fini pour cette source.\")\n",
    "\n",
    "                for extract_idx, extract_info in enumerate(extracts):\n",
    "                    extract_name = extract_info.get(\"extract_name\", f\"Extrait #{extract_idx+1}\")\n",
    "                    start_marker = extract_info.get(\"start_marker\")\n",
    "                    end_marker = extract_info.get(\"end_marker\")\n",
    "                    total_checks += 1\n",
    "                    source_checks += 1\n",
    "                    marker_errors = []\n",
    "\n",
    "                    if not start_marker or not end_marker:\n",
    "                        marker_errors.append(\"Marqueur(s) Manquant(s)\")\n",
    "                    else:\n",
    "                        start_found = start_marker in texte_brut_source\n",
    "                        end_found_after_start = False\n",
    "                        if start_found:\n",
    "                            try:\n",
    "                                start_pos = texte_brut_source.index(start_marker)\n",
    "                                end_found_after_start = end_marker in texte_brut_source[start_pos + len(start_marker):]\n",
    "                            except ValueError: # Ne devrait pas arriver si start_found est True\n",
    "                                 start_found = False\n",
    "\n",
    "                        if not start_found: marker_errors.append(\"D√©but NON TROUV√â\")\n",
    "                        if not end_found_after_start: marker_errors.append(\"Fin NON TROUV√âE (apr√®s d√©but)\")\n",
    "\n",
    "                    if marker_errors:\n",
    "                        print(f\"      -> ‚ùå Probl√®me Extrait '{extract_name}': {', '.join(marker_errors)}\")\n",
    "                        results.append(f\"<li>{source_name} -> {extract_name}: <strong style='color:red;'>{', '.join(marker_errors)}</strong></li>\")\n",
    "                        source_errors += 1\n",
    "                        total_errors += 1\n",
    "                    else:\n",
    "                         print(f\"      -> ‚úÖ OK: Extrait '{extract_name}'\")\n",
    "                         # results.append(f\"<li>{source_name} -> {extract_name}: OK</li>\") # Optionnel: lister aussi les OK\n",
    "\n",
    "            else: # Cas o√π le texte brut n'a pas pu √™tre r√©cup√©r√© (ex: erreur Tika pendant la v√©rif)\n",
    "                 num_extracts = len(source_info.get(\"extracts\",[]))\n",
    "                 results.append(f\"<li>{source_name}: V√©rification impossible (texte source non obtenu)</li>\")\n",
    "                 total_errors += num_extracts\n",
    "                 total_checks += num_extracts\n",
    "\n",
    "\n",
    "        except Exception as e_verify:\n",
    "            print(f\"   -> ‚ùå Erreur inattendue v√©rification source '{source_name}': {e_verify}\")\n",
    "            num_extracts = len(source_info.get(\"extracts\",[]))\n",
    "            results.append(f\"<li>{source_name}: Erreur V√©rification G√©n√©rale ({type(e_verify).__name__})</li>\")\n",
    "            total_errors += num_extracts\n",
    "            total_checks += num_extracts # Compter comme √©chec si erreur globale\n",
    "\n",
    "    summary = f\"--- R√©sultat V√©rification ---<br/>{total_checks} extraits v√©rifi√©s. <strong style='color: {'red' if total_errors > 0 else 'green'};'>{total_errors} erreur(s) trouv√©e(s).</strong>\"\n",
    "    if results:\n",
    "        summary += \"<br/>D√©tails erreurs :<ul>\" + \"\".join(results) + \"</ul>\"\n",
    "    else:\n",
    "        summary += \"<br/>Tous les marqueurs semblent corrects.\"\n",
    "\n",
    "    print(f\"\\n{summary.replace('<br/>', '\\n').replace('<li>', '- ').replace('</li>', '').replace('<ul>', '').replace('</ul>', '').replace('<strong>', '').replace('</strong>', '')}\") # Affichage console simple\n",
    "    return summary\n",
    "\n",
    "\n",
    "print(\"Fonctions utilitaires UI_Configuration d√©finies.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c738562",
   "metadata": {},
   "source": [
    "## 4. Initialisation du Cache (Optionnel)\n",
    "\n",
    "V√©rification et pr√©-remplissage du cache fichier pour les textes complets des sources d√©finies (celles d√©finies initialement ou charg√©es depuis le fichier chiffr√© √† l'√©tape pr√©c√©dente)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0e2d2004",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Initialisation du Cache des Textes Complets ---\n",
      "V√©rification du cache pour 4 source(s)...\n",
      "\n",
      "--- Fin Initialisation du Cache ---\n",
      "‚úÖ Cache initialis√©/v√©rifi√©.\n"
     ]
    }
   ],
   "source": [
    "# --- Bloc Python 4 (Initialisation Cache - MODIFI√â pour extensions texte) ---\n",
    "\n",
    "print(\"\\n--- Initialisation du Cache des Textes Complets ---\")\n",
    "\n",
    "definitions_to_check = current_extract_definitions if 'current_extract_definitions' in locals() and current_extract_definitions else EXTRACT_SOURCES\n",
    "TEMP_DOWNLOAD_DIR = Path(\"./temp_downloads\") # S'assurer qu'il est d√©fini\n",
    "\n",
    "if not definitions_to_check or definitions_to_check == DEFAULT_EXTRACT_SOURCES:\n",
    "     print(\" -> Aucune d√©finition de source valide √† v√©rifier/initialiser.\")\n",
    "else:\n",
    "    initialisation_errors = 0\n",
    "    print(f\"V√©rification du cache pour {len(definitions_to_check)} source(s)...\")\n",
    "    for i, source_info in enumerate(definitions_to_check):\n",
    "        source_name = source_info.get(\"source_name\", f\"Source #{i+1}\")\n",
    "        try:\n",
    "            reconstructed_url = reconstruct_url(\n",
    "                source_info.get(\"schema\"), source_info.get(\"host_parts\", []), source_info.get(\"path\")\n",
    "            )\n",
    "            if not reconstructed_url: print(f\"   -> ‚ö†Ô∏è URL invalide pour '{source_name}'.\"); initialisation_errors += 1; continue\n",
    "\n",
    "            source_type = source_info.get(\"source_type\")\n",
    "            original_path_str = source_info.get(\"path\", \"\")\n",
    "            is_plaintext_url = any(original_path_str.lower().endswith(ext) for ext in PLAINTEXT_EXTENSIONS)\n",
    "\n",
    "            # Utiliser l'URL reconstruite comme cl√© pour le cache texte final\n",
    "            filepath = get_cache_filepath(reconstructed_url)\n",
    "            if not filepath.exists():\n",
    "                print(f\"   -> Cache texte absent pour '{source_name}'. R√©cup√©ration (type: {source_type})...\")\n",
    "                try:\n",
    "                    if source_type == \"jina\":\n",
    "                        fetch_with_jina(reconstructed_url)\n",
    "                    elif source_type == \"direct_download\":\n",
    "                         fetch_direct_text(reconstructed_url)\n",
    "                    elif source_type == \"tika\":\n",
    "                        if is_plaintext_url:\n",
    "                             # Si type=tika mais URL est texte simple, utiliser fetch direct\n",
    "                             print(\"      (URL type texte d√©tect√©e, utilisation fetch direct au lieu de Tika)\")\n",
    "                             fetch_direct_text(reconstructed_url)\n",
    "                        else:\n",
    "                            # Type Tika pour fichier binaire (PDF, DOCX...)\n",
    "                            url_hash = hashlib.sha256(reconstructed_url.encode()).hexdigest()\n",
    "                            file_extension = Path(original_path_str).suffix if Path(original_path_str).suffix else \".download\"\n",
    "                            temp_save_path = TEMP_DOWNLOAD_DIR / f\"{url_hash}{file_extension}\"\n",
    "                            fetch_with_tika(source_url=reconstructed_url, raw_file_cache_path=temp_save_path)\n",
    "                    else:\n",
    "                         print(f\"   -> ‚ö†Ô∏è Type source inconnu '{source_type}'.\")\n",
    "                         initialisation_errors += 1\n",
    "\n",
    "                except Exception as e_fetch: # Attraper erreur PENDANT le fetch\n",
    "                    print(f\"   -> ‚ùå Erreur fetch pour '{source_name}': {e_fetch}\")\n",
    "                    initialisation_errors += 1\n",
    "            # else: print(f\"   -> Cache texte trouv√© pour '{source_name}'.\")\n",
    "\n",
    "        except Exception as e_loop: # Attraper erreur DANS la boucle (ex: reconstruct_url)\n",
    "            print(f\"   -> ‚ùå Erreur traitement source '{source_name}': {e_loop}\")\n",
    "            initialisation_errors += 1\n",
    "\n",
    "    print(\"\\n--- Fin Initialisation du Cache ---\")\n",
    "    if initialisation_errors > 0: print(f\"‚ö†Ô∏è {initialisation_errors} erreur(s) rencontr√©e(s).\")\n",
    "    else: print(\"‚úÖ Cache initialis√©/v√©rifi√©.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "355de48a",
   "metadata": {},
   "source": [
    "## 5. D√©finition de la Fonction Principale de l'UI (`configure_analysis_task`)\n",
    "\n",
    "D√©finition de la fonction qui sera appel√©e par le notebook ex√©cuteur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "140c9f17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fonction configure_analysis_task() d√©finie dans UI_Configuration.ipynb.\n"
     ]
    }
   ],
   "source": [
    "def configure_analysis_task():\n",
    "    \"\"\"Affiche l'UI, g√®re interactions et retourne texte pr√©par√©.\"\"\"\n",
    "\n",
    "    # --- Variables locales √† la fonction pour l'√©tat de l'UI ---\n",
    "    # Note: On utilise 'nonlocal' pour les modifier dans les callbacks\n",
    "    texte_analyse_prepare_local = \"\"\n",
    "    analyse_ready_to_run_local = False\n",
    "\n",
    "    # --- R√©cup√©ration cl√© et chargement initial ---\n",
    "    # Utilise les variables globales d√©finies dans les cellules pr√©c√©dentes\n",
    "    global ENCRYPTION_KEY, current_extract_definitions, CONFIG_FILE, EXTRACT_SOURCES\n",
    "    # Charger/Recharger les d√©finitions au d√©but de l'appel de la fonction\n",
    "    # pour refl√©ter un √©ventuel chargement/sauvegarde via les boutons de l'UI\n",
    "    current_extract_definitions = load_extract_definitions(CONFIG_FILE, ENCRYPTION_KEY)\n",
    "\n",
    "    # --- Cr√©ation des Widgets ---\n",
    "    # (Utilise current_extract_definitions charg√©e)\n",
    "\n",
    "    # Biblioth√®que\n",
    "    source_mode_radio = widgets.RadioButtons(\n",
    "        options=['Source Al√©atoire', 'Choisir Document & Extrait'],\n",
    "        description='Mode:', value='Source Al√©atoire', disabled=False, style={'description_width': 'initial'}\n",
    "    )\n",
    "    # V√©rification pour √©viter l'erreur si current_extract_definitions est invalide au d√©marrage\n",
    "    valid_source_names = [s.get(\"source_name\", f\"Erreur Def #{i}\")\n",
    "                          for i, s in enumerate(current_extract_definitions) if isinstance(s, dict)]\n",
    "    if not valid_source_names: # Fournir une option par d√©faut si tout √©choue\n",
    "         print(\"‚ö†Ô∏è Erreur: Aucune d√©finition de source valide trouv√©e pour le dropdown.\")\n",
    "         valid_source_names = [\"Erreur Chargement Config\"]\n",
    "\n",
    "    source_doc_dropdown = widgets.Dropdown(\n",
    "        options=valid_source_names,\n",
    "        description='Document:', disabled=True, style={'description_width': 'initial'}, layout={'width': '90%'}\n",
    "    )\n",
    "    extract_dropdown = widgets.Dropdown(\n",
    "        options=[], description='Extrait:', disabled=True, style={'description_width': 'initial'}, layout={'width': '90%'}\n",
    "    )\n",
    "    tab_library = widgets.VBox([source_mode_radio, source_doc_dropdown, extract_dropdown])\n",
    "\n",
    "    # URL\n",
    "    url_input = widgets.Text(placeholder=\"Entrez l'URL\", description=\"URL:\", layout={'width': '90%'}, style={'description_width': 'initial'})\n",
    "    url_processing_type_radio = widgets.RadioButtons(options=[('Page Web (via Jina)', 'jina'), ('Document PDF/Office (via Tika)', 'tika')], description='Type:', value='jina', disabled=False, style={'description_width': 'initial'})\n",
    "    tab_url = widgets.VBox([widgets.Label(\"Entrez l'URL et choisissez le type:\"), url_input, url_processing_type_radio])\n",
    "\n",
    "    # Fichier\n",
    "    file_uploader = widgets.FileUpload(accept='.txt,.pdf,.doc,.docx,.html,.xml,.md', multiple=False, description=\"Fichier:\", style={'description_width': 'initial'})\n",
    "    tab_file = widgets.VBox([widgets.Label(\"T√©l√©versez fichier (trait√© par Tika si besoin):\"), file_uploader]) # Texte Tika ajust√©\n",
    "\n",
    "    # Texte Direct\n",
    "    direct_text_input = widgets.Textarea(placeholder=\"Collez texte ici...\", layout={'width': '90%', 'height': '200px'})\n",
    "    tab_direct = widgets.VBox([widgets.Label(\"Saisissez le texte :\"), direct_text_input])\n",
    "\n",
    "    # Tabs\n",
    "    tabs = widgets.Tab(children=[tab_library, tab_url, tab_file, tab_direct])\n",
    "    tabs.set_title(0, 'üìö Biblioth√®que'); tabs.set_title(1, 'üåê URL'); tabs.set_title(2, 'üìÑ Fichier'); tabs.set_title(3, '‚úçÔ∏è Texte Direct')\n",
    "\n",
    "    # Extraction\n",
    "    start_marker_input = widgets.Text(placeholder=\"(Optionnel) D√©but (exclus)\", description=\"D√©but Extrait:\", layout={'width': '90%'}, style={'description_width': 'initial'})\n",
    "    end_marker_input = widgets.Text(placeholder=\"(Optionnel) Fin (exclue)\", description=\"Fin Extrait:\", layout={'width': '90%'}, style={'description_width': 'initial'})\n",
    "    extraction_box = widgets.VBox([\n",
    "        widgets.HTML(\"<hr><h4>Options d'Extraction (Optionnel)</h4>\"),\n",
    "        widgets.HTML(\"<p style='font-size:0.9em; color:grey;'>Marqueurs uniques. Exclus du r√©sultat.</p>\"),\n",
    "        start_marker_input, end_marker_input\n",
    "    ])\n",
    "\n",
    "    # Gestion Config\n",
    "    config_output_area = widgets.HTML(value=\"<i>Chargement...</i>\", layout={'border': '1px solid #ccc', 'padding': '5px', 'margin_top': '5px', 'max_height': '200px', 'overflow_y':'auto'})\n",
    "    load_config_button = widgets.Button(description=\"Charger/Actualiser D√©f.\", icon=\"refresh\", button_style='info', tooltip=\"Charge les d√©finitions\")\n",
    "    save_config_button = widgets.Button(description=\"Sauvegarder D√©f.\", icon=\"save\", button_style='warning', disabled=(not ENCRYPTION_KEY), tooltip=\"Sauvegarde les d√©finitions\")\n",
    "    verify_button = widgets.Button(description=\"V√©rifier Marqueurs\", icon=\"check\", button_style='primary', tooltip=\"V√©rifie les marqueurs\") # Bouton V√©rif\n",
    "    config_management_box = widgets.VBox([\n",
    "         widgets.HTML(\"<hr style='margin: 20px 0;'><h3>Gestion Configuration Sources</h3>\"),\n",
    "         widgets.HBox([load_config_button, save_config_button, verify_button]), # Bouton V√©rif ajout√©\n",
    "         config_output_area\n",
    "    ])\n",
    "\n",
    "    # Boutons Principaux et Sortie\n",
    "    prepare_button = widgets.Button(description=\"Pr√©parer le Texte\", button_style='info', icon='cogs', tooltip=\"Charge, extrait et pr√©pare texte.\")\n",
    "    run_button = widgets.Button(description=\"Lancer l'Analyse\", button_style='success', icon='play', disabled=True, tooltip=\"D√©marre l'analyse.\")\n",
    "    main_output_area = widgets.Output(layout={'border': '1px solid #ccc', 'padding': '10px', 'margin_top': '10px', 'min_height': '100px'})\n",
    "\n",
    "    # --- Callbacks ---\n",
    "    def update_extract_options_ui(change):\n",
    "        nonlocal extract_dropdown # R√©f√©rence widget\n",
    "        global current_extract_definitions # Acc√®s d√©finitions\n",
    "        selected_doc_name = change.get('new', source_doc_dropdown.value)\n",
    "        # Utiliser .get pour √©viter KeyError si structure invalide\n",
    "        source_info = next((s for s in current_extract_definitions if isinstance(s, dict) and s.get(\"source_name\") == selected_doc_name), None)\n",
    "        if source_info:\n",
    "            extract_options = [\"Texte Complet\"] + [e.get(\"extract_name\", \"Sans Nom\") for e in source_info.get(\"extracts\", []) if isinstance(e, dict)]\n",
    "            current_extract_value = extract_dropdown.value\n",
    "            extract_dropdown.options = extract_options\n",
    "            if current_extract_value in extract_options:\n",
    "                extract_dropdown.value = current_extract_value\n",
    "            elif extract_options: # S'assurer qu'il y a des options avant d'acc√©der √† [0]\n",
    "                 extract_dropdown.value = extract_options[0]\n",
    "            else: # Cas o√π il n'y a que \"Texte Complet\" et pas d'extraits\n",
    "                 extract_dropdown.value = None\n",
    "        else:\n",
    "            extract_dropdown.options = []\n",
    "            extract_dropdown.value = None\n",
    "    source_doc_dropdown.observe(update_extract_options_ui, names='value')\n",
    "\n",
    "    def handle_source_mode_change_ui(change):\n",
    "        nonlocal source_doc_dropdown, extract_dropdown\n",
    "        is_manual_choice = (change.get('new', source_mode_radio.value) == 'Choisir Document & Extrait')\n",
    "        source_doc_dropdown.disabled = not is_manual_choice\n",
    "        extract_dropdown.disabled = not is_manual_choice\n",
    "        # ATTENTION: Indentation cruciale ici\n",
    "        if is_manual_choice:\n",
    "            if source_doc_dropdown.options:\n",
    "                 # S'assurer qu'une valeur est s√©lectionn√©e avant de mettre √† jour les extraits\n",
    "                 if source_doc_dropdown.value:\n",
    "                     update_extract_options_ui({'new': source_doc_dropdown.value})\n",
    "                 # Si aucune valeur n'est s√©lectionn√©e (cas initial ou apr√®s chargement liste vide), on vide les extraits\n",
    "                 else:\n",
    "                     extract_dropdown.options = []\n",
    "                     extract_dropdown.value = None\n",
    "            else: # Si pas d'options dans le premier dropdown, vider le second\n",
    "                 extract_dropdown.options = []\n",
    "                 extract_dropdown.value = None\n",
    "        else: # Cas 'Source Al√©atoire'\n",
    "             extract_dropdown.options = []\n",
    "             extract_dropdown.value = None\n",
    "    source_mode_radio.observe(handle_source_mode_change_ui, names='value')\n",
    "\n",
    "    def display_definitions_in_ui(definitions_list):\n",
    "        # ... (Code identique, mais utilise .get pour s√©curit√©) ...\n",
    "        if not definitions_list: return \"Aucune d√©finition charg√©e.\"\n",
    "        MAX_EXTRACTS_DISPLAY = 5; html = \"<ul style='list-style-type: none; padding-left: 0;'>\";\n",
    "        for source in definitions_list:\n",
    "            if not isinstance(source, dict): continue # Ignorer √©l√©ments non valides\n",
    "            source_name_display = source.get('source_name', 'Erreur: Nom Manquant')\n",
    "            html += f\"<li style='margin-bottom: 10px;'><b>{source_name_display}</b> ({source.get('source_type', 'N/A')})\"\n",
    "            # Utilisation nouvelle structure URL\n",
    "            reconstructed = reconstruct_url(source.get(\"schema\"), source.get(\"host_parts\", []), source.get(\"path\"))\n",
    "            html += f\"<br/><small style='color:grey;'>{reconstructed or 'URL Invalide'}</small>\"\n",
    "            extracts = source.get('extracts', [])\n",
    "            if extracts and isinstance(extracts, list): # V√©rifier que extracts est une liste\n",
    "                html += \"<ul style='margin-top: 4px; font-size: 0.9em; list-style-type: none; padding-left: 10px;'>\";\n",
    "                for i, extract in enumerate(extracts):\n",
    "                    if not isinstance(extract, dict): continue # Ignorer extraits non valides\n",
    "                    if i >= MAX_EXTRACTS_DISPLAY: html += f\"<li>... et {len(extracts) - MAX_EXTRACTS_DISPLAY} autre(s)</li>\"; break\n",
    "                    extract_name_display = extract.get('extract_name', 'Erreur: Nom Extrait Manquant')\n",
    "                    html += f\"<li>- {extract_name_display}</li>\";\n",
    "                html += \"</ul>\";\n",
    "            html += \"</li>\";\n",
    "        html += \"</ul>\"; return html\n",
    "\n",
    "    def on_load_config_click_ui(b):\n",
    "        nonlocal config_output_area, source_doc_dropdown, save_config_button # Widgets externes\n",
    "        global current_extract_definitions, ENCRYPTION_KEY, CONFIG_FILE # Variables globales\n",
    "        with main_output_area: clear_output(wait=True); print(\"‚è≥ Chargement d√©finitions...\")\n",
    "        loaded_defs = load_extract_definitions(CONFIG_FILE, ENCRYPTION_KEY)\n",
    "        # ---- Validation robuste ----\n",
    "        valid_defs = [s for s in loaded_defs if isinstance(s, dict) and \"source_name\" in s]\n",
    "        if len(valid_defs) != len(loaded_defs):\n",
    "            print(\"‚ö†Ô∏è Attention: Certaines d√©finitions charg√©es/par d√©faut √©taient invalides et ont √©t√© ignor√©es.\")\n",
    "        current_extract_definitions = valid_defs # Utiliser seulement les valides\n",
    "        # ---------------------------\n",
    "        config_output_area.value = display_definitions_in_ui(current_extract_definitions)\n",
    "        # Mettre √† jour dropdown biblioth√®que\n",
    "        current_doc_selection = source_doc_dropdown.value # Sauver la s√©lection\n",
    "        source_doc_options = [s[\"source_name\"] for s in current_extract_definitions] # Utilise la liste filtr√©e\n",
    "        source_doc_dropdown.options = source_doc_options\n",
    "        # Essayer de restaurer la s√©lection ou prendre la premi√®re\n",
    "        if current_doc_selection in source_doc_options: source_doc_dropdown.value = current_doc_selection\n",
    "        elif source_doc_options: source_doc_dropdown.value = source_doc_options[0]\n",
    "        else: source_doc_dropdown.value = None\n",
    "        # Mettre √† jour les extraits (appelle update_extract_options_ui via observe)\n",
    "        # Forcer l'appel au cas o√π la valeur n'a pas chang√© mais les options oui\n",
    "        if source_doc_dropdown.value: update_extract_options_ui({'new': source_doc_dropdown.value})\n",
    "        else: extract_dropdown.options = []\n",
    "\n",
    "        with main_output_area: clear_output(wait=True); print(\"‚úÖ D√©finitions charg√©es/actualis√©es.\")\n",
    "        save_config_button.disabled = (not ENCRYPTION_KEY)\n",
    "\n",
    "    def on_save_config_click_ui(b):\n",
    "        nonlocal main_output_area # Widget externe\n",
    "        global current_extract_definitions, ENCRYPTION_KEY, CONFIG_FILE # Variables globales\n",
    "        with main_output_area: clear_output(wait=True); print(\"‚è≥ Sauvegarde d√©finitions...\")\n",
    "        success = save_extract_definitions(current_extract_definitions, CONFIG_FILE, ENCRYPTION_KEY)\n",
    "        if success: print(\"‚úÖ D√©finitions sauvegard√©es.\")\n",
    "        else: print(\"‚ùå √âchec sauvegarde.\")\n",
    "\n",
    "    def on_verify_click_ui(b):\n",
    "        \"\"\"Lance la v√©rification et affiche le r√©sultat.\"\"\"\n",
    "        nonlocal main_output_area # Widget externe\n",
    "        global current_extract_definitions # Variable globale\n",
    "        with main_output_area:\n",
    "            clear_output(wait=True)\n",
    "            print(\"Lancement de la v√©rification (peut prendre du temps)...\")\n",
    "            # Appelle la fonction de v√©rification d√©finie dans la cellule pr√©c√©dente\n",
    "            # S'assurer que verify_extract_definitions est bien d√©finie globalement\n",
    "            if 'verify_extract_definitions' in globals():\n",
    "                 summary = verify_extract_definitions(current_extract_definitions)\n",
    "                 clear_output(wait=True)\n",
    "                 display(widgets.HTML(summary)) # Afficher le r√©sultat HTML\n",
    "                 print(\"\\nV√©rification termin√©e.\") # Message console\n",
    "            else:\n",
    "                 print(\"ERREUR: La fonction verify_extract_definitions n'est pas trouv√©e.\")\n",
    "\n",
    "\n",
    "    def on_prepare_click_ui(b):\n",
    "        nonlocal texte_analyse_prepare_local, analyse_ready_to_run_local\n",
    "        global current_extract_definitions\n",
    "        # ... (Logique compl√®te et corrig√©e de on_prepare_click_ui de ma r√©ponse pr√©c√©dente) ...\n",
    "        # ... Assurez-vous que cette logique utilise bien la structure URL corrig√©e ...\n",
    "        # ... et la gestion des extensions texte simple ...\n",
    "        analyse_ready_to_run_local = False; run_button.disabled = True\n",
    "        texte_brut_source = \"\"; source_description = \"\"; start_marker_final = \"\"; end_marker_final = \"\"; error_occured = False\n",
    "\n",
    "        with main_output_area:\n",
    "            clear_output(wait=True); print(\"‚è≥ Pr√©paration texte...\")\n",
    "            selected_tab_index = tabs.selected_index\n",
    "            try:\n",
    "                if selected_tab_index == 0: # Biblioth√®que\n",
    "                    source_info = None ; extract_info = None ; reconstructed_url = None\n",
    "                    if source_mode_radio.value == 'Source Al√©atoire':\n",
    "                        if not current_extract_definitions: raise ValueError(\"Biblio vide!\")\n",
    "                        source_info = random.choice(current_extract_definitions)\n",
    "                        extracts_available = source_info.get(\"extracts\", []); potential_extracts = [{\"extract_name\": \"Texte Complet\"}] + extracts_available; extract_info = random.choice(potential_extracts); print(f\"-> Choix Al√©atoire: Doc='{source_info.get('source_name', '?')}', Extrait='{extract_info['extract_name']}'\")\n",
    "                    else:\n",
    "                        selected_doc_name = source_doc_dropdown.value; selected_extract_name = extract_dropdown.value\n",
    "                        if not selected_doc_name: raise ValueError(\"Aucun document s√©lectionn√©.\")\n",
    "                        source_info = next((s for s in current_extract_definitions if s.get(\"source_name\") == selected_doc_name), None)\n",
    "                        if not source_info: raise ValueError(f\"Doc '{selected_doc_name}' non trouv√©.\")\n",
    "                        if selected_extract_name == \"Texte Complet\": extract_info = {\"extract_name\": \"Texte Complet\"}\n",
    "                        else: extract_info = next((e for e in source_info.get(\"extracts\", []) if e.get(\"extract_name\") == selected_extract_name), None);\n",
    "                        if not extract_info: raise ValueError(f\"Extrait '{selected_extract_name}' non trouv√©.\")\n",
    "                        print(f\"-> Choix Manuel: Doc='{source_info['source_name']}', Extrait='{extract_info['extract_name']}'\")\n",
    "\n",
    "                    start_marker_final = extract_info.get(\"start_marker\", \"\") if extract_info.get(\"extract_name\") != \"Texte Complet\" else \"\"\n",
    "                    end_marker_final = extract_info.get(\"end_marker\", \"\") if extract_info.get(\"extract_name\") != \"Texte Complet\" else \"\"\n",
    "                    reconstructed_url = reconstruct_url(source_info.get(\"schema\"), source_info.get(\"host_parts\", []), source_info.get(\"path\"))\n",
    "                    if not reconstructed_url: raise ValueError(\"URL source invalide.\")\n",
    "                    source_description = f\"Biblio: {source_info.get('source_name','?')} ({extract_info.get('extract_name','?')})\"\n",
    "\n",
    "                    cached_text = load_from_cache(reconstructed_url)\n",
    "                    if cached_text is not None: texte_brut_source = cached_text\n",
    "                    else:\n",
    "                        source_type = source_info.get(\"source_type\"); original_path_str = source_info.get(\"path\", \"\"); is_plaintext_url = any(original_path_str.lower().endswith(ext) for ext in PLAINTEXT_EXTENSIONS)\n",
    "                        print(f\"-> Cache vide. R√©cup√©ration (Type: {source_type}, URL: ...)...\")\n",
    "                        if source_type == \"jina\": texte_brut_source = fetch_with_jina(reconstructed_url)\n",
    "                        elif source_type == \"direct_download\": texte_brut_source = fetch_direct_text(reconstructed_url)\n",
    "                        elif source_type == \"tika\":\n",
    "                             if is_plaintext_url: print(\"      (URL type texte, fetch direct)\"); texte_brut_source = fetch_direct_text(reconstructed_url)\n",
    "                             else: url_hash = hashlib.sha256(reconstructed_url.encode()).hexdigest(); temp_save_path = TEMP_DOWNLOAD_DIR / f\"{url_hash}.download_debug\"; texte_brut_source = fetch_with_tika(source_url=reconstructed_url, raw_file_cache_path=temp_save_path)\n",
    "                        else: raise ValueError(f\"Type source inconnu '{source_type}'.\")\n",
    "\n",
    "                elif selected_tab_index == 1: # URL\n",
    "                    url = url_input.value.strip(); processing_type = url_processing_type_radio.value\n",
    "                    if not url or not url.startswith(('http://', 'https://')): raise ValueError(\"URL invalide.\")\n",
    "                    source_description = f\"URL ({processing_type.upper()}): {url}\"; cached_text = load_from_cache(url)\n",
    "                    if cached_text is not None: texte_brut_source = cached_text\n",
    "                    else:\n",
    "                        is_plaintext_url = any(url.lower().endswith(ext) for ext in PLAINTEXT_EXTENSIONS)\n",
    "                        if processing_type == \"jina\": texte_brut_source = fetch_with_jina(url)\n",
    "                        elif processing_type == \"tika\":\n",
    "                             if is_plaintext_url: print(\"   -> URL type texte, fetch direct.\"); texte_brut_source = fetch_direct_text(url)\n",
    "                             else: texte_brut_source = fetch_with_tika(source_url=url)\n",
    "                        else: raise ValueError(f\"Type traitement inconnu: {processing_type}\")\n",
    "                    start_marker_final = start_marker_input.value.strip()\n",
    "                    end_marker_final = end_marker_input.value.strip()\n",
    "\n",
    "                elif selected_tab_index == 2: # Fichier\n",
    "                    if not file_uploader.value: raise ValueError(\"Veuillez t√©l√©verser un fichier.\")\n",
    "                    uploaded_file_info = file_uploader.value[0]; file_name = uploaded_file_info['name']; cache_key = f\"file://{file_name}\"; cached_text = load_from_cache(cache_key)\n",
    "                    if cached_text is not None: texte_brut_source = cached_text; source_description = f\"Fichier (Cache): {file_name}\"\n",
    "                    else:\n",
    "                        is_plaintext_file = any(file_name.lower().endswith(ext) for ext in PLAINTEXT_EXTENSIONS)\n",
    "                        file_content_bytes = uploaded_file_info['content']\n",
    "                        if is_plaintext_file:\n",
    "                            print(f\"-> Traitement fichier texte local : '{file_name}'\");\n",
    "                            try: texte_brut_source = file_content_bytes.decode('utf-8', errors='ignore'); print(f\"   -> Contenu lu direct.\"); save_to_cache(cache_key, texte_brut_source); source_description = f\"Fichier Texte: {file_name}\"\n",
    "                            except Exception as e_decode: print(f\"   -> ‚ö†Ô∏è Erreur d√©codage, tentative Tika: {e_decode}\"); texte_brut_source = fetch_with_tika(file_content=file_content_bytes, file_name=file_name); source_description = f\"Fichier (via Tika post-err): {file_name}\"\n",
    "                        else: print(f\"-> Traitement fichier '{file_name}' via Tika...\"); source_description = f\"Fichier (via Tika): {file_name}\"; texte_brut_source = fetch_with_tika(file_content=file_content_bytes, file_name=file_name)\n",
    "                    try: file_uploader.value = {}; file_uploader._counter = 0\n",
    "                    except Exception: pass\n",
    "                    start_marker_final = start_marker_input.value.strip()\n",
    "                    end_marker_final = end_marker_input.value.strip()\n",
    "\n",
    "                elif selected_tab_index == 3: # Texte Direct\n",
    "                    texte_brut_source = direct_text_input.value; source_description = \"Texte Direct\"\n",
    "                    if not texte_brut_source: raise ValueError(\"Veuillez saisir du texte.\")\n",
    "                    print(f\"-> Utilisation texte direct (longueur: {len(texte_brut_source)}).\"); start_marker_final = start_marker_input.value.strip(); end_marker_final = end_marker_input.value.strip()\n",
    "                else: raise ValueError(\"Onglet inconnu.\")\n",
    "\n",
    "                # --- Application finale des marqueurs ---\n",
    "                texte_final = texte_brut_source\n",
    "                if start_marker_final or end_marker_final:\n",
    "                    # ... (logique d'extraction identique) ...\n",
    "                    print(\"\\n-> Application marqueurs...\"); start_index = 0; end_index = len(texte_brut_source);\n",
    "                    if start_marker_final:\n",
    "                        try: found_start = texte_brut_source.index(start_marker_final); start_index = found_start + len(start_marker_final); print(f\"   -> D√©but trouv√©.\")\n",
    "                        except ValueError: print(f\"   ‚ö†Ô∏è D√©but non trouv√©.\"); start_index = 0\n",
    "                    if end_marker_final:\n",
    "                        try: found_end = texte_brut_source.index(end_marker_final, start_index); end_index = found_end; print(f\"   -> Fin trouv√©e.\")\n",
    "                        except ValueError: print(f\"   ‚ö†Ô∏è Fin non trouv√©e.\"); end_index = len(texte_brut_source)\n",
    "                    if start_index < end_index: texte_final = texte_brut_source[start_index:end_index].strip();\n",
    "                    else: print(f\"   ‚ö†Ô∏è Conflit/Vide.\"); texte_final = \"\"\n",
    "                    if texte_final and (start_marker_final or end_marker_final) : source_description += \" (Extrait)\"\n",
    "                    if not texte_final and texte_brut_source: print(\"   -> Extraction vide.\")\n",
    "\n",
    "                # --- Finalisation ---\n",
    "                texte_analyse_prepare_local = texte_final\n",
    "                if not texte_analyse_prepare_local: print(\"\\n‚ö†Ô∏è Texte pr√©par√© final vide !\")\n",
    "                print(\"\\n--- Aper√ßu Texte Pr√©par√© ---\")\n",
    "                preview = texte_analyse_prepare_local[:1500]; print(preview + ('\\n[...]' if len(texte_analyse_prepare_local) > 1500 else '')); print(\"-\" * 30)\n",
    "                print(f\"\\n‚úÖ Texte pr√©par√© (Source: {source_description}, Longueur: {len(texte_analyse_prepare_local)}).\")\n",
    "                if len(texte_analyse_prepare_local) > 0: print(\"Cliquez sur 'Lancer l'Analyse'.\"); run_button.disabled = False\n",
    "                else: print(\"Texte vide.\"); run_button.disabled = True\n",
    "\n",
    "            except Exception as e:\n",
    "                 # ... (gestion d'erreur identique) ...\n",
    "                 error_occured = True ; texte_analyse_prepare_local = \"\"\n",
    "                 print(f\"\\n‚ùå Erreur Pr√©paration : {type(e).__name__} - {e}\"); print(\"\\n--- Trace ---\"); print(traceback.format_exc()); print(\"-\" * 25); run_button.disabled = True\n",
    "\n",
    "    def on_run_click_ui(b):\n",
    "        nonlocal analyse_ready_to_run_local, texte_analyse_prepare_local\n",
    "        # ... (code identique) ...\n",
    "        if run_button.disabled or not texte_analyse_prepare_local:\n",
    "             with main_output_area: clear_output(wait=True); print(\"‚ö†Ô∏è Pr√©parez un texte non vide.\")\n",
    "        else:\n",
    "            analyse_ready_to_run_local = True; prepare_button.disabled = True; run_button.disabled = True; tabs.disabled = True; start_marker_input.disabled = True; end_marker_input.disabled = True; load_config_button.disabled = True; save_config_button.disabled = True; source_mode_radio.disabled = True; source_doc_dropdown.disabled=True; extract_dropdown.disabled=True; url_input.disabled = True; url_processing_type_radio.disabled=True; file_uploader.disabled = True; direct_text_input.disabled = True\n",
    "            with main_output_area: clear_output(wait=True); print(f\"üìù Texte final pr√™t (Longueur: {len(texte_analyse_prepare_local)}).\"); print(\"\\nüöÄ Lancement analyse...\")\n",
    "\n",
    "    # --- Lier Callbacks ---\n",
    "    prepare_button.on_click(on_prepare_click_ui)\n",
    "    run_button.on_click(on_run_click_ui)\n",
    "    load_config_button.on_click(on_load_config_click_ui)\n",
    "    save_config_button.on_click(on_save_config_click_ui)\n",
    "    verify_button.on_click(on_verify_click_ui) # <-- Lier nouveau bouton\n",
    "\n",
    "    # --- Affichage et Boucle ---\n",
    "    print(\"Initialisation interface...\")\n",
    "    ui_container = widgets.VBox([\n",
    "        widgets.HTML(\"<h2>Configuration T√¢che Analyse</h2>\"),\n",
    "        widgets.HTML(\"<h3>1. Source Texte</h3>\"), tabs, extraction_box,\n",
    "        config_management_box, # <-- Bo√Æte gestion config incluant nouveau bouton\n",
    "        widgets.HTML(\"<hr><h3>2. Pr√©paration</h3>\"), prepare_button, main_output_area,\n",
    "        widgets.HTML(\"<hr><h3>3. D√©marrage</h3>\"), run_button\n",
    "    ])\n",
    "    display(ui_container)\n",
    "\n",
    "    # Initialiser l'UI\n",
    "    handle_source_mode_change_ui({})\n",
    "    on_load_config_click_ui(None) # Charger config initiale\n",
    "\n",
    "    print(\"\\n‚è≥ En attente interaction...\")\n",
    "    with ui_events() as poll:\n",
    "        while not analyse_ready_to_run_local: poll(10); time.sleep(0.1)\n",
    "\n",
    "    print(\"\\nüèÅ Configuration t√¢che termin√©e. Retour notebook principal...\")\n",
    "    return texte_analyse_prepare_local\n",
    "\n",
    "# --- Fin de la d√©finition de configure_analysis_task ---\n",
    "print(\"Fonction configure_analysis_task() d√©finie dans UI_Configuration.ipynb.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333e0c9c",
   "metadata": {},
   "source": [
    "## 6. Fin\n",
    "\n",
    "Le notebook `Argument_Analysis_UI_configuration.ipynb` est maintenant pr√™t. Il contient toute la logique n√©cessaire pour l'interface utilisateur, la gestion des sources, le cache et le chiffrement.\n",
    "\n",
    "Le notebook ex√©cuteur principal peut maintenant utiliser la fonction `configure_analysis_task()` d√©finie ici pour obtenir le texte pr√©par√© avant de lancer l'analyse par les agents."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
