{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6835139",
   "metadata": {},
   "source": [
    "# Tutoriel TweetyProject : Logiques Symboliques et Argumentation en Python (via JPype)\n",
    "\n",
    "Ce notebook explore la bibliothèque Java [TweetyProject](https://tweetyproject.org/) pour l'intelligence artificielle symbolique, en mettant l'accent sur ses riches fonctionnalités pour la **représentation de connaissances** et l'**argumentation computationnelle**. Nous utiliserons **JPype** pour interfacer Python avec les classes Java de Tweety.\n",
    "\n",
    "**IMPORTANT :** Le succès de ce notebook dépend crucialement de la bonne configuration de l'environnement Java (JDK) et de l'accès aux fichiers JAR de Tweety par JPype. Suivez attentivement les étapes de la Partie 1.\n",
    "\n",
    "**Objectifs :**\n",
    "* Installer et configurer l'environnement Python + JPype + Tweety.\n",
    "* Manipuler différentes logiques (Propositionnelle, Premier Ordre, Description, Modale, Conditionnelle, QBF...).\n",
    "* Appliquer des mécanismes de raisonnement avancés : révision de croyances et mesures d'incohérence.\n",
    "* Explorer en profondeur divers formalismes d'argumentation :\n",
    "    * Cadres abstraits de Dung (sémantiques, génération, apprentissage).\n",
    "    * Approches structurées (ASPIC+, DeLP, ABA, Déductive).\n",
    "    * Variantes avancées (ADF, Bipolaire, Pondérée, Sociale, SetAF, Étendue).\n",
    "    * Analyses spécifiques (Classement, Probabiliste).\n",
    "\n",
    "**Public visé :** Étudiants, chercheurs ou développeurs intéressés par l'IA symbolique, le raisonnement logique et l'argumentation. Une connaissance de base de Python et des concepts logiques est recommandée.\n",
    "\n",
    "*(Version du Notebook: [Date/Version], Basé sur TweetyProject v1.28)*\n",
    "\n",
    "---\n",
    "\n",
    "## Plan du Notebook\n",
    "\n",
    "**Partie 1 : [Introduction et Configuration](#partie1)**\n",
    "* 1.1 [Présentation et Objectifs](#1.1) (Cellule ci-dessus)\n",
    "* 1.2 [Pré-requis](#1.2)\n",
    "* 1.3 [Installation des Packages Python](#1.3)\n",
    "* 1.4 [Téléchargement des JARs Tweety et Dépendances](#1.4)\n",
    "* 1.5 [Configuration des Outils Externes (Optionnel)](#1.5)\n",
    "* 1.6 [Démarrage de la JVM via JPype](#1.6)\n",
    "* 1.7 [Concepts Clés de Tweety et JPype](#1.7)\n",
    "\n",
    "**Partie 2 : [Logiques Fondamentales dans Tweety](#partie2)**\n",
    "* 2.1 [Logique Propositionnelle (PL)](#2.1)\n",
    "    * 2.1.1 [Syntaxe, Parsing, Mondes Possibles](#2.1.1)\n",
    "    * 2.1.2 [Raisonnement Simple et Solveurs SAT (SAT4J interne)](#2.1.2)\n",
    "    * 2.1.3 [Solveurs SAT Externes (Optionnel)](#2.1.3)\n",
    "* 2.2 [Logique du Premier Ordre (FOL)](#2.2)\n",
    "    * 2.2.1 [Signatures, Formules, Parsing](#2.2.1)\n",
    "    * 2.2.2 [Raisonnement FOL (Simple, Externe - EProver/SPASS)](#2.2.2)\n",
    "* 2.3 [Logique de Description (DL)](#2.3)\n",
    "    * 2.3.1 [Concepts, Rôles, ABox, TBox](#2.3.1)\n",
    "    * 2.3.2 [Raisonnement DL (Naïf)](#2.3.2)\n",
    "* 2.4 [Logique Modale (ML)](#2.4)\n",
    "    * 2.4.1 [Syntaxe, Parsing](#2.4.1)\n",
    "    * 2.4.2 [Raisonnement ML (Simple, Externe - SPASS)](#2.4.2)\n",
    "* 2.5 [Autres Logiques (Aperçu)](#2.5)\n",
    "    * 2.5.1 [Formules Booléennes Quantifiées (QBF)](#2.5.1)\n",
    "    * 2.5.2 [Logique Conditionnelle (CL)](#2.5.2)\n",
    "    * 2.5.3 [Logique Conditionnelle Probabiliste (PCL)](#2.5.3)\n",
    "    * 2.5.4 [Logique Conditionnelle Relationnelle (RCL/RPCL)](#2.5.4)\n",
    "    * 2.5.5 [Markov Logic Networks (MLN)](#2.5.5)\n",
    "    * 2.5.6 [Business Process Management (BPM)](#2.5.6)\n",
    "    * 2.5.7 [Langages d'Action](#2.5.7)\n",
    "\n",
    "**Partie 3 : [Révision de Croyances et Analyse d'Incohérence](#partie3)**\n",
    "* 3.1 [Révision de Croyances Multi-Agents (CrMas)](#3.1)\n",
    "* 3.2 [Mesures d'Incohérence (PL)](#3.2)\n",
    "    * 3.2.1 [Basées sur la Distance (DSum, DMax, DHit)](#3.2.1)\n",
    "    * 3.2.2 [Autres (Contension, Fuzzy)](#3.2.2)\n",
    "* 3.3 [Énumération de MUS et Mesures Associées (Ma, Mcsc)](#3.3)\n",
    "* 3.4 [MaxSAT (Optionnel - Open-WBO)](#3.4)\n",
    "\n",
    "**Partie 4 : [Argumentation Abstraite et Structurée](#partie4)**\n",
    "* 4.1 [Cadres d'Argumentation Abstraits (Dung)](#4.1)\n",
    "    * 4.1.1 [Construction et Sémantiques Standards](#4.1.1)\n",
    "    * 4.1.2 [Sémantique CF2](#4.1.2)\n",
    "    * 4.1.3 [Génération de Cadres](#4.1.3) *(Intégration exemple orphelin Cellule 50)*\n",
    "    * 4.1.4 [Apprentissage de Cadres](#4.1.4) *(Intégration exemple orphelin Cellule 49)*\n",
    "    * 4.1.5 [Autres Raisonneurs (Vacuous Reduct, Resolution-based)](#4.1.5) *(Optionnel)*\n",
    "* 4.2 [ASPIC+](#4.2)\n",
    "    * 4.2.1 [Construction (PL, FOL)](#4.2.1)\n",
    "    * 4.2.2 [Conversion vers Dung et Raisonnement](#4.2.2)\n",
    "    * 4.2.3 [Génération et Comparaison de Raisonneurs (Optionnel)](#4.2.3)\n",
    "* 4.3 [Defeasible Logic Programming (DeLP)](#4.3)\n",
    "* 4.4 [Assumption-Based Argumentation (ABA)](#4.4)\n",
    "* 4.5 [Argumentation Déductive (PL)](#4.5)\n",
    "* 4.6 [Answer Set Programming (ASP)](#4.6)\n",
    "\n",
    "**Partie 5 : [Argumentation Avancée et Analyse](#partie5)**\n",
    "* 5.1 [Abstract Dialectical Frameworks (ADF)](#5.1)\n",
    "* 5.2 [Frameworks Bipolaires](#5.2)\n",
    "    * 5.2.1 [EAF (Support simple)](#5.2.1)\n",
    "    * 5.2.2 [PEAF (Support probabiliste)](#5.2.2)\n",
    "    * 5.2.3 [Evidential AF](#5.2.3)\n",
    "    * 5.2.4 [Necessity AF](#5.2.4)\n",
    "    * 5.2.5 [Analyse de Justification (PEAF)](#5.2.5)\n",
    "* 5.3 [Frameworks Pondérés (WAF)](#5.3)\n",
    "* 5.4 [Frameworks Sociaux (SAF)](#5.4)\n",
    "* 5.5 [Set Argumentation Frameworks (SetAF)](#5.5)\n",
    "* 5.6 [Frameworks Étendus (Attaques sur Attaques)](#5.6)\n",
    "    * 5.6.1 [Extended AF (EAF)](#5.6.1)\n",
    "    * 5.6.2 [Recursive Extended AF (REAF)](#5.6.2)\n",
    "* 5.7 [Sémantiques Basées sur le Classement (Ranking)](#5.7)\n",
    "* 5.8 [Argumentation Probabiliste (Approche de Li, Hunter, Thimm)](#5.8)\n",
    "\n",
    "**Partie 6 : [Conclusion et Perspectives](#partie6)**\n",
    "* 6.1 [Récapitulatif](#6.1)\n",
    "* 6.2 [Pistes d'exploration et Contributions](#6.2)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "857b4633",
   "metadata": {},
   "source": [
    "## Partie 1 : Introduction et Configuration\n",
    "<a id=\"partie1\"></a>\n",
    "\n",
    "Cette section couvre la mise en place de l'environnement nécessaire pour exécuter les exemples de ce notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf92c1d",
   "metadata": {},
   "source": [
    "### 1.2 Pré-requis\n",
    "<a id=\"1.2\"></a>\n",
    "\n",
    "*   **Python 3.x** : Assurez-vous d'avoir une installation Python fonctionnelle (testé avec 3.10+).\n",
    "*   **Java Development Kit (JDK)** : JPype nécessite un JDK (version 11 ou supérieure recommandée) pour démarrer la JVM.\n",
    "    *   Vérifiez votre installation avec `java -version` dans un terminal.\n",
    "    *   Assurez-vous que la variable d'environnement `JAVA_HOME` pointe vers le répertoire racine de votre installation JDK (par exemple, `/usr/lib/jvm/java-17-openjdk-amd64` sur Linux, `C:\\Program Files\\Java\\jdk-17` sur Windows).\n",
    "    *   Si `JAVA_HOME` n'est pas définie, le script de démarrage de la JVM (section 1.6) essaiera de trouver un JDK automatiquement, mais il est préférable de la définir explicitement.\n",
    "*   **(Optionnel) Outils Externes** : Pour certaines fonctionnalités avancées (voir section [1.5](#1.5)), vous devrez installer des outils spécifiques et configurer leurs chemins d'accès plus loin dans le notebook.\n",
    "*   **(Optionnel) Graphviz**: Pour visualiser certains graphes d'argumentation (non implémenté dans ce tutoriel mais possible)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf65605f",
   "metadata": {},
   "source": [
    "### 1.3 Installation des Packages Python\n",
    "<a id=\"1.3\"></a>\n",
    "\n",
    "Nous utilisons `jpype1` pour le pont Java-Python. Les autres packages (`requests`, `tqdm`) sont des utilitaires pour le téléchargement des JARs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b4464c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vérification/Installation des packages Python nécessaires\n",
    "import importlib\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "# Le package s'appelle 'jpype1' sur PyPI, mais on importe 'jpype'\n",
    "packages_to_check = {'jpype': 'jpype1', 'requests': 'requests', 'tqdm': 'tqdm', 'clingo': 'clingo'}\n",
    "packages_to_install = []\n",
    "all_found = True\n",
    "\n",
    "print(\"--- Vérification des packages Python requis ---\")\n",
    "for import_name, install_name in packages_to_check.items():\n",
    "    try:\n",
    "        importlib.import_module(import_name)\n",
    "        print(f\"✔️ {import_name} trouvé.\")\n",
    "    except ImportError:\n",
    "        print(f\"⚠️ {import_name} manquant (package: {install_name}).\")\n",
    "        packages_to_install.append(install_name)\n",
    "        all_found = False\n",
    "\n",
    "if packages_to_install:\n",
    "    print(f\"\\nTentative d'installation des packages manquants: {', '.join(packages_to_install)}...\")\n",
    "    try:\n",
    "        # Utiliser -q pour une sortie moins verbeuse, retirer si le debug est nécessaire\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\"] + packages_to_install)\n",
    "        print(f\"✅ Packages {', '.join(packages_to_install)} installés.\")\n",
    "        print(\"\\n‼️ IMPORTANT : Vous devez probablement REDÉMARRER LE NOYAU (Kernel -> Restart Kernel) pour que les nouveaux packages soient pris en compte.\")\n",
    "        # Marquer comme non trouvés pour l'instant, car le noyau doit redémarrer\n",
    "        all_found = False\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Échec de l'installation automatique : {e}\")\n",
    "        print(f\"   Veuillez installer manuellement : pip install {' '.join(packages_to_install)}\")\n",
    "        all_found = False # Échec -> pas trouvé\n",
    "\n",
    "if all_found:\n",
    "    print(\"\\n✔️ Tous les packages Python requis sont présents.\")\n",
    "\n",
    "# Importations pour vérifier après redémarrage potentiel (ne lèvera pas d'erreur ici)\n",
    "try:\n",
    "    import jpype\n",
    "    import requests\n",
    "    import tqdm\n",
    "except ImportError:\n",
    "    if not packages_to_install: # Si on n'a pas essayé d'installer, c'est une autre erreur\n",
    "         print(\"\\n⚠️ Erreur d'import inattendue. Vérifiez votre environnement Python.\")\n",
    "    # Si on a installé, le message d'erreur est déjà affiché.\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0072a42",
   "metadata": {},
   "source": [
    "### 1.4 Téléchargement des JARs Tweety et Dépendances\n",
    "<a id=\"1.4\"></a>\n",
    "\n",
    "TweetyProject est une collection de bibliothèques Java distribuées sous forme de fichiers JAR. Pour utiliser Tweety avec JPype, nous devons télécharger ces JARs et les rendre accessibles à la JVM.\n",
    "\n",
    "Le script suivant va :\n",
    "1.  Créer un sous-dossier `libs/` s'il n'existe pas.\n",
    "2.  Vérifier si l'URL de base pour la version spécifiée de Tweety (`TWEETY_VERSION`) est accessible.\n",
    "3.  Télécharger (ou vérifier la présence) du JAR **principal** `tweety-full-...-with-dependencies.jar`. Celui-ci contient le noyau de Tweety et de nombreuses dépendances courantes.\n",
    "4.  Télécharger (ou vérifier la présence) des JARs **spécifiques aux modules** utilisés dans ce notebook (argumentation, logiques spécifiques, etc.). La liste `REQUIRED_MODULES` définit les modules nécessaires.\n",
    "\n",
    "*Note : Le téléchargement peut prendre quelques minutes lors de la première exécution. Assurez-vous que tous les JARs nécessaires sont bien présents dans le dossier `libs/` avant de démarrer la JVM, car des JARs manquants causeront des erreurs d'import plus loin.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d5d7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import urllib.request\n",
    "import os\n",
    "import requests\n",
    "from tqdm.auto import tqdm # Barre de progression plus jolie dans les notebooks\n",
    "\n",
    "# --- Configuration ---\n",
    "TWEETY_VERSION = \"1.28\"\n",
    "BASE_URL = f\"https://tweetyproject.org/builds/{TWEETY_VERSION}/\"\n",
    "LIB_DIR = pathlib.Path(\"libs\")\n",
    "LIB_DIR.mkdir(exist_ok=True)\n",
    "CORE_JAR_NAME = f\"org.tweetyproject.tweety-full-{TWEETY_VERSION}-with-dependencies.jar\"\n",
    "CORE_JAR_PATH = LIB_DIR / CORE_JAR_NAME\n",
    "\n",
    "# Modules Tweety requis pour ce notebook (couvre tous les exemples prévus)\n",
    "REQUIRED_MODULES = sorted([\n",
    "    \"arg.adf\", \"arg.aba\", \"arg.bipolar\", \"arg.aspic\", \"arg.dung\", \"arg.weighted\",\n",
    "    \"arg.social\", \"arg.setaf\", \"arg.rankings\", \"arg.prob\", \"arg.extended\",\n",
    "    \"arg.delp\", \"arg.deductive\", \"arg.caf\",\n",
    "    \"beliefdynamics\", \"agents.dialogues\", \"action\",\n",
    "    \"logics.pl\", \"logics.fol\", \"logics.ml\", \"logics.dl\", \"logics.cl\",\n",
    "    \"logics.qbf\", \"logics.pcl\", \"logics.rcl\", \"logics.rpcl\", \"logics.mln\", \"logics.bpm\",\n",
    "    \"lp.asp\",\n",
    "    \"math\", \"commons\", \"agents\" # Dépendances coeur/utilitaires\n",
    "])\n",
    "\n",
    "# Vérification accessibilité URL de base\n",
    "print(f\"Vérification de l'accès à {BASE_URL}...\")\n",
    "url_accessible = False\n",
    "try:\n",
    "    response = requests.head(BASE_URL, timeout=10)\n",
    "    response.raise_for_status()\n",
    "    print(f\"✔️ URL de base Tweety v{TWEETY_VERSION} accessible.\")\n",
    "    url_accessible = True\n",
    "except requests.exceptions.RequestException as e:\n",
    "    print(f\"❌ Impossible d'accéder à l'URL de base {BASE_URL}. Vérifiez la version ou votre connexion. Erreur : {e}\")\n",
    "    print(\"   Le téléchargement des JARs manquants échouera. Seuls les JARs locaux seront utilisables.\")\n",
    "\n",
    "# Barre de progression TQDM\n",
    "class TqdmUpTo(tqdm):\n",
    "    def update_to(self, b=1, bsize=1, tsize=None):\n",
    "        if tsize is not None:\n",
    "            self.total = tsize\n",
    "        self.update(b * bsize - self.n)\n",
    "\n",
    "# Fonction de téléchargement\n",
    "def download_jar(jar_name, url_base, target_dir):\n",
    "    jar_path = target_dir / jar_name\n",
    "    url = url_base + jar_name\n",
    "    newly_downloaded = False\n",
    "\n",
    "    if not jar_path.exists():\n",
    "        if not url_accessible:\n",
    "            print(f\"   ⏭️ '{jar_name}' manquant, mais URL inaccessible. Téléchargement sauté.\")\n",
    "            return False, False\n",
    "        # print(f\"⏳ Téléchargement de {jar_name}...\") # Tqdm le fait\n",
    "        try:\n",
    "            response = requests.head(url, timeout=5)\n",
    "            response.raise_for_status()\n",
    "            with TqdmUpTo(unit='B', unit_scale=True, unit_divisor=1024, miniters=1, desc=jar_name[:40]) as t:\n",
    "                urllib.request.urlretrieve(url, filename=jar_path, reporthook=t.update_to)\n",
    "            if jar_path.exists() and jar_path.stat().st_size > 0:\n",
    "                newly_downloaded = True\n",
    "            else:\n",
    "                print(f\"\\n❓ Téléchargement de {jar_name} terminé mais fichier vide ou absent.\")\n",
    "                if jar_path.exists(): jar_path.unlink(missing_ok=True)\n",
    "        except requests.exceptions.HTTPError as e:\n",
    "            print(f\"\\n❌ {jar_name} non trouvé sur le serveur (Erreur {e.response.status_code}).\")\n",
    "            return False, False\n",
    "        except Exception as e:\n",
    "            print(f\"\\n❌ Erreur lors du téléchargement de {jar_name}: {e}\")\n",
    "            if jar_path.exists(): jar_path.unlink(missing_ok=True)\n",
    "            return False, False\n",
    "\n",
    "    return newly_downloaded, jar_path.exists()\n",
    "\n",
    "# --- Exécution du Téléchargement ---\n",
    "\n",
    "# 1. JAR Core\n",
    "print(f\"\\n--- Vérification/Téléchargement JAR Core ---\")\n",
    "core_new, core_exists = download_jar(CORE_JAR_NAME, BASE_URL, LIB_DIR)\n",
    "if core_exists:\n",
    "    status = \"téléchargé\" if core_new else \"déjà présent\"\n",
    "    print(f\"✔️ JAR Core '{CORE_JAR_NAME}' {status}.\")\n",
    "else:\n",
    "     print(f\"❌ ERREUR CRITIQUE : Le JAR core {CORE_JAR_NAME} est manquant et n'a pas pu être téléchargé.\")\n",
    "\n",
    "# 2. JARs Modules\n",
    "print(f\"\\n--- Vérification/Téléchargement des {len(REQUIRED_MODULES)} JARs de modules ---\")\n",
    "modules_downloaded_count = 0\n",
    "modules_present_count = 0\n",
    "modules_missing = []\n",
    "\n",
    "if core_exists:\n",
    "    with tqdm(REQUIRED_MODULES, desc=\"Modules\") as pbar:\n",
    "        for module in pbar:\n",
    "            pbar.set_postfix_str(module, refresh=True)\n",
    "            module_jar_name = f\"org.tweetyproject.{module}-{TWEETY_VERSION}-with-dependencies.jar\"\n",
    "            new_dl, present = download_jar(module_jar_name, BASE_URL, LIB_DIR)\n",
    "            if new_dl:\n",
    "                modules_downloaded_count += 1\n",
    "            if present:\n",
    "                modules_present_count += 1\n",
    "            else:\n",
    "                modules_missing.append(module_jar_name)\n",
    "else:\n",
    "    print(\"\\nSkipping module download because Core JAR is missing.\")\n",
    "    # Compter quand même ceux qui sont présents localement\n",
    "    modules_present_count = 0\n",
    "    for module in REQUIRED_MODULES:\n",
    "         module_jar_name = f\"org.tweetyproject.{module}-{TWEETY_VERSION}-with-dependencies.jar\"\n",
    "         if (LIB_DIR / module_jar_name).exists():\n",
    "              modules_present_count += 1\n",
    "         else:\n",
    "              modules_missing.append(module_jar_name)\n",
    "\n",
    "\n",
    "print(f\"\\n--- Résumé Téléchargement ---\")\n",
    "print(f\"  JAR Core: {'Présent' if core_exists else 'MANQUANT'}\")\n",
    "print(f\"  JARs Modules:\")\n",
    "print(f\"    - Nouveaux téléchargés : {modules_downloaded_count}\")\n",
    "print(f\"    - Total présents       : {modules_present_count} / {len(REQUIRED_MODULES)}\")\n",
    "if modules_missing:\n",
    "    print(f\"    - ⚠️ Modules MANQUANTS : {', '.join(modules_missing)}\")\n",
    "print(f\"  Chemin du dossier libs : {LIB_DIR.resolve()}\")\n",
    "\n",
    "# Vérification finale\n",
    "all_jars = list(LIB_DIR.glob(\"*.jar\"))\n",
    "min_expected_jars = 1 + len(REQUIRED_MODULES) // 2 # Heuristique : au moins le core et la moitié des modules\n",
    "if not core_exists or modules_present_count < len(REQUIRED_MODULES):\n",
    "    print(\"\\n⚠️ Des JARs Tweety semblent manquants. Vérifiez les messages d'erreur ci-dessus.\")\n",
    "    print(\"   Le démarrage de la JVM ou l'utilisation de certaines fonctionnalités échoueront probablement.\")\n",
    "else:\n",
    "    print(\"\\n✔️ Vérification des JARs Tweety terminée. Le démarrage de la JVM peut continuer.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c4b5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1.4bis Téléchargement des Fichiers de Données (.txt, .aba, etc.) ---\n",
    "print(\"\\n--- 1.4bis Téléchargement des Fichiers de Données ---\")\n",
    "\n",
    "import pathlib\n",
    "import requests\n",
    "import os\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Créer le dossier de destination s'il n'existe pas\n",
    "RESOURCE_DIR = pathlib.Path(\"resources\")\n",
    "RESOURCE_DIR.mkdir(exist_ok=True)\n",
    "print(f\"ℹ️ Les fichiers de données seront téléchargés dans: {RESOURCE_DIR.resolve()}\")\n",
    "\n",
    "# Base URL pour les fichiers bruts sur GitHub (branche main)\n",
    "GITHUB_RAW_BASE_URL = \"https://raw.githubusercontent.com/TweetyProjectTeam/TweetyProject/main/\"\n",
    "\n",
    "# Mapper les noms de fichiers aux chemins relatifs probables dans le dépôt GitHub\n",
    "# (Liste inchangée par rapport à votre version)\n",
    "FILES_TO_DOWNLOAD = {\n",
    "    # DeLP Files\n",
    "    \"birds.txt\": \"org-tweetyproject-arg-delp/src/main/resources/birds.txt\",\n",
    "    \"birds2.txt\": \"org-tweetyproject-arg-delp/src/main/resources/birds2.txt\",\n",
    "    \"nixon.txt\": \"org-tweetyproject-arg-delp/src/main/resources/nixon.txt\",\n",
    "    \"counterarg.txt\": \"org-tweetyproject-arg-delp/src/main/resources/counterarg.txt\",\n",
    "    # ABA Files\n",
    "    \"example1.aba\": \"org-tweetyproject-arg-aba/src/main/resources/example1.aba\",\n",
    "    \"example2.aba\": \"org-tweetyproject-arg-aba/src/main/resources/example2.aba\",\n",
    "    \"example5.aba\": \"org-tweetyproject-arg-aba/src/main/resources/example5.aba\",\n",
    "    \"smp_fol.aba\": \"org-tweetyproject-arg-aba/src/main/resources/smp_fol.aba\",\n",
    "    # ASPIC Files\n",
    "    \"ex1.aspic\": \"org-tweetyproject-arg-aspic/src/main/resources/ex1.aspic\",\n",
    "    \"ex5_fol.aspic\": \"org-tweetyproject-arg-aspic/src/main/resources/ex5_fol.aspic\",\n",
    "    # Autres Logiques/Args\n",
    "     \"examplebeliefbase.proplogic\": \"org-tweetyproject-logics-pl/src/main/resources/examplebeliefbase.proplogic\",\n",
    "     \"examplebeliefbase_multiple.proplogic\": \"org-tweetyproject-logics-pl/src/main/resources/examplebeliefbase_multiple.proplogic\",\n",
    "     \"examplebeliefbase_xor.proplogic\": \"org-tweetyproject-logics-pl/src/main/resources/examplebeliefbase_xor.proplogic\",\n",
    "     \"dimacs_ex4.cnf\": \"org-tweetyproject-logics-pl/src/main/resources/dimacs_ex4.cnf\",\n",
    "     \"examplebeliefbase.dlogic\": \"org-tweetyproject-logics-dl/src/main/resources/examplebeliefbase.dlogic\",\n",
    "     \"examplebeliefbase2.fologic\": \"org-tweetyproject-logics-fol/src/main/resources/examplebeliefbase2.fologic\",\n",
    "     \"examplebeliefbase.mlogic\": \"org-tweetyproject-logics-ml/src/main/resources/examplebeliefbase.mlogic\",\n",
    "     \"examplebeliefbase2.mlogic\": \"org-tweetyproject-logics-ml/src/main/resources/examplebeliefbase2.mlogic\",\n",
    "     \"tweety-example.qbf\": \"org-tweetyproject-logics-qbf/src/main/resources/tweety-example.qbf\",\n",
    "     \"qdimacs-example1.qdimacs\": \"org-tweetyproject-logics-qbf/src/main/resources/qdimacs-example1.qdimacs\",\n",
    "     \"qcir-example1.qcir\": \"org-tweetyproject-logics-qbf/src/main/resources/qcir-example1.qcir\",\n",
    "     \"qcir-example2-sat.qcir\": \"org-tweetyproject-logics-qbf/src/main/resources/qcir-example2-sat.qcir\",\n",
    "     # BPMN - Gardons celui de votre TP comme exemple\n",
    "     \"problematic_hit.bpmn\": \"org-tweetyproject-logics-bpm/src/main/resources/problematic_hit.bpmn\",\n",
    "     \"monkey.desc\": \"org-tweetyproject-action/src/main/resources/monkey.desc\",\n",
    "     \"conditioner.desc\": \"org-tweetyproject-action/src/main/resources/conditioner.desc\",\n",
    "     \"adf_example.txt\": \"org-tweetyproject-arg-adf/src/main/resources/adf_example.txt\",\n",
    "     \"ex1.apx\": \"org-tweetyproject-arg-setaf/src/main/resources/ex1.apx\",\n",
    "     \"ex1_bonzon.apx\": \"org-tweetyproject-arg-rankings/src/main/resources/ex1_bonzon.apx\",\n",
    "     \"ex1.tgf\": \"org-tweetyproject-arg-dung/src/main/resources/ex1.tgf\",\n",
    "}\n",
    "\n",
    "# Barre de progression TQDM (inchangée)\n",
    "class TqdmUpTo(tqdm):\n",
    "    def update_to(self, b=1, bsize=1, tsize=None):\n",
    "        if tsize is not None: self.total = tsize\n",
    "        self.update(b * bsize - self.n)\n",
    "\n",
    "# Boucle de téléchargement\n",
    "downloaded_count = 0\n",
    "present_count = 0\n",
    "failed_count = 0\n",
    "skipped_count = 0\n",
    "\n",
    "print(f\"\\nVérification/Téléchargement de {len(FILES_TO_DOWNLOAD)} fichiers de données...\")\n",
    "\n",
    "# Vérification de l'accessibilité GitHub avec GET et User-Agent\n",
    "github_accessible = False\n",
    "# Header User-Agent standard\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'}\n",
    "try:\n",
    "    # Utiliser GET pour vérifier la base (parfois HEAD est bloqué)\n",
    "    response_gh = requests.get(GITHUB_RAW_BASE_URL, timeout=10, headers=headers, stream=True)\n",
    "    github_accessible = response_gh.ok\n",
    "    response_gh.close() # Important si stream=True\n",
    "    if not github_accessible:\n",
    "        print(f\"⚠️ Impossible d'accéder à la base GitHub {GITHUB_RAW_BASE_URL}. Code: {response_gh.status_code}\")\n",
    "    else:\n",
    "        print(\"✔️ Accès à la base GitHub Raw confirmé.\")\n",
    "except requests.exceptions.RequestException as e_gh:\n",
    "    print(f\"⚠️ Erreur de connexion à GitHub: {e_gh}\")\n",
    "\n",
    "if not github_accessible:\n",
    "    print(\"   Skipping all file downloads from GitHub.\")\n",
    "    skipped_count = len(FILES_TO_DOWNLOAD)\n",
    "    # Compter ceux déjà présents localement\n",
    "    for filename in FILES_TO_DOWNLOAD:\n",
    "        if (RESOURCE_DIR / filename).exists():\n",
    "             present_count += 1\n",
    "else:\n",
    "    with tqdm(FILES_TO_DOWNLOAD.items(), desc=\"Fichiers Données\") as pbar:\n",
    "        for filename, relative_path in pbar:\n",
    "            pbar.set_postfix_str(filename, refresh=True)\n",
    "            target_path = RESOURCE_DIR / filename\n",
    "            file_url = GITHUB_RAW_BASE_URL + relative_path\n",
    "\n",
    "            if target_path.exists() and target_path.stat().st_size > 0:\n",
    "                present_count += 1\n",
    "                continue # Skip download if already present and not empty\n",
    "\n",
    "            try:\n",
    "                # Utiliser GET avec header pour le téléchargement aussi\n",
    "                response = requests.get(file_url, stream=True, timeout=15, headers=headers) # Timeout augmenté\n",
    "                # Vérifier explicitement 404\n",
    "                if response.status_code == 404:\n",
    "                    print(f\"\\n   ⚠️ Fichier '{filename}' non trouvé sur GitHub (404) à l'URL: {file_url}\")\n",
    "                    failed_count += 1\n",
    "                    continue\n",
    "                response.raise_for_status() # Lève une exception pour les autres erreurs HTTP\n",
    "\n",
    "                total_size = int(response.headers.get('content-length', 0))\n",
    "                with TqdmUpTo(unit='B', unit_scale=True, unit_divisor=1024, total=total_size, desc=filename, leave=False) as t:\n",
    "                    with open(target_path, 'wb') as f:\n",
    "                        for chunk in response.iter_content(chunk_size=8192):\n",
    "                            if chunk:\n",
    "                                f.write(chunk)\n",
    "                                t.update(len(chunk))\n",
    "\n",
    "                if target_path.exists() and target_path.stat().st_size > 0:\n",
    "                    downloaded_count += 1\n",
    "                    present_count += 1\n",
    "                else:\n",
    "                    print(f\"\\n   ❓ Téléchargement de '{filename}' terminé mais fichier vide/absent.\")\n",
    "                    if target_path.exists(): target_path.unlink(missing_ok=True)\n",
    "                    failed_count += 1\n",
    "\n",
    "            except requests.exceptions.RequestException as e:\n",
    "                print(f\"\\n   ❌ Échec téléchargement '{filename}' : {e}\")\n",
    "                if target_path.exists(): target_path.unlink(missing_ok=True)\n",
    "                failed_count += 1\n",
    "            except Exception as e_other:\n",
    "                 print(f\"\\n   ❌ Erreur inattendue pour '{filename}': {e_other}\")\n",
    "                 if target_path.exists(): target_path.unlink(missing_ok=True)\n",
    "                 failed_count += 1\n",
    "\n",
    "\n",
    "# Résumé\n",
    "print(f\"\\n--- Résumé Téléchargement Données ---\")\n",
    "print(f\"   Dossier cible          : {RESOURCE_DIR.resolve()}\")\n",
    "print(f\"   Fichiers téléchargés  : {downloaded_count}\")\n",
    "print(f\"   Fichiers déjà présents : {present_count - downloaded_count}\")\n",
    "if skipped_count > 0: print(f\"   Fichiers sautés (connexion échouée): {skipped_count}\")\n",
    "print(f\"   Total fichiers OK      : {present_count} / {len(FILES_TO_DOWNLOAD)}\")\n",
    "if failed_count > 0:\n",
    "     print(f\"   ⚠️ Échecs (Non trouvés sur GitHub ou autre erreur): {failed_count}\")\n",
    "     print(\"      Les sections utilisant ces fichiers pourraient échouer.\")\n",
    "elif skipped_count == 0 and present_count == len(FILES_TO_DOWNLOAD):\n",
    "     print(\"✔️ Tous les fichiers de données nécessaires semblent présents.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f889fe79",
   "metadata": {},
   "source": [
    "### 1.5 Configuration des Outils Externes (Optionnel)\n",
    "<a id=\"1.5\"></a>\n",
    "\n",
    "Certaines fonctionnalités avancées de Tweety s'appuient sur des outils externes (solveurs SAT/MaxSAT, prouveurs FOL/ML, énumérateurs MUS, solveurs ASP). Pour utiliser ces fonctionnalités, vous devez :\n",
    "\n",
    "1.  **Installer l'outil externe** séparément en suivant les instructions de son site web.\n",
    "2.  **Indiquer le chemin d'accès** à l'exécutable de l'outil dans la cellule de code ci-dessous.\n",
    "\n",
    "**Outils potentiellement utilisés dans ce notebook :**\n",
    "\n",
    "*   **Solveurs SAT externes** (pour `logics.pl.sat.CmdLineSatSolver` - Section 2.1.3) :\n",
    "    *   Lingeling, CaDiCaL, Kissat, MiniSat, Glucose, etc. (prennent souvent le format DIMACS)\n",
    "*   **Prouveur FOL** (pour `logics.fol.reasoner.EFOLReasoner` - Section 2.2.2) :\n",
    "    *   **EProver** : Téléchargement et compilation peuvent être complexes. ([Site Eprover](https://eprover.org/))\n",
    "    *   *Alternative* : Tweety peut aussi utiliser SPASS pour certains fragments FOL, configuré ci-dessous.\n",
    "*   **Prouveur ML** (pour `logics.ml.reasoner.SPASSMlReasoner` - Section 2.4.2) :\n",
    "    *   **SPASS** : ([Site SPASS](https://www.spass-prover.org/)) - Binaires souvent disponibles.\n",
    "*   **Énumérateur MUS** (pour `logics.pl.sat.MarcoMusEnumerator` - Section 3.3) :\n",
    "    *   **MARCO** : Script Python. ([Lien potentiel via recherche](https://github.com/marcomus/marco))\n",
    "*   **Solveur MaxSAT** (pour `logics.pl.sat.OpenWboSolver` - Section 3.4) :\n",
    "    *   **Open-WBO** : ([Site Open-WBO](https://github.com/sat-group/open-wbo))\n",
    "*   **Solveur ASP** (pour `lp.asp.reasoner.ClingoSolver` - Section 4.6) :\n",
    "    *   **Clingo** (partie de Potassco) : ([Site Potassco](https://potassco.org/))\n",
    "*   **Solveurs ADF** (pour `arg.adf.sat.solver.*` - Section 5.1) :\n",
    "    *   PicoSAT, Lingeling, MiniSat (fournis avec Tweety pour certaines plateformes, voir `libs/`)\n",
    "\n",
    "**Instructions :**\n",
    "*   Modifiez les variables `*_PATH` dans la cellule suivante avec les chemins corrects sur **votre** système.\n",
    "*   Si un outil n'est pas installé ou si vous ne souhaitez pas l'utiliser, laissez le chemin vide (`\"\"`) ou commentez la ligne correspondante. Le notebook essaiera d'utiliser des alternatives internes (plus lentes) ou sautera les sections concernées.\n",
    "*   Sous Windows, n'oubliez pas l'extension `.exe` et utilisez des anti-slashs (`\\\\`) ou des slashs (`/`) pour les chemins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ee4eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Cellule 10 : Configuration Outils Externes (Révisée pour Clingo auto-détection) ---\n",
    "import os\n",
    "import pathlib\n",
    "import platform\n",
    "import shutil # Importé pour shutil.which\n",
    "\n",
    "# Dictionnaire pour stocker les chemins des outils externes\n",
    "EXTERNAL_TOOLS = {\n",
    "    \"SAT_SOLVER\": \"\",\n",
    "    # Mettez à jour EPROVER si nécessaire\n",
    "    \"EPROVER\": r\".\\ext_tools\\EProver\\eprover.exe\",\n",
    "    \"MARCO\": \"\",\n",
    "    \"OPEN_WBO\": \"\",\n",
    "    # Clingo: On essaie de le détecter automatiquement ci-dessous\n",
    "    \"CLINGO\": \"\", # Garde la valeur précédente (peut-être \"clingo\")\n",
    "    # SPASS: Garde la valeur précédente (configurée manuellement ou par Cellule 11)\n",
    "    \"SPASS\": \"C:\\Program Files (x86)\\SPASS\\SPASS 3.7\\SPASS.exe\"\n",
    "}\n",
    "\n",
    "# --- Tentative de détection automatique de Clingo ---\n",
    "print(\"\\n--- Détection automatique de Clingo ---\")\n",
    "clingo_executable_name = \"clingo.exe\" if platform.system() == \"Windows\" else \"clingo\"\n",
    "clingo_path_found = shutil.which(clingo_executable_name)\n",
    "\n",
    "if clingo_path_found:\n",
    "    print(f\"✔️ Clingo trouvé dans le PATH : {clingo_path_found}\")\n",
    "    # Mettre à jour le dictionnaire si trouvé et différent de la valeur existante (ou si vide)\n",
    "    if not EXTERNAL_TOOLS.get(\"CLINGO\") or EXTERNAL_TOOLS.get(\"CLINGO\") != clingo_path_found:\n",
    "         EXTERNAL_TOOLS[\"CLINGO\"] = clingo_path_found\n",
    "         print(f\"   Mise à jour de EXTERNAL_TOOLS['CLINGO'] à '{clingo_path_found}'\")\n",
    "elif EXTERNAL_TOOLS.get(\"CLINGO\"):\n",
    "     print(f\"ℹ️ Clingo non trouvé dans le PATH système via shutil.which. Utilisation de la valeur configurée : '{EXTERNAL_TOOLS['CLINGO']}' (peut échouer si invalide).\")\n",
    "else:\n",
    "    print(f\"ℹ️ Clingo non trouvé dans le PATH système via shutil.which et non configuré manuellement.\")\n",
    "    print(f\"   Pour utiliser ASP (Cellule 54), installez Clingo et configurez EXTERNAL_TOOLS['CLINGO'] manuellement si besoin.\")\n",
    "\n",
    "\n",
    "print(\"\\n--- Configuration des Chemins des Outils Externes (Après détection Clingo) ---\")\n",
    "# ... (Le reste de la cellule 10 : Affichage initial, fonction get_tool_path, Vérification Finale) ...\n",
    "\n",
    "# --- Fonction get_tool_path (Ajustée pour Clingo) ---\n",
    "def get_tool_path(tool_name):\n",
    "    path_str = EXTERNAL_TOOLS.get(tool_name, \"\")\n",
    "    if not path_str: return None\n",
    "\n",
    "    # Si c'est juste le nom (comme \"clingo\" après détection auto), shutil.which a déjà validé.\n",
    "    # Si c'est un chemin complet, on vérifie.\n",
    "    if path_str == \"clingo\" or path_str == \"clingo.exe\":\n",
    "         # Vérifier à nouveau au cas où il aurait été retiré du PATH depuis la détection\n",
    "         if shutil.which(path_str):\n",
    "             return path_str # Retourner le nom, Java l'appellera via le shell\n",
    "         else:\n",
    "             return None # N'est plus dans le PATH\n",
    "\n",
    "    path_obj = pathlib.Path(path_str)\n",
    "    # ... (vérifications pour OpenWBO, fichiers exécutables comme avant) ...\n",
    "    if tool_name == \"OPEN_WBO\" and path_obj.is_dir():\n",
    "        executables = [\"open-wbo\", \"open-wbo.exe\", \"open-wbo_release\", \"open-wbo_static\"]\n",
    "        if any((path_obj / e).exists() for e in executables):\n",
    "            return str(path_obj.resolve())\n",
    "        else: return None\n",
    "\n",
    "    is_executable = False\n",
    "    if path_obj.is_file():\n",
    "        if os.name == 'nt': is_executable = True\n",
    "        else: is_executable = os.access(path_obj, os.X_OK)\n",
    "\n",
    "    if is_executable:\n",
    "        return str(path_obj.resolve())\n",
    "    else: return None\n",
    "\n",
    "# --- Vérification Finale Après Configuration ---\n",
    "print(\"\\n--- Vérification Finale des Chemins (Après mise à jour) ---\")\n",
    "for tool, path_str_config in EXTERNAL_TOOLS.items():\n",
    "    valid_path = get_tool_path(tool) # Utilise la fonction qui vérifie\n",
    "    if valid_path:\n",
    "        if valid_path == path_str_config and not pathlib.Path(valid_path).is_file() and tool == \"CLINGO\":\n",
    "             print(f\"✔️ {tool:<10}: Trouvé dans PATH système ('{valid_path}')\")\n",
    "        else:\n",
    "             print(f\"✔️ {tool:<10}: Chemin valide trouvé/configuré à '{valid_path}'\")\n",
    "    else:\n",
    "        # ... (messages d'erreur/info comme avant) ...\n",
    "        if tool == \"SPASS\" and platform.system() == \"Windows\":\n",
    "             print(f\"ℹ️ {tool:<10}: Non configuré ou chemin invalide ('{path_str_config}'). Requiert install manuelle Win.\")\n",
    "        elif tool == \"CLINGO\":\n",
    "             print(f\"ℹ️ {tool:<10}: Non configuré ou chemin invalide ('{path_str_config}'). Installez ou vérifiez PATH.\")\n",
    "        else:\n",
    "             print(f\"ℹ️ {tool:<10}: Non configuré ou chemin invalide ('{path_str_config}').\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b982fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Cellule 10 (Code - Auto-Download Tools) : Modifiée ---\n",
    "import os\n",
    "import platform\n",
    "import pathlib\n",
    "import requests\n",
    "import urllib.request\n",
    "import zipfile\n",
    "import tarfile\n",
    "import shutil\n",
    "from tqdm.auto import tqdm\n",
    "import stat # Pour chmod\n",
    "\n",
    "# Reprise de la classe TqdmUpTo (inchangée)\n",
    "class TqdmUpTo(tqdm):\n",
    "    def update_to(self, b=1, bsize=1, tsize=None):\n",
    "        if tsize is not None: self.total = tsize\n",
    "        self.update(b * bsize - self.n)\n",
    "\n",
    "# Répertoires (inchangés)\n",
    "if 'LIB_DIR' not in globals(): LIB_DIR = pathlib.Path(\"libs\")\n",
    "EXT_TOOLS_DIR = pathlib.Path(\"ext_tools\")\n",
    "EXT_TOOLS_DIR.mkdir(exist_ok=True)\n",
    "NATIVE_LIBS_DIR = LIB_DIR / \"native\"\n",
    "NATIVE_LIBS_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "print(f\"\\n--- Téléchargement/Vérification Automatique des Outils Externes ---\")\n",
    "print(f\"INFO: Outils externes dans '{EXT_TOOLS_DIR.resolve()}'\")\n",
    "print(f\"INFO: Binaires natifs Tweety dans '{NATIVE_LIBS_DIR.resolve()}'\")\n",
    "\n",
    "# --- 1. SPASS ---\n",
    "print(\"\\n1. Vérification/Téléchargement SPASS...\")\n",
    "system = platform.system()\n",
    "spass_path_found = None # Sera mis à jour si trouvé/extrait (Linux)\n",
    "\n",
    "# ** Modification : Plus de téléchargement auto pour Windows **\n",
    "if system == \"Windows\":\n",
    "     print(\"  ℹ️ Pour Windows: Installation manuelle de SPASS requise.\")\n",
    "     print(\"      Veuillez télécharger depuis https://www.spass-prover.org/, installer,\")\n",
    "     print(f\"      puis configurer le chemin vers SPASS.exe dans EXTERNAL_TOOLS['SPASS'] (Cellule 9).\")\n",
    "     # On vérifie quand même si l'utilisateur l'a configuré manuellement\n",
    "     spass_path_config = EXTERNAL_TOOLS.get(\"SPASS\", \"\")\n",
    "     if spass_path_config and get_tool_path('SPASS'): # Utilise la fonction de vérif\n",
    "          print(f\"  ✔️ Chemin SPASS configuré manuellement trouvé et valide: {spass_path_config}\")\n",
    "          spass_path_found = spass_path_config # Conserver le chemin valide\n",
    "     else:\n",
    "          print(f\"  ⚠️ Chemin SPASS non configuré ou invalide dans EXTERNAL_TOOLS.\")\n",
    "\n",
    "# ** Conservation du téléchargement/extraction pour Linux **\n",
    "elif system == \"Linux\":\n",
    "    spass_dir = EXT_TOOLS_DIR / \"spass\"\n",
    "    spass_dir.mkdir(exist_ok=True)\n",
    "    spass_urls_linux = (\n",
    "        \"https://www.spass-prover.org/download/binaries/spass35pclinux64.tgz\" if platform.architecture()[0] == '64bit' else \"https://www.spass-prover.org/download/binaries/spass35pclinux32.tgz\",\n",
    "        \"tgz\",\n",
    "        \"SPASS\"\n",
    "    )\n",
    "    url, archive_type, exec_filename = spass_urls_linux\n",
    "    target_exec_path = spass_dir / exec_filename\n",
    "    archive_filename = pathlib.Path(url).name\n",
    "    archive_path = spass_dir / archive_filename\n",
    "\n",
    "    spass_already_ok = False\n",
    "    if target_exec_path.is_file() and os.access(target_exec_path, os.X_OK):\n",
    "        spass_already_ok = True\n",
    "        spass_path_found = str(target_exec_path.resolve())\n",
    "        print(f\"  ✔️ SPASS ({exec_filename}) semble déjà présent et exécutable (Linux).\")\n",
    "\n",
    "    if not spass_already_ok:\n",
    "        if not archive_path.exists():\n",
    "            print(f\"  Téléchargement de {archive_filename} (Linux)...\")\n",
    "            try:\n",
    "                # Assurer que url_accessible est défini (normalement par Cellule 7)\n",
    "                if 'url_accessible' not in globals(): url_accessible = True # Optimiste\n",
    "                if not url_accessible:\n",
    "                     print(\"  ⏭️ URL de base Tweety inaccessible, téléchargement SPASS sauté.\")\n",
    "                else:\n",
    "                    # (Code de téléchargement avec Tqdm... comme avant)\n",
    "                    response = requests.head(url, timeout=10); response.raise_for_status()\n",
    "                    with TqdmUpTo(unit='B', unit_scale=True, unit_divisor=1024, miniters=1, desc=\"SPASS Archive (Linux)\") as t:\n",
    "                         urllib.request.urlretrieve(url, filename=archive_path, reporthook=t.update_to)\n",
    "                    print(f\"\\\\n  ✔️ {archive_filename} téléchargé.\")\n",
    "            except Exception as e:\n",
    "                print(f\"\\\\n  ❌ Échec du téléchargement de l'archive SPASS (Linux): {e}\")\n",
    "                if archive_path.exists(): archive_path.unlink(missing_ok=True)\n",
    "\n",
    "        if archive_path.exists():\n",
    "            print(f\"  Extraction de {archive_filename} (Linux)...\")\n",
    "            try:\n",
    "                with tarfile.open(archive_path, \"r:gz\") as tar:\n",
    "                    tar.extractall(path=spass_dir)\n",
    "                extracted_exec_path = spass_dir / \"SPASS\" / \"SPASS\" # Chemin attendu dans l'archive\n",
    "                if extracted_exec_path.exists():\n",
    "                    shutil.move(str(extracted_exec_path), str(target_exec_path)) # Déplacer vers spass/SPASS\n",
    "                    shutil.rmtree(spass_dir / \"SPASS\") # Nettoyer dossier vide\n",
    "                    spass_path_found = str(target_exec_path.resolve())\n",
    "                    print(f\"  ✔️ SPASS extrait et déplacé à '{spass_path_found}'\")\n",
    "                    os.chmod(spass_path_found, stat.S_IRWXU | stat.S_IRGRP | stat.S_IXGRP | stat.S_IROTH | stat.S_IXOTH) # chmod 755\n",
    "                    print(\"      (Permissions d'exécution ajoutées)\")\n",
    "                else: print(f\"  ❌ Exécutable SPASS non trouvé après extraction.\")\n",
    "                archive_path.unlink(missing_ok=True)\n",
    "            except Exception as e: print(f\"  ❌ Échec de l'extraction de SPASS: {e}\")\n",
    "\n",
    "    if spass_path_found:\n",
    "        EXTERNAL_TOOLS[\"SPASS\"] = spass_path_found # Mettre à jour le dictionnaire global\n",
    "    else:\n",
    "         print(f\"  ❌ SPASS n'a pas pu être configuré automatiquement pour Linux.\")\n",
    "\n",
    "elif system == \"Darwin\":\n",
    "     print(\"  ℹ️ Téléchargement auto SPASS pour Mac (.dmg) non supporté. Installation manuelle requise.\")\n",
    "else:\n",
    "    print(f\"  Système d'exploitation '{system}' non géré pour SPASS.\")\n",
    "\n",
    "\n",
    "# --- 2. Binaires Natifs Tweety (ADF/SAT) ---\n",
    "# (Code inchangé par rapport à la version précédente)\n",
    "print(\"\\n2. Téléchargement/Vérification des binaires natifs Tweety...\")\n",
    "# ... (le reste du code pour les binaires natifs reste identique) ...\n",
    "native_binaries_repo_path = \"https://github.com/TweetyProjectTeam/TweetyProject/raw/main/org-tweetyproject-arg-adf/src/main/resources/\"\n",
    "native_binaries = {\n",
    "    \"Windows\": [\"picosat.dll\", \"lingeling.dll\", \"minisat.dll\"],\n",
    "    \"Linux\":   [\"picosat.so\", \"lingeling.so\", \"minisat.so\"],\n",
    "    \"Darwin\":  [\"picosat.dylib\", \"lingeling.dylib\", \"minisat.dylib\"]\n",
    "}.get(system, [])\n",
    "downloaded_native_count = 0\n",
    "native_files_present = []\n",
    "if native_binaries:\n",
    "     with tqdm(native_binaries, desc=\"Binaires Natifs\") as pbar_native:\n",
    "          # (boucle de téléchargement identique...)\n",
    "          for name in pbar_native:\n",
    "              pbar_native.set_postfix_str(name, refresh=True)\n",
    "              target_path = NATIVE_LIBS_DIR / name\n",
    "              if not target_path.exists():\n",
    "                  if 'url_accessible' not in globals() or not url_accessible: continue\n",
    "                  url = native_binaries_repo_path + name\n",
    "                  try:\n",
    "                      response = requests.get(url, stream=True, timeout=10); response.raise_for_status()\n",
    "                      total_size = int(response.headers.get('content-length', 0))\n",
    "                      with TqdmUpTo(unit='B', unit_scale=True, unit_divisor=1024, total=total_size, desc=name, leave=False) as t:\n",
    "                          with open(target_path, 'wb') as f:\n",
    "                              for chunk in response.iter_content(chunk_size=8192):\n",
    "                                  if chunk: f.write(chunk); t.update(len(chunk))\n",
    "                      if target_path.exists() and target_path.stat().st_size > 0:\n",
    "                          downloaded_native_count += 1; native_files_present.append(name)\n",
    "                      else:\n",
    "                          if target_path.exists(): target_path.unlink(missing_ok=True)\n",
    "                  except Exception as e:\n",
    "                      if target_path.exists(): target_path.unlink(missing_ok=True)\n",
    "              else: native_files_present.append(name)\n",
    "else: print(f\"  ℹ️ Aucun binaire natif connu pour '{system}'.\")\n",
    "# ... (Résumé et note sur java.library.path identiques) ...\n",
    "total_native_expected = len(native_binaries) if native_binaries else 0\n",
    "print(f\"\\n  Résumé Natifs: {downloaded_native_count} téléchargés, {len(native_files_present)}/{total_native_expected} présents dans '{NATIVE_LIBS_DIR.resolve()}'.\")\n",
    "if len(native_files_present) < total_native_expected:\n",
    "    missing = set(native_binaries) - set(native_files_present)\n",
    "    print(f\"  ⚠️ Natifs manquants: {', '.join(missing)}\")\n",
    "print(\"\\n  Note importante sur les binaires natifs (.dll/.so/.dylib) :\")\n",
    "print(\"    - ... (texte identique) ...\")\n",
    "print(f\"      spécifique, typiquement : -Djava.library.path=\\\\\\\"{NATIVE_LIBS_DIR.resolve()}\\\\\\\"\")\n",
    "print(\"    - ... (texte identique) ...\")\n",
    "\n",
    "\n",
    "# --- Vérification Finale des Chemins Configurés ---\n",
    "print(\"\\n--- Vérification Finale des Chemins Outils Externes ---\")\n",
    "print(\"    (Basé sur EXTERNAL_TOOLS après tentatives auto)\")\n",
    "for tool, path_str_config in EXTERNAL_TOOLS.items():\n",
    "    valid_path = get_tool_path(tool) # Utilise la fonction qui vérifie existence/type/exec\n",
    "    if valid_path:\n",
    "        print(f\"✔️ {tool:<10}: Chemin valide trouvé/configuré à '{valid_path}'\")\n",
    "    else:\n",
    "        # Si SPASS n'est pas valide, rappeler l'install manuelle sous Windows\n",
    "        if tool == \"SPASS\" and platform.system() == \"Windows\":\n",
    "             print(f\"ℹ️ {tool:<10}: Non configuré ou chemin invalide ('{path_str_config}'). Requiert installation manuelle sous Windows.\")\n",
    "        else:\n",
    "             print(f\"ℹ️ {tool:<10}: Non configuré ou chemin invalide ('{path_str_config}').\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be324f0",
   "metadata": {},
   "source": [
    "### 1.6 Démarrage de la JVM via JPype\n",
    "<a id=\"1.6\"></a>\n",
    "\n",
    "JPype permet à Python d'interagir directement avec le code Java. Nous devons démarrer une Machine Virtuelle Java (JVM) et lui indiquer où trouver les fichiers JAR de Tweety que nous venons de télécharger.\n",
    "\n",
    "* Le code tente de trouver votre `JAVA_HOME`. Modifiez `java_home_path` si nécessaire dans la cellule suivante.\n",
    "* Il construit le `classpath` Java en listant tous les `.jar` dans le dossier `libs/`.\n",
    "* `jpype.startJVM()` lance la JVM. Si elle est déjà lancée (ex: après redémarrage du noyau), l'appel est ignoré.\n",
    "* **Crucial**: `jpype.imports.registerDomain(...)` doit être appelé **après** le démarrage de la JVM pour permettre les imports courts (ex: `from org.tweetyproject...`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e4087f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1.6 Démarrage de la JVM via JPype ---\n",
    "print(\"\\n--- 1.6 Démarrage de la JVM via JPype ---\")\n",
    "\n",
    "# -------- RAPPEL IMPORTANT --------\n",
    "print(\"\\n‼️‼️‼️‼️‼️‼️‼️‼️‼️‼️‼️‼️‼️‼️‼️‼️‼️‼️‼️‼️‼️‼️‼️‼️‼️‼️‼️‼️‼️‼️‼️‼️‼️‼️\")\n",
    "print(\"‼️ SI DES JARs ONT ÉTÉ TÉLÉCHARGÉS (Cellule 7), REDÉMARREZ LE NOYAU MAINTENANT ‼️\")\n",
    "print(\"‼️ Kernel -> Restart Kernel...                                         ‼️\")\n",
    "print(\"‼️‼️‼️‼️‼️‼️‼️‼️‼️‼️‼️‼️‼️‼️‼️‼️‼️‼️‼️‼️‼️‼️‼️‼️‼️‼️‼️‼️‼️‼️‼️‼️‼️‼️\")\n",
    "# Mettre une pause pour laisser le temps de lire ? Non, l'utilisateur doit le faire.\n",
    "\n",
    "import jpype\n",
    "import jpype.imports\n",
    "import os\n",
    "import pathlib\n",
    "import platform\n",
    "from jpype.types import * # Nécessaire pour JString etc. plus tard\n",
    "import stat\n",
    "\n",
    "# --- Configuration JAVA_HOME ---\n",
    "# (Fonction find_java_home() inchangée)\n",
    "def find_java_home():\n",
    "    java_home_env = os.getenv(\"JAVA_HOME\")\n",
    "    if java_home_env and pathlib.Path(java_home_env).is_dir():\n",
    "        exe_suffix = \".exe\" if platform.system() == \"Windows\" else \"\"\n",
    "        if (pathlib.Path(java_home_env) / \"bin\" / f\"java{exe_suffix}\").exists():\n",
    "            print(f\"ℹ️ Utilisation de JAVA_HOME trouvé dans l'environnement : {java_home_env}\")\n",
    "            return java_home_env\n",
    "        else:\n",
    "            print(f\"⚠️ JAVA_HOME ('{java_home_env}') trouvé mais ne semble pas être un JDK valide (bin/java manquant).\")\n",
    "\n",
    "    print(\"ℹ️ JAVA_HOME non défini ou invalide. Tentative de détection automatique...\")\n",
    "    # Logique de détection simplifiée (adapter si besoin pour Linux/Mac)\n",
    "    possible_locations = []\n",
    "    if platform.system() == \"Windows\":\n",
    "        java_dir = pathlib.Path(\"C:/Program Files/Java/\")\n",
    "        if java_dir.is_dir(): possible_locations = sorted(java_dir.glob(\"jdk-*/\"), reverse=True)\n",
    "        program_files_x86 = os.environ.get(\"ProgramFiles(x86)\")\n",
    "        if program_files_x86:\n",
    "             java_dir_x86 = pathlib.Path(program_files_x86) / \"Java\"\n",
    "             if java_dir_x86.is_dir(): possible_locations.extend(sorted(java_dir_x86.glob(\"jdk-*/\"), reverse=True))\n",
    "    elif platform.system() == \"Linux\":\n",
    "         # Ajouter des chemins communs pour Linux\n",
    "         linux_paths = [\"/usr/lib/jvm\"]\n",
    "         for p_str in linux_paths:\n",
    "             p_obj = pathlib.Path(p_str)\n",
    "             if p_obj.is_dir():\n",
    "                 possible_locations.extend(sorted(p_obj.glob(\"java-*\"), reverse=True)) # Format typique Ubuntu/Debian\n",
    "                 possible_locations.extend(sorted(p_obj.glob(\"jdk*\"), reverse=True))   # Format Oracle/Autre\n",
    "    elif platform.system() == \"Darwin\": # macOS\n",
    "        # Chemin typique pour les JDKs sur macOS\n",
    "        mac_path = pathlib.Path(\"/Library/Java/JavaVirtualMachines\")\n",
    "        if mac_path.is_dir():\n",
    "            possible_locations.extend(sorted(mac_path.glob(\"jdk*.jdk\"), reverse=True))\n",
    "\n",
    "\n",
    "    exe_suffix = \".exe\" if platform.system() == \"Windows\" else \"\"\n",
    "    for p in possible_locations:\n",
    "        # Pour macOS, le chemin est <jdk_name>.jdk/Contents/Home\n",
    "        java_bin_dir = p / \"Contents/Home/bin\" if platform.system() == \"Darwin\" else p / \"bin\"\n",
    "        if java_bin_dir.is_dir() and (java_bin_dir / f\"java{exe_suffix}\").exists():\n",
    "             detected_home = p / \"Contents/Home\" if platform.system() == \"Darwin\" else p\n",
    "             print(f\"✔️ JDK valide détecté : {detected_home}\")\n",
    "             if not java_home_env: # Seulement si non défini par l'utilisateur\n",
    "                 print(f\"   (Tentative de définition de JAVA_HOME pour ce script : {detected_home})\")\n",
    "                 os.environ['JAVA_HOME'] = str(detected_home)\n",
    "             return str(detected_home)\n",
    "\n",
    "    print(\"❌ ERREUR: JAVA_HOME n'est pas défini et aucun JDK n'a pu être détecté automatiquement.\")\n",
    "    print(\"           ==> Veuillez définir JAVA_HOME dans vos variables d'environnement système <== \")\n",
    "    print(\"           ==> et redémarrer votre environnement Jupyter/Python.                 <==\")\n",
    "    return None\n",
    "\n",
    "java_home_path = find_java_home()\n",
    "\n",
    "# --- Construction Classpath ---\n",
    "classpath_separator = os.pathsep\n",
    "if 'LIB_DIR' not in globals(): LIB_DIR = pathlib.Path(\"libs\")\n",
    "jar_list = [str(p.resolve()) for p in LIB_DIR.glob(\"*.jar\")]\n",
    "classpath = \"\"\n",
    "beliefdynamics_jar_found_in_glob = False\n",
    "num_jars_found = len(jar_list)\n",
    "\n",
    "if not jar_list:\n",
    "    print(\"❌ ERREUR: Le dossier 'libs/' ne contient aucun fichier JAR. Le classpath est vide.\")\n",
    "else:\n",
    "    classpath = classpath_separator.join(jar_list)\n",
    "    print(f\"\\nClasspath ({num_jars_found} JARs trouvé(s)) assemblé.\")\n",
    "    print(\"\\n--- DEBUG CLASSPATH ---\")\n",
    "    # print(classpath) # Décommenter pour voir le classpath complet si nécessaire\n",
    "    print(f\"Longueur totale: {len(classpath)} caractères\")\n",
    "    beliefdynamics_jar_name = \"org.tweetyproject.beliefdynamics\"\n",
    "    beliefdynamics_jar_full_path = None\n",
    "    for jar_path in jar_list:\n",
    "        if beliefdynamics_jar_name in jar_path:\n",
    "             beliefdynamics_jar_found_in_glob = True\n",
    "             beliefdynamics_jar_full_path = jar_path\n",
    "             print(f\"✔️ JAR '{beliefdynamics_jar_name}' TROUVÉ dans la liste: ...{jar_path[-80:]}\") # Afficher plus\n",
    "             break\n",
    "    if not beliefdynamics_jar_found_in_glob:\n",
    "        print(f\"⚠️⚠️⚠️ ATTENTION: Le JAR '{beliefdynamics_jar_name}' n'a PAS été trouvé par glob('*.jar') ! ⚠️⚠️⚠️\")\n",
    "    print(\"--- FIN DEBUG CLASSPATH ---\\n\")\n",
    "\n",
    "\n",
    "# --- Démarrage JVM ---\n",
    "# (Logique de démarrage inchangée, utilise 'classpath')\n",
    "jvm_started_in_this_cell = False\n",
    "if not jpype.isJVMStarted():\n",
    "    if not java_home_path:\n",
    "        print(\"❌ Impossible de démarrer la JVM sans JAVA_HOME valide.\")\n",
    "    # **Modification : Vérifier num_jars_found et beliefdynamics_jar_found_in_glob**\n",
    "    elif num_jars_found == 0 or not beliefdynamics_jar_found_in_glob:\n",
    "        print(f\"❌ Impossible de démarrer la JVM: classpath vide ({num_jars_found} JARs) ou JAR beliefdynamics non trouvé par glob.\")\n",
    "    else:\n",
    "        try:\n",
    "            print(\"\\n⏳ Démarrage de la JVM...\")\n",
    "            # Construire les arguments JVM\n",
    "            jvm_args = [\n",
    "                \"-ea\", # Enable assertions\n",
    "                f\"-Djava.class.path={classpath}\"\n",
    "            ]\n",
    "            # Ajouter java.library.path si le dossier native existe et contient des fichiers\n",
    "            if 'NATIVE_LIBS_DIR' in globals() and NATIVE_LIBS_DIR.exists() and any(NATIVE_LIBS_DIR.iterdir()):\n",
    "                 native_path_arg = f\"-Djava.library.path={NATIVE_LIBS_DIR.resolve()}\"\n",
    "                 jvm_args.append(native_path_arg)\n",
    "                 print(f\"   Argument JVM ajouté : {native_path_arg}\")\n",
    "\n",
    "            jpype.startJVM(*jvm_args, convertStrings=False) # Passer les arguments\n",
    "            jvm_started_in_this_cell = True # Marquer que NOUS l'avons démarrée ici\n",
    "\n",
    "            print(\"   Enregistrement des domaines JPype (org, java, net)...\")\n",
    "            jpype.imports.registerDomain(\"org\")\n",
    "            jpype.imports.registerDomain(\"java\")\n",
    "            jpype.imports.registerDomain(\"net\")\n",
    "            print(\"✅ JVM démarrée et domaines enregistrés.\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"\\n❌❌❌ Erreur LORS du démarrage de la JVM : {e} ❌❌❌\")\n",
    "            if hasattr(e, 'stacktrace'): print(\"\\n--- Stacktrace Java ---\\n\" + e.stacktrace() + \"\\n-----------------------\")\n",
    "            # Ne pas lever d'exception ici pour permettre les tests d'imports plus bas\n",
    "else:\n",
    "    print(\"ℹ️ JVM déjà en route.\")\n",
    "    # Si elle était déjà démarrée, s'assurer que les domaines sont enregistrés\n",
    "    # (peut être nécessaire après un redémarrage de noyau où la JVM persiste mais pas l'état Python)\n",
    "    try:\n",
    "        # Tenter un import simple pour voir si les domaines sont actifs\n",
    "        from org.tweetyproject.logics.pl.syntax import Proposition\n",
    "    except ImportError:\n",
    "        try:\n",
    "            print(\"   Ré-enregistrement des domaines JPype (la JVM persistait peut-être)...\")\n",
    "            jpype.imports.registerDomain(\"org\"); jpype.imports.registerDomain(\"java\"); jpype.imports.registerDomain(\"net\")\n",
    "            print(\"   Domaines ré-enregistrés.\")\n",
    "        except Exception as e_re_reg:\n",
    "             print(f\"   ⚠️ Erreur lors de la ré-enregistrement des domaines : {e_re_reg}\")\n",
    "\n",
    "\n",
    "# --- Test d'import post-démarrage/vérification ---\n",
    "print(\"\\nEffectuant des tests d'import Java plus spécifiques...\")\n",
    "imports_ok = True\n",
    "missing_imports = []\n",
    "if jpype.isJVMStarted():\n",
    "    try:\n",
    "        # --- Tests d'imports critiques ---\n",
    "        print(\"   Test imports critiques...\")\n",
    "        # 1. beliefdynamics.InformationObject (le problème principal)\n",
    "        info_obj_loaded = False\n",
    "        try:\n",
    "            # Essayer l'import direct\n",
    "            from org.tweetyproject.beliefdynamics import InformationObject\n",
    "            print(\"   ✔️ Import direct InformationObject réussi.\")\n",
    "            info_obj_loaded = True\n",
    "        except ImportError:\n",
    "            print(\"   ⚠️ Import direct InformationObject échoué. Tentative JClass...\")\n",
    "            try:\n",
    "                 InformationObject = jpype.JClass(\"org.tweetyproject.beliefdynamics.InformationObject\")\n",
    "                 print(\"   ✔️ Chargement InformationObject via JClass réussi.\")\n",
    "                 info_obj_loaded = True\n",
    "            except Exception as e_jclass_info:\n",
    "                 print(f\"   ❌ Chargement InformationObject via JClass échoué: {e_jclass_info}\")\n",
    "                 missing_imports.append(\"beliefdynamics.InformationObject\")\n",
    "                 imports_ok = False\n",
    "        except Exception as e_other_info:\n",
    "             print(f\"   ❌ Erreur inattendue lors de l'import/chargement de InformationObject: {e_other_info}\")\n",
    "             missing_imports.append(\"beliefdynamics.InformationObject\")\n",
    "             imports_ok = False\n",
    "\n",
    "        # 2. Autres imports nécessaires (simplifié)\n",
    "        print(\"   Test autres imports nécessaires...\")\n",
    "        try: from org.tweetyproject.commons import Formula; print(\"   ✔️ Import commons.Formula OK.\")\n",
    "        except ImportError: missing_imports.append(\"commons.Formula\"); imports_ok = False\n",
    "        try: from org.tweetyproject.logics.pl.syntax import Proposition; print(\"   ✔️ Import logics.pl.syntax.* OK.\")\n",
    "        except ImportError: missing_imports.append(\"logics.pl.syntax.*\"); imports_ok = False\n",
    "        try: from org.tweetyproject.arg.dung.syntax import Argument; print(\"   ✔️ Import arg.dung.syntax.* OK.\")\n",
    "        except ImportError: missing_imports.append(\"arg.dung.syntax.*\"); imports_ok = False\n",
    "        try: from java.util import ArrayList; print(\"   ✔️ Import java.util.* OK.\")\n",
    "        except ImportError: missing_imports.append(\"java.util.*\"); imports_ok = False\n",
    "\n",
    "    except Exception as e_other:\n",
    "            print(f\"❌ Erreur inattendue pendant test import : {e_other}\")\n",
    "            imports_ok = False\n",
    "\n",
    "    if not imports_ok:\n",
    "        print(f\"\\n‼️ Des imports Java essentiels ont échoué : {', '.join(missing_imports)}\")\n",
    "        print(\"   Cela indique un problème de classpath ou des JARs manquants/corrompus.\")\n",
    "        print(\"   Vérifiez les messages d'erreur ci-dessus et la présence des JARs dans 'libs/'.\")\n",
    "        if not beliefdynamics_jar_found_in_glob and \"beliefdynamics\" in \",\".join(missing_imports):\n",
    "             print(\"   **Le JAR 'beliefdynamics' n'a pas été trouvé par le script, ce qui explique l'échec.**\")\n",
    "        print(\"   La suite du notebook ne fonctionnera probablement pas.\")\n",
    "    else:\n",
    "        print(\"\\n✔️ Tests d'imports de base (y compris beliefdynamics) réussis.\")\n",
    "else:\n",
    "    print(\"\\n⚠️ Tests d'imports sautés car la JVM n'a pas démarré ou a échoué au démarrage.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df835515",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Cellule 13.1 : Test Minimal Import InformationObject ---\n",
    "print(\"\\n--- Test Minimal Import InformationObject ---\")\n",
    "minimal_import_ok = False\n",
    "info_obj_class_ref = None\n",
    "\n",
    "if 'jpype' in globals() and jpype.isJVMStarted():\n",
    "    try:\n",
    "        # Essayer import direct\n",
    "        from org.tweetyproject.beliefdynamics import InformationObject\n",
    "        print(\"✔️ Import direct org.tweetyproject.beliefdynamics.InformationObject RÉUSSI.\")\n",
    "        info_obj_class_ref = InformationObject # Garder la référence\n",
    "        minimal_import_ok = True\n",
    "    except ImportError as e_imp:\n",
    "        print(f\"⚠️ Import direct échoué: {e_imp}. Tentative JClass...\")\n",
    "        try:\n",
    "            info_obj_class_ref = jpype.JClass(\"org.tweetyproject.beliefdynamics.InformationObject\")\n",
    "            print(\"✔️ Chargement via JClass org.tweetyproject.beliefdynamics.InformationObject RÉUSSI.\")\n",
    "            minimal_import_ok = True\n",
    "        except Exception as e_jclass:\n",
    "            print(f\"❌ Chargement via JClass ÉCHOUÉ: {e_jclass}\")\n",
    "    except Exception as e_other:\n",
    "        print(f\"❌ Erreur inattendue lors du test d'import minimal: {e_other}\")\n",
    "\n",
    "    if minimal_import_ok:\n",
    "         # Test d'instanciation simple (nécessite d'autres classes, mais juste pour voir)\n",
    "         try:\n",
    "             from org.tweetyproject.logics.pl.syntax import Proposition\n",
    "             from org.tweetyproject.agents import DummyAgent\n",
    "             p = Proposition(\"test_prop\")\n",
    "             ag = DummyAgent(\"test_agent\")\n",
    "             # Assumons que info_obj_class_ref est la classe chargée\n",
    "             # Note: Nécessite de caster les arguments pour le constructeur Java\n",
    "             test_info_obj = info_obj_class_ref(jpype.JObject(p, jpype.JClass(\"org.tweetyproject.logics.pl.syntax.PlFormula\")),\n",
    "                                                jpype.JObject(ag, jpype.JClass(\"org.tweetyproject.agents.Agent\")))\n",
    "             print(f\"✔️ Instanciation test de InformationObject réussie: {test_info_obj}\")\n",
    "         except Exception as e_inst:\n",
    "             print(f\"⚠️ L'import/chargement a réussi, MAIS l'instanciation test a échoué: {e_inst}\")\n",
    "             print(\"   (Cela peut être dû à des dépendances manquantes pour le constructeur)\")\n",
    "\n",
    "else:\n",
    "    print(\"ℹ️ Test sauté (JVM non démarrée).\")\n",
    "\n",
    "# Mettre à jour la variable globale pour la cellule CrMas\n",
    "# Écraser la valeur précédente si elle existait\n",
    "CrMas_Imports_OK = minimal_import_ok\n",
    "print(f\"\\n==> Résultat du test minimal: CrMas_Imports_OK = {CrMas_Imports_OK}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e8b5b3",
   "metadata": {},
   "source": [
    "### 1.7 Concepts Clés de Tweety et JPype\n",
    "<a id=\"1.7\"></a>\n",
    "\n",
    "Avant de plonger dans les exemples, comprenons quelques concepts fondamentaux de Tweety et comment nous interagissons avec eux via JPype :\n",
    "\n",
    "**Concepts Tweety :**\n",
    "\n",
    "*   **Signature** (`org.tweetyproject.logics.[logic].syntax.[Logic]Signature`) : Définit le vocabulaire d'une logique.\n",
    "*   **Formula** (`org.tweetyproject.logics.[logic].syntax.[Logic]Formula`) : Représente une formule bien formée.\n",
    "*   **BeliefBase** (`org.tweetyproject.logics.[logic].syntax.[Logic]BeliefSet`) : Un ensemble de formules (base de connaissances).\n",
    "*   **Interpretation** (`org.tweetyproject.logics.[logic].semantics.Interpretation`) : Assigne une signification sémantique (ex: `PossibleWorld`).\n",
    "*   **Parser** (`org.tweetyproject.logics.[logic].parser.[Logic]Parser`) : Analyse chaînes/fichiers vers `Formula`/`BeliefSet`.\n",
    "*   **Reasoner** (`org.tweetyproject.logics.[logic].reasoner.[Logic]Reasoner`) : Implémente le raisonnement (`query`, `getModels`). Des raisonneurs par défaut peuvent être définis.\n",
    "*   **Argumentation Frameworks** (`org.tweetyproject.arg.*`): Classes pour les cadres (`DungTheory`, `AspicArgumentationTheory`, etc.) et composants (`Argument`, `Attack`, `Support`).\n",
    "\n",
    "**Interaction Python-Java avec JPype :**\n",
    "\n",
    "*   **Imports**: Grâce à `jpype.imports.registerDomain(\"org\", alias=\"org\")` (exécuté dans la cellule de démarrage JVM), on peut importer les classes Java comme des modules Python :\n",
    "    ```python\n",
    "    from org.tweetyproject.logics.pl.syntax import Proposition\n",
    "    from org.tweetyproject.arg.dung.syntax import Argument, Attack\n",
    "    from java.util import ArrayList # Également possible via registerDomain(\"java\", alias=\"java\")\n",
    "    ```\n",
    "*   **Instanciation**: `p = Proposition(\"a\")`.\n",
    "*   **Appel de Méthodes**: `kb.add(p)`.\n",
    "*   **Types Primitifs**: Conversion auto (int, float, bool, str).\n",
    "*   **Collections Java**: Utiliser les types Java explicites (`ArrayList`, `HashSet` depuis `java.util`).\n",
    "*   **Surcharge (Overloading)**: Si ambiguïté, caster avec `JObject(variable, ClasseJava)` ou `JInt()`, `JString()`, etc. (depuis `jpype.types`).\n",
    "*   **Exceptions Java**: Attraper avec `except jpype.JException as e_java:`. Accéder au message avec `e_java.message()` et à la trace avec `e_java.stacktrace()`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd3ec64f",
   "metadata": {},
   "source": [
    "## Partie 2 : Logiques Fondamentales dans Tweety\n",
    "<a id=\"partie2\"></a>\n",
    "\n",
    "Explorons comment représenter et raisonner avec certaines logiques de base en utilisant Tweety via JPype.\n",
    "\n",
    "### 2.1 Logique Propositionnelle (PL)\n",
    "<a id=\"2.1\"></a>\n",
    "\n",
    "La logique propositionnelle est la fondation de nombreux systèmes de raisonnement. Tweety fournit des outils robustes pour la manipuler.\n",
    "\n",
    "**Concepts Clés :**\n",
    "*   **`Proposition`**: Un symbole atomique (ex: `a`, `pluie`).\n",
    "*   **Connecteurs**: `Negation` (`!`), `Conjunction` (`&&`), `Disjunction` (`||`), `Implication` (`=>`), `Equivalence` (`<=>`), `Xor` (`^^`).\n",
    "*   **`PlFormula`**: Interface/classe de base pour toutes les formules PL.\n",
    "*   **`PlBeliefSet`**: Un ensemble de `PlFormula`.\n",
    "*   **`PossibleWorld`**: Une assignation de vérité aux propositions (une interprétation).\n",
    "*   **`PlParser`**: Pour créer des formules/bases depuis des chaînes.\n",
    "*   **Raisonnement**: `SimplePlReasoner` (basique), `SatSolver` (interface pour solveurs SAT).\n",
    "\n",
    "#### 2.1.1 Syntaxe, Parsing, Mondes Possibles\n",
    "<a id=\"2.1.1\"></a>\n",
    "\n",
    "Voyons comment créer, parser et évaluer des formules PL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0023e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2.1.1 Logique Propositionnelle : Syntaxe, Parsing, Mondes Possibles ---\n",
    "print(\"\\n--- 2.1.1 Logique Propositionnelle : Syntaxe, Parsing, Mondes Possibles ---\")\n",
    "\n",
    "# Vérifier si la JVM est démarrée et imports OK (sécurité)\n",
    "jvm_ready = False\n",
    "try:\n",
    "    import jpype\n",
    "    if jpype.isJVMStarted():\n",
    "        from org.tweetyproject.logics.pl.syntax import Proposition\n",
    "        jvm_ready = True\n",
    "except Exception: pass\n",
    "\n",
    "if not jvm_ready:\n",
    "    print(\"❌ ERREUR: JVM non démarrée. Veuillez exécuter/corriger les cellules de la Partie 1.\")\n",
    "else:\n",
    "    print(\"ℹ️ JVM prête. Exécution de l'exemple PL (Base)...\")\n",
    "    try:\n",
    "        # Imports nécessaires pour CET exemple\n",
    "        from jpype.types import *\n",
    "        import java.util # Pour accéder aux classes Java comme Collection\n",
    "        # Renommer List pour éviter conflit avec list Python\n",
    "        from java.util import ArrayList, Arrays, Collection, List as JavaList\n",
    "\n",
    "        from org.tweetyproject.logics.pl.syntax import (\n",
    "            PlBeliefSet, Proposition, Negation, Conjunction, Implication, Disjunction, Equivalence,\n",
    "            PlFormula, Contradiction, Tautology, PlSignature\n",
    "        )\n",
    "        from org.tweetyproject.logics.pl.parser import PlParser\n",
    "        from org.tweetyproject.logics.pl.reasoner import SimplePlReasoner\n",
    "        from org.tweetyproject.logics.pl.semantics import PossibleWorld\n",
    "        # Imports SAT Solver corrigés et complets\n",
    "        from org.tweetyproject.logics.pl.sat import SatSolver, Sat4jSolver, CmdLineSatSolver, DimacsSatSolver # Import DimacsSatSolver ajouté\n",
    "        from org.tweetyproject.commons import BeliefSet # Interface parente\n",
    "\n",
    "        # Récupérer la fonction get_tool_path (définie en Cellule 9)\n",
    "        if 'get_tool_path' not in globals():\n",
    "             import pathlib, os\n",
    "             if 'EXTERNAL_TOOLS' not in globals(): EXTERNAL_TOOLS = {} # Assurer existence\n",
    "             def get_tool_path(tool_name):\n",
    "                  path_str = EXTERNAL_TOOLS.get(tool_name, \"\")\n",
    "                  if not path_str: return None\n",
    "                  path_obj = pathlib.Path(path_str)\n",
    "                  if tool_name == \"OPEN_WBO\" and path_obj.is_dir():\n",
    "                       execs = [\"open-wbo\", \"open-wbo.exe\", \"open-wbo_release\", \"open-wbo_static\"]\n",
    "                       if any((path_obj / e).exists() for e in execs): return str(path_obj.resolve())\n",
    "                       else: return None\n",
    "                  is_exec = False\n",
    "                  if path_obj.is_file():\n",
    "                       if os.name == 'nt': is_exec = True\n",
    "                       else: is_exec = os.access(path_obj, os.X_OK)\n",
    "                  if is_exec: return str(path_obj.resolve())\n",
    "                  else: return None\n",
    "\n",
    "        print(\"✔️ Imports spécifiques PL (Base) réussis.\")\n",
    "\n",
    "        # --- Création manuelle et Parsing ---\n",
    "        pl_parser = PlParser() # Instance locale\n",
    "        belief_set_manual = PlBeliefSet()\n",
    "        a = Proposition(\"a\"); b = Proposition(\"b\"); c = Proposition(\"c\"); d = Proposition(\"d\")\n",
    "        f1 = a; f2 = Negation(b); f3 = Conjunction(a, Negation(c)); f4 = Implication(a, b)\n",
    "\n",
    "        # CORRECTION: Revenir à l'utilisation de ArrayList pour Disjunction\n",
    "        list_f5 = ArrayList()\n",
    "        list_f5.add(c)\n",
    "        list_f5.add(d)\n",
    "        f5 = Disjunction(list_f5) # Utiliser le constructeur avec Collection\n",
    "\n",
    "        belief_set_manual.add(f1); belief_set_manual.add(f2); belief_set_manual.add(f3); belief_set_manual.add(f4); belief_set_manual.add(f5)\n",
    "        print(\"\\nKB Manuelle:\\n\", belief_set_manual)\n",
    "\n",
    "        # Mémoriser cette KB pour la cellule suivante si besoin (optionnel)\n",
    "        kb_parsed_str = \"a || b || c \\n !a || b \\n !b || c\"\n",
    "        global belief_set_parsed_global # Rendre accessible globalement\n",
    "        belief_set_parsed_global = pl_parser.parseBeliefBase(kb_parsed_str)\n",
    "        print(\"\\nKB Parsée (stockée dans belief_set_parsed_global):\\n\", belief_set_parsed_global)\n",
    "\n",
    "        formula_xor_str = \"a ^^ b ^^ c\"\n",
    "        formula_xor = pl_parser.parseFormula(formula_xor_str)\n",
    "        print(f\"\\nFormule XOR ({formula_xor}):\")\n",
    "        print(f\" - DNF: {formula_xor.toDnf()}\")\n",
    "\n",
    "        # --- Sémantique et Satisfiabilité ---\n",
    "        world1 = PossibleWorld(); world1.add(a); world1.add(b)\n",
    "        formula_sat_str = \"a && !c\"\n",
    "        formula_sat = pl_parser.parseFormula(formula_sat_str)\n",
    "        print(f\"\\nMonde Possible w1 = {world1}\")\n",
    "        Collection_class = jpype.JClass(\"java.util.Collection\") # Pour les casts\n",
    "        PlFormula_class = jpype.JClass(\"org.tweetyproject.logics.pl.syntax.PlFormula\") # Pour cast\n",
    "        print(f\"Est-ce que w1 satisfait '{formula_sat}'? {world1.satisfies(JObject(formula_sat, PlFormula_class))}\")\n",
    "        print(f\"Est-ce que w1 satisfait '!b'? {world1.satisfies(JObject(pl_parser.parseFormula('!b'), PlFormula_class))}\")\n",
    "\n",
    "        print(f\"\\nModèles de '{formula_xor}':\")\n",
    "        models_xor_collection = formula_xor.getModels()\n",
    "        models_xor_list = [str(pw) for pw in models_xor_collection]\n",
    "        print(\"  \", models_xor_list)\n",
    "\n",
    "        # --- Conversion DIMACS (Exemple) ---\n",
    "        kb_for_dimacs = PlBeliefSet()\n",
    "        kb_dimacs_formulas = [\"a || b || c\", \"!a || b && d\", \"a\", \"!c\"]\n",
    "        for f_str in kb_dimacs_formulas: kb_for_dimacs.add(pl_parser.parseFormula(f_str))\n",
    "        print(f\"\\nConversion DIMACS de '{kb_for_dimacs}':\")\n",
    "        try:\n",
    "            dimacs_output_java_list = DimacsSatSolver.convertToDimacs(kb_for_dimacs)\n",
    "            dimacs_output_list = [str(line) for line in dimacs_output_java_list]\n",
    "            for line in dimacs_output_list:\n",
    "                print(line.strip())\n",
    "        except jpype.JException as e_dimacs_java:\n",
    "             print(f\"  ❌ Erreur Java lors de la conversion DIMACS: {e_dimacs_java.message()}\")\n",
    "        except Exception as e_dimacs:\n",
    "            print(f\"  ❌ Erreur Python lors de la conversion DIMACS: {e_dimacs}\")\n",
    "\n",
    "\n",
    "        # --- Test Solveur SAT Externe (Activé si configuré) ---\n",
    "        external_sat_path = get_tool_path('SAT_SOLVER')\n",
    "        if external_sat_path:\n",
    "            print(f\"\\n--- Test Solveur SAT Externe ---\")\n",
    "            print(f\"Utilisation du solveur SAT externe configuré: {external_sat_path}\")\n",
    "            try:\n",
    "                external_solver = CmdLineSatSolver(external_sat_path)\n",
    "                # external_solver.addOption(\"--quiet\") # Exemple d'option\n",
    "                is_sat_ext = external_solver.isSatisfiable(kb_for_dimacs)\n",
    "                print(f\" - KB '{kb_for_dimacs}' satisfiable (Externe)? {is_sat_ext}\")\n",
    "                if is_sat_ext:\n",
    "                    # Cast Collection nécessaire\n",
    "                    witness_ext = external_solver.getWitness(JObject(kb_for_dimacs, Collection_class))\n",
    "                    if witness_ext:\n",
    "                       print(f\" - Witness (Externe): {witness_ext}\")\n",
    "                    else:\n",
    "                        print(\" - Externe: getWitness a retourné None.\")\n",
    "            except jpype.JException as e_ext_sat_java:\n",
    "                 print(f\"  ❌ Erreur Java avec le solveur externe: {e_ext_sat_java.message()}\")\n",
    "            except Exception as e_ext_sat:\n",
    "                 print(f\"  ❌ Erreur Python avec le solveur externe: {e_ext_sat}\")\n",
    "        else:\n",
    "            print(\"\\n(Solveur SAT externe non configuré ou chemin invalide, test externe sauté.)\")\n",
    "\n",
    "\n",
    "    # Gestion globale des erreurs pour cette cellule\n",
    "    except ImportError as e:\n",
    "        print(f\"❌ Erreur d'import critique pour la Logique Propositionnelle : {e}\")\n",
    "    except jpype.JException as e_java:\n",
    "        print(f\"❌ Erreur Java générale dans l'exemple PL (Base): {e_java.message()}\")\n",
    "        print(e_java.stacktrace())\n",
    "    except Exception as e_gen:\n",
    "        print(f\"❌ Erreur Python inattendue dans l'exemple PL (Base): {e_gen}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "044f5ef1",
   "metadata": {},
   "source": [
    "#### 2.1.2 Raisonnement Simple et Solveurs SAT (SAT4J interne)\n",
    "<a id=\"2.1.2\"></a>\n",
    "\n",
    "Une fois les formules et bases définies, on peut effectuer des raisonnements :\n",
    "\n",
    "*   **Conséquence Logique (Query)** : Déterminer si une formule $\\phi$ est une conséquence logique d'une base $KB$ ($KB \\models \\phi$).\n",
    "*   **Satisfiabilité (SAT)** : Déterminer si une base $KB$ admet au moins un modèle (une assignation de vérité qui rend toutes les formules vraies).\n",
    "*   **Trouver un Modèle (Witness)** : Si la base est satisfiable, trouver une assignation de vérité qui la satisfait.\n",
    "\n",
    "Tweety propose :\n",
    "*   `SimplePlReasoner` : Un raisonneur basique pour la conséquence logique, potentiellement lent.\n",
    "*   `SatSolver` : Une interface pour les solveurs SAT. `Sat4jSolver` est une implémentation Java intégrée. `SatSolver.setDefaultSolver(...)` permet de choisir le solveur à utiliser globalement.\n",
    "    *   `isSatisfiable(kb)`: Vérifie la satisfiabilité.\n",
    "    *   `getWitness(kb)`: Retourne un `PossibleWorld` modèle si la KB est satisfiable, sinon `None`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020bc6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2.1.2 Logique Propositionnelle : Raisonnement Simple et SAT4J (Interne) ---\n",
    "print(\"\\n--- 2.1.2 Logique Propositionnelle : Raisonnement Simple et SAT4J (Interne) ---\")\n",
    "\n",
    "# Vérifier si la JVM est prête\n",
    "if not jvm_ready:\n",
    "    print(\"❌ ERREUR: JVM non démarrée. Impossible de continuer.\")\n",
    "else:\n",
    "    print(\"ℹ️ JVM prête. Exécution des exemples de raisonnement PL...\")\n",
    "    try:\n",
    "        # Imports nécessaires\n",
    "        import jpype\n",
    "        from jpype.types import *\n",
    "        from java.util import Collection # Interface\n",
    "        from org.tweetyproject.logics.pl.syntax import PlBeliefSet, PlFormula, Contradiction\n",
    "        from org.tweetyproject.logics.pl.parser import PlParser\n",
    "        from org.tweetyproject.logics.pl.reasoner import SimplePlReasoner\n",
    "        from org.tweetyproject.logics.pl.sat import SatSolver, Sat4jSolver\n",
    "\n",
    "        Collection_class = jpype.JClass(\"java.util.Collection\") # Pour cast JObject\n",
    "\n",
    "        # Initialisation locale\n",
    "        pl_parser_reasoning = PlParser()\n",
    "\n",
    "        # Recréation explicite de la KB pour cet exemple\n",
    "        kb_parsed_str = \"a || b || c \\n !a || b \\n !b || c\"\n",
    "        print(f\"\\nUtilisation de la KB: '{kb_parsed_str}'\")\n",
    "        kb_parsed_reasoning = pl_parser_reasoning.parseBeliefBase(kb_parsed_str)\n",
    "\n",
    "        # --- Raisonnement Simple ---\n",
    "        print(f\"\\nTest avec SimplePlReasoner sur '{kb_parsed_reasoning}':\")\n",
    "        simple_reasoner = SimplePlReasoner()\n",
    "        query1_pl = pl_parser_reasoning.parseFormula(\"c\")\n",
    "        query2_pl = Contradiction()\n",
    "\n",
    "        try:\n",
    "            print(f\" - Query '{query1_pl}'? {simple_reasoner.query(kb_parsed_reasoning, query1_pl)}\")\n",
    "            print(f\" - Query ⊥ (inconsistance KB)? {simple_reasoner.query(kb_parsed_reasoning, query2_pl)}\")\n",
    "        except jpype.JException as e_simple:\n",
    "            print(f\"   ❌ Erreur pendant SimplePlReasoner: {e_simple.message()}\")\n",
    "\n",
    "        # --- Utilisation de SAT4J (Solveur Interne) ---\n",
    "        print(f\"\\nTest avec Sat4jSolver:\")\n",
    "        SatSolver.setDefaultSolver(Sat4jSolver()) # Assurer que c'est le solver par défaut\n",
    "        solver_internal = SatSolver.getDefaultSolver()\n",
    "\n",
    "        # Exemple 1: KB satisfiable (légèrement différent de Cell 16)\n",
    "        kb_sat1_formulas = [\"a || b\", \"!a || c\", \"b || !c\"]\n",
    "        kb_sat1 = PlBeliefSet()\n",
    "        print(f\"\\nTest SAT sur KB '{kb_sat1_formulas}':\")\n",
    "        for f_str in kb_sat1_formulas: kb_sat1.add(pl_parser_reasoning.parseFormula(f_str))\n",
    "\n",
    "        try:\n",
    "            is_sat1 = solver_internal.isSatisfiable(kb_sat1)\n",
    "            print(f\" - Satisfiable? {is_sat1}\")\n",
    "            if is_sat1:\n",
    "                witness1 = solver_internal.getWitness(JObject(kb_sat1, Collection_class))\n",
    "                print(f\" - Witness (Modèle): {witness1}\")\n",
    "                if witness1:\n",
    "                    print(f\"   - Vérification : Witness satisfait KB? {witness1.satisfies(JObject(kb_sat1, Collection_class))}\")\n",
    "        except jpype.JException as e_sat1:\n",
    "            print(f\"   ❌ Erreur pendant SAT4J (KB1): {e_sat1.message()}\")\n",
    "\n",
    "        # Exemple 2: KB insatisfiable\n",
    "        kb_sat2 = PlBeliefSet([pl_parser_reasoning.parseFormula(\"a\"), pl_parser_reasoning.parseFormula(\"!a\")])\n",
    "        print(f\"\\nTest SAT sur KB '{kb_sat2}':\")\n",
    "        try:\n",
    "            is_sat2 = solver_internal.isSatisfiable(kb_sat2)\n",
    "            print(f\" - Satisfiable? {is_sat2}\") # Devrait être False\n",
    "            if not is_sat2:\n",
    "                witness2 = solver_internal.getWitness(JObject(kb_sat2, Collection_class))\n",
    "                print(f\" - Witness: {witness2}\") # Devrait être None\n",
    "        except jpype.JException as e_sat2:\n",
    "            print(f\"   ❌ Erreur pendant SAT4J (KB2): {e_sat2.message()}\")\n",
    "\n",
    "\n",
    "    except ImportError as e:\n",
    "        print(f\"❌ Erreur d'import pour le Raisonnement PL : {e}\")\n",
    "    except jpype.JException as e_java:\n",
    "         print(f\"❌ Erreur Java générale dans l'exemple PL (Raisonnement): {e_java.message()}\")\n",
    "         print(e_java.stacktrace())\n",
    "    except Exception as e_gen:\n",
    "         print(f\"❌ Erreur Python inattendue dans l'exemple PL (Raisonnement): {e_gen}\")\n",
    "         import traceback\n",
    "         traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfcbe2ff",
   "metadata": {},
   "source": [
    "### 2.2 Logique du Premier Ordre (FOL)\n",
    "<a id=\"2.2\"></a>\n",
    "\n",
    "La logique du premier ordre étend la logique propositionnelle avec des prédicats, des constantes, des variables et des quantificateurs (`forall`, `exists`).\n",
    "\n",
    "* **Signature (`FolSignature`)** : Définit les `Sort`s (types), `Constant`s (avec leur sort), et `Predicate`s (avec leur arité et les sorts de leurs arguments). L'égalité (`==`, `/==`) peut être activée.\n",
    "* **Formules (`FolFormula`)** : Peuvent inclure des atomes (`Predicate(term1, term2)`), des connecteurs logiques (`!`, `&&`, `||`, `=>`, `<=>`), et des quantificateurs (`forall X: (formula)`, `exists Y: (formula)`). Les variables quantifiées doivent être déclarées (souvent implicitement par leur première utilisation avec un quantificateur).\n",
    "* **Parsing (`FolParser`)** : Nécessite une signature pour interpréter correctement les constantes et prédicats.\n",
    "* **Raisonnement (`FolReasoner`)** : Tweety intègre des prouveurs externes comme **EProver**. `SimpleFolReasoner` est une implémentation basique. Il faut configurer le chemin vers l'exécutable du prouveur externe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7135d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2.2 Logique du Premier Ordre ---\n",
    "print(\"\\n--- 2.2 Logique du Premier Ordre ---\")\n",
    "\n",
    "if not jvm_ready:\n",
    "    print(\"❌ ERREUR: JVM non démarrée. Impossible de continuer cet exemple.\")\n",
    "else:\n",
    "    print(\"ℹ️ JVM prête. Exécution de l'exemple FOL...\")\n",
    "    fol_imports_ok = False\n",
    "    try:\n",
    "        # Imports (inchangés)\n",
    "        import jpype\n",
    "        from jpype.types import *\n",
    "        from java.util import ArrayList, Collection\n",
    "        import pathlib\n",
    "\n",
    "        from org.tweetyproject.logics.fol.syntax import FolFormula, FolSignature, FolBeliefSet, FolAtom\n",
    "        from org.tweetyproject.logics.commons.syntax import Sort, Constant, Predicate, Variable\n",
    "        from org.tweetyproject.logics.fol.parser import FolParser\n",
    "        from org.tweetyproject.logics.fol.reasoner import FolReasoner, SimpleFolReasoner, EFOLReasoner\n",
    "\n",
    "        # Récupérer get_tool_path si nécessaire\n",
    "        if 'get_tool_path' not in globals() or 'EXTERNAL_TOOLS' not in globals():\n",
    "             raise NameError(\"La fonction 'get_tool_path' ou 'EXTERNAL_TOOLS' n'est pas définie.\")\n",
    "\n",
    "        Collection_class = jpype.JClass(\"java.util.Collection\")\n",
    "        FolFormula_class = jpype.JClass(\"org.tweetyproject.logics.fol.syntax.FolFormula\")\n",
    "        print(\"✔️ Imports FOL/Commons réussis.\")\n",
    "        fol_imports_ok = True\n",
    "\n",
    "        # --- Signature (inchangée) ---\n",
    "        sig_fol = FolSignature(True)\n",
    "        sort_person = Sort(\"Person\"); sort_city = Sort(\"City\")\n",
    "        sig_fol.add(sort_person); sig_fol.add(sort_city)\n",
    "        alice = Constant(\"alice\", sort_person); bob = Constant(\"bob\", sort_person)\n",
    "        paris = Constant(\"paris\", sort_city); london = Constant(\"london\", sort_city)\n",
    "        sig_fol.add(alice); sig_fol.add(bob); sig_fol.add(paris); sig_fol.add(london)\n",
    "        livesIn_arity = ArrayList(); livesIn_arity.add(sort_person); livesIn_arity.add(sort_city)\n",
    "        livesIn = Predicate(\"livesIn\", livesIn_arity)\n",
    "        mortal_arity = ArrayList(); mortal_arity.add(sort_person)\n",
    "        mortal = Predicate(\"mortal\", mortal_arity)\n",
    "        sig_fol.add(livesIn); sig_fol.add(mortal)\n",
    "        isHappy_arity = ArrayList(); isHappy_arity.add(sort_person)\n",
    "        isHappy = Predicate(\"isHappy\", isHappy_arity)\n",
    "        sig_fol.add(isHappy)\n",
    "        print(\"\\nSignature FOL:\\n\", sig_fol)\n",
    "\n",
    "        # --- Parsing et Base de Croyances (inchangé) ---\n",
    "        parser_fol = FolParser()\n",
    "        parser_fol.setSignature(sig_fol)\n",
    "        kb_fol = FolBeliefSet()\n",
    "        print(\"\\nINFO: Test de parsing limité aux faits atomiques en raison de problèmes avec les quantificateurs.\")\n",
    "        formulas_to_test = [\"livesIn(alice, paris)\", \"livesIn(bob, london)\", \"paris /== london\", \"isHappy(alice)\"]\n",
    "        parsing_ok = True\n",
    "        print(\"\\nParsing des formules FOL (limitées)...\")\n",
    "        formulas_added_count = 0\n",
    "        for f_str in formulas_to_test:\n",
    "            # print(f\"  Parsing '{f_str}'...\", end=\"\") # Moins verbeux\n",
    "            try:\n",
    "                formula_obj = parser_fol.parseFormula(f_str)\n",
    "                kb_fol.add(JObject(formula_obj, FolFormula_class))\n",
    "                formulas_added_count += 1\n",
    "                # print(\" ✔️ OK\")\n",
    "            except jpype.JException as e_parse:\n",
    "                print(f\" ❌ ERREUR JAVA Parsing '{f_str}': {e_parse.message()}\")\n",
    "                parsing_ok = False\n",
    "            except Exception as e_gen_parse:\n",
    "                print(f\" ❌ ERREUR PYTHON Parsing '{f_str}': {e_gen_parse}\")\n",
    "                parsing_ok = False\n",
    "        if not parsing_ok: print(\"\\n⚠️ Des erreurs de parsing ont eu lieu.\")\n",
    "        print(f\"\\nKB FOL contient {kb_fol.size()} formules.\")\n",
    "\n",
    "        # --- Raisonnement ---\n",
    "        if kb_fol.size() > 0 and parsing_ok:\n",
    "            # *** MODIFIÉ : Tenter EProver si configuré ***\n",
    "            fol_reasoner = None\n",
    "            eprover_path_str = get_tool_path('EPROVER') # Utilise la fonction de vérification\n",
    "\n",
    "            if eprover_path_str:\n",
    "                print(f\"\\nTentative d'utilisation de EProver: {eprover_path_str}\")\n",
    "                try:\n",
    "                    # EFOLReasoner(String pathToProver)\n",
    "                    fol_reasoner = EFOLReasoner(JString(eprover_path_str))\n",
    "                    FolReasoner.setDefaultReasoner(fol_reasoner)\n",
    "                    print(\"   ✔️ EProver configuré comme raisonneur FOL par défaut.\")\n",
    "                except Exception as e_eprover:\n",
    "                    print(f\"   ❌ Erreur configuration/instanciation EProver: {e_eprover}.\")\n",
    "                    print(\"      Fallback vers SimpleFolReasoner.\")\n",
    "                    fol_reasoner = None # Forcer fallback\n",
    "\n",
    "            if not fol_reasoner:\n",
    "                if not eprover_path_str: print(\"\\nEProver non configuré ou chemin invalide.\")\n",
    "                print(\"Utilisation de SimpleFolReasoner.\")\n",
    "                fol_reasoner = SimpleFolReasoner()\n",
    "                FolReasoner.setDefaultReasoner(fol_reasoner)\n",
    "\n",
    "            current_reasoner = FolReasoner.getDefaultReasoner()\n",
    "            print(f\"\\nRaisonneur FOL utilisé: {current_reasoner.getClass().getSimpleName()}\")\n",
    "\n",
    "            # Queries simples (inchangées pour l'instant)\n",
    "            queries_fol_str = [\n",
    "                 \"livesIn(alice, paris)\", # Devrait être True\n",
    "                 \"livesIn(bob, paris)\",   # Devrait être False\n",
    "                 \"isHappy(alice)\",        # Devrait être True\n",
    "                 \"isHappy(bob)\",          # Devrait être False/Unknown\n",
    "                 \"paris == london\"        # Devrait être False\n",
    "            ]\n",
    "\n",
    "            print(\"\\nRésultats des requêtes:\")\n",
    "            for q_str in queries_fol_str:\n",
    "                print(f\"   Querying '{q_str}'...\", end=\"\")\n",
    "                try:\n",
    "                    query_formula = parser_fol.parseFormula(q_str)\n",
    "                    # query(BeliefBase, Formula)\n",
    "                    result = current_reasoner.query(kb_fol, JObject(query_formula, FolFormula_class))\n",
    "                    # SimpleFolReasoner peut retourner null pour 'unknown'\n",
    "                    result_str = 'Unknown' if result is None else str(result)\n",
    "                    print(f\" Résultat: {result_str}\")\n",
    "                except jpype.JException as e_query_java:\n",
    "                    print(f\" ERREUR JAVA: {e_query_java.message()}\")\n",
    "                except Exception as e_query_py:\n",
    "                    print(f\" ERREUR PYTHON: {e_query_py}\")\n",
    "        else:\n",
    "            print(\"\\n⚠️ Le raisonnement FOL est sauté car le parsing a échoué ou la KB est vide/incomplète.\")\n",
    "\n",
    "    # Gestion globale (inchangée)\n",
    "    except ImportError as e: print(f\"❌ Erreur d'import pour FOL : {e}\")\n",
    "    except jpype.JException as e_java: print(f\"❌ Erreur Java générale FOL: {e_java.message()}\"); print(e_java.stacktrace())\n",
    "    except Exception as e_gen: print(f\"❌ Erreur Python inattendue FOL: {e_gen}\"); import traceback; traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d9d39c",
   "metadata": {},
   "source": [
    "### 2.3 Logique de Description (DL)\n",
    "<a id=\"2.3\"></a>\n",
    "\n",
    "Les logiques de description sont une famille de formalismes pour représenter des connaissances structurées, souvent utilisées pour les ontologies (ex: OWL). Elles se concentrent sur la définition de **Concepts** (classes d'individus), de **Rôles** (relations binaires) et d'**Individus**.\n",
    "\n",
    "* **Signature (`DlSignature`)** : Comprend `AtomicConcept`, `AtomicRole`, `Individual`.\n",
    "* **Axiomes** :\n",
    "    * **TBox (Terminological Box)** : Axiomes définissant les concepts et les rôles (ex: `SubConceptAxiom`, `EquivalenceAxiom`, `DisjointAxiom`). Les concepts peuvent être combinés (`Intersection`, `Union`, `Complement`, `ExistsRestriction`, `ForAllRestriction`).\n",
    "    * **ABox (Assertional Box)** : Axiomes sur les individus (ex: `ConceptAssertion` - `Human(Alice)`, `RoleAssertion` - `fatherOf(Bob, Alice)`).\n",
    "* **Base de Connaissances (`DlBeliefSet`)** : Contient les axiomes TBox et ABox.\n",
    "* **Raisonnement (`DlReasoner`)** : Vérifie la consistance, la subsomption de concepts, l'instanciation. `NaiveDlReasoner` est une implémentation simple. Des raisonneurs plus puissants (comme Pellet, HermiT - non intégrés directement comme solveurs externes dans cet exemple) existent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a3ee00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2.3 Logique de Description ---\n",
    "print(\"\\n--- 2.3 Logique de Description ---\")\n",
    "\n",
    "# Vérifier si la JVM est prête\n",
    "if not jvm_ready:\n",
    "    print(\"❌ ERREUR: JVM non démarrée. Impossible de continuer cet exemple.\")\n",
    "else:\n",
    "    print(\"ℹ️ JVM prête. Exécution de l'exemple DL...\")\n",
    "    try:\n",
    "        # Imports DL et Communs\n",
    "        import jpype\n",
    "        from jpype.types import *\n",
    "        from java.util import ArrayList # Besoin pour Union\n",
    "\n",
    "        # Classes DL spécifiques (maintenant qu'elles semblent importables)\n",
    "        from org.tweetyproject.logics.dl.syntax import (\n",
    "            AtomicConcept, AtomicRole, Individual,\n",
    "            EquivalenceAxiom, ConceptAssertion, RoleAssertion,\n",
    "            DlBeliefSet, DlSignature, DlAxiom, # DlAxiom pour l'itération\n",
    "            Complement, Union # Constructeurs de concepts\n",
    "        )\n",
    "        from org.tweetyproject.logics.dl.parser import DlParser\n",
    "        from org.tweetyproject.logics.dl.reasoner import NaiveDlReasoner\n",
    "\n",
    "        print(\"✔️ Imports DL réussis.\")\n",
    "\n",
    "        # --- Signature et Axiomes (basé sur DlExample.java) ---\n",
    "        # Concepts\n",
    "        human = AtomicConcept(\"Human\")\n",
    "        male = AtomicConcept(\"Male\")\n",
    "        female = AtomicConcept(\"Female\")\n",
    "        house = AtomicConcept(\"House\")\n",
    "        father = AtomicConcept(\"Father\")\n",
    "        # Rôles\n",
    "        fatherOf = AtomicRole(\"fatherOf\")\n",
    "        # Individus\n",
    "        bob = Individual(\"Bob\")\n",
    "        alice = Individual(\"Alice\")\n",
    "\n",
    "        # Axiomes Terminologiques (TBox)\n",
    "        # Note: La syntaxe Python pour créer ces objets\n",
    "        femaleHuman = EquivalenceAxiom(female, human)\n",
    "        maleHuman = EquivalenceAxiom(male, human)\n",
    "        femaleNotMale = EquivalenceAxiom(female, Complement(male)) # female = not Male\n",
    "        maleNotFemale = EquivalenceAxiom(male, Complement(female)) # male = not Female\n",
    "\n",
    "        # Concept 'Father' = Male AND fatherOf some Thing (approximé par Union ici faute d'ExistsRestriction facile à importer?)\n",
    "        # L'exemple Java original utilisait Union(male, fatherOf) ce qui est sémantiquement étrange.\n",
    "        # Essayons Male AND Exists(fatherOf, Thing) si on trouve ExistsRestriction plus tard.\n",
    "        # Pour l'instant, on garde l'exemple Java, même si étrange : Father = Male OR fatherOf ???\n",
    "        # Ou peut-être était-ce Intersection ? Essayons Intersection.\n",
    "        # from org.tweetyproject.logics.dl.syntax import Intersection\n",
    "        # fatherEq = EquivalenceAxiom(father, Intersection(male, fatherOf)) # Encore étrange...\n",
    "        # Gardons l'original pour tester, même si conceptuellement douteux :\n",
    "        # fatherEq = EquivalenceAxiom(father, Union(male, fatherOf))\n",
    "        # Allons-y avec une définition plus simple pour l'exemple : Male = Human\n",
    "        # (On peut complexifier si ça marche)\n",
    "        print(\"ℹ️ Définition de 'Father' simplifiée pour cet exemple.\")\n",
    "        # fatherEq = EquivalenceAxiom(father, male) # Simplifions pour le test\n",
    "\n",
    "        houseNotHuman = EquivalenceAxiom(house, Complement(human)) # house = not Human\n",
    "\n",
    "        # Axiomes Assertoriels (ABox)\n",
    "        aliceHuman = ConceptAssertion(alice, human)\n",
    "        bobHuman = ConceptAssertion(bob, human)\n",
    "        aliceFemale = ConceptAssertion(alice, female)\n",
    "        bobMale = ConceptAssertion(bob, male)\n",
    "        bobFatherOfAlice = RoleAssertion(bob, alice, fatherOf)\n",
    "\n",
    "        # Base de connaissances\n",
    "        dbs = DlBeliefSet()\n",
    "        dbs.add(femaleHuman); dbs.add(maleHuman); dbs.add(femaleNotMale); dbs.add(maleNotFemale)\n",
    "        # dbs.add(fatherEq) # On omet la définition complexe de Father pour l'instant\n",
    "        dbs.add(houseNotHuman)\n",
    "        dbs.add(aliceHuman); dbs.add(bobHuman); dbs.add(aliceFemale); dbs.add(bobMale)\n",
    "        dbs.add(bobFatherOfAlice)\n",
    "\n",
    "        print(\"\\nDL Knowledge Base (créée manuellement):\\n\", dbs)\n",
    "        print(\"ABox seule:\", dbs.getABox())\n",
    "        print(\"TBox seule:\", dbs.getTBox())\n",
    "\n",
    "        # --- Parsing depuis Fichier (Optionnel) ---\n",
    "        # Assurez-vous que le fichier examplebeliefbase.dlogic est au bon endroit\n",
    "        # dlogic_filepath = \"./Resources/examplebeliefbase.dlogic\" # Adapter le chemin\n",
    "        # print(f\"\\\\nParsing du fichier {dlogic_filepath}...\")\n",
    "        # try:\n",
    "        #     parser_dl = DlParser()\n",
    "        #     parsed_dbs = parser_dl.parseBeliefBaseFromFile(dlogic_filepath)\n",
    "        #     print(\"KB Parsée depuis fichier:\\n\")\n",
    "        #     for axiom in parsed_dbs: # Itérer sur les axiomes\n",
    "        #         print(axiom)\n",
    "        # except Exception as e_parse_file:\n",
    "        #     print(f\"  ❌ Erreur lors du parsing du fichier DL: {e_parse_file}\")\n",
    "\n",
    "\n",
    "        # --- Raisonnement Naïf ---\n",
    "        print(\"\\nRaisonnement DL (Naïf):\")\n",
    "        # Utilisons une petite KB pour le raisonnement\n",
    "        dbs_reason = DlBeliefSet()\n",
    "        tweety = Individual(\"Tweety\")\n",
    "        tweetyMale = ConceptAssertion(tweety, male)\n",
    "        tweetyHuman = ConceptAssertion(tweety, human) # Est-ce que Tweety est humain ?\n",
    "        dbs_reason.add(aliceFemale) # Alice is Female\n",
    "        dbs_reason.add(tweetyMale)  # Tweety is Male\n",
    "        dbs_reason.add(maleNotFemale) # Male = not Female\n",
    "        dbs_reason.add(aliceHuman) # Alice is Human\n",
    "        # On ajoute la TBox nécessaire\n",
    "        dbs_reason.add(femaleHuman) # female = Human\n",
    "\n",
    "        reasoner_dl = NaiveDlReasoner()\n",
    "\n",
    "        # Query 1: Est-ce que Female implique Human ? (TBox query)\n",
    "        q1_dl = femaleHuman # L'axiome lui-même\n",
    "        print(f\" - Query '{q1_dl}'? {reasoner_dl.query(dbs_reason, q1_dl)}\")\n",
    "\n",
    "        # Query 2: Est-ce que Tweety est Humain ? (ABox query, nécessite Male=>Human ou Female=>Human)\n",
    "        q2_dl = tweetyHuman\n",
    "        # On doit ajouter Male => Human à la TBox pour que ça marche\n",
    "        dbs_reason.add(maleHuman)\n",
    "        print(f\" - Query '{q2_dl}' (après ajout Male=Human)? {reasoner_dl.query(dbs_reason, q2_dl)}\")\n",
    "\n",
    "        # Query 3: Est-ce que Alice est Male ? (Devrait être faux)\n",
    "        q3_dl = ConceptAssertion(alice, male)\n",
    "        print(f\" - Query '{q3_dl}'? {reasoner_dl.query(dbs_reason, q3_dl)}\")\n",
    "\n",
    "\n",
    "    except ImportError as e:\n",
    "        print(f\"❌ Erreur d'import pour la Logique de Description : {e}. Vérifiez le JAR logics.dl.\")\n",
    "    except jpype.JException as e_java:\n",
    "        print(f\"❌ Erreur Java générale dans l'exemple DL: {e_java.message()}\")\n",
    "        print(e_java.stacktrace())\n",
    "    except Exception as e_gen:\n",
    "        print(f\"❌ Erreur Python inattendue dans l'exemple DL: {e_gen}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf43586a",
   "metadata": {},
   "source": [
    "### 2.4 Logique Modale (ML)\n",
    "<a id=\"2.4\"></a>\n",
    "\n",
    "La logique modale ajoute des opérateurs pour qualifier la *manière* dont une proposition est vraie. Les opérateurs classiques sont :\n",
    "* `[]` (Box) : Nécessité (\"il est nécessaire que\", \"dans tous les mondes accessibles\")\n",
    "* `<>` (Diamond) : Possibilité (\"il est possible que\", \"dans au moins un monde accessible\")\n",
    "\n",
    "Tweety permet de définir des bases de croyances modales et d'utiliser des raisonneurs.\n",
    "\n",
    "* **Syntaxe**: Utilise la syntaxe FOL avec les opérateurs `[]` et `<>`.\n",
    "* **Parsing (`MlParser`)**: Peut parser des formules et bases de croyances modales.\n",
    "* **Raisonnement**:\n",
    "    * `SimpleMlReasoner` : Implémentation basique.\n",
    "    * `SPASSMlReasoner` : Interface avec le prouveur externe SPASS (performant mais nécessite installation et configuration du chemin)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7807d357",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2.4 Logique Modale ---\n",
    "print(\"\\n--- 2.4 Logique Modale ---\")\n",
    "\n",
    "# Vérifier si la JVM est prête\n",
    "if not jvm_ready:\n",
    "    print(\"❌ ERREUR: JVM non démarrée. Impossible de continuer cet exemple.\")\n",
    "else:\n",
    "    print(\"ℹ️ JVM prête. Exécution de l'exemple ML...\")\n",
    "    try:\n",
    "        # Imports\n",
    "        import jpype\n",
    "        from jpype.types import *\n",
    "        import pathlib\n",
    "        # Importer explicitement les exceptions Java nécessaires pour isinstance\n",
    "        IOException = jpype.JClass(\"java.io.IOException\")\n",
    "        RuntimeException = jpype.JClass(\"java.lang.RuntimeException\")\n",
    "\n",
    "        from org.tweetyproject.logics.ml.syntax import MlBeliefSet\n",
    "        from org.tweetyproject.logics.ml.parser import MlParser\n",
    "        from org.tweetyproject.logics.fol.syntax import FolSignature, FolFormula\n",
    "        from org.tweetyproject.logics.commons.syntax import Predicate\n",
    "        from org.tweetyproject.logics.ml.reasoner import AbstractMlReasoner, SimpleMlReasoner, SPASSMlReasoner\n",
    "\n",
    "        if 'get_tool_path' not in globals() or 'EXTERNAL_TOOLS' not in globals():\n",
    "             raise NameError(\"La fonction 'get_tool_path' ou 'EXTERNAL_TOOLS' n'est pas définie.\")\n",
    "\n",
    "        FolFormula_class = jpype.JClass(\"org.tweetyproject.logics.fol.syntax.FolFormula\")\n",
    "\n",
    "        print(\"✔️ Imports ML réussis.\")\n",
    "\n",
    "        # --- Signature et Base de Croyances ---\n",
    "        # (Identique)\n",
    "        sig_ml = FolSignature()\n",
    "        p = Predicate(\"p\", 0); q = Predicate(\"q\", 0); r = Predicate(\"r\", 0)\n",
    "        sig_ml.add(p); sig_ml.add(q); sig_ml.add(r)\n",
    "        parser_ml = MlParser()\n",
    "        parser_ml.setSignature(sig_ml)\n",
    "        kb_ml = MlBeliefSet()\n",
    "        formulas_ml = [\"!(<>(p))\", \"p || r\", \"!r || [](q && r)\", \"[](r && <>(p || q))\", \"!p && !q\"]\n",
    "        print(\"\\nParsing des formules ML...\")\n",
    "        parsing_ml_ok = True\n",
    "        for f_str in formulas_ml:\n",
    "            try: kb_ml.add(parser_ml.parseFormula(f_str)); print(f\"  ✔️ Ajouté: {f_str}\")\n",
    "            except Exception as e_parse_ml: print(f\"  ❌ Erreur parsing '{f_str}': {e_parse_ml}\"); parsing_ml_ok = False\n",
    "\n",
    "        if not parsing_ml_ok: print(\"⚠️ Erreurs lors du parsing ML.\")\n",
    "        print(\"\\nKB Modale:\\n\", kb_ml)\n",
    "\n",
    "\n",
    "        # --- Raisonnement ---\n",
    "        if parsing_ml_ok and kb_ml.size() > 0:\n",
    "            ml_reasoner = None\n",
    "            spass_path = get_tool_path('SPASS')\n",
    "            spass_configured_and_tried = False\n",
    "            simple_reasoner_fallback = None\n",
    "\n",
    "            if spass_path:\n",
    "                print(f\"\\nTentative d'utilisation de SPASS: {spass_path}\")\n",
    "                try:\n",
    "                    spass_reasoner = SPASSMlReasoner(JString(spass_path))\n",
    "                    AbstractMlReasoner.setDefaultReasoner(spass_reasoner)\n",
    "                    ml_reasoner = AbstractMlReasoner.getDefaultReasoner()\n",
    "                    spass_configured_and_tried = True\n",
    "                    print(\"  ✔️ SPASS configuré comme raisonneur ML par défaut.\")\n",
    "                except Exception as e_spass:\n",
    "                    print(f\"  ❌ Erreur configuration SPASS: {e_spass}. Fallback...\")\n",
    "                    ml_reasoner = None\n",
    "\n",
    "            if not ml_reasoner:\n",
    "                if not spass_path: print(\"\\nSPASS non configuré.\")\n",
    "                print(\"Utilisation de SimpleMlReasoner (basique, peut être TRES lent ou bloquer!).\")\n",
    "                simple_reasoner_fallback = SimpleMlReasoner()\n",
    "                AbstractMlReasoner.setDefaultReasoner(simple_reasoner_fallback)\n",
    "                ml_reasoner = AbstractMlReasoner.getDefaultReasoner()\n",
    "\n",
    "            current_ml_reasoner = AbstractMlReasoner.getDefaultReasoner()\n",
    "            print(f\"\\nRaisonneur ML utilisé: {current_ml_reasoner.getClass().getSimpleName()}\")\n",
    "\n",
    "            queries_ml_str = [\"[](!p)\", \"<>(q || r)\", \"p\", \"r\", \"[](q)\"]\n",
    "            is_spass_active = isinstance(current_ml_reasoner, SPASSMlReasoner)\n",
    "            is_simple_active = isinstance(current_ml_reasoner, SimpleMlReasoner)\n",
    "\n",
    "            if is_simple_active:\n",
    "                 print(\"  (Limitation des requêtes pour SimpleMlReasoner pour éviter blocage potentiel)\")\n",
    "                 queries_to_run = [\"p\", \"r\"]\n",
    "            else:\n",
    "                 queries_to_run = queries_ml_str\n",
    "\n",
    "            print(\"\\nRésultats des requêtes:\")\n",
    "            for query_str in queries_to_run:\n",
    "                print(f\"  Querying '{query_str}'...\", end=\"\")\n",
    "                try:\n",
    "                    query_formula = parser_ml.parseFormula(query_str)\n",
    "                    result = current_ml_reasoner.query(kb_ml, JObject(query_formula, FolFormula_class))\n",
    "                    print(f\" Résultat: {result}\")\n",
    "\n",
    "                # CORRECTION : Utiliser isinstance() pour vérifier la cause de l'exception\n",
    "                except jpype.JException as e_query_java:\n",
    "                    root_cause = e_query_java # L'exception attrapée\n",
    "                    actual_io_exception = None\n",
    "                    max_depth = 5\n",
    "                    current_cause = root_cause\n",
    "                    for _ in range(max_depth):\n",
    "                        # Utiliser isinstance() Python pour vérifier le type Java\n",
    "                        if isinstance(current_cause, IOException):\n",
    "                            actual_io_exception = current_cause\n",
    "                            break\n",
    "                        # Essayer d'obtenir la cause suivante\n",
    "                        if hasattr(current_cause, 'getCause') and callable(current_cause.getCause):\n",
    "                             next_cause = current_cause.getCause()\n",
    "                             if next_cause is None: break\n",
    "                             current_cause = next_cause\n",
    "                        else: break\n",
    "\n",
    "                    if actual_io_exception and \"error=740\" in str(actual_io_exception.getMessage()):\n",
    "                        print(\" ERREUR 740 (Élévation requise pour SPASS).\")\n",
    "                        print(\"     ==> Essayez de lancer Jupyter/Python 'En tant qu'administrateur'.\")\n",
    "                        if is_spass_active:\n",
    "                             print(\"     Tentative de fallback avec SimpleMlReasoner...\", end=\"\")\n",
    "                             try:\n",
    "                                  if simple_reasoner_fallback is None:\n",
    "                                       simple_reasoner_fallback = SimpleMlReasoner()\n",
    "                                  result_fallback = simple_reasoner_fallback.query(kb_ml, JObject(query_formula, FolFormula_class))\n",
    "                                  print(f\" Résultat (Simple): {result_fallback}\")\n",
    "                             except Exception as e_fallback:\n",
    "                                  print(f\" ÉCHEC Fallback: {e_fallback}\")\n",
    "                    else:\n",
    "                         print(f\" ERREUR JAVA non gérée spécifiquement: {e_query_java.message()}\")\n",
    "                         # print(e_query_java.stacktrace()) # Optionnel pour debug\n",
    "\n",
    "                except Exception as e_query_py:\n",
    "                     print(f\" ERREUR PYTHON: {e_query_py}\")\n",
    "                     import traceback\n",
    "                     traceback.print_exc()\n",
    "        else:\n",
    "             print(\"\\n⚠️ Le raisonnement ML est sauté car le parsing a échoué ou la KB est vide.\")\n",
    "\n",
    "    # Gestion globale des erreurs\n",
    "    except ImportError as e:\n",
    "        print(f\"❌ Erreur d'import pour la Logique Modale : {e}\")\n",
    "    except jpype.JException as e_java:\n",
    "        print(f\"❌ Erreur Java générale dans l'exemple ML: {e_java.message()}\")\n",
    "        print(e_java.stacktrace())\n",
    "    except Exception as e_gen:\n",
    "        print(f\"❌ Erreur Python inattendue dans l'exemple ML: {e_gen}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06cb6d36",
   "metadata": {},
   "source": [
    "### 2.5 Autres Logiques (Aperçu QBF, CL)\n",
    "<a id=\"2.5\"></a>\n",
    "\n",
    "Tweety supporte d'autres logiques que nous n'explorerons pas en détail ici, mais dont voici un aperçu fonctionnel :\n",
    "\n",
    "* **Formules Booléennes Quantifiées (QBF)** (`org.tweetyproject.logics.qbf`): Étend PL avec des quantificateurs existentiels (`exists`) et universels (`forall`) sur les **propositions**. Utile pour modéliser des problèmes PSPACE. Tweety inclut des parseurs pour les formats QDIMACS et QCir, ainsi qu'un writer QDIMACS. Le raisonnement QBF nécessite généralement des solveurs externes spécialisés (non intégrés directement comme `CmdLineQbfSolver` pour le moment, contrairement aux SAT solvers).\n",
    "\n",
    "* **Logique Conditionnelle (CL)** (`org.tweetyproject.logics.cl`): Traite des conditionnels de la forme `(B | A)` signifiant \"Si A est vrai, alors B est typiquement vrai\". Utilisée pour le raisonnement non monotone et la modélisation des défauts. Tweety fournit des raisonneurs basés sur les fonctions de classement (`SimpleCReasoner`, `RuleBasedCReasoner`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a78fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2.5 Autres Logiques (Aperçu QBF et CL) ---\n",
    "print(\"\\n--- 2.5 Autres Logiques (Aperçu QBF et CL) ---\")\n",
    "\n",
    "# Vérifier si la JVM est prête\n",
    "if not jvm_ready:\n",
    "    print(\"❌ ERREUR: JVM non démarrée. Impossible de continuer cet exemple.\")\n",
    "else:\n",
    "    print(\"ℹ️ JVM prête. Exécution des exemples QBF et CL...\")\n",
    "\n",
    "    # --- QBF ---\n",
    "    print(\"\\n--- Aperçu QBF ---\")\n",
    "    try:\n",
    "        # Imports QBF et PL\n",
    "        import jpype\n",
    "        from jpype.types import *\n",
    "        # Besoin de PL pour Proposition, Conjunction, Negation, PlBeliefSet\n",
    "        from org.tweetyproject.logics.pl.syntax import Proposition, PlBeliefSet, Conjunction, Negation\n",
    "\n",
    "        # Charger ExistsQuantifiedFormula via JClass ou import\n",
    "        ExistsQuantifiedFormula = None\n",
    "        try:\n",
    "             ExistsQuantifiedFormula = jpype.JClass(\"org.tweetyproject.logics.qbf.syntax.ExistsQuantifiedFormula\")\n",
    "             print(\"✔️ Classe ExistsQuantifiedFormula chargée.\")\n",
    "        except Exception as e_qbf_jclass:\n",
    "             print(f\"⚠️ Impossible de charger ExistsQuantifiedFormula via JClass: {e_qbf_jclass}. Tentative d'import direct...\")\n",
    "             try:\n",
    "                  from org.tweetyproject.logics.qbf.syntax import ExistsQuantifiedFormula\n",
    "                  print(\"✔️ Import direct de ExistsQuantifiedFormula réussi.\")\n",
    "             except ImportError:\n",
    "                   print(\"❌ Import direct de ExistsQuantifiedFormula échoué aussi. Section QBF inutilisable.\")\n",
    "                   ExistsQuantifiedFormula = None # Marquer comme inutilisable\n",
    "\n",
    "        # Parser/Writer QBF\n",
    "        from org.tweetyproject.logics.qbf.parser import QbfParser, QdimacsParser, QCirParser\n",
    "        from org.tweetyproject.logics.qbf.writer import QdimacsWriter\n",
    "\n",
    "        if ExistsQuantifiedFormula: # Ne continuer que si la classe est chargée\n",
    "            # Création programmatique de la formule: exists P: (P && !P)\n",
    "            p_qbf = Proposition(\"P\")\n",
    "            # CORRECTION: Utiliser le constructeur ExistsQuantifiedFormula(body, variable)\n",
    "            # Construire le corps d'abord\n",
    "            body_formula = Conjunction(p_qbf, Negation(p_qbf))\n",
    "            qbf_formula = ExistsQuantifiedFormula(body_formula, p_qbf) # Ordre corrigé\n",
    "\n",
    "            qbf_bs = PlBeliefSet()\n",
    "            qbf_bs.add(qbf_formula)\n",
    "            print(\"\\nQBF BeliefSet (créé programmatiquement):\\n\", qbf_bs)\n",
    "\n",
    "            # Conversion en QDIMACS\n",
    "            print(\"\\nFormat QDIMACS:\")\n",
    "            qdimacs_writer = QdimacsWriter()\n",
    "            print(qdimacs_writer.printBase(qbf_bs))\n",
    "\n",
    "            # Section parsing (commentée par défaut)\n",
    "            print(\"\\nℹ️ Parsers QBF, QDIMACS et QCir existent mais nécessitent fichiers spécifiques.\")\n",
    "\n",
    "    except ImportError as e:\n",
    "        print(f\"❌ Erreur d'import pour QBF : {e}. Vérifiez les JARs logics.qbf et logics.pl.\")\n",
    "    except jpype.JException as e_java:\n",
    "        print(f\"❌ Erreur Java générale dans l'exemple QBF: {e_java.message()}\")\n",
    "        # print(e_java.stacktrace())\n",
    "    except Exception as e_gen:\n",
    "        print(f\"❌ Erreur Python inattendue dans l'exemple QBF: {e_gen}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "\n",
    "    # --- Logique Conditionnelle (CL) ---\n",
    "    print(\"\\n\\n--- Aperçu Logique Conditionnelle (CL) ---\")\n",
    "    try:\n",
    "        # Imports CL et PL\n",
    "        import jpype\n",
    "        from jpype.types import *\n",
    "        from org.tweetyproject.logics.cl.syntax import ClBeliefSet, Conditional\n",
    "        from org.tweetyproject.logics.pl.syntax import Proposition, Negation\n",
    "        from org.tweetyproject.logics.cl.reasoner import SimpleCReasoner\n",
    "        # RankingFunction est dans cl.semantics\n",
    "        from org.tweetyproject.logics.cl.semantics import RankingFunction\n",
    "\n",
    "        print(\"✔️ Imports CL réussis.\")\n",
    "\n",
    "        # Création de la base CL\n",
    "        f = Proposition(\"f\"); b = Proposition(\"b\"); p = Proposition(\"p\")\n",
    "        c1 = Conditional(f, b); c2 = Conditional(b, p); c3 = Conditional(Negation(f), p)\n",
    "        bs_cl = ClBeliefSet(); bs_cl.add(c1); bs_cl.add(c2); bs_cl.add(c3)\n",
    "        print(\"\\nBase Conditionnelle:\\n\", bs_cl)\n",
    "\n",
    "        # Raisonnement\n",
    "        cl_reasoner = SimpleCReasoner()\n",
    "        print(f\"\\nCalcul de la fonction de classement avec {cl_reasoner.getClass().getSimpleName()}...\")\n",
    "        try:\n",
    "            kappa_model = cl_reasoner.getModel(bs_cl)\n",
    "            print(\"\\nFonction de Classement (kappa) calculée:\\n\")\n",
    "            # CORRECTION: Utiliser str() pour appeler toString()\n",
    "            print(str(kappa_model))\n",
    "            # kappa_model.prettyPrint() n'existe pas\n",
    "\n",
    "        except jpype.JException as e_cl_reason:\n",
    "            print(f\"❌ Erreur Java lors du calcul du modèle CL: {e_cl_reason.message()}\")\n",
    "\n",
    "    except ImportError as e:\n",
    "        print(f\"❌ Erreur d'import pour CL : {e}. Vérifiez le JAR logics.cl.\")\n",
    "    except jpype.JException as e_java:\n",
    "        print(f\"❌ Erreur Java générale dans l'exemple CL: {e_java.message()}\")\n",
    "        # print(e_java.stacktrace())\n",
    "    except Exception as e_gen:\n",
    "        print(f\"❌ Erreur Python inattendue dans l'exemple CL: {e_gen}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf29085",
   "metadata": {},
   "source": [
    "## Partie 3 : Révision de Croyances et Analyse d'Incohérence\n",
    "<a id=\"partie3\"></a>\n",
    "\n",
    "Cette partie aborde des mécanismes de raisonnement plus avancés : comment mettre à jour des croyances face à de nouvelles informations (révision) et comment quantifier ou gérer les contradictions (incohérence). Nous nous concentrerons principalement sur la logique propositionnelle pour ces exemples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e269ed08",
   "metadata": {},
   "source": [
    "### 3.1 Révision de Croyances Multi-Agents (CrMas)\n",
    "<a id=\"3.1\"></a>\n",
    "\n",
    "La révision de croyances s'intéresse à l'intégration de nouvelles informations dans une base de connaissances existante, en résolvant les éventuelles contradictions de manière rationnelle (cf. postulats AGM). Tweety implémente notamment des approches pour des bases de croyances **multi-agents** où chaque information est associée à un **agent** et où un **ordre de crédibilité** peut exister entre ces agents.\n",
    "\n",
    "* **`CrMasBeliefSet`** : Base de croyances multi-agents, nécessite un `Order<Agent>`.\n",
    "* **`InformationObject`** : Encapsule une formule et l'agent source.\n",
    "* **Opérateurs de Révision** (`org.tweetyproject.beliefdynamics.mas`) :\n",
    "    * `CrMasRevisionWrapper`: Utilise un opérateur de révision classique (ex: Levi) sur les formules, en ignorant la structure multi-agents sauf pour prioriser la nouvelle information.\n",
    "    * `CrMasSimpleRevisionOperator`: Prend en compte la crédibilité des agents de manière simple pour fusionner les informations.\n",
    "    * `CrMasArgumentativeRevisionOperator`: Modélise la révision comme un processus argumentatif où les informations des agents plus crédibles peuvent \"attaquer\" celles des agents moins crédibles.\n",
    "\n",
    "L'exemple suivant reprend la logique de `CrMasExample.java` et du TP C#."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d84f86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3.1 Révision de Croyances Multi-Agents (CrMas) ---\n",
    "print(\"\\n--- 3.1 Révision de Croyances Multi-Agents (CrMas) ---\")\n",
    "\n",
    "# Vérifier si la JVM est prête et si les imports précédents étaient OK\n",
    "if not jvm_ready:\n",
    "    print(\"❌ ERREUR: JVM non démarrée. Impossible de continuer cet exemple.\")\n",
    "# Utiliser la variable globale définie dans la cellule précédente\n",
    "elif 'CrMas_Imports_OK' not in globals() or not CrMas_Imports_OK:\n",
    "     print(\"❌ ERREUR: Imports CrMas échoués dans la cellule précédente. Impossible d'exécuter.\")\n",
    "else:\n",
    "    print(\"ℹ️ JVM prête et imports CrMas OK. Exécution de l'exemple CrMas...\")\n",
    "    try:\n",
    "        # Les imports ont déjà été tentés/réussis dans la cellule précédente.\n",
    "        # On réimporte juste ce qui est nécessaire localement pour la clarté\n",
    "        # Ou on utilise les références chargées (si JClass a été utilisé)\n",
    "\n",
    "        import jpype\n",
    "        from jpype.types import *\n",
    "\n",
    "        # Références aux classes (soit importées, soit chargées via JClass)\n",
    "        # Si JClass a été utilisé, ces variables existent déjà globalement\n",
    "        # Si l'import direct a marché, elles sont dans le scope global\n",
    "        if 'InformationObject' not in globals(): InformationObject = jpype.JClass(\"org.tweetyproject.beliefdynamics.InformationObject\")\n",
    "        if 'CrMasBeliefSet' not in globals(): CrMasBeliefSet = jpype.JClass(\"org.tweetyproject.beliefdynamics.mas.CrMasBeliefSet\")\n",
    "        if 'CrMasRevisionWrapper' not in globals(): CrMasRevisionWrapper = jpype.JClass(\"org.tweetyproject.beliefdynamics.mas.CrMasRevisionWrapper\")\n",
    "        if 'CrMasSimpleRevisionOperator' not in globals(): CrMasSimpleRevisionOperator = jpype.JClass(\"org.tweetyproject.beliefdynamics.mas.CrMasSimpleRevisionOperator\")\n",
    "        if 'CrMasArgumentativeRevisionOperator' not in globals(): CrMasArgumentativeRevisionOperator = jpype.JClass(\"org.tweetyproject.beliefdynamics.mas.CrMasArgumentativeRevisionOperator\")\n",
    "        if 'LeviMultipleBaseRevisionOperator' not in globals(): LeviMultipleBaseRevisionOperator = jpype.JClass(\"org.tweetyproject.beliefdynamics.operators.LeviMultipleBaseRevisionOperator\")\n",
    "        if 'DefaultMultipleBaseExpansionOperator' not in globals(): DefaultMultipleBaseExpansionOperator = jpype.JClass(\"org.tweetyproject.beliefdynamics.operators.DefaultMultipleBaseExpansionOperator\")\n",
    "        if 'KernelContractionOperator' not in globals(): KernelContractionOperator = jpype.JClass(\"org.tweetyproject.beliefdynamics.kernels.KernelContractionOperator\")\n",
    "        if 'RandomIncisionFunction' not in globals(): RandomIncisionFunction = jpype.JClass(\"org.tweetyproject.beliefdynamics.kernels.RandomIncisionFunction\")\n",
    "        if 'Agent' not in globals(): Agent = jpype.JClass(\"org.tweetyproject.agents.Agent\")\n",
    "        if 'DummyAgent' not in globals(): DummyAgent = jpype.JClass(\"org.tweetyproject.agents.DummyAgent\")\n",
    "        if 'Order' not in globals(): Order = jpype.JClass(\"org.tweetyproject.comparator.Order\")\n",
    "\n",
    "        # Imports Java util et PL (devraient être OK)\n",
    "        from java.util import ArrayList, HashSet, Collection, List as JavaList\n",
    "        from org.tweetyproject.logics.pl.parser import PlParser\n",
    "        from org.tweetyproject.logics.pl.syntax import PlFormula, PlSignature\n",
    "        from org.tweetyproject.logics.pl.reasoner import SimplePlReasoner, PlReasoner\n",
    "\n",
    "        # Classes Java nécessaires pour les casts\n",
    "        PlFormula_class = jpype.JClass(\"org.tweetyproject.logics.pl.syntax.PlFormula\")\n",
    "        Agent_class = jpype.JClass(\"org.tweetyproject.agents.Agent\")\n",
    "        PlReasoner_class = jpype.JClass(\"org.tweetyproject.logics.pl.reasoner.PlReasoner\")\n",
    "        Collection_class = jpype.JClass(\"java.util.Collection\")\n",
    "\n",
    "\n",
    "        # --- Initialisation ---\n",
    "        parser = PlParser()\n",
    "        agents_list = ArrayList() # Utiliser ArrayList Java\n",
    "        agent1 = DummyAgent(\"A1\"); agent2 = DummyAgent(\"A2\"); agent3 = DummyAgent(\"A3\")\n",
    "        agents_list.add(agent1); agents_list.add(agent2); agents_list.add(agent3)\n",
    "\n",
    "        # Ordre de crédibilité: A1 > A2 > A3\n",
    "        # Order(Collection<Agent>)\n",
    "        credOrder = Order(JObject(agents_list, Collection_class))\n",
    "        credOrder.setOrderedBefore(agent1, agent2)\n",
    "        credOrder.setOrderedBefore(agent2, agent3)\n",
    "        print(\"\\nOrdre de crédibilité:\", str(credOrder))\n",
    "\n",
    "        # Base de croyances initiale\n",
    "        pl_sig_empty = PlSignature()\n",
    "        # CrMasBeliefSet(Order<Agent>, Signature)\n",
    "        base = CrMasBeliefSet(credOrder, pl_sig_empty)\n",
    "        print(\"Base initiale (vide):\", str(base))\n",
    "\n",
    "        # Ajout InformationObject\n",
    "        # InformationObject(Formula, Agent)\n",
    "        info1_formula = parser.parseFormula(\"!c\")\n",
    "        info1_agent = agent2\n",
    "        # Cast explicite pour lever toute ambiguïté potentielle\n",
    "        info1 = InformationObject(JObject(info1_formula, PlFormula_class), JObject(info1_agent, Agent_class))\n",
    "\n",
    "        info2_formula = parser.parseFormula(\"b\")\n",
    "        info2_agent = agent3\n",
    "        info2 = InformationObject(JObject(info2_formula, PlFormula_class), JObject(info2_agent, Agent_class))\n",
    "\n",
    "        info3_formula = parser.parseFormula(\"!b||!a\")\n",
    "        info3_agent = agent3\n",
    "        info3 = InformationObject(JObject(info3_formula, PlFormula_class), JObject(info3_agent, Agent_class))\n",
    "\n",
    "        base.add(info1); base.add(info2); base.add(info3)\n",
    "        print(\"Base après ajouts:\", str(base))\n",
    "\n",
    "        # Nouvelles informations\n",
    "        news_collection = HashSet() # Utiliser HashSet Java\n",
    "        news1_formula = parser.parseFormula(\"a\")\n",
    "        news1_agent = agent3\n",
    "        news_collection.add(InformationObject(JObject(news1_formula, PlFormula_class), JObject(news1_agent, Agent_class)))\n",
    "\n",
    "        news2_formula = parser.parseFormula(\"!a||c\")\n",
    "        news2_agent = agent3\n",
    "        news_collection.add(InformationObject(JObject(news2_formula, PlFormula_class), JObject(news2_agent, Agent_class)))\n",
    "\n",
    "\n",
    "        # Affichage lisible\n",
    "        news_str = \", \".join([str(info.getFormula())+\" (\"+str(info.getSource().getName())+\")\" for info in news_collection])\n",
    "        print(f\"\\nNouvelles infos: {{ {news_str} }}\")\n",
    "        print(f\"\\nCalcul des révisions pour : {base} * {{ {news_str} }}\")\n",
    "\n",
    "        # --- Opérateurs de Révision ---\n",
    "\n",
    "        # 1) Révision priorisée simple (Levi Wrapper)\n",
    "        print(\"\\n1. Révision Priorisée Simple (Levi Wrapper):\")\n",
    "        try:\n",
    "            # Utiliser les classes chargées\n",
    "            # KernelContractionOperator(IncisionFunction, PlReasoner)\n",
    "            incision_func = RandomIncisionFunction()\n",
    "            # Utiliser un SimplePlReasoner, caster en PlReasoner pour le constructeur\n",
    "            pl_reasoner_instance = SimplePlReasoner()\n",
    "            kernel_contract = KernelContractionOperator(incision_func, JObject(pl_reasoner_instance, PlReasoner_class))\n",
    "            # LeviMultipleBaseRevisionOperator(BaseContractionOperator, BaseExpansionOperator)\n",
    "            levi_operator = LeviMultipleBaseRevisionOperator(kernel_contract, DefaultMultipleBaseExpansionOperator())\n",
    "            # CrMasRevisionWrapper(MultipleBaseRevisionOperator)\n",
    "            revision_prio = CrMasRevisionWrapper(levi_operator)\n",
    "\n",
    "            # revise(CrMasBeliefSet, Collection<InformationObject>)\n",
    "            result_prio = revision_prio.revise(base, JObject(news_collection, Collection_class))\n",
    "            print(\"   Résultat PRIO       :\", str(result_prio))\n",
    "        except jpype.JException as e_prio:\n",
    "             print(f\"   ❌ Erreur Java (PRIO): {e_prio.message()}\")\n",
    "             # print(e_prio.stacktrace()) # Pour debug\n",
    "        except Exception as e_prio_py:\n",
    "             print(f\"   ❌ Erreur Python (PRIO): {e_prio_py}\")\n",
    "             import traceback; traceback.print_exc()\n",
    "\n",
    "\n",
    "        # 2) Révision non priorisée simple (Crédibilité)\n",
    "        print(\"\\n2. Révision Non-Priorisée Simple (Crédibilité):\")\n",
    "        try:\n",
    "            revision_nonprio = CrMasSimpleRevisionOperator()\n",
    "            result_nonprio = revision_nonprio.revise(base, JObject(news_collection, Collection_class))\n",
    "            print(\"   Résultat N-PRIO CRED:\", str(result_nonprio))\n",
    "        except jpype.JException as e_nonprio:\n",
    "             print(f\"   ❌ Erreur Java (N-PRIO): {e_nonprio.message()}\")\n",
    "             # print(e_nonprio.stacktrace())\n",
    "        except Exception as e_nonprio_py:\n",
    "             print(f\"   ❌ Erreur Python (N-PRIO): {e_nonprio_py}\")\n",
    "             import traceback; traceback.print_exc()\n",
    "\n",
    "        # 3) Révision argumentative (Crédibilité)\n",
    "        print(\"\\n3. Révision Argumentative (Crédibilité):\")\n",
    "        try:\n",
    "            revision_arg = CrMasArgumentativeRevisionOperator()\n",
    "            result_arg = revision_arg.revise(base, JObject(news_collection, Collection_class))\n",
    "            print(\"   Résultat ARG        :\", str(result_arg))\n",
    "        except jpype.JException as e_arg:\n",
    "             print(f\"   ❌ Erreur Java (ARG): {e_arg.message()}\")\n",
    "             # print(e_arg.stacktrace())\n",
    "        except Exception as e_arg_py:\n",
    "             print(f\"   ❌ Erreur Python (ARG): {e_arg_py}\")\n",
    "             import traceback; traceback.print_exc()\n",
    "\n",
    "\n",
    "    # Gestion globale des erreurs\n",
    "    except ImportError as e:\n",
    "        print(f\"❌ Erreur d'import initiale pour CrMas : {e}\") # Ne devrait pas arriver ici\n",
    "    except jpype.JException as e_java:\n",
    "        print(f\"❌ Erreur Java générale dans l'exemple CrMas: {e_java.message()}\")\n",
    "        print(e_java.stacktrace())\n",
    "    except Exception as e_gen:\n",
    "        print(f\"❌ Erreur Python inattendue dans l'exemple CrMas: {e_gen}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "753da350",
   "metadata": {},
   "source": [
    "### 3.2 Mesures d'Incohérence (PL)\n",
    "<a id=\"3.2\"></a>\n",
    "\n",
    "Mesurer le degré d'incohérence d'une base de connaissances propositionnelle.\n",
    "\n",
    "* **`ContensionInconsistencyMeasure`**: Basée sur le nombre minimal de variables à assigner pour trouver un modèle.\n",
    "* **`MaInconsistencyMeasure` / `McscInconsistencyMeasure`**: Basées sur les MUS (Minimal Unsatisfiable Subsets). Nécessitent un énumérateur de MUS (ex: `MarcoMusEnumerator` externe ou `NaiveMusEnumerator` interne).\n",
    "* **`FuzzyInconsistencyMeasure`**: Utilise une sémantique floue pour évaluer la satisfaction des formules.\n",
    "* **`DSum/DMax/DHitInconsistencyMeasure`**: Basées sur la distance (ex: distance de Dalal) entre la base et les mondes possibles les plus proches la satisfaisant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d97aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3.2 Mesures d'Incohérence (PL) ---\n",
    "print(\"\\n--- 3.2 Mesures d'Incohérence (PL) ---\")\n",
    "\n",
    "if not jvm_ready:\n",
    "    print(\"❌ ERREUR: JVM non démarrée.\")\n",
    "else:\n",
    "    print(\"ℹ️ JVM prête. Exécution des exemples de mesures d'incohérence...\")\n",
    "    imports_inc_ok = False\n",
    "    try:\n",
    "        # *** AJOUT : Vérification des imports DANS cette cellule ***\n",
    "        print(\"   Vérification imports PL de base DANS la cellule 31...\")\n",
    "        import jpype\n",
    "        from jpype.types import *\n",
    "        from org.tweetyproject.logics.pl.syntax import PlBeliefSet, PlParser, PlFormula, PlSignature, Proposition\n",
    "        from org.tweetyproject.logics.pl.sat import Sat4jSolver, SatSolver\n",
    "        print(\"   ✔️ Imports PL de base réussis DANS la cellule 31.\")\n",
    "        # *** FIN AJOUT ***\n",
    "\n",
    "        # Imports spécifiques aux mesures\n",
    "        from java.util import HashSet, Collection # HashSet requis pour DSum/DMax/DHit\n",
    "        from org.tweetyproject.logics.pl.semantics import PossibleWorldIterator, DalalDistance # Pour DSum/DMax/DHit\n",
    "        from org.tweetyproject.math.func.fuzzy import ProductNorm # Pour Fuzzy\n",
    "        from org.tweetyproject.logics.pl.analysis import ContensionInconsistencyMeasure, FuzzyInconsistencyMeasure\n",
    "        from org.tweetyproject.logics.pl.analysis import DSumInconsistencyMeasure, DMaxInconsistencyMeasure, DHitInconsistencyMeasure\n",
    "        from org.tweetyproject.logics.commons.analysis import NaiveMusEnumerator, BeliefSetInconsistencyMeasure # Interface commune\n",
    "        # Importer Ma/Mcsc spécifiquement ici\n",
    "        from org.tweetyproject.logics.pl.analysis import MaInconsistencyMeasure, McscInconsistencyMeasure\n",
    "\n",
    "        print(\"✔️ Imports pour Mesures d'Incohérence réussis.\")\n",
    "        imports_inc_ok = True\n",
    "\n",
    "        # --- Configuration ---\n",
    "        parser_inc = PlParser()\n",
    "        SatSolver.setDefaultSolver(Sat4jSolver()) # Nécessaire pour certaines mesures\n",
    "\n",
    "        # --- Exemples ---\n",
    "        # (Le reste du code de la cellule 31 reste identique à ma proposition précédente)\n",
    "        # ... (Collé ici pour référence, mais inchangé fonctionnellement)\n",
    "\n",
    "        # 1. Contension (Basé sur ContensionExample.java)\n",
    "        print(\"\\n--- Mesure Contension ---\")\n",
    "        kb_cont = PlBeliefSet()\n",
    "        formulas_cont = [\"a\", \"!a && b\", \"!b\", \"c || a\", \"!c || a\", \"!c || d\", \"!d\", \"d\", \"c\"]\n",
    "        for f_str in formulas_cont: kb_cont.add(parser_inc.parseFormula(f_str))\n",
    "        print(\"KB:\", kb_cont)\n",
    "        try:\n",
    "            cont_measure = ContensionInconsistencyMeasure()\n",
    "            cont_value = cont_measure.inconsistencyMeasure(kb_cont)\n",
    "            print(f\"Valeur Contension: {cont_value}\")\n",
    "        except Exception as e_cont:\n",
    "            print(f\"❌ Erreur Contension: {e_cont}\")\n",
    "\n",
    "        # 2. Fuzzy (Basé sur FuzzyMeasureExample.java)\n",
    "        print(\"\\n--- Mesure Fuzzy ---\")\n",
    "        kb_fuzzy = PlBeliefSet()\n",
    "        formulas_fuzzy = [\"a && !a\", \"!(!(a && !a))\", \"a && a\"] # Exemple simplifié\n",
    "        for f_str in formulas_fuzzy: kb_fuzzy.add(parser_inc.parseFormula(f_str))\n",
    "        print(\"KB:\", kb_fuzzy)\n",
    "        try:\n",
    "            # FuzzyInconsistencyMeasure(TNorm, int type) ; Type 0: SUMFUZZY_MEASURE\n",
    "            fuzzy_measure = FuzzyInconsistencyMeasure(ProductNorm(), FuzzyInconsistencyMeasure.SUMFUZZY_MEASURE)\n",
    "            fuzzy_value = fuzzy_measure.inconsistencyMeasure(kb_fuzzy)\n",
    "            print(f\"Valeur Fuzzy (ProductNorm, Sum): {fuzzy_value}\")\n",
    "        except Exception as e_fuzzy:\n",
    "            print(f\"❌ Erreur Fuzzy: {e_fuzzy}\")\n",
    "\n",
    "        # 3. DSum / DMax / DHit (Basé sur InconsistancyMeasures C#)\n",
    "        print(\"\\n--- Mesures Basées sur Distance (Dalal) ---\")\n",
    "        kb_dist_collection = HashSet()\n",
    "        f1_dist = parser_inc.parseFormula(\"a && b && c\")\n",
    "        f2_dist = parser_inc.parseFormula(\"!a && !b && !c\")\n",
    "        kb_dist_collection.add(f1_dist)\n",
    "        kb_dist_collection.add(f2_dist)\n",
    "        print(\"Collection de formules:\", kb_dist_collection)\n",
    "        sig_dist = PlSignature()\n",
    "        sig_dist.addAll(f1_dist.getSignature())\n",
    "        sig_dist.addAll(f2_dist.getSignature())\n",
    "        print(\"Signature:\", sig_dist)\n",
    "        if not sig_dist.isEmpty():\n",
    "            try:\n",
    "                pw_iter_dist = PossibleWorldIterator(sig_dist)\n",
    "                dalal_dist = DalalDistance()\n",
    "                dsum_measure = DSumInconsistencyMeasure(dalal_dist, pw_iter_dist)\n",
    "                dsum_value = dsum_measure.inconsistencyMeasure(kb_dist_collection)\n",
    "                print(f\"Valeur DSum: {dsum_value}\")\n",
    "                dmax_measure = DMaxInconsistencyMeasure(dalal_dist, pw_iter_dist)\n",
    "                dmax_value = dmax_measure.inconsistencyMeasure(kb_dist_collection)\n",
    "                print(f\"Valeur DMax: {dmax_value}\")\n",
    "                dhit_measure = DHitInconsistencyMeasure(dalal_dist, pw_iter_dist)\n",
    "                dhit_value = dhit_measure.inconsistencyMeasure(kb_dist_collection)\n",
    "                print(f\"Valeur DHit: {dhit_value}\")\n",
    "            except jpype.JException as e_dist_java:\n",
    "                 print(f\"❌ Erreur Java (Mesures Distance): {e_dist_java.message()}\")\n",
    "            except Exception as e_dist_py:\n",
    "                 print(f\"❌ Erreur Python (Mesures Distance): {e_dist_py}\")\n",
    "        else:\n",
    "            print(\"⚠️ Signature vide, impossible de calculer les mesures basées sur la distance.\")\n",
    "\n",
    "        # 4. Mesures Ma et Mcsc (nécessitent MUS - voir section suivante)\n",
    "        print(\"\\n--- Mesures Ma / Mcsc (nécessitent énumération MUS - voir 3.3) ---\")\n",
    "        kb_mus_demo = PlBeliefSet()\n",
    "        formulas_mus_demo = [\"a\", \"!a\", \"!a && !b\", \"b\"]\n",
    "        for f_str in formulas_mus_demo: kb_mus_demo.add(parser_inc.parseFormula(f_str))\n",
    "        print(\"KB pour démo Ma/Mcsc:\", kb_mus_demo)\n",
    "        try:\n",
    "            mus_enum_naive = NaiveMusEnumerator(SatSolver.getDefaultSolver())\n",
    "            ma_measure_naive = MaInconsistencyMeasure(mus_enum_naive)\n",
    "            ma_value = ma_measure_naive.inconsistencyMeasure(kb_mus_demo)\n",
    "            print(f\"Valeur Ma (Naive): {ma_value}\")\n",
    "            mcsc_measure_naive = McscInconsistencyMeasure(mus_enum_naive)\n",
    "            mcsc_value = mcsc_measure_naive.inconsistencyMeasure(kb_mus_demo)\n",
    "            print(f\"Valeur Mcsc (Naive): {mcsc_value}\")\n",
    "        except Exception as e_ma_mcsc:\n",
    "             print(f\"❌ Erreur calcul Ma/Mcsc (Naive): {e_ma_mcsc}\")\n",
    "\n",
    "    # Gestion globale (inchangée)\n",
    "    except ImportError as e:\n",
    "        # Cette erreur sera maintenant plus spécifique si elle vient des vérifications ajoutées\n",
    "        print(f\"❌ Erreur d'import pour Mesures d'Incohérence : {e}\")\n",
    "    except jpype.JException as e_java:\n",
    "        print(f\"❌ Erreur Java générale dans Mesures d'Incohérence: {e_java.message()}\")\n",
    "        # print(e_java.stacktrace())\n",
    "    except Exception as e_gen:\n",
    "        print(f\"❌ Erreur Python inattendue dans Mesures d'Incohérence: {e_gen}\")\n",
    "        import traceback; traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e41e9a0b",
   "metadata": {},
   "source": [
    "### 3.3 Énumération de MUS (Minimal Unsatisfiable Subsets)\n",
    "<a id=\"3.3\"></a>\n",
    "\n",
    "Un Sous-ensemble Minimal Inconsistant (MUS) d'une base de connaissances $KB$ est un sous-ensemble $M \\subseteq KB$ tel que $M$ est inconsistant, mais tout sous-ensemble propre de $M$ est consistant. Trouver les MUS est utile pour diagnostiquer les sources d'incohérence.\n",
    "\n",
    "* **`NaiveMusEnumerator`**: Implémentation simple mais potentiellement très lente, intégrée à Tweety.\n",
    "* **`MarcoMusEnumerator`**: Interface avec l'outil externe `marco.py`, beaucoup plus efficace. Nécessite d'installer MARCO et de fournir le chemin vers `marco.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5210fa12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # --- 3.3 Énumération de MUS ---\n",
    "# from org.tweetyproject.logics.pl.syntax import PlBeliefSet, PlParser\n",
    "# from org.tweetyproject.logics.pl.sat import Sat4jSolver, SatSolver\n",
    "# from org.tweetyproject.logics.commons.analysis import NaiveMusEnumerator\n",
    "# # from org.tweetyproject.logics.pl.sat import MarcoMusEnumerator # Décommenter si Marco est configuré\n",
    "# # from org.tweetyproject.logics.pl.util import CnfSampler # Pour générer des KB aléatoires\n",
    "# # from org.tweetyproject.logics.pl.syntax import PropositionalSignature, Proposition # Pour CnfSampler\n",
    "\n",
    "# # --- Configuration ---\n",
    "# parser_mus = PlParser()\n",
    "# SatSolver.setDefaultSolver(Sat4jSolver())\n",
    "\n",
    "# # Exemple simple (MusExample.java simplifié)\n",
    "# kb_mus_ex = PlBeliefSet()\n",
    "# formulas_mus_ex = [\"a\", \"!a\", \"!a && !b\", \"b\", \"c\", \"!c\", \"!a || !c\"]\n",
    "# for f_str in formulas_mus_ex: kb_mus_ex.add(parser_mus.parseFormula(f_str))\n",
    "\n",
    "# print(\"KB pour MUS:\\n\", kb_mus_ex)\n",
    "\n",
    "# # --- Énumération ---\n",
    "\n",
    "# # Option 1: NaiveMusEnumerator\n",
    "# print(\"\\nCalcul des MUS (Naive Enumerator - peut être lent):\")\n",
    "# try:\n",
    "#     mus_enum_naive = NaiveMusEnumerator(SatSolver.getDefaultSolver())\n",
    "#     all_mus_naive = mus_enum_naive.minimalInconsistentSubsets(kb_mus_ex)\n",
    "#     print(f\" - Trouvé {len(all_mus_naive)} MUS:\")\n",
    "#     for mus in all_mus_naive:\n",
    "#         print(f\"   - {mus}\")\n",
    "# except Exception as e:\n",
    "#     print(f\"❌ Erreur NaiveMusEnumerator: {e}\")\n",
    "\n",
    "# # Option 2: MarcoMusEnumerator (Externe)\n",
    "# # MARCO_PATH = \"/path/to/your/marco.py\" # <--- MODIFIEZ CECI\n",
    "# # if pathlib.Path(MARCO_PATH).exists():\n",
    "# #     print(\"\\nCalcul des MUS (Marco Enumerator):\")\n",
    "# #     try:\n",
    "# #         mus_enum_marco = MarcoMusEnumerator(MARCO_PATH)\n",
    "# #         all_mus_marco = mus_enum_marco.minimalInconsistentSubsets(kb_mus_ex)\n",
    "# #         print(f\" - Trouvé {len(all_mus_marco)} MUS:\")\n",
    "# #         for mus in all_mus_marco:\n",
    "# #             print(f\"   - {mus}\")\n",
    "# #     except Exception as e:\n",
    "# #         print(f\"❌ Erreur MarcoMusEnumerator: {e}\")\n",
    "# # else:\n",
    "# #     print(\"\\nMarco MUS Enumerator non trouvé/configuré, test externe sauté.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a35f77eb",
   "metadata": {},
   "source": [
    "### 3.4 MaxSAT\n",
    "<a id=\"3.4\"></a>\n",
    "\n",
    "MaxSAT (Maximum Satisfiability) est une généralisation du problème SAT. Étant donné un ensemble de clauses \"dures\" (qui doivent être satisfaites) et un ensemble de clauses \"molles\" (qui peuvent être violées, souvent avec un coût/poids associé), MaxSAT cherche une assignation qui satisfait toutes les clauses dures et minimise le coût total des clauses molles violées (ou maximise le poids des clauses molles satisfaites).\n",
    "\n",
    "Tweety intègre des solveurs MaxSAT externes comme **Open-WBO**.\n",
    "\n",
    "* **`MaxSatSolver`**: Interface abstraite.\n",
    "* **`OpenWboSolver`**: Implémentation pour Open-WBO (nécessite chemin).\n",
    "* **Entrée**: Une `PlBeliefSet` pour les clauses dures, et une `Map<PlFormula, Integer>` pour les clauses molles et leurs poids (coûts de violation).\n",
    "* **Sortie**: Une `Interpretation` (un `PossibleWorld`) qui est une solution optimale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb25959",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # --- 3.4 MaxSAT ---\n",
    "# from org.tweetyproject.logics.pl.syntax import PlBeliefSet, PlParser, PlFormula\n",
    "# from org.tweetyproject.logics.pl.semantics import PossibleWorld # Interpretation est typiquement un PossibleWorld\n",
    "# # from org.tweetyproject.logics.pl.sat import MaxSatSolver, OpenWboSolver # Décommenter si OpenWBO est configuré\n",
    "# from java.util import HashMap\n",
    "\n",
    "# # --- Configuration ---\n",
    "# parser_maxsat = PlParser()\n",
    "\n",
    "# # Clauses Dures (doivent être satisfaites)\n",
    "# hard_clauses_bs = PlBeliefSet()\n",
    "# hard_formulas = [\"!a && b\", \"b || c\", \"c || d\", \"f || (c && g)\"]\n",
    "# for f_str in hard_formulas: hard_clauses_bs.add(parser_maxsat.parseFormula(f_str))\n",
    "\n",
    "# # Clauses Molles (avec poids/coût de violation)\n",
    "# # Utiliser HashMap Java: Map<PlFormula, Integer>\n",
    "# soft_clauses_map = HashMap()\n",
    "# soft_clauses_map.put(parser_maxsat.parseFormula(\"a || !b\"), 25) # violer coûte 25\n",
    "# soft_clauses_map.put(parser_maxsat.parseFormula(\"!c\"), 15)      # violer coûte 15\n",
    "\n",
    "# print(\"--- MaxSAT ---\")\n",
    "# print(\"Clauses Dures:\", hard_clauses_bs)\n",
    "# print(\"Clauses Molles:\", soft_clauses_map) # L'affichage peut être technique\n",
    "\n",
    "# # --- Résolution (nécessite OpenWBO) ---\n",
    "# # OPENWBO_PATH = \"/path/to/your/open-wbo_exec\" # <--- MODIFIEZ CECI\n",
    "# # if pathlib.Path(OPENWBO_PATH).exists():\n",
    "# #     print(\"\\nRésolution MaxSAT (OpenWBO):\")\n",
    "# #     try:\n",
    "# #         maxsat_solver = OpenWboSolver(OPENWBO_PATH)\n",
    "# #         # Note: MaxSatSolver.getWitness prend (BeliefSet<Hard>, Map<Soft, Weight>)\n",
    "# #         witness_maxsat = maxsat_solver.getWitness(hard_clauses_bs, soft_clauses_map)\n",
    "\n",
    "# #         if witness_maxsat:\n",
    "# #             print(\" - Solution (Interpretation):\", witness_maxsat)\n",
    "# #             # Calculer le coût de la solution\n",
    "# #             # Note: MaxSatSolver.costOf n'est pas statique dans l'exemple Java, il faut une instance\n",
    "# #             cost = maxsat_solver.costOf(witness_maxsat, hard_clauses_bs, soft_clauses_map)\n",
    "# #             print(f\" - Coût de la solution (clauses molles violées * poids): {cost}\")\n",
    "\n",
    "# #             # Vérifier si les clauses dures sont satisfaites\n",
    "# #             print(f\"   - Les clauses dures sont satisfaites? {witness_maxsat.satisfies(hard_clauses_bs)}\")\n",
    "# #         else:\n",
    "# #             print(\" - Aucune solution trouvée (potentiellement clauses dures inconsistantes).\")\n",
    "\n",
    "# #     except Exception as e:\n",
    "# #          print(f\"❌ Erreur OpenWboSolver: {e}\")\n",
    "# # else:\n",
    "# #      print(\"\\nOpen-WBO non trouvé/configuré, test MaxSAT externe sauté.\")\n",
    "# print(\"\\n(Section MaxSAT nécessite la configuration du chemin vers OpenWBO)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f36b8ea",
   "metadata": {},
   "source": [
    "## Partie 4 : Argumentation Abstraite et Structurée\n",
    "<a id=\"partie4\"></a>\n",
    "\n",
    "Nous entrons maintenant au cœur de l'argumentation computationnelle, en commençant par le cadre fondateur de Dung et en progressant vers des approches qui prennent en compte la structure interne des arguments. Cette partie est souvent plus stable car elle repose sur des modules centraux de Tweety."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0772b0f0",
   "metadata": {},
   "source": [
    "### 4.1 Cadres d'Argumentation Abstraits (Dung)\n",
    "<a id=\"4.1\"></a>\n",
    "\n",
    "Le cadre de Dung (Abstract Argumentation Framework - AAF) est la base de nombreuses extensions. Il modélise les conflits entre arguments de manière abstraite.\n",
    "\n",
    "* Un ensemble d'**Arguments** (`Argument`) considérés comme des entités atomiques.\n",
    "* Une relation d'**Attaque** (`Attack`) binaire entre arguments ($a$ attaque $b$).\n",
    "* L'ensemble forme une **Théorie de Dung** (`DungTheory`).\n",
    "\n",
    "L'objectif est de déterminer des ensembles d'arguments collectivement acceptables, appelés **extensions**, selon différentes **sémantiques** (Conflict-Free, Admissible, Complete, Grounded, Preferred, Stable, etc.). Tweety fournit des **raisonneurs** (`org.tweetyproject.arg.dung.reasoner.*`) pour calculer ces extensions.\n",
    "\n",
    "* **Conflict-Free (CF)**: Aucun argument dans l'extension n'attaque un autre argument de l'extension.\n",
    "* **Admissible (ADM)**: Conflict-Free + chaque argument de l'extension est défendu par l'extension contre ses attaquants.\n",
    "* **Complete (COM)**: Admissible + contient tous les arguments qu'elle défend.\n",
    "* **Grounded (GR)**: L'extension complète minimale (calculée itérativement, sceptique).\n",
    "* **Preferred (PRF)**: Une extension complète maximale (par inclusion). Il peut y en avoir plusieurs (crédule).\n",
    "* **Stable (ST)**: Conflict-Free + attaque tous les arguments qui ne sont pas dans l'extension. Peut ne pas exister, mais si elle existe, elle est aussi Preferred et Complete.\n",
    "* **CF2**: Sémantique gérant les cycles impairs via la décomposition en Composantes Fortement Connexes (SCC).\n",
    "\n",
    "Tweety fournit des **raisonneurs** (`org.tweetyproject.arg.dung.reasoner.*`) pour calculer ces extensions (ex: `SimpleGroundedReasoner`, `SimpleStableReasoner`, `SccCF2Reasoner`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c07b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 4.1.1 Cadres d'Argumentation Abstraits (Dung) : Bases et Sémantiques ---\n",
    "print(\"\\n--- 4.1.1 Cadres d'Argumentation Abstraits (Dung) : Bases et Sémantiques ---\")\n",
    "\n",
    "# Vérifier si la JVM est prête\n",
    "if not jvm_ready:\n",
    "    print(\"❌ ERREUR: JVM non démarrée. Impossible de continuer cet exemple.\")\n",
    "else:\n",
    "    print(\"ℹ️ JVM prête. Exécution de l'exemple Dung...\")\n",
    "    try:\n",
    "        # Imports nécessaires pour Dung\n",
    "        import jpype\n",
    "        from jpype.types import *\n",
    "        from org.tweetyproject.arg.dung.syntax import DungTheory, Argument, Attack\n",
    "        # Importer plusieurs raisonneurs\n",
    "        from org.tweetyproject.arg.dung.reasoner import (\n",
    "            SimpleGroundedReasoner, SimpleStableReasoner, SimplePreferredReasoner,\n",
    "            SimpleCompleteReasoner, SimpleAdmissibleReasoner, SimpleConflictFreeReasoner\n",
    "        )\n",
    "        # Importer Semantics si besoin pour certains raisonneurs plus avancés (non utilisés ici)\n",
    "        # from org.tweetyproject.arg.dung.semantics import Semantics\n",
    "        from java.util import Collection # Pour vérifier taille retour\n",
    "\n",
    "        print(\"✔️ Imports Dung réussis.\")\n",
    "\n",
    "        # --- Exemple 1: A <-> B -> C ---\n",
    "        af1 = DungTheory()\n",
    "        a1 = Argument(\"a1\"); b1 = Argument(\"b1\"); c1 = Argument(\"c1\")\n",
    "        # Ajouter des arguments\n",
    "        af1.add(a1); af1.add(b1); af1.add(c1)\n",
    "        # Ajouter des attaques\n",
    "        af1.add(Attack(a1, b1)); af1.add(Attack(b1, a1)); af1.add(Attack(b1, c1))\n",
    "\n",
    "        print(\"\\n--- AF1: a1 <-> b1 -> c1 ---\")\n",
    "        print(\"Cadre :\", af1)\n",
    "\n",
    "        # Calculer les extensions pour différentes sémantiques\n",
    "        print(\"\\nCalcul des extensions pour AF1:\")\n",
    "        try:\n",
    "            # Grounded: getModel() retourne une Extension, getModels() retourne une Collection<Extension>\n",
    "            grounded_ext = SimpleGroundedReasoner().getModel(af1) # Plus direct pour grounded\n",
    "            print(f\" - Grounded   : {{{grounded_ext}}}\") # Afficher comme un ensemble pour la cohérence\n",
    "        except Exception as e: print(f\"   Erreur Grounded: {e}\")\n",
    "        try:\n",
    "            stable_exts = SimpleStableReasoner().getModels(af1)\n",
    "            print(f\" - Stable     ({stable_exts.size()}):\", stable_exts)\n",
    "        except Exception as e: print(f\"   Erreur Stable: {e}\")\n",
    "        try:\n",
    "            preferred_exts = SimplePreferredReasoner().getModels(af1)\n",
    "            print(f\" - Preferred  ({preferred_exts.size()}):\", preferred_exts)\n",
    "        except Exception as e: print(f\"   Erreur Preferred: {e}\")\n",
    "        try:\n",
    "            complete_exts = SimpleCompleteReasoner().getModels(af1)\n",
    "            print(f\" - Complete   ({complete_exts.size()}):\", complete_exts)\n",
    "        except Exception as e: print(f\"   Erreur Complete: {e}\")\n",
    "        try:\n",
    "            admissible_exts = SimpleAdmissibleReasoner().getModels(af1)\n",
    "            # Convertir la Collection Java en liste Python pour len()\n",
    "            # Note: Cela peut être coûteux si la collection est énorme\n",
    "            admissible_list = list(admissible_exts)\n",
    "            print(f\" - Admissible ({len(admissible_list)}):\", admissible_exts) # Afficher la collection Java\n",
    "        except Exception as e: print(f\"   Erreur Admissible: {e}\")\n",
    "        try:\n",
    "            conflict_free_exts = SimpleConflictFreeReasoner().getModels(af1)\n",
    "            cf_list = list(conflict_free_exts)\n",
    "            print(f\" - ConflictFree ({len(cf_list)}):\", conflict_free_exts) # Attention, peut être très grand\n",
    "        except Exception as e: print(f\"   Erreur ConflictFree: {e}\")\n",
    "\n",
    "\n",
    "        # --- Exemple 2: Cycle a->b->c->a ---\n",
    "        af_cycle = DungTheory()\n",
    "        a_cy = Argument(\"a_cy\"); b_cy = Argument(\"b_cy\"); c_cy = Argument(\"c_cy\")\n",
    "        af_cycle.add(a_cy); af_cycle.add(b_cy); af_cycle.add(c_cy)\n",
    "        af_cycle.add(Attack(a_cy, b_cy)); af_cycle.add(Attack(b_cy, c_cy)); af_cycle.add(Attack(c_cy, a_cy))\n",
    "\n",
    "        print(\"\\n--- AF Cycle: a -> b -> c -> a ---\")\n",
    "        print(\"Cadre :\", af_cycle)\n",
    "        print(\"\\nCalcul des extensions pour AF Cycle:\")\n",
    "        try:\n",
    "            print(\" - Grounded   :\", SimpleGroundedReasoner().getModel(af_cycle)) # {}\n",
    "        except Exception as e: print(f\"   Erreur Grounded: {e}\")\n",
    "        try:\n",
    "            stable_exts_cy = SimpleStableReasoner().getModels(af_cycle)\n",
    "            print(f\" - Stable     ({stable_exts_cy.size()}):\", stable_exts_cy) # {}\n",
    "        except Exception as e: print(f\"   Erreur Stable: {e}\")\n",
    "        try:\n",
    "            preferred_exts_cy = SimplePreferredReasoner().getModels(af_cycle)\n",
    "            print(f\" - Preferred  ({preferred_exts_cy.size()}):\", preferred_exts_cy) # [{}]\n",
    "        except Exception as e: print(f\"   Erreur Preferred: {e}\")\n",
    "        try:\n",
    "            complete_exts_cy = SimpleCompleteReasoner().getModels(af_cycle)\n",
    "            print(f\" - Complete   ({complete_exts_cy.size()}):\", complete_exts_cy) # [{}]\n",
    "        except Exception as e: print(f\"   Erreur Complete: {e}\")\n",
    "\n",
    "\n",
    "    except ImportError as e:\n",
    "        print(f\"❌ Erreur d'import pour l'Argumentation Abstraite : {e}\")\n",
    "        print(\"   Vérifiez le JAR 'org.tweetyproject.arg.dung'.\")\n",
    "    except jpype.JException as e_java:\n",
    "        print(f\"❌ Erreur Java générale dans l'exemple Dung: {e_java.message()}\")\n",
    "        # print(e_java.stacktrace()) # Décommenter pour trace Java complète\n",
    "    except Exception as e_gen:\n",
    "        print(f\"❌ Erreur Python inattendue dans l'exemple Dung: {e_gen}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd9e2eb",
   "metadata": {},
   "source": [
    "#### 4.1.2 Sémantique CF2\n",
    "<a id=\"4.1.2\"></a>\n",
    "\n",
    "La sémantique CF2 ([Baroni, Giacomin, Guida, *SCC-recursive semantics for abstract argumentation frameworks*, 2005](https://link.springer.com/chapter/10.1007/11557791_3)) est une alternative aux sémantiques classiques qui gère différemment les cycles, notamment les cycles impairs. Elle se base sur une décomposition du graphe d'argumentation en Composantes Fortement Connexes (SCCs). Tweety fournit le `SccCF2Reasoner`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50d3062",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 4.1.2 Sémantique CF2 ---\n",
    "print(\"\\n--- 4.1.2 Sémantique CF2 ---\")\n",
    "\n",
    "# Vérifier si la JVM est prête\n",
    "if not jvm_ready:\n",
    "    print(\"❌ ERREUR: JVM non démarrée. Impossible de continuer cet exemple.\")\n",
    "else:\n",
    "    print(\"ℹ️ JVM prête. Exécution de l'exemple CF2...\")\n",
    "    try:\n",
    "        # Imports (peuvent être déjà faits, mais sécurité)\n",
    "        import jpype\n",
    "        from jpype.types import *\n",
    "        from org.tweetyproject.arg.dung.syntax import DungTheory, Argument, Attack\n",
    "        from org.tweetyproject.arg.dung.reasoner import SccCF2Reasoner\n",
    "        from org.tweetyproject.arg.dung.semantics import Extension # Pour type hinting éventuel\n",
    "        from java.util import Collection\n",
    "\n",
    "        print(\"✔️ Imports Dung (pour CF2) réussis.\")\n",
    "\n",
    "        # --- Exemple AF2 : Cycle a->b->c->d->e->a, e->f ---\n",
    "        # (Recréation pour autonomie de la cellule)\n",
    "        af2 = DungTheory()\n",
    "        args_cf2_map = {name: Argument(name) for name in \"abcdef\"} # Utiliser un dictionnaire\n",
    "        for arg in args_cf2_map.values(): af2.add(arg)\n",
    "\n",
    "        attacks_cf2 = [(\"a\",\"b\"), (\"b\",\"c\"), (\"c\",\"d\"), (\"d\",\"e\"), (\"e\",\"a\"), (\"e\",\"f\")]\n",
    "        for s, t in attacks_cf2:\n",
    "             # S'assurer que les arguments existent avant d'ajouter l'attaque\n",
    "             if s in args_cf2_map and t in args_cf2_map:\n",
    "                  af2.add(Attack(args_cf2_map[s], args_cf2_map[t]))\n",
    "             else:\n",
    "                  print(f\"WARN: Argument(s) non trouvé(s) pour l'attaque ({s},{t})\")\n",
    "\n",
    "        print(\"\\n--- AF pour CF2 : Cycle a->b->c->d->e->a, e->f ---\")\n",
    "        print(\"Cadre :\", af2)\n",
    "\n",
    "        # --- Raisonnement CF2 ---\n",
    "        cf2_reasoner = SccCF2Reasoner()\n",
    "        print(\"\\nCalcul des extensions CF2:\")\n",
    "        try:\n",
    "            cf2_extensions_collection = cf2_reasoner.getModels(af2) # Retourne Collection<Extension>\n",
    "            if cf2_extensions_collection.isEmpty():\n",
    "                 print(\"  (Aucune extension CF2 trouvée)\")\n",
    "            else:\n",
    "                 # Itérer sur la collection Java\n",
    "                 ext_iterator = cf2_extensions_collection.iterator()\n",
    "                 count = 0\n",
    "                 while ext_iterator.hasNext():\n",
    "                      ext = ext_iterator.next()\n",
    "                      # Pour un affichage plus propre des arguments dans l'extension:\n",
    "                      args_in_ext = \", \".join(sorted([str(arg.getName()) for arg in ext]))\n",
    "                      print(f\"  - {{{args_in_ext}}}\")\n",
    "                      count += 1\n",
    "                 print(f\"  ({count} extension(s) trouvée(s))\")\n",
    "\n",
    "        except jpype.JException as e_cf2_java:\n",
    "             print(f\"  ❌ Erreur Java lors du raisonnement CF2: {e_cf2_java.message()}\")\n",
    "             # print(e_cf2_java.stacktrace())\n",
    "        except Exception as e_cf2_py:\n",
    "              print(f\"  ❌ Erreur Python lors du raisonnement CF2: {e_cf2_py}\")\n",
    "\n",
    "    # Gestion globale\n",
    "    except ImportError as e:\n",
    "        print(f\"❌ Erreur d'import pour CF2 : {e}. Vérifiez le JAR 'arg.dung'.\")\n",
    "    except jpype.JException as e_java:\n",
    "        print(f\"❌ Erreur Java générale dans l'exemple CF2: {e_java.message()}\")\n",
    "    except Exception as e_gen:\n",
    "        print(f\"❌ Erreur Python inattendue dans l'exemple CF2: {e_gen}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec4a75c",
   "metadata": {},
   "source": [
    "#### 4.1.3 Génération de Cadres d'Argumentation\n",
    "<a id=\"4.1.3\"></a>\n",
    "\n",
    "Tweety fournit des outils pour générer aléatoirement des cadres d'argumentation abstraits (`DungTheory`), ce qui est utile pour les tests, benchmarks ou simulations. `DefaultDungTheoryGenerator` est un générateur simple paramétrable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31064b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 4.1.3 Génération de Cadres Dung ---\n",
    "print(\"\\n--- 4.1.3 Génération de Cadres Dung ---\")\n",
    "\n",
    "if not jvm_ready:\n",
    "    print(\"❌ ERREUR: JVM non démarrée.\")\n",
    "else:\n",
    "    print(\"ℹ️ JVM prête. Exécution de l'exemple de génération...\")\n",
    "    try:\n",
    "        # Imports\n",
    "        import jpype\n",
    "        from jpype.types import *\n",
    "        from org.tweetyproject.arg.dung.syntax import DungTheory, Argument, Attack\n",
    "        from org.tweetyproject.arg.dung.util import DefaultDungTheoryGenerator, DungTheoryGenerationParameters\n",
    "\n",
    "        print(\"✔️ Imports pour génération Dung réussis.\")\n",
    "\n",
    "        # Paramètres de génération\n",
    "        params = DungTheoryGenerationParameters()\n",
    "        params.numberOfArguments = 6\n",
    "        params.attackProbability = 0.25\n",
    "        # CORRECTION: La ligne suivante est retirée car le champ n'existe probablement plus\n",
    "        # params.allowSelfAttacks = False\n",
    "        print(f\"ℹ️ Paramètres de génération: {params.numberOfArguments} args, proba_attaque={params.attackProbability} (comportement par défaut pour auto-attaques)\")\n",
    "\n",
    "        generator = DefaultDungTheoryGenerator(params)\n",
    "\n",
    "        # Générer UN cadre\n",
    "        generated_af = generator.next()\n",
    "\n",
    "        print(\"\\nCadre généré aléatoirement :\")\n",
    "        print(f\"  Arguments: {generated_af.getNodes()}\")\n",
    "        print(f\"  Attaques : {generated_af.getAttacks()}\")\n",
    "        print(f\"  Représentation compacte: {generated_af}\")\n",
    "\n",
    "    except ImportError as e:\n",
    "        print(f\"❌ Erreur d'import pour la génération Dung : {e}. Vérifiez le JAR 'arg.dung'.\")\n",
    "    except jpype.JException as e_java:\n",
    "        print(f\"❌ Erreur Java générale dans l'exemple génération Dung: {e_java.message()}\")\n",
    "        # print(e_java.stacktrace())\n",
    "    except Exception as e_gen:\n",
    "        print(f\"❌ Erreur Python inattendue dans l'exemple génération Dung: {e_gen}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e17ce72",
   "metadata": {},
   "source": [
    "#### 4.1.4 Apprentissage de Cadres d'Argumentation (depuis Labellisations)\n",
    "<a id=\"4.1.4\"></a>\n",
    "\n",
    "L'apprentissage de cadre vise à reconstruire un cadre d'argumentation (ou un ensemble de cadres possibles) à partir d'informations partielles, typiquement des exemples de labellisations d'arguments (IN, OUT, UNDEC) selon une certaine sémantique. Tweety propose `SimpleAFLearner` pour cela."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9e02a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 4.1.4 Apprentissage de Cadres Dung (depuis Labellisations) ---\n",
    "print(\"\\n--- 4.1.4 Apprentissage de Cadres Dung ---\")\n",
    "\n",
    "print(\"!! SECTION COMMENTÉE !!\")\n",
    "print(\"L'exécution de cet exemple échoue en raison d'une ClassCastException interne à Tweety\")\n",
    "print(\"(Tautology cannot be cast to AssociativePlFormula) lors de l'appel à getLabeling/learnLabeling\")\n",
    "print(\"pour le cadre d'argumentation spécifique utilisé ici. Ceci semble être un bug interne.\")\n",
    "\n",
    "# if not jvm_ready:\n",
    "#     print(\"❌ ERREUR: JVM non démarrée.\")\n",
    "# else:\n",
    "#     print(\"ℹ️ JVM prête. Exécution de l'exemple d'apprentissage...\")\n",
    "#     try:\n",
    "#         # Imports\n",
    "#         import jpype\n",
    "#         from jpype.types import *\n",
    "#         from org.tweetyproject.arg.dung.syntax import DungTheory, Argument, Attack\n",
    "#         from org.tweetyproject.arg.dung.learning import SimpleAFLearner\n",
    "#         from org.tweetyproject.arg.dung.learning.syntax import Entity\n",
    "#         from org.tweetyproject.arg.dung.semantics import Semantics\n",
    "#         # Import de Label retiré (correction précédente)\n",
    "#\n",
    "#         print(\"✔️ Imports pour apprentissage Dung réussis.\")\n",
    "#\n",
    "#         # 1. Définir le cadre \"caché\"\n",
    "#         hidden_af = DungTheory()\n",
    "#         a_learn = Argument(\"a\"); b_learn = Argument(\"b\"); c_learn = Argument(\"c\")\n",
    "#         hidden_af.add(a_learn); hidden_af.add(b_learn); hidden_af.add(c_learn)\n",
    "#         hidden_af.add(Attack(a_learn, b_learn)); hidden_af.add(Attack(b_learn, a_learn)); hidden_af.add(Attack(b_learn, c_learn))\n",
    "#         print(\"\\nCadre caché (à apprendre):\", hidden_af)\n",
    "#\n",
    "#         # 2. Créer l'Oracle\n",
    "#         oracle = Entity(hidden_af)\n",
    "#         arguments_known = oracle.getArguments()\n",
    "#         print(\"Arguments connus par l'apprenant:\", arguments_known)\n",
    "#\n",
    "#         # 3. Créer l'Apprenant\n",
    "#         learner = SimpleAFLearner(arguments_known)\n",
    "#         print(f\"État initial apprenant: {learner.getNumberOfFrameworks()} cadres compatibles possibles.\")\n",
    "#\n",
    "#         # 4. Apprendre depuis des labellisations\n",
    "#         # Labellisation Stable\n",
    "#         print(\"\\nApprentissage depuis labellisation Stable:\")\n",
    "#         try:\n",
    "#              labeling_stable = oracle.getLabeling(Semantics.STABLE_SEMANTICS) # C'est ici que l'erreur se produit\n",
    "#              print(f\"  Oracle fournit Labellisation STABLE: {labeling_stable}\")\n",
    "#              learner.learnLabeling(labeling_stable)\n",
    "#              print(f\"  Après STABLE: {learner.getNumberOfFrameworks()} cadres compatibles restants.\")\n",
    "#         except jpype.JException as e_stable:\n",
    "#               print(f\"  Erreur lors de l'obtention/apprentissage de la labellisation Stable: {e_stable.message()}\")\n",
    "#               # Afficher la stacktrace Java peut aider à confirmer l'erreur interne\n",
    "#               # print(e_stable.stacktrace())\n",
    "#\n",
    "#         # Labellisation Conflict-Free (pourrait aussi échouer)\n",
    "#         print(\"\\nApprentissage depuis labellisation Conflict-Free:\")\n",
    "#         try:\n",
    "#              labeling_cf = oracle.getLabeling(Semantics.CONFLICTFREE_SEMANTICS)\n",
    "#              print(f\"  Oracle fournit Labellisation CONFLICT_FREE: {labeling_cf}\")\n",
    "#              learner.learnLabeling(labeling_cf)\n",
    "#              print(f\"  Après CONFLICT_FREE: {learner.getNumberOfFrameworks()} cadres compatibles restants.\")\n",
    "#         except jpype.JException as e_cf:\n",
    "#              print(f\"  Erreur lors de l'obtention/apprentissage de la labellisation ConflictFree: {e_cf.message()}\")\n",
    "#\n",
    "#\n",
    "#         # 5. Obtenir le(s) cadre(s) appris\n",
    "#         # Ce code ne sera probablement pas atteint\n",
    "#         learned_af = learner.getModel()\n",
    "#         print(\"\\nCadre appris (un des cadres compatibles) :\")\n",
    "#         print(str(learned_af))\n",
    "#\n",
    "#     # ... (Blocs except ImportError, JException, Exception comme avant) ...\n",
    "#     except ImportError as e:\n",
    "#        print(f\"❌ Erreur d'import pour l'apprentissage Dung : {e}.\")\n",
    "#     except jpype.JException as e_java:\n",
    "#        print(f\"❌ Erreur Java générale dans l'exemple apprentissage Dung: {e_java.message()}\")\n",
    "#     except Exception as e_gen:\n",
    "#        print(f\"❌ Erreur Python inattendue dans l'exemple apprentissage Dung: {e_gen}\")\n",
    "#        import traceback\n",
    "#        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "675ee0f8",
   "metadata": {},
   "source": [
    "### 4.2 ASPIC+\n",
    "<a id=\"4.2\"></a>\n",
    "\n",
    "ASPIC+ est un framework mature et largement utilisé pour l'argumentation **structurée**. Contrairement à Dung où les arguments sont abstraits, ASPIC+ construit des arguments logiques à partir d'une base de connaissances et de règles d'inférence, en distinguant règles strictes et règles défaisables.\n",
    "\n",
    "* **Base de Connaissances (KB)**: Contient des axiomes (faits certains) et des règles.\n",
    "* **Règles d'inférence**:\n",
    "    * Strictes (`StrictInferenceRule`, `->`): Si les prémisses sont acceptées, la conclusion l'est nécessairement.\n",
    "    * Défaisables (`DefeasibleInferenceRule`, `=>`): Si les prémisses sont acceptées, la conclusion l'est plausiblement, mais la règle elle-même peut être attaquée (undercutting) ou la conclusion réfutée (rebutting).\n",
    "* **Préférences**: Un ordre (souvent partiel) peut être défini sur les règles défaisables pour résoudre les attaques \"rebutting\".\n",
    "* **Arguments**: Construits par chaînage de règles depuis les axiomes.\n",
    "* **Attaques**: Peuvent viser la conclusion (rebutting), une sous-conclusion (undermining sur conclusion intermédiaire) ou une règle défaisable (undercutting).\n",
    "* **`AspicArgumentationTheory`**: Représente la théorie ASPIC+. Nécessite un `RuleFormulaGenerator` pour spécifier la logique sous-jacente (ex: `PlFormulaGenerator` pour la logique propositionnelle).\n",
    "* **Conversion vers Dung (`asDungTheory`)**: Permet d'analyser la théorie ASPIC+ en la transformant en un AAF standard, sur lequel on peut appliquer les sémantiques de Dung (Grounded, Preferred, etc.).\n",
    "\n",
    "L'exemple suivant utilise la logique propositionnelle comme langage sous-jacent, basé sur `AspicExample.java`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6340ab53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 4.2.1 ASPIC+ : Construction et Conversion en Dung (PL) ---\n",
    "print(\"\\n--- 4.2.1 ASPIC+ : Construction et Conversion en Dung (PL) ---\")\n",
    "\n",
    "if not jvm_ready:\n",
    "    print(\"❌ ERREUR: JVM non démarrée.\")\n",
    "else:\n",
    "    print(\"ℹ️ JVM prête. Exécution de l'exemple ASPIC+...\")\n",
    "    try:\n",
    "        # Imports\n",
    "        import jpype\n",
    "        from jpype.types import *\n",
    "        # Logique Propositionnelle comme base\n",
    "        from org.tweetyproject.logics.pl.syntax import Proposition, Negation, PlFormula\n",
    "        # Classes ASPIC+\n",
    "        from org.tweetyproject.arg.aspic.syntax import AspicArgumentationTheory, DefeasibleInferenceRule, StrictInferenceRule\n",
    "        from org.tweetyproject.arg.aspic.ruleformulagenerator import PlFormulaGenerator # Crucial pour PL\n",
    "        # Classes Dung pour la conversion et le raisonnement\n",
    "        from org.tweetyproject.arg.dung.syntax import Argument as DungArgument, Attack as DungAttack, DungTheory\n",
    "        from org.tweetyproject.arg.dung.reasoner import SimpleGroundedReasoner\n",
    "\n",
    "        print(\"✔️ Imports ASPIC+ (PL) et Dung réussis.\")\n",
    "\n",
    "        # --- Théorie ASPIC+ ---\n",
    "        # Nécessite un générateur pour la logique sous-jacente (ici PL)\n",
    "        pl_formula_generator = PlFormulaGenerator()\n",
    "        aspic_theory = AspicArgumentationTheory(pl_formula_generator)\n",
    "        # Spécifier aussi le générateur pour les formules DANS les règles\n",
    "        aspic_theory.setRuleFormulaGenerator(pl_formula_generator)\n",
    "\n",
    "        # Propositions\n",
    "        a = Proposition(\"a\"); b = Proposition(\"b\"); c = Proposition(\"c\"); d_prop = Proposition(\"d\") # Renommé\n",
    "\n",
    "        # Règles Défaisables (=>)\n",
    "        # r1: b, c => a\n",
    "        r1_def = DefeasibleInferenceRule()\n",
    "        r1_def.setConclusion(a)\n",
    "        r1_def.addPremise(b); r1_def.addPremise(c)\n",
    "        aspic_theory.addRule(r1_def)\n",
    "\n",
    "        # r2: b => d\n",
    "        r2_def = DefeasibleInferenceRule()\n",
    "        r2_def.setConclusion(d_prop)\n",
    "        r2_def.addPremise(b)\n",
    "        aspic_theory.addRule(r2_def)\n",
    "\n",
    "        # r3: a => !d\n",
    "        r3_def = DefeasibleInferenceRule()\n",
    "        r3_def.setConclusion(Negation(d_prop))\n",
    "        r3_def.addPremise(a)\n",
    "        aspic_theory.addRule(r3_def)\n",
    "\n",
    "        # (Pas de règles strictes dans cet exemple)\n",
    "\n",
    "        # Axiomes (faits certains ->)\n",
    "        aspic_theory.addAxiom(b) # -> b\n",
    "        aspic_theory.addAxiom(c) # -> c\n",
    "\n",
    "        print(\"\\n--- Théorie ASPIC+ ---\")\n",
    "        print(str(aspic_theory)) # Utilise toString()\n",
    "\n",
    "        # --- Conversion en Cadre de Dung ---\n",
    "        print(\"\\n--- Conversion en AF de Dung ---\")\n",
    "        try:\n",
    "            # asDungTheory() génère le graphe d'attaque basé sur la théorie ASPIC+\n",
    "            dung_equivalent = aspic_theory.asDungTheory()\n",
    "\n",
    "            print(\"Arguments générés par ASPIC+:\")\n",
    "            args_aspic = dung_equivalent.getNodes()\n",
    "            if args_aspic.isEmpty():\n",
    "                print(\"  (Aucun argument généré)\")\n",
    "            else:\n",
    "                for arg in args_aspic:\n",
    "                    # L'affichage d'un argument ASPIC+ peut être complexe\n",
    "                    print(f\"  - {arg}\")\n",
    "\n",
    "            print(\"\\nAttaques générées par ASPIC+:\")\n",
    "            attacks_aspic = dung_equivalent.getAttacks()\n",
    "            if attacks_aspic.isEmpty():\n",
    "                 print(\"  (Aucune attaque générée)\")\n",
    "            else:\n",
    "                for att in attacks_aspic:\n",
    "                    print(f\"  - {att}\")\n",
    "\n",
    "            # --- Raisonnement sur l'AF équivalent ---\n",
    "            print(\"\\nRaisonnement sur l'AF de Dung équivalent:\")\n",
    "            grounded_reasoner_dung = SimpleGroundedReasoner()\n",
    "            grounded_extension = grounded_reasoner_dung.getModel(dung_equivalent)\n",
    "            print(f\" - Extension Grounded : {grounded_extension}\")\n",
    "\n",
    "            # Pourrait-on vérifier si 'a' est acceptable ?\n",
    "            # Il faudrait trouver l'argument ASPIC correspondant à 'a'\n",
    "            # C'est plus complexe, on se contente de l'extension pour l'instant.\n",
    "\n",
    "        except jpype.JException as e_conv_java:\n",
    "            print(f\"❌ Erreur Java lors de la conversion ASPIC->Dung: {e_conv_java.message()}\")\n",
    "            # print(e_conv_java.stacktrace())\n",
    "        except Exception as e_conv_py:\n",
    "            print(f\"❌ Erreur Python lors de la conversion ASPIC->Dung: {e_conv_py}\")\n",
    "\n",
    "\n",
    "    except ImportError as e:\n",
    "        print(f\"❌ Erreur d'import pour ASPIC+ : {e}. Vérifiez le JAR 'arg.aspic'.\")\n",
    "    except jpype.JException as e_java:\n",
    "        print(f\"❌ Erreur Java générale dans l'exemple ASPIC+: {e_java.message()}\")\n",
    "        # print(e_java.stacktrace())\n",
    "    except Exception as e_gen:\n",
    "        print(f\"❌ Erreur Python inattendue dans l'exemple ASPIC+: {e_gen}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06220aec",
   "metadata": {},
   "source": [
    "### 4.3 Defeasible Logic Programming (DeLP)\n",
    "<a id=\"4.3\"></a>\n",
    "\n",
    "*(Section à compléter avec l'exemple `DeLPExample.java`)*\n",
    "\n",
    "DeLP combine la programmation logique avec le raisonnement défaisable. Il utilise des règles strictes et des règles défaisables (`-<`). Un argument est construit pour supporter un littéral, et la notion de \"warrant\" (justification) est déterminée en comparant les arguments pour et contre ce littéral, en utilisant un critère de comparaison comme la spécificité généralisée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f573f125",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 4.3 Defeasible Logic Programming (DeLP) ---\n",
    "print(\"\\n--- 4.3 Defeasible Logic Programming (DeLP) ---\")\n",
    "\n",
    "if not jvm_ready:\n",
    "    print(\"❌ ERREUR: JVM non démarrée.\")\n",
    "else:\n",
    "    print(\"ℹ️ JVM prête. Exécution de l'exemple DeLP...\")\n",
    "    try:\n",
    "        # Imports\n",
    "        import jpype\n",
    "        from jpype.types import *\n",
    "        import pathlib\n",
    "        from java.io import StringReader\n",
    "        from java.util import ArrayList\n",
    "\n",
    "        # Imports DeLP\n",
    "        from org.tweetyproject.arg.delp.parser import DelpParser\n",
    "        from org.tweetyproject.arg.delp.reasoner import DelpReasoner\n",
    "        from org.tweetyproject.arg.delp.semantics import GeneralizedSpecificity\n",
    "        from org.tweetyproject.arg.delp.syntax import DefeasibleLogicProgram\n",
    "\n",
    "        # Imports FOL/Commons nécessaires\n",
    "        from org.tweetyproject.logics.fol.syntax import FolFormula, FolSignature, FolAtom\n",
    "        # ** CORRECTION: Importer Constant et Predicate depuis commons.syntax **\n",
    "        from org.tweetyproject.logics.commons.syntax import Constant, Predicate\n",
    "\n",
    "        print(\"✔️ Imports DeLP, FOL et Commons nécessaires réussis.\")\n",
    "\n",
    "        # --- Parsing du programme DeLP ---\n",
    "        # (Code de chargement depuis fichier ou chaîne inchangé)\n",
    "        delp_filename = \"birds2.txt\"\n",
    "        delp_filepath = pathlib.Path(\"resources\") / delp_filename\n",
    "        delp_program = None\n",
    "        parser_delp = DelpParser() # Parser pour le programme\n",
    "\n",
    "        if not delp_filepath.is_file():\n",
    "            print(f\"❌ ERREUR: Fichier DeLP requis '{delp_filepath}' non trouvé !\")\n",
    "            print(\"   Utilisation d'un exemple intégré (birds.txt simplifié).\")\n",
    "            birds_program_str = \"\"\"\n",
    "            Bird(X) <- Chicken(X). Bird(X) <- Penguin(X). ~Flies(X) <- Penguin(X).\n",
    "            Chicken(tina). Penguin(tweety). Scared(tina).\n",
    "            Flies(X) -< Bird(X). ~Flies(X) -< Chicken(X). Flies(X) -< Chicken(X), Scared(X).\n",
    "            Nests_in_trees(X) -< Flies(X).\n",
    "            \"\"\"\n",
    "            try:\n",
    "                 string_reader = StringReader(birds_program_str)\n",
    "                 delp_program = parser_delp.parseBeliefBase(string_reader); string_reader.close()\n",
    "                 print(\"✔️ Programme chargé avec succès depuis la chaîne intégrée.\")\n",
    "            except Exception as e_str: print(f\"❌ Erreur parsing chaîne intégrée: {e_str}\"); delp_program = None\n",
    "        else:\n",
    "            print(f\"\\nChargement du programme DeLP depuis: {delp_filepath}\")\n",
    "            try:\n",
    "                 delp_program = parser_delp.parseBeliefBaseFromFile(str(delp_filepath))\n",
    "                 print(\"✔️ Programme chargé avec succès depuis le fichier.\")\n",
    "            except Exception as e_file: print(f\"❌ Erreur chargement fichier: {e_file}\"); delp_program = None\n",
    "\n",
    "\n",
    "        # --- Raisonnement DeLP ---\n",
    "        if delp_program is not None:\n",
    "            print(\"\\nProgramme DeLP chargé:\\n\", str(delp_program))\n",
    "\n",
    "            # DEBUG Signature (inchangé)\n",
    "            sig_delp = None\n",
    "            try:\n",
    "                sig_delp = delp_program.getSignature()\n",
    "                print(\"\\nDEBUG Signature extraite par DelpParser:\")\n",
    "                print(sig_delp)\n",
    "                if hasattr(sig_delp, 'getPredicates'): print(\"Predicates:\", sig_delp.getPredicates())\n",
    "                if hasattr(sig_delp, 'getConstants'): print(\"Constants:\", sig_delp.getConstants())\n",
    "            except Exception as e_sig: print(f\"⚠️ Erreur récupération/affichage signature: {e_sig}\")\n",
    "\n",
    "            # Construction programmatique des requêtes (inchangée, mais utilise les classes importées correctement)\n",
    "            print(\"\\nConstruction programmatique des requêtes FOL...\")\n",
    "            queries_fol_obj = {}\n",
    "            try:\n",
    "                # Redéfinir Predicate/Constant avec les classes importées de commons.syntax\n",
    "                Flies = Predicate(\"Flies\", 1)\n",
    "                Nests = Predicate(\"Nests_in_trees\", 1)\n",
    "                tina = Constant(\"tina\")\n",
    "                tweety = Constant(\"tweety\")\n",
    "\n",
    "                # Construire les FolAtom (le constructeur prend Predicate, List<Term>)\n",
    "                # Créer une ArrayList Java pour les arguments\n",
    "                args_tina = ArrayList([tina])\n",
    "                args_tweety = ArrayList([tweety])\n",
    "\n",
    "                # Utiliser JObject pour passer la liste Java de manière sûre\n",
    "                queries_fol_obj[\"Flies(tina)\"] = FolAtom(Flies, JObject(args_tina, \"java.util.List\"))\n",
    "                queries_fol_obj[\"Flies(tweety)\"] = FolAtom(Flies, JObject(args_tweety, \"java.util.List\"))\n",
    "                queries_fol_obj[\"Nests_in_trees(tina)\"] = FolAtom(Nests, JObject(args_tina, \"java.util.List\"))\n",
    "                queries_fol_obj[\"Nests_in_trees(tweety)\"] = FolAtom(Nests, JObject(args_tweety, \"java.util.List\"))\n",
    "\n",
    "                print(\"✔️ Requêtes construites programmatiquement.\")\n",
    "\n",
    "            except Exception as e_build:\n",
    "                print(f\"❌ Erreur lors de la construction programmatique des requêtes: {e_build}\")\n",
    "                queries_fol_obj = None\n",
    "\n",
    "            if queries_fol_obj:\n",
    "                reasoner_delp = DelpReasoner(GeneralizedSpecificity())\n",
    "                FolFormula_class = jpype.JClass(\"org.tweetyproject.logics.fol.syntax.FolFormula\")\n",
    "\n",
    "                print(\"\\nÉvaluation des requêtes DeLP (construites programmatiquement):\")\n",
    "                for q_str, query_formula_obj in queries_fol_obj.items():\n",
    "                    print(f\"  Querying '{q_str}'...\", end=\"\")\n",
    "                    try:\n",
    "                        result_delp = reasoner_delp.query(delp_program, JObject(query_formula_obj, FolFormula_class))\n",
    "                        print(f\" Résultat: {result_delp}\")\n",
    "                    except jpype.JException as e_query_java:\n",
    "                        print(f\" ERREUR JAVA: {e_query_java.message()}\")\n",
    "                    except Exception as e_query_py:\n",
    "                         print(f\" ERREUR PYTHON: {e_query_py}\")\n",
    "            else:\n",
    "                 print(\"\\n❌ Construction des requêtes échouée, raisonnement sauté.\")\n",
    "        else:\n",
    "            print(\"\\n❌ Aucun programme DeLP chargé ou erreur de chargement, raisonnement sauté.\")\n",
    "\n",
    "    # ... (Blocs except globaux inchangés) ...\n",
    "    except ImportError as e: print(f\"❌ Erreur d'import pour DeLP/Commons/FOL : {e}.\")\n",
    "    except jpype.JException as e_java: print(f\"❌ Erreur Java générale: {e_java.message()}\")\n",
    "    except Exception as e_gen: print(f\"❌ Erreur Python inattendue: {e_gen}\"); import traceback; traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e355de",
   "metadata": {},
   "source": [
    "### 4.4 Assumption-Based Argumentation (ABA)\n",
    "<a id=\"4.4\"></a>\n",
    "\n",
    "*(Section à compléter avec l'exemple `AbaExample.java`)*\n",
    "\n",
    "En ABA, certains littéraux sont désignés comme des **hypothèses** (assumptions). Les arguments sont dérivés en utilisant des règles logiques (similaires à ASPIC+) à partir de ces hypothèses. Une attaque d'un argument vers un autre se produit si la conclusion du premier est le **contraire** d'une hypothèse utilisée dans le second.\n",
    "\n",
    "* **`AbaTheory`**: Contient les règles, l'ensemble des hypothèses, et la définition des contraires.\n",
    "* **Logique sous-jacente**: Peut être PL ou FOL.\n",
    "* **Raisonnement**: Souvent basé sur la conversion en AF de Dung (`FlatAbaReasoner`, `PreferredReasoner`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0785a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 4.4 Assumption-Based Argumentation (ABA) ---\n",
    "print(\"\\n--- 4.4 Assumption-Based Argumentation (ABA) ---\")\n",
    "\n",
    "if not jvm_ready:\n",
    "    print(\"❌ ERREUR: JVM non démarrée.\")\n",
    "else:\n",
    "    print(\"ℹ️ JVM prête. Exécution de l'exemple ABA...\")\n",
    "    try:\n",
    "        # Imports (inchangés)\n",
    "        import jpype; from jpype.types import *; import pathlib; from java.io import StringReader\n",
    "        from org.tweetyproject.arg.aba.parser import AbaParser\n",
    "        from org.tweetyproject.arg.aba.syntax import AbaTheory, Assumption\n",
    "        from org.tweetyproject.logics.pl.parser import PlParser\n",
    "        from org.tweetyproject.logics.pl.syntax import Proposition, PlFormula\n",
    "        from org.tweetyproject.logics.fol.parser import FolParser\n",
    "        from org.tweetyproject.logics.fol.syntax import FolFormula, FolSignature\n",
    "        from org.tweetyproject.logics.pl.sat import SatSolver, Sat4jSolver\n",
    "        from org.tweetyproject.arg.aba.reasoner import FlatAbaReasoner, PreferredReasoner\n",
    "        from org.tweetyproject.arg.dung.semantics import Semantics\n",
    "        from org.tweetyproject.arg.dung.syntax import DungTheory\n",
    "\n",
    "        print(\"✔️ Imports ABA et dépendances réussis.\")\n",
    "\n",
    "        # --- Exemple 1: Propositional Logic (PL) ---\n",
    "        print(\"\\n--- Exemple ABA avec Logique Propositionnelle ---\")\n",
    "        # (Code PL inchangé, il fonctionnait)\n",
    "        SatSolver.setDefaultSolver(Sat4jSolver())\n",
    "        pl_parser_for_aba = PlParser()\n",
    "        aba_parser_pl = AbaParser(pl_parser_for_aba)\n",
    "        aba_pl_filename = \"example2.aba\"\n",
    "        aba_pl_filepath = pathlib.Path(\"resources\") / aba_pl_filename\n",
    "        aba_theory_pl = None\n",
    "        if not aba_pl_filepath.is_file():\n",
    "            print(f\"❌ ERREUR: Fichier ABA (PL) requis '{aba_pl_filepath}' non trouvé !\")\n",
    "        else:\n",
    "            print(f\"Chargement ABA (PL) depuis fichier: {aba_pl_filepath}\")\n",
    "            try:\n",
    "                 aba_theory_pl = aba_parser_pl.parseBeliefBaseFromFile(str(aba_pl_filepath))\n",
    "                 print(\"✔️ Théorie ABA (PL) chargée depuis fichier.\")\n",
    "            except Exception as e_fpl: print(f\"❌ Erreur chargement fichier ABA (PL): {e_fpl}\")\n",
    "\n",
    "        if aba_theory_pl is not None:\n",
    "            print(\"\\nThéorie ABA (PL):\", str(aba_theory_pl))\n",
    "            reasoner_flat_pref = FlatAbaReasoner(Semantics.PREFERRED_SEMANTICS)\n",
    "            reasoner_pref_aba = PreferredReasoner()\n",
    "            assumption_pl = Assumption(Proposition(\"a\"))\n",
    "            print(\"\\nRequêtes sur la théorie ABA (PL):\")\n",
    "            print(f\" - Query '{assumption_pl}' (Flat Preferred)? {reasoner_flat_pref.query(aba_theory_pl, assumption_pl)}\")\n",
    "            print(f\" - Query '{assumption_pl}' (ABA Preferred)? {reasoner_pref_aba.query(aba_theory_pl, assumption_pl)}\")\n",
    "\n",
    "\n",
    "        # --- Exemple 2: First-Order Logic (FOL) ---\n",
    "        print(\"\\n\\n--- Exemple ABA avec Logique du Premier Ordre ---\")\n",
    "        aba_fol_filename = \"smp_fol.aba\"\n",
    "        aba_fol_filepath = pathlib.Path(\"resources\") / aba_fol_filename\n",
    "        aba_theory_fol = None\n",
    "\n",
    "        if not aba_fol_filepath.is_file():\n",
    "             print(f\"❌ ERREUR: Fichier ABA (FOL) requis '{aba_fol_filepath}' non trouvé !\")\n",
    "        else:\n",
    "            fol_parser_for_aba = FolParser()\n",
    "            # ** CORRECTION : Ajouter des sauts de ligne '\\n' **\n",
    "            sig_fol_str = \"\"\"\n",
    "            Male = {a, b}\n",
    "            Female = {c, d}\n",
    "            type(Pair(Male, Female))\n",
    "            type(ContraryPair(Male, Female))\n",
    "            type(MPrefers(Male, Female, Female))\n",
    "            type(WPrefers(Female, Male, Male))\n",
    "            \"\"\"\n",
    "            try:\n",
    "                 sig_fol_aba = fol_parser_for_aba.parseSignature(sig_fol_str)\n",
    "                 fol_parser_for_aba.setSignature(sig_fol_aba)\n",
    "                 print(\"✔️ Signature FOL pour ABA définie.\")\n",
    "\n",
    "                 aba_parser_fol = AbaParser(fol_parser_for_aba)\n",
    "                 # Important si les termes sont séparés par ';' dans le .aba\n",
    "                 # smp_fol.aba utilise bien ';', donc on décommente :\n",
    "                 aba_parser_fol.setSymbolComma(\";\")\n",
    "                 print(\"ℹ️ Utilisation de ';' comme séparateur pour le parser ABA FOL.\")\n",
    "\n",
    "\n",
    "                 print(f\"Chargement ABA (FOL) depuis fichier: {aba_fol_filepath}\")\n",
    "                 try:\n",
    "                      aba_theory_fol = aba_parser_fol.parseBeliefBaseFromFile(str(aba_fol_filepath))\n",
    "                      print(\"✔️ Théorie ABA (FOL) chargée depuis fichier.\")\n",
    "                 except Exception as e_ffol: print(f\"❌ Erreur chargement fichier ABA (FOL): {e_ffol}\")\n",
    "\n",
    "                 if aba_theory_fol is not None:\n",
    "                       print(\"\\nThéorie ABA (FOL):\\n\", str(aba_theory_fol))\n",
    "                       # Raisonnement ABA (FOL)\n",
    "                       reasoner_flat_stable_fol = FlatAbaReasoner(Semantics.STABLE_SEMANTICS)\n",
    "                       reasoner_pref_aba_fol = PreferredReasoner()\n",
    "                       FolFormula_class = jpype.JClass(\"org.tweetyproject.logics.fol.syntax.FolFormula\")\n",
    "                       # Vérifier que 'Pair(a,d)' est bien une assumption dans smp_fol.aba\n",
    "                       # Elle l'est, comme 'Pair(b,c)', etc.\n",
    "                       assumption_fol_query_str = \"Pair(a,d)\"\n",
    "                       assumption_fol = Assumption(JObject(fol_parser_for_aba.parseFormula(assumption_fol_query_str), FolFormula_class))\n",
    "                       print(\"\\nRequêtes sur la théorie ABA (FOL):\")\n",
    "                       # print(f\" - Modèles (Flat Stable): {reasoner_flat_stable_fol.getModels(aba_theory_fol)}\")\n",
    "                       print(f\" - Query '{assumption_fol}' (ABA Preferred)? {reasoner_pref_aba_fol.query(aba_theory_fol, assumption_fol)}\")\n",
    "\n",
    "            except jpype.JException as e_sig_java: print(f\"❌ Erreur Java lors de la config FOL pour ABA: {e_sig_java.message()}\")\n",
    "            except Exception as e_sig_py: print(f\"❌ Erreur Python lors de la config FOL pour ABA: {e_sig_py}\")\n",
    "\n",
    "    # ... (Blocs except globaux inchangés) ...\n",
    "    except ImportError as e: print(f\"❌ Erreur d'import pour ABA : {e}.\")\n",
    "    except jpype.JException as e_java: print(f\"❌ Erreur Java générale: {e_java.message()}\")\n",
    "    except Exception as e_gen: print(f\"❌ Erreur Python inattendue: {e_gen}\"); import traceback; traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06de9718",
   "metadata": {},
   "source": [
    "### 4.5 Argumentation Déductive (PL)\n",
    "<a id=\"4.5\"></a>\n",
    "\n",
    "Cette approche, souvent associée à Besnard & Hunter, construit des arguments comme des paires `(Support, Conclusion)` où `Support` est un sous-ensemble minimal et consistant de la base de connaissances qui implique logiquement la `Conclusion`.\n",
    "\n",
    "* **`DeductiveKnowledgeBase`**: Une simple `PlBeliefSet` dans l'implémentation de Tweety.\n",
    "* **Argument**: Généré implicitement par le raisonneur.\n",
    "* **Attaque**: Un argument `(S1, C1)` attaque `(S2, C2)` si `C1` est la négation d'un élément de `S2` (attaque \"undercut\" classique) ou la négation de `C2` (attaque \"rebut\" classique).\n",
    "* **Raisonnement (`SimpleDeductiveReasoner`)**: Construit un arbre d'arguments/contre-arguments pour une requête donnée.\n",
    "    * **`Categorizer`**: Détermine la force initiale d'un argument (ex: `ClassicalCategorizer`).\n",
    "    * **`Accumulator`**: Agrège la force des arguments/contre-arguments dans l'arbre (ex: `SimpleAccumulator`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9ba855",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 4.5 Argumentation Déductive (PL) ---\n",
    "# Correction: Le package pour ClassicalCategorizer et SimpleAccumulator était 'categorizer' et 'accumulator', pas 'semantics'.\n",
    "try:\n",
    "    from org.tweetyproject.logics.pl.parser import PlParser\n",
    "    from org.tweetyproject.arg.deductive.syntax import DeductiveKnowledgeBase\n",
    "    from org.tweetyproject.arg.deductive.reasoner import SimpleDeductiveReasoner, AbstractDeductiveArgumentationReasoner\n",
    "    # Correction des imports:\n",
    "    from org.tweetyproject.arg.deductive.categorizer import ClassicalCategorizer\n",
    "    from org.tweetyproject.arg.deductive.accumulator import SimpleAccumulator\n",
    "\n",
    "    from org.tweetyproject.logics.pl.sat import Sat4jSolver, SatSolver # Souvent nécessaire en interne\n",
    "\n",
    "    # --- Initialisation ---\n",
    "    SatSolver.setDefaultSolver(Sat4jSolver())\n",
    "    parser_ded = PlParser()\n",
    "    kb_ded = DeductiveKnowledgeBase() # Est essentiellement un PlBeliefSet\n",
    "\n",
    "    # Base de connaissances de l'exemple\n",
    "    formulas_ded = [\"s\", \"!s || h\", \"f\", \"!f || !h\", \"v\", \"!v || !h\"]\n",
    "    for f_str in formulas_ded: kb_ded.add(parser_ded.parseFormula(f_str))\n",
    "\n",
    "    print(\"KB Déductive:\\n\", kb_ded)\n",
    "\n",
    "    # --- Raisonnement ---\n",
    "    # Utilise un catégoriseur classique et un accumulateur simple\n",
    "    ded_reasoner = SimpleDeductiveReasoner(ClassicalCategorizer(), SimpleAccumulator())\n",
    "\n",
    "    query_ded = parser_ded.parseFormula(\"h\") # La requête est \"h\"\n",
    "    result_ded = ded_reasoner.query(kb_ded, query_ded)\n",
    "\n",
    "    print(f\"\\nQuery '{query_ded}'? {result_ded}\") # Devrait être ACCEPTED ou REJECTED\n",
    "\n",
    "except ImportError as e:\n",
    "     print(f\"❌ Erreur d'import pour Argumentation Déductive : {e}\")\n",
    "     print(\"   Vérifiez le JAR 'org.tweetyproject.arg.deductive'.\")\n",
    "except Exception as e:\n",
    "     print(f\"❌ Erreur lors de l'exécution de l'exemple Déductif: {e}\")\n",
    "     import traceback\n",
    "     traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d237ec",
   "metadata": {},
   "source": [
    "### 4.6 Answer Set Programming (ASP)\n",
    "<a id=\"4.6\"></a>\n",
    "\n",
    "ASP est un paradigme de programmation déclarative puissant pour résoudre des problèmes combinatoires complexes, souvent utilisé en représentation de connaissances et raisonnement. Un programme ASP est un ensemble de règles logiques (similaires à Prolog mais avec une sémantique différente basée sur les \"modèles stables\" ou \"answer sets\").\n",
    "\n",
    "* **Syntaxe :** Règles de la forme `tete :- corps.` où `corps` est une conjonction de littéraux. Utilise la négation par défaut (`not`) et la négation classique (`-`). Permet les contraintes (règles sans tête) et les règles de choix/agrégats.\n",
    "* **Sémantique :** Les \"answer sets\" sont des ensembles minimaux d'atomes vrais qui satisfont toutes les règles du programme.\n",
    "* **Tweety :** Permet de définir des `Program`mes ASP (`org.tweetyproject.lp.asp.syntax`). Le raisonnement nécessite un **solveur externe** comme **Clingo** (de la suite Potassco). Tweety fournit `ClingoSolver` pour l'interfacer, ainsi qu'un `GringoGrounder` (Gringo est le \"grounder\" de Clingo qui instancie les variables).\n",
    "* **Pré-requis :** Nécessite l'installation de **Clingo** ([Potassco](https://potassco.org/)) et la configuration du chemin vers l'exécutable Clingo dans `EXTERNAL_TOOLS['CLINGO']` (Cellule 9)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ff79c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 4.6 Answer Set Programming (ASP) ---\n",
    "print(\"\\n--- 4.6 Answer Set Programming (ASP) ---\")\n",
    "\n",
    "if not jvm_ready:\n",
    "    print(\"❌ ERREUR: JVM non démarrée.\")\n",
    "else:\n",
    "    print(\"ℹ️ JVM prête. Exécution de l'exemple ASP...\")\n",
    "    asp_imports_ok = False\n",
    "    try:\n",
    "        # Imports (inchangés)\n",
    "        import jpype\n",
    "        from jpype.types import *\n",
    "        from java.util import ArrayList, List as JavaList, Collection\n",
    "        from org.tweetyproject.lp.asp.syntax import (\n",
    "            Program, ASPRule, ASPAtom, DefaultNegation, StrictNegation,\n",
    "            ClassicalHead, AggregateHead, AggregateAtom, ASPHead, ASPBodyElement\n",
    "        )\n",
    "        from org.tweetyproject.logics.commons.syntax import Constant, Predicate, Variable\n",
    "        from org.tweetyproject.lp.asp.reasoner import ClingoSolver\n",
    "        from org.tweetyproject.lp.asp.grounder import GringoGrounder\n",
    "        from org.tweetyproject.lp.asp.semantics import AnswerSet\n",
    "\n",
    "        # Récupérer get_tool_path\n",
    "        if 'get_tool_path' not in globals() or 'EXTERNAL_TOOLS' not in globals():\n",
    "            raise NameError(\"La fonction 'get_tool_path' ou 'EXTERNAL_TOOLS' n'est pas définie.\")\n",
    "\n",
    "        # Récupérer le chemin Clingo configuré par l'utilisateur\n",
    "        CLINGO_PATH = get_tool_path('CLINGO') # Renvoie None si non configuré ou invalide\n",
    "\n",
    "        print(\"✔️ Imports ASP réussis.\")\n",
    "        asp_imports_ok = True\n",
    "\n",
    "        # --- Programme ASP Simple (Construction inchangée) ---\n",
    "        print(\"\\n--- Programme ASP Simple ---\")\n",
    "        p = ASPAtom(\"p\"); r_atom = ASPAtom(\"r\"); q = ASPAtom(\"q\"); b_atom = ASPAtom(\"b\") # Renommé r -> r_atom\n",
    "        body1 = ArrayList(); body1.add(DefaultNegation(r_atom))\n",
    "        r1_asp = ASPRule(ClassicalHead(p), JObject(body1, JavaList))\n",
    "        body2 = ArrayList(); body2.add(StrictNegation(q)); body2.add(DefaultNegation(b_atom))\n",
    "        r2_asp = ASPRule(ClassicalHead(r_atom), JObject(body2, JavaList))\n",
    "        body3 = ArrayList(); body3.add(b_atom)\n",
    "        r3_asp = ASPRule(ClassicalHead(StrictNegation(q)), JObject(body3, JavaList))\n",
    "        body4 = ArrayList()\n",
    "        r4_asp = ASPRule(ClassicalHead(b_atom), JObject(body4, JavaList))\n",
    "        rules_prog1 = ArrayList([r1_asp, r2_asp, r3_asp, r4_asp])\n",
    "        program1 = Program(JObject(rules_prog1, Collection))\n",
    "        print(\"Programme 1:\\n\", str(program1))\n",
    "\n",
    "\n",
    "        # --- Programme ASP Suspects (Construction inchangée) ---\n",
    "        print(\"\\n--- Programme ASP Suspects ---\")\n",
    "        motive = Predicate(\"motive\", 1); guilty = Predicate(\"guilty\", 1); innocent = Predicate(\"innocent\", 1)\n",
    "        harry = Constant(\"harry\"); sally = Constant(\"sally\")\n",
    "        Suspect = Variable(\"Suspect\")\n",
    "        motive_h = ASPAtom(motive, [harry]); motive_s = ASPAtom(motive, [sally]) # Mettre les termes dans une liste\n",
    "        guilty_h = ASPAtom(guilty, [harry])\n",
    "        innocent_S = ASPAtom(innocent, [Suspect]); motive_S = ASPAtom(motive, [Suspect])\n",
    "        guilty_S = ASPAtom(guilty, [Suspect])\n",
    "        r1_sus = ASPRule(ClassicalHead(motive_h), JObject(ArrayList(), JavaList))\n",
    "        r2_sus = ASPRule(ClassicalHead(motive_s), JObject(ArrayList(), JavaList))\n",
    "        r3_sus = ASPRule(ClassicalHead(guilty_h), JObject(ArrayList(), JavaList))\n",
    "        body4_sus = ArrayList(); body4_sus.add(motive_S); body4_sus.add(DefaultNegation(guilty_S))\n",
    "        r4_sus = ASPRule(ClassicalHead(innocent_S), JObject(body4_sus, JavaList))\n",
    "        rules_prog2 = ArrayList([r1_sus, r2_sus, r3_sus, r4_sus])\n",
    "        program2 = Program(JObject(rules_prog2, Collection))\n",
    "        print(\"Programme 2:\\n\", str(program2))\n",
    "\n",
    "\n",
    "        # --- Raisonnement avec Clingo ---\n",
    "        if not CLINGO_PATH:\n",
    "            print(\"\\n⚠️ Clingo non configuré ou chemin invalide dans EXTERNAL_TOOLS['CLINGO'] (Cellule 10).\")\n",
    "            print(\"   Veuillez installer Clingo (via pip/conda ou manuellement) et configurer le chemin.\")\n",
    "            print(\"   Raisonnement ASP sauté.\")\n",
    "        else:\n",
    "            print(f\"\\nUtilisation de Clingo trouvé/configuré à: {CLINGO_PATH}\")\n",
    "            try:\n",
    "                # Instancier AVEC le chemin\n",
    "                solver_instance = ClingoSolver(JString(CLINGO_PATH))\n",
    "                print(f\"\\nCalcul des Answer Sets pour Programme 2...\")\n",
    "                # getModels(Program)\n",
    "                answer_sets_collection = solver_instance.getModels(program2)\n",
    "\n",
    "                print(f\"Answer Sets trouvés ({answer_sets_collection.size()}):\")\n",
    "                if answer_sets_collection.isEmpty():\n",
    "                    print(\"   (Aucun Answer Set)\")\n",
    "                else:\n",
    "                    count = 1\n",
    "                    for ans_set in answer_sets_collection:\n",
    "                        # Correction : ans_set est l'AnswerSet, on veut ses littéraux\n",
    "                        atoms_in_set_obj = ans_set.getLiterals() # Renvoie Set<Literal>\n",
    "                        # Convertir en liste de strings Python triée\n",
    "                        atoms_in_set = \", \".join(sorted([str(atom) for atom in atoms_in_set_obj]))\n",
    "                        print(f\"   - AS {count}: {{{atoms_in_set}}}\")\n",
    "                        count += 1\n",
    "\n",
    "                # --- Grounding (Optionnel) ---\n",
    "                # (Le code de grounding reste identique mais indenté dans le 'else')\n",
    "                print(\"\\nTentative de Grounding...\")\n",
    "                try:\n",
    "                    grounder_instance = GringoGrounder(JString(CLINGO_PATH))\n",
    "                    ground_program = grounder_instance.getGroundProgram(program2)\n",
    "                    print(\"   ✔️ Grounding réussi.\")\n",
    "                    print(f\"     (Nombre de règles groundées: {ground_program.size()})\")\n",
    "                    # print(\"Programme Groundé:\\n\", str(ground_program)) # Potentiellement très long\n",
    "                except Exception as e_ground:\n",
    "                    print(f\"   ❌ Erreur lors du grounding: {e_ground}\")\n",
    "\n",
    "            except jpype.JException as e_clingo_java:\n",
    "                print(f\"❌ Erreur Java lors de l'appel à Clingo: {e_clingo_java.message()}\")\n",
    "                print(\"   Vérifiez que le chemin vers Clingo est correct et que Clingo fonctionne.\")\n",
    "                # print(e_clingo_java.stacktrace())\n",
    "            except Exception as e_clingo_py:\n",
    "                print(f\"❌ Erreur Python lors de l'appel à Clingo: {e_clingo_py}\")\n",
    "                import traceback; traceback.print_exc()\n",
    "\n",
    "\n",
    "    # ... (Blocs except globaux inchangés) ...\n",
    "    except ImportError as e: print(f\"❌ Erreur d'import pour ASP : {e}. Vérifiez le JAR 'lp.asp'.\")\n",
    "    except jpype.JException as e_java: print(f\"❌ Erreur Java générale ASP: {e_java.message()}\")\n",
    "    except Exception as e_gen: print(f\"❌ Erreur Python inattendue ASP: {e_gen}\"); import traceback; traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db63c8ae",
   "metadata": {},
   "source": [
    "## Partie 5 : Argumentation Avancée et Analyse\n",
    "<a id=\"partie5\"></a>\n",
    "\n",
    "Cette section explore des extensions plus complexes et spécifiques des cadres d'argumentation, ainsi que des méthodes d'analyse dédiées comme le classement ou la prise en compte des probabilités. Ces formalismes permettent de modéliser des scénarios de raisonnement plus riches."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c2dc483",
   "metadata": {},
   "source": [
    "### 5.1 Abstract Dialectical Frameworks (ADF)\n",
    "<a id=\"5.1\"></a>\n",
    "\n",
    "Les ADF [Brewka et al., 2013] généralisent les cadres de Dung. Au lieu d'une simple relation d'attaque, chaque argument (ou \"statement\") se voit associer une **condition d'acceptation** ($\\phi_s$), qui est une formule propositionnelle définie sur les arguments parents (ceux qui ont un lien vers $s$). Le statut d'un argument dépend de la satisfaction de sa condition d'acceptation en fonction du statut de ses parents.\n",
    "\n",
    "* **Structure :** Un ADF est un triplet $(S, L, C)$ où $S$ est l'ensemble des \"statements\" (arguments), $L \\subseteq S \\times S$ sont les liens, et $C = \\{\\phi_s\\}_{s \\in S}$ est l'ensemble des conditions d'acceptation.\n",
    "* **Conditions d'Acceptation ($\\phi_s$) :** Une fonction booléenne $Val(par(s)) \\to \\{\\mathbf{t}, \\mathbf{f}\\}$ où $par(s)$ sont les parents de $s$. Souvent exprimée comme une formule propositionnelle (ex: `a & (~b | c)`).\n",
    "* **Sémantiques :** Généralisent celles de Dung (admissible, complète, fondée, préférée, stable, modèle/2-valué). Le raisonnement est souvent coûteux (plus complexe que pour les AAF) et typiquement réduit à des problèmes SAT ou QBF.\n",
    "* **Tweety :** `AbstractDialecticalFramework`, `Argument`, `AcceptanceCondition`, `KppADFFormatParser` (pour lire un format texte spécifique). Les raisonneurs (`arg.adf.reasoner.*`) utilisent souvent des solveurs SAT natifs (`arg.adf.sat.solver.*` - ex: `NativeMinisatSolver`) qui nécessitent les bibliothèques `.dll` ou `.so` téléchargées précédemment (voir note Cellule 10). Si ces bibliothèques natives ne sont pas trouvées/utilisables par la JVM (problème `java.library.path`), le raisonnement ADF risque d'échouer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e216ba61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 5.1 Abstract Dialectical Frameworks (ADF) ---\n",
    "print(\"\\n--- 5.1 Abstract Dialectical Frameworks (ADF) ---\")\n",
    "\n",
    "if not jvm_ready:\n",
    "    print(\"❌ ERREUR: JVM non démarrée.\")\n",
    "else:\n",
    "    print(\"ℹ️ JVM prête. Exécution de l'exemple ADF...\")\n",
    "    print(\"⚠️ NOTE IMPORTANTE : Le raisonnement ADF dans Tweety repose fortement sur des\")\n",
    "    print(\"         solveurs SAT natifs (Minisat, Lingeling, Picosat) qui implémentent\")\n",
    "    print(\"         l'interface 'IncrementalSatSolver'.\")\n",
    "\n",
    "    adf_imports_ok = False\n",
    "    native_solver_load_failed = False\n",
    "    try:\n",
    "        # Imports\n",
    "        import jpype; from jpype.types import *; import pathlib\n",
    "        from java.io import File; from java.util import Collection\n",
    "\n",
    "        from org.tweetyproject.arg.adf.syntax.adf import AbstractDialecticalFramework\n",
    "        from org.tweetyproject.arg.adf.syntax import Argument as AdfArgument\n",
    "        from org.tweetyproject.arg.adf.syntax.acc import AcceptanceCondition\n",
    "        from org.tweetyproject.arg.adf.io import KppADFFormatParser\n",
    "        from org.tweetyproject.arg.adf.semantics.link import SatLinkStrategy, LinkStrategy\n",
    "        from org.tweetyproject.arg.adf.semantics.interpretation import Interpretation\n",
    "        from org.tweetyproject.arg.adf.reasoner import AdmissibleReasoner, CompleteReasoner, GroundReasoner, PreferredReasoner, StableReasoner, ModelReasoner\n",
    "        from org.tweetyproject.logics.pl.sat import Sat4jSolver # Fallback\n",
    "        # Interface requise par SatLinkStrategy\n",
    "        from org.tweetyproject.arg.adf.sat import IncrementalSatSolver\n",
    "\n",
    "        print(\"✔️ Imports ADF de base réussis.\")\n",
    "        adf_imports_ok = True\n",
    "\n",
    "        # Tenter de charger un solveur natif\n",
    "        adf_solver = None\n",
    "        try:\n",
    "             from org.tweetyproject.arg.adf.sat.solver import NativeMinisatSolver\n",
    "             adf_solver = NativeMinisatSolver()\n",
    "             print(\"ℹ️ Utilisation tentée de NativeMinisatSolver.\")\n",
    "        except Exception as e_native_init:\n",
    "             native_solver_load_failed = True\n",
    "             print(f\"⚠️ Échec chargement/init NativeMinisatSolver (attendu sans java.library.path): {e_native_init}\")\n",
    "             print(\"   Utilisation du fallback Sat4jSolver...\")\n",
    "             adf_solver = Sat4jSolver()\n",
    "\n",
    "        # --- Tentative d'initialisation du Parser ADF ---\n",
    "        print(\"\\nTentative de création de SatLinkStrategy...\")\n",
    "        link_strategy = None\n",
    "        try:\n",
    "            # SatLinkStrategy attend un IncrementalSatSolver\n",
    "            # Vérifions si notre solveur l'est (le natif oui, Sat4j non)\n",
    "            IncrementalSatSolver_class = jpype.JClass(\"org.tweetyproject.arg.adf.sat.IncrementalSatSolver\")\n",
    "\n",
    "            # *** CORRECTION: Utiliser isinstance() Python ***\n",
    "            if isinstance(adf_solver, IncrementalSatSolver_class):\n",
    "                 print(f\"   Le solveur ({adf_solver.getClass().getSimpleName()}) est un IncrementalSatSolver.\")\n",
    "                 link_strategy = SatLinkStrategy(adf_solver) # Devrait fonctionner si natif chargé\n",
    "                 print(\"✔️ SatLinkStrategy créée avec succès.\")\n",
    "            else:\n",
    "                 print(f\"   ❌ Le solveur fallback ({adf_solver.getClass().getSimpleName()}) N'EST PAS un IncrementalSatSolver.\")\n",
    "                 print(\"      Impossible de créer SatLinkStrategy requis par KppADFFormatParser.\")\n",
    "                 # On ne tente même pas de l'appeler car on sait que ça échouera avec TypeError\n",
    "\n",
    "        except jpype.JException as e_link_java:\n",
    "             print(f\"❌ Erreur Java lors de la création de SatLinkStrategy: {e_link_java.message()}\")\n",
    "        except Exception as e_link_py:\n",
    "              print(f\"❌ Erreur Python lors de la création de SatLinkStrategy: {e_link_py}\")\n",
    "\n",
    "\n",
    "        # --- Conclusion ADF ---\n",
    "        if link_strategy is None:\n",
    "             print(\"\\n❌ CONCLUSION ADF : Impossible de procéder.\")\n",
    "             print(\"   Le raisonnement ADF nécessite un solveur SAT incrémental natif.\")\n",
    "             if native_solver_load_failed:\n",
    "                 print(\"   Celui-ci n'a pas pu être chargé (UnsatisfiedLinkError probable),\")\n",
    "             print(\"   et le fallback Sat4jSolver n'est pas compatible avec SatLinkStrategy.\")\n",
    "             print(\"   Pour faire fonctionner cette section, il faudrait configurer\")\n",
    "             print(\"   le java.library.path de la JVM pour inclure le dossier 'libs/native',\")\n",
    "             print(\"   ce qui est complexe à faire proprement avec JPype.\")\n",
    "\n",
    "        # --- Code commenté (ne peut pas fonctionner sans link_strategy) ---\n",
    "        # print(\"\\nLe parsing et le raisonnement ADF sont commentés car non fonctionnels dans cet état.\")\n",
    "        '''\n",
    "        # --- Parsing ADF depuis Fichier ---\n",
    "        adf_filename = \"adf_example.txt\"\n",
    "        adf_filepath = pathlib.Path(\"resources\") / adf_filename\n",
    "        adf_framework = None\n",
    "\n",
    "        if not adf_filepath.is_file():\n",
    "            print(f\"\\\\n❌ ERREUR: Fichier ADF requis '{adf_filepath}' non trouvé !\")\n",
    "        elif link_strategy:\n",
    "            print(f\"\\\\nChargement de l'ADF depuis: {adf_filepath}\")\n",
    "            try:\n",
    "                adf_parser = KppADFFormatParser(link_strategy, True)\n",
    "                adf_framework = adf_parser.parse(File(str(adf_filepath)))\n",
    "                print(\"✔️ ADF chargé avec succès depuis le fichier.\")\n",
    "                # ... (affichage) ...\n",
    "            except Exception as e_parse_adf: print(f\"❌ Erreur parsing ADF: {e_parse_adf}\")\n",
    "\n",
    "        # --- Raisonnement ADF ---\n",
    "        if adf_framework is not None:\n",
    "            print(\"\\\\n--- Calcul des Sémantiques ADF ---\")\n",
    "            # ... (raisonneurs) ...\n",
    "        else:\n",
    "            print(\"\\\\n❌ Aucun ADF chargé, raisonnement sauté.\")\n",
    "        '''\n",
    "\n",
    "    # ... (Blocs except globaux inchangés) ...\n",
    "    except ImportError as e: print(f\"❌ Erreur d'import pour ADF : {e}. Vérifiez le JAR 'arg.adf'.\")\n",
    "    except jpype.JException as e_java: print(f\"❌ Erreur Java générale: {e_java.message()}\")\n",
    "    except Exception as e_gen: print(f\"❌ Erreur Python inattendue: {e_gen}\"); import traceback; traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a7b204",
   "metadata": {},
   "source": [
    "### 5.2 Frameworks Bipolaires (EAF, PEAF, Evidential, Necessity)\n",
    "<a id=\"5.2\"></a>\n",
    "\n",
    "Les cadres d'argumentation bipolaires étendent explicitement les AAFs de Dung en introduisant une relation de **support** distincte de l'attaque. Différentes propositions existent pour définir la nature exacte de ce support et son interaction avec l'attaque. Tweety implémente plusieurs de ces formalismes :\n",
    "\n",
    "* **EAF (Evidential/Extended AF)** (`org.tweetyproject.arg.bipolar.syntax.EAFTheory`): Introduit un support ensembliste simple (un ensemble d'arguments supporte un autre ensemble). Le raisonnement se fait souvent par traduction vers un AAF standard.\n",
    "* **PEAF (Probabilistic EAF)** (`org.tweetyproject.arg.bipolar.syntax.PEAFTheory`): Ajoute une probabilité à chaque relation de support, permettant de modéliser l'incertitude du support. Utilisé pour l'analyse de justification probabiliste.\n",
    "* **Evidential AF** (`org.tweetyproject.arg.bipolar.syntax.EvidentialArgumentationFramework`): Framework avec support ensembliste et la notion d'arguments \"prima facie\" (acceptés par défaut). Possède ses propres sémantiques (SelfSupporting, ConflictFree, Admissible...).\n",
    "* **Necessity AF** (`org.tweetyproject.arg.bipolar.syntax.NecessityArgumentationFramework`): Support ensembliste interprété comme une \"nécessité\" (tous les arguments supportants sont requis). Possède également ses propres sémantiques.\n",
    "\n",
    "Les exemples suivants illustreront l'Evidential AF et le Necessity AF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c84706",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 5.2 Frameworks Bipolaires ---\n",
    "print(\"\\n--- 5.2 Frameworks Bipolaires ---\")\n",
    "\n",
    "if not jvm_ready:\n",
    "    print(\"❌ ERREUR: JVM non démarrée.\")\n",
    "else:\n",
    "    print(\"ℹ️ JVM prête. Exécution des exemples Bipolaires...\")\n",
    "    bipolar_imports_ok = False\n",
    "    try:\n",
    "        # Imports\n",
    "        import jpype\n",
    "        from jpype.types import *\n",
    "        from java.util import HashSet, Collection, Set as JavaSet\n",
    "\n",
    "        # Syntaxe Dung de base (Argument) et Bipolaire\n",
    "        from org.tweetyproject.arg.dung.syntax import Argument\n",
    "        from org.tweetyproject.arg.bipolar.syntax import (\n",
    "             EvidentialArgumentationFramework, NecessityArgumentationFramework,\n",
    "             BArgument, ArgumentSet,\n",
    "             Attack, Support, # Interfaces/Classes de base\n",
    "             BinaryAttack, BinarySupport, # Pour Necessity\n",
    "             SetAttack, SetSupport # Pour Evidential et Necessity\n",
    "             )\n",
    "        # Raisonneurs Evidential\n",
    "        from org.tweetyproject.arg.bipolar.reasoner.evidential import (\n",
    "            SelfSupportingReasoner, ConflictFreeReasoner as EvidentialConflictFreeReasoner,\n",
    "            AdmissibleReasoner as EvidentialAdmissibleReasoner, GroundedReasoner as EvidentialGroundedReasoner,\n",
    "            CompleteReasoner as EvidentialCompleteReasoner, PreferredReasoner as EvidentialPreferredReasoner,\n",
    "            StableReasoner as EvidentialStableReasoner\n",
    "            )\n",
    "        # Raisonneurs Necessity\n",
    "        from org.tweetyproject.arg.bipolar.reasoner.necessity import (\n",
    "            AdmissibleReasoner as NecessityAdmissibleReasoner, GroundedReasoner as NecessityGroundedReasoner,\n",
    "            CompleteReasoner as NecessityCompleteReasoner, PreferredReasoner as NecessityPreferredReasoner,\n",
    "            StableReasoner as NecessityStableReasoner\n",
    "            )\n",
    "\n",
    "        print(\"✔️ Imports pour Frameworks Bipolaires réussis.\")\n",
    "        bipolar_imports_ok = True\n",
    "\n",
    "        # --- Exemple Evidential Argumentation ---\n",
    "        if bipolar_imports_ok:\n",
    "            print(\"\\n--- Exemple Evidential AF ---\")\n",
    "            et = EvidentialArgumentationFramework()\n",
    "            args_ev = {name: BArgument(name) for name in \"abcdef\"}\n",
    "            for arg in args_ev.values(): et.add(arg) # add(Argument) est ok\n",
    "\n",
    "            # Créer les objets Attack/Support\n",
    "            attack_b_a = SetAttack(args_ev['b'], args_ev['a'])\n",
    "            attack_b_c = SetAttack(args_ev['b'], args_ev['c'])\n",
    "            attack_c_b = SetAttack(args_ev['c'], args_ev['b'])\n",
    "            attack_c_d = SetAttack(args_ev['c'], args_ev['d'])\n",
    "            attack_d_f = SetAttack(args_ev['d'], args_ev['f'])\n",
    "            attack_f_f = SetAttack(args_ev['f'], args_ev['f'])\n",
    "            support_d_e = SetSupport(args_ev['d'], args_ev['e'])\n",
    "\n",
    "            # *** CORRECTION: Utiliser getAttacks().add() et getSupports().add() ***\n",
    "            print(\"   Ajout des attaques et supports (Evidential)...\")\n",
    "            attacks_et = et.getAttacks() # Récupérer la Collection<Attack>\n",
    "            supports_et = et.getSupports() # Récupérer la Collection<Support>\n",
    "            attacks_et.add(attack_b_a)\n",
    "            attacks_et.add(attack_b_c)\n",
    "            attacks_et.add(attack_c_b)\n",
    "            attacks_et.add(attack_c_d)\n",
    "            attacks_et.add(attack_d_f)\n",
    "            attacks_et.add(attack_f_f)\n",
    "            supports_et.add(support_d_e)\n",
    "            print(\"   ✔️ Relations ajoutées.\")\n",
    "\n",
    "            # Arguments Prima Facie (inchangé)\n",
    "            et.addPrimaFacie(args_ev['b'])\n",
    "            et.addPrimaFacie(args_ev['c'])\n",
    "            et.addPrimaFacie(args_ev['d'])\n",
    "            et.addPrimaFacie(args_ev['f'])\n",
    "\n",
    "            print(\"\\nFramework Evidential créé:\")\n",
    "            print(str(et.prettyPrint()))\n",
    "\n",
    "            # Raisonnement Evidential (inchangé)\n",
    "            print(\"\\nCalcul des extensions Evidential:\")\n",
    "            try:\n",
    "                print(f\" - Self-Supporting: {SelfSupportingReasoner().getModels(et)}\")\n",
    "                print(f\" - Conflict-Free: {EvidentialConflictFreeReasoner().getModels(et)}\")\n",
    "                print(f\" - Admissible: {EvidentialAdmissibleReasoner().getModels(et)}\")\n",
    "                print(f\" - Grounded: {EvidentialGroundedReasoner().getModels(et)}\")\n",
    "                print(f\" - Complete: {EvidentialCompleteReasoner().getModels(et)}\")\n",
    "                print(f\" - Preferred: {EvidentialPreferredReasoner().getModels(et)}\")\n",
    "                print(f\" - Stable: {EvidentialStableReasoner().getModels(et)}\")\n",
    "            except Exception as e_ev_reason:\n",
    "                print(f\"❌ Erreur raisonnement Evidential: {e_ev_reason}\")\n",
    "\n",
    "\n",
    "            # --- Exemple Necessity Argumentation ---\n",
    "            print(\"\\n\\n--- Exemple Necessity AF ---\")\n",
    "            nt = NecessityArgumentationFramework()\n",
    "            args_nec = {name: BArgument(name) for name in \"abcde\"}\n",
    "            for arg in args_nec.values(): nt.add(arg) # add(Argument) ok\n",
    "\n",
    "            # Créer les objets Attack/Support\n",
    "            attack_b_a_n = BinaryAttack(args_nec['b'], args_nec['a'])\n",
    "            attack_e_a_n = BinaryAttack(args_nec['e'], args_nec['a'])\n",
    "            attack_c_d_n = BinaryAttack(args_nec['c'], args_nec['d'])\n",
    "            support_a_c_n = BinarySupport(args_nec['a'], args_nec['c'])\n",
    "            support_b_b_n = BinarySupport(args_nec['b'], args_nec['b'])\n",
    "            # Pour SetSupport\n",
    "            supportants_s3 = ArgumentSet()\n",
    "            supportants_s3.add(args_nec['b'])\n",
    "            supportants_s3.add(args_nec['d'])\n",
    "            supportes_s3 = HashSet()\n",
    "            supportes_s3.add(args_nec['e'])\n",
    "            support_set_n = SetSupport(supportants_s3, JObject(supportes_s3, JavaSet))\n",
    "\n",
    "            # *** CORRECTION: Utiliser getAttacks().add() et getSupports().add() ***\n",
    "            print(\"   Ajout des attaques et supports (Necessity)...\")\n",
    "            attacks_nt = nt.getAttacks()\n",
    "            supports_nt = nt.getSupports()\n",
    "            attacks_nt.add(attack_b_a_n)\n",
    "            attacks_nt.add(attack_e_a_n)\n",
    "            attacks_nt.add(attack_c_d_n)\n",
    "            supports_nt.add(support_a_c_n)\n",
    "            supports_nt.add(support_b_b_n)\n",
    "            supports_nt.add(support_set_n)\n",
    "            print(\"   ✔️ Relations ajoutées.\")\n",
    "\n",
    "\n",
    "            print(\"\\nFramework Necessity créé:\")\n",
    "            print(str(nt.prettyPrint()))\n",
    "\n",
    "             # Raisonnement Necessity (inchangé)\n",
    "            print(\"\\nCalcul des extensions Necessity:\")\n",
    "            try:\n",
    "                print(f\" - Admissible: {NecessityAdmissibleReasoner().getModels(nt)}\")\n",
    "                print(f\" - Grounded: {NecessityGroundedReasoner().getModels(nt)}\")\n",
    "                print(f\" - Complete: {NecessityCompleteReasoner().getModels(nt)}\")\n",
    "                print(f\" - Preferred: {NecessityPreferredReasoner().getModels(nt)}\")\n",
    "                print(f\" - Stable: {NecessityStableReasoner().getModels(nt)}\")\n",
    "            except Exception as e_nec_reason:\n",
    "                print(f\"❌ Erreur raisonnement Necessity: {e_nec_reason}\")\n",
    "\n",
    "\n",
    "        else:\n",
    "             print(\"❌ Imports Bipolaires échoués. Impossible de continuer l'exemple.\")\n",
    "\n",
    "    # Gestion globale (inchangée)\n",
    "    except ImportError as e: print(f\"❌ Erreur d'import Bipolaires: {e}.\")\n",
    "    except jpype.JException as e_java: print(f\"❌ Erreur Java générale Bipolaires: {e_java.message()}\"); print(e_java.stacktrace())\n",
    "    except Exception as e_gen: print(f\"❌ Erreur Python inattendue Bipolaires: {e_gen}\"); import traceback; traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70893d1",
   "metadata": {},
   "source": [
    "### 5.3 Frameworks Pondérés (WAF)\n",
    "<a id=\"5.3\"></a>\n",
    "\n",
    "Les Cadres d'Argumentation Pondérés (Weighted Argumentation Frameworks - WAF) étendent les cadres de Dung en associant un **poids** à chaque attaque, représentant sa force ou son coût. L'évaluation de l'acceptabilité des arguments prend alors en compte ces poids, souvent à travers des **seuils** ou des **agrégations**.\n",
    "\n",
    "* **Structure :** Un WAF est un triplet $(Args, Atts, w)$ où $(Args, Atts)$ est un AAF de Dung et $w: Atts \\\\to \\\\mathcal{W}$ est une fonction qui assigne un poids de l'ensemble $\\\\mathcal{W}$ à chaque attaque.\n",
    "* **Semi-anneaux (`Semiring`) :** Tweety utilise la structure algébrique des semi-anneaux pour définir comment les poids sont interprétés et agrégés. Exemples courants :\n",
    "    * `WeightedSemiring`: Poids numériques sommés (souvent interprétés comme des coûts).\n",
    "    * `FuzzySemiring`: Poids dans $[0, 1]$ interprétés comme des degrés de vérité/force (logique floue).\n",
    "    * `ProbabilisticSemiring`: Poids dans $[0, 1]$ interprétés comme des probabilités.\n",
    "    * `BottleneckSemiring`: L'agrégation prend le \"maillon faible\" (max ou min selon l'interprétation).\n",
    "    * `BooleanSemiring`: Poids booléens, équivalent à un AAF standard.\n",
    "* **`WeightedArgumentationFramework<S>`**: Classe Tweety paramétrée par le type de semi-anneau `S`.\n",
    "* **Raisonnement (`SimpleWeighted...Reasoner`)**: Les raisonneurs pour WAF généralisent les sémantiques standards (admissible, complète, etc.). Ils prennent souvent des **seuils** (`alpha`, `gamma`) en paramètres pour déterminer quand un argument est considéré comme \"suffisamment défendu\" ou quand une attaque est \"suffisamment forte\" pour être prise en compte.\n",
    "\n",
    "L'exemple suivant implémente `WeightedReasonerExample.java` en utilisant `WeightedSemiring`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd6fb7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 5.3 Frameworks Pondérés (WAF) ---\n",
    "print(\"\\n--- 5.3 Frameworks Pondérés (WAF) ---\")\n",
    "\n",
    "if not jvm_ready:\n",
    "    print(\"❌ ERREUR: JVM non démarrée.\")\n",
    "else:\n",
    "    print(\"ℹ️ JVM prête. Exécution de l'exemple WAF...\")\n",
    "    waf_imports_ok = False\n",
    "    try:\n",
    "        # Imports\n",
    "        import jpype\n",
    "        from jpype.types import *\n",
    "\n",
    "        # WAF et composants Dung\n",
    "        from org.tweetyproject.arg.weighted.syntax import WeightedArgumentationFramework\n",
    "        from org.tweetyproject.arg.dung.syntax import Argument, Attack, DungTheory\n",
    "        # Semi-anneau spécifique (autres possibles: FuzzySemiring, ProbabilisticSemiring, etc.)\n",
    "        from org.tweetyproject.math.algebra import WeightedSemiring\n",
    "        # Raisonneurs pondérés\n",
    "        from org.tweetyproject.arg.weighted.reasoner import (\n",
    "             SimpleWeightedConflictFreeReasoner, SimpleWeightedAdmissibleReasoner,\n",
    "             SimpleWeightedCompleteReasoner, SimpleWeightedPreferredReasoner,\n",
    "             SimpleWeightedStableReasoner, SimpleWeightedGroundedReasoner\n",
    "        )\n",
    "        # Raisonneurs Dung standards pour comparaison\n",
    "        from org.tweetyproject.arg.dung.reasoner import (\n",
    "            SimpleAdmissibleReasoner, SimpleCompleteReasoner, SimplePreferredReasoner,\n",
    "            SimpleStableReasoner, SimpleGroundedReasoner\n",
    "        )\n",
    "        from org.tweetyproject.arg.dung.semantics import Extension # Pour type hinting\n",
    "        from java.util import Collection\n",
    "\n",
    "        print(\"✔️ Imports WAF et dépendances réussis.\")\n",
    "        waf_imports_ok = True\n",
    "\n",
    "        # --- Création du WAF ---\n",
    "        if waf_imports_ok:\n",
    "            # Utiliser WeightedSemiring (poids numériques additifs/coûts)\n",
    "            # On peut spécifier une valeur max (comme 20.0 dans l'exemple Java) ou non\n",
    "            semiring = WeightedSemiring() # Par défaut, pas de max explicitement défini ici\n",
    "\n",
    "            # WeightedArgumentationFramework<S extends Semiring>\n",
    "            waf = WeightedArgumentationFramework(semiring)\n",
    "\n",
    "            # Arguments\n",
    "            a = Argument(\"a\"); b = Argument(\"b\"); c = Argument(\"c\"); d = Argument(\"d\"); e_arg = Argument(\"e\") # Renommé e -> e_arg\n",
    "            waf.add(a); waf.add(b); waf.add(c); waf.add(d); waf.add(e_arg)\n",
    "\n",
    "            # Attaques pondérées: add(Attack, Double weight)\n",
    "            waf.add(Attack(a, b), 7.0)\n",
    "            waf.add(Attack(c, b), 8.0)\n",
    "            waf.add(Attack(d, c), 8.0)\n",
    "            waf.add(Attack(c, d), 9.0)\n",
    "            waf.add(Attack(d, e_arg), 5.0)\n",
    "            waf.add(Attack(e_arg, e_arg), 6.0) # Auto-attaque sur e\n",
    "\n",
    "            print(\"\\nFramework Pondéré (WAF) créé:\")\n",
    "            print(str(waf)) # Devrait montrer les poids\n",
    "\n",
    "            # --- Raisonnement Pondéré ---\n",
    "            print(\"\\n--- Raisonnement Pondéré ---\")\n",
    "\n",
    "            # Raisonneur Conflict-Free Pondéré\n",
    "            print(\"\\n* Conflict-Free Pondéré:\")\n",
    "            try:\n",
    "                weighted_cf_reasoner = SimpleWeightedConflictFreeReasoner()\n",
    "                # getModels(WAF, threshold) - Le seuil n'est généralement pas pertinent pour CF seul\n",
    "                # L'implémentation Java semble l'ignorer, mettons 0.0\n",
    "                cf_sets_0 = weighted_cf_reasoner.getModels(waf, 0.0)\n",
    "                cf_sets_15 = weighted_cf_reasoner.getModels(waf, 15.0) # Test avec seuil > max poids\n",
    "                print(f\"  - Seuil 0.0 : ({cf_sets_0.size()}) {cf_sets_0}\")\n",
    "                print(f\"  - Seuil 15.0: ({cf_sets_15.size()}) {cf_sets_15}\")\n",
    "            except Exception as e_cf: print(f\"   ❌ Erreur Weighted ConflictFree: {e_cf}\")\n",
    "\n",
    "\n",
    "            # Raisonneur Admissible Pondéré vs Standard\n",
    "            print(\"\\n* Admissible Pondéré (alpha, gamma) vs Standard:\")\n",
    "            try:\n",
    "                adm_reasoner_std = SimpleAdmissibleReasoner()\n",
    "                weighted_adm_reasoner = SimpleWeightedAdmissibleReasoner()\n",
    "                dung_theory_std = DungTheory(waf) # Version non pondérée pour comparaison\n",
    "\n",
    "                adm_sets_std = adm_reasoner_std.getModels(dung_theory_std)\n",
    "                print(f\"  - Standard    : ({adm_sets_std.size()}) {adm_sets_std}\")\n",
    "\n",
    "                # getModels(WAF, alpha, gamma)\n",
    "                adm_sets_0_0 = weighted_adm_reasoner.getModels(waf, 0.0, 0.0)\n",
    "                print(f\"  - Pondéré (α=0, γ=0) : ({adm_sets_0_0.size()}) {adm_sets_0_0}\")\n",
    "                adm_sets_15_0 = weighted_adm_reasoner.getModels(waf, 15.0, 0.0)\n",
    "                print(f\"  - Pondéré (α=15, γ=0): ({adm_sets_15_0.size()}) {adm_sets_15_0}\")\n",
    "                adm_sets_11_1 = weighted_adm_reasoner.getModels(waf, 11.0, 1.0)\n",
    "                print(f\"  - Pondéré (α=11, γ=1): ({adm_sets_11_1.size()}) {adm_sets_11_1}\")\n",
    "\n",
    "            except Exception as e_adm: print(f\"   ❌ Erreur Weighted Admissible: {e_adm}\")\n",
    "\n",
    "\n",
    "            # Raisonneur Complet Pondéré vs Standard\n",
    "            print(\"\\n* Complet Pondéré (alpha, gamma) vs Standard:\")\n",
    "            try:\n",
    "                comp_reasoner_std = SimpleCompleteReasoner()\n",
    "                weighted_comp_reasoner = SimpleWeightedCompleteReasoner()\n",
    "                comp_sets_std = comp_reasoner_std.getModels(dung_theory_std)\n",
    "                print(f\"  - Standard    : ({comp_sets_std.size()}) {comp_sets_std}\")\n",
    "\n",
    "                comp_sets_0_0 = weighted_comp_reasoner.getModels(waf, 0.0, 0.0)\n",
    "                print(f\"  - Pondéré (α=0, γ=0) : ({comp_sets_0_0.size()}) {comp_sets_0_0}\")\n",
    "                comp_sets_0_1 = weighted_comp_reasoner.getModels(waf, 0.0, 1.0)\n",
    "                print(f\"  - Pondéré (α=0, γ=1) : ({comp_sets_0_1.size()}) {comp_sets_0_1}\")\n",
    "                comp_sets_11_1 = weighted_comp_reasoner.getModels(waf, 11.0, 1.0)\n",
    "                print(f\"  - Pondéré (α=11, γ=1): ({comp_sets_11_1.size()}) {comp_sets_11_1}\")\n",
    "            except Exception as e_comp: print(f\"   ❌ Erreur Weighted Complete: {e_comp}\")\n",
    "\n",
    "\n",
    "            # Raisonneur Préféré Pondéré vs Standard\n",
    "            print(\"\\n* Préféré Pondéré (alpha, gamma) vs Standard:\")\n",
    "            try:\n",
    "                pref_reasoner_std = SimplePreferredReasoner()\n",
    "                weighted_pref_reasoner = SimpleWeightedPreferredReasoner()\n",
    "                pref_sets_std = pref_reasoner_std.getModels(dung_theory_std)\n",
    "                print(f\"  - Standard    : ({pref_sets_std.size()}) {pref_sets_std}\")\n",
    "\n",
    "                pref_sets_0_0 = weighted_pref_reasoner.getModels(waf, 0.0, 0.0)\n",
    "                print(f\"  - Pondéré (α=0, γ=0) : ({pref_sets_0_0.size()}) {pref_sets_0_0}\")\n",
    "                pref_sets_0_1 = weighted_pref_reasoner.getModels(waf, 0.0, 1.0)\n",
    "                print(f\"  - Pondéré (α=0, γ=1) : ({pref_sets_0_1.size()}) {pref_sets_0_1}\")\n",
    "            except Exception as e_pref: print(f\"   ❌ Erreur Weighted Preferred: {e_pref}\")\n",
    "\n",
    "\n",
    "            # Raisonneur Stable Pondéré vs Standard\n",
    "            print(\"\\n* Stable Pondéré (alpha, gamma) vs Standard:\")\n",
    "            try:\n",
    "                stab_reasoner_std = SimpleStableReasoner()\n",
    "                weighted_stab_reasoner = SimpleWeightedStableReasoner()\n",
    "                stab_sets_std = stab_reasoner_std.getModels(dung_theory_std)\n",
    "                print(f\"  - Standard    : ({stab_sets_std.size()}) {stab_sets_std}\")\n",
    "\n",
    "                stab_sets_0_0 = weighted_stab_reasoner.getModels(waf, 0.0, 0.0)\n",
    "                print(f\"  - Pondéré (α=0, γ=0) : ({stab_sets_0_0.size()}) {stab_sets_0_0}\")\n",
    "                stab_sets_0_1 = weighted_stab_reasoner.getModels(waf, 0.0, 1.0)\n",
    "                print(f\"  - Pondéré (α=0, γ=1) : ({stab_sets_0_1.size()}) {stab_sets_0_1}\")\n",
    "            except Exception as e_stab: print(f\"   ❌ Erreur Weighted Stable: {e_stab}\")\n",
    "\n",
    "            # Raisonneur Grounded Pondéré vs Standard\n",
    "            print(\"\\n* Grounded Pondéré (alpha, gamma) vs Standard:\")\n",
    "            try:\n",
    "                gr_reasoner_std = SimpleGroundedReasoner()\n",
    "                weighted_gr_reasoner = SimpleWeightedGroundedReasoner()\n",
    "                gr_set_std = gr_reasoner_std.getModel(dung_theory_std) # Grounded est unique\n",
    "                print(f\"  - Standard    : {{{gr_set_std}}}\") # Afficher comme set\n",
    "\n",
    "                gr_set_0_0 = weighted_gr_reasoner.getModel(waf, 0.0, 0.0)\n",
    "                print(f\"  - Pondéré (α=0, γ=0) : {{{gr_set_0_0}}}\")\n",
    "            except Exception as e_gr: print(f\"   ❌ Erreur Weighted Grounded: {e_gr}\")\n",
    "\n",
    "\n",
    "        else:\n",
    "             print(\"❌ Imports WAF échoués. Impossible de continuer l'exemple.\")\n",
    "\n",
    "    # Gestion globale\n",
    "    except ImportError as e:\n",
    "        print(f\"❌ Erreur d'import pour WAF : {e}. Vérifiez les JARs 'arg.weighted', 'arg.dung', 'math'.\")\n",
    "    except jpype.JException as e_java:\n",
    "        print(f\"❌ Erreur Java générale WAF: {e_java.message()}\")\n",
    "        # print(e_java.stacktrace())\n",
    "    except Exception as e_gen:\n",
    "        print(f\"❌ Erreur Python inattendue WAF: {e_gen}\")\n",
    "        import traceback; traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a97851",
   "metadata": {},
   "source": [
    "### 5.4 Frameworks Sociaux (SAF)\n",
    "<a id=\"5.4\"></a>\n",
    "\n",
    "Les Cadres d'Argumentation Sociaux (SAF) [Leite, Martins, 2011] étendent les cadres de Dung en permettant d'associer des **votes** (positifs ou négatifs) aux arguments. Ces votes influencent la force ou l'acceptabilité finale des arguments, en plus des relations d'attaque.\n",
    "\n",
    "* **Structure :** Un AAF de Dung + une fonction V qui assigne à chaque argument un support numérique (ex: nombre de votes positifs - nombre de votes négatifs).\n",
    "* **Tweety :** `SocialAbstractArgumentationFramework` étend `DungTheory` et fournit les méthodes `voteUp(arg, count)` et `voteDown(arg, count)`.\n",
    "* **Sémantique :** Souvent itérative, comme **ISS (Iterated Schema Semantics)** [Gabbay, Rodrigues], qui calcule un score pour chaque argument basé sur les scores de ses attaquants et sur les votes, jusqu'à convergence.\n",
    "* **Raisonnement :** `IssReasoner` implémente cette sémantique. Il prend en paramètre une fonction de mise à jour (ex: `SimpleProductSemantics`) et un seuil de convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda4a2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 5.4 Frameworks Sociaux (SAF) ---\n",
    "print(\"\\n--- 5.4 Frameworks Sociaux (SAF) ---\")\n",
    "\n",
    "if not jvm_ready:\n",
    "    print(\"❌ ERREUR: JVM non démarrée.\")\n",
    "else:\n",
    "    print(\"ℹ️ JVM prête. Exécution de l'exemple SAF...\")\n",
    "    saf_imports_ok = False\n",
    "    try:\n",
    "        # Imports SAF et Dung (Argument, Attack)\n",
    "        import jpype\n",
    "        from jpype.types import *\n",
    "        # Utiliser JClass pour être sûr si les imports directs échouent\n",
    "        try:\n",
    "            from org.tweetyproject.arg.social.syntax import SocialAbstractArgumentationFramework\n",
    "            from org.tweetyproject.arg.dung.syntax import Argument, Attack\n",
    "            from org.tweetyproject.arg.social.reasoner import IssReasoner\n",
    "            from org.tweetyproject.arg.social.semantics import SimpleProductSemantics\n",
    "            print(\"✔️ Imports SAF directs réussis.\")\n",
    "            saf_imports_ok = True\n",
    "        except ImportError:\n",
    "            print(\"⚠️ Imports directs SAF échoués. Tentative avec JClass...\")\n",
    "            SocialAbstractArgumentationFramework = jpype.JClass(\"org.tweetyproject.arg.social.syntax.SocialAbstractArgumentationFramework\")\n",
    "            Argument = jpype.JClass(\"org.tweetyproject.arg.dung.syntax.Argument\")\n",
    "            Attack = jpype.JClass(\"org.tweetyproject.arg.dung.syntax.Attack\")\n",
    "            IssReasoner = jpype.JClass(\"org.tweetyproject.arg.social.reasoner.IssReasoner\")\n",
    "            SimpleProductSemantics = jpype.JClass(\"org.tweetyproject.arg.social.semantics.SimpleProductSemantics\")\n",
    "            print(\"✔️ Imports SAF via JClass réussis.\")\n",
    "            saf_imports_ok = True\n",
    "\n",
    "        # Collection Java pour getAttacks()\n",
    "        from java.util import Collection\n",
    "\n",
    "        # --- Création du SAF ---\n",
    "        if saf_imports_ok:\n",
    "            saf = SocialAbstractArgumentationFramework()\n",
    "            A = Argument(\"A\"); B = Argument(\"B\"); C = Argument(\"C\"); D = Argument(\"D\")\n",
    "            saf.add(A); saf.add(B); saf.add(C); saf.add(D) # add(Argument) est non ambigu\n",
    "\n",
    "            # Attaques: A->B, B<->C, C->D\n",
    "            attack_ab = Attack(A, B)\n",
    "            attack_bc = Attack(B, C)\n",
    "            attack_cb = Attack(C, B)\n",
    "            attack_cd = Attack(C, D)\n",
    "\n",
    "            # *** NOUVELLE APPROCHE : Obtenir la collection et utiliser son add ***\n",
    "            try:\n",
    "                attacks_collection = saf.getAttacks() # Devrait retourner Collection<Attack>\n",
    "                # Utiliser la méthode add de la Collection Java\n",
    "                attacks_collection.add(attack_ab)\n",
    "                attacks_collection.add(attack_bc)\n",
    "                attacks_collection.add(attack_cb)\n",
    "                attacks_collection.add(attack_cd)\n",
    "                print(\"   ✔️ Attaques ajoutées avec succès (via getAttacks().add()).\")\n",
    "\n",
    "                # --- Ajout des Votes ---\n",
    "                saf.voteUp(A, 3); saf.voteDown(A, 1) # A: +2 net\n",
    "                saf.voteUp(B, 2)                     # B: +2 net\n",
    "                saf.voteUp(C, 2); saf.voteDown(C, 5) # C: -3 net\n",
    "                saf.voteUp(D, 2); saf.voteDown(D, 1) # D: +1 net\n",
    "\n",
    "                print(\"\\nFramework Social (SAF) créé:\")\n",
    "                print(str(saf))\n",
    "\n",
    "                # --- Raisonnement ISS ---\n",
    "                print(\"\\nCalcul du modèle avec ISS (Iterated Schema Semantics)...\")\n",
    "                try:\n",
    "                    iss_reasoner = IssReasoner(SimpleProductSemantics(0.01), 0.001)\n",
    "                    iss_model = iss_reasoner.getModel(saf)\n",
    "                    print(\"\\nModèle ISS (scores d'acceptabilité):\\n\", str(iss_model))\n",
    "\n",
    "                except jpype.JException as e_iss_java:\n",
    "                     print(f\"❌ Erreur Java lors du raisonnement ISS: {e_iss_java.message()}\")\n",
    "                     # print(e_iss_java.stacktrace())\n",
    "                except Exception as e_iss_py:\n",
    "                     print(f\"❌ Erreur Python lors du raisonnement ISS: {e_iss_py}\")\n",
    "\n",
    "            except Exception as e_add_attack:\n",
    "                 print(f\"❌ Erreur lors de l'ajout d'attaques via getAttacks().add(): {e_add_attack}\")\n",
    "                 print(\"   Impossible de continuer avec cet exemple SAF.\")\n",
    "\n",
    "\n",
    "        else:\n",
    "             print(\"❌ Imports SAF échoués. Impossible de continuer l'exemple.\")\n",
    "\n",
    "\n",
    "    # ... (Blocs except globaux inchangés) ...\n",
    "    except ImportError as e: print(f\"❌ Erreur d'import initiale pour SAF : {e}.\")\n",
    "    except jpype.JException as e_java: print(f\"❌ Erreur Java générale: {e_java.message()}\")\n",
    "    except Exception as e_gen: print(f\"❌ Erreur Python inattendue: {e_gen}\"); import traceback; traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99202444",
   "metadata": {},
   "source": [
    "### 5.5 Set Argumentation Frameworks (SetAF)\n",
    "<a id=\"5.5\"></a>\n",
    "\n",
    "Les Set Argumentation Frameworks (SetAF), introduits par Nielsen et Parsons (2006), généralisent les attaques des AAF de Dung. Au lieu qu'un argument unique attaque un autre argument, c'est un **ensemble** d'arguments qui attaque collectivement un argument.\n",
    "\n",
    "* **Structure :** Un SetAF est une paire $(Args, Atts_{set})$ où $Args$ est l'ensemble d'arguments et $Atts_{set} \\\\subseteq (2^{Args} \\\\setminus \\\\emptyset) \\\\times Args$ est la relation d'attaque d'ensemble. Une attaque est de la forme $(X, a)$ où $X$ est un ensemble non vide d'arguments et $a$ est l'argument attaqué.\n",
    "* **Sémantique :** Les sémantiques classiques (conflict-free, admissible, complète, préférée, fondée, stable) sont étendues aux SetAF. Par exemple, un ensemble $E$ est sans conflit si aucun sous-ensemble $X \\\\subseteq E$ n'attaque un argument $a \\\\in E$. Un argument $a$ est défendu par $E$ si pour chaque ensemble $X$ qui attaque $a$, il existe un $e \\\\in E$ tel qu'un sous-ensemble $Y \\\\subseteq E$ attaque un $x \\\\in X$.\n",
    "* **Tweety :**\n",
    "    * `SetAf` : Représente le framework.\n",
    "    * `SetAttack` : Représente une attaque $(X, a)$. Prend un `Set<Argument>` et un `Argument`.\n",
    "    * Raisonneurs (`org.tweetyproject.arg.setaf.reasoners.*`) : `SimpleGroundedSetAfReasoner`, `SimpleAdmissibleSetAfReasoner`, `SimplePreferredSetAfReasoner`.\n",
    "\n",
    "L'exemple suivant implémente `SetAfTheoryTest.java`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d34d47ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 5.5 Set Argumentation Frameworks (SetAF) ---\n",
    "print(\"\\n--- 5.5 Set Argumentation Frameworks (SetAF) ---\")\n",
    "\n",
    "if not jvm_ready:\n",
    "    print(\"❌ ERREUR: JVM non démarrée.\")\n",
    "else:\n",
    "    print(\"ℹ️ JVM prête. Exécution de l'exemple SetAF...\")\n",
    "    setaf_imports_ok = False\n",
    "    try:\n",
    "        # Imports\n",
    "        import jpype\n",
    "        from jpype.types import *\n",
    "        from java.util import HashSet, Set as JavaSet # Pour créer l'ensemble attaquant\n",
    "\n",
    "        # Composants SetAF et Dung\n",
    "        from org.tweetyproject.arg.setaf.syntax import SetAf, SetAttack\n",
    "        from org.tweetyproject.arg.dung.syntax import Argument # Argument est commun\n",
    "        # Raisonneurs SetAF\n",
    "        from org.tweetyproject.arg.setaf.reasoners import SimpleGroundedSetAfReasoner, SimpleAdmissibleSetAfReasoner, SimplePreferredSetAfReasoner\n",
    "\n",
    "        print(\"✔️ Imports SetAF et dépendances réussis.\")\n",
    "        setaf_imports_ok = True\n",
    "\n",
    "        # --- Création du SetAF ---\n",
    "        if setaf_imports_ok:\n",
    "            set_af = SetAf()\n",
    "            a = Argument(\"a\"); b = Argument(\"b\"); c = Argument(\"c\"); d_arg = Argument(\"d\") # Renommé d -> d_arg\n",
    "            set_af.add(a); set_af.add(b); set_af.add(c); set_af.add(d_arg)\n",
    "\n",
    "            # Créer les ensembles attaquants (HashSet Java)\n",
    "            attacker_set1 = HashSet()\n",
    "            attacker_set1.add(b)\n",
    "            attacker_set1.add(d_arg)\n",
    "\n",
    "            attacker_set2 = HashSet()\n",
    "            attacker_set2.add(c)\n",
    "            attacker_set2.add(a)\n",
    "\n",
    "            # Ajouter les attaques d'ensemble: SetAttack(Set<Argument> attackers, Argument attacked)\n",
    "            # Cast explicite du HashSet en java.util.Set pour le constructeur\n",
    "            set_attack1 = SetAttack(JObject(attacker_set1, JavaSet), a)\n",
    "            set_attack2 = SetAttack(JObject(attacker_set2, JavaSet), c)\n",
    "            set_af.add(set_attack1)\n",
    "            set_af.add(set_attack2)\n",
    "\n",
    "            print(\"\\nFramework SetAF créé:\")\n",
    "            # Utiliser toString() ou la représentation Python standard\n",
    "            print(str(set_af))\n",
    "            # Alternative: Afficher arguments et attaques séparément pour plus de clarté\n",
    "            print(f\"   Arguments: {set_af.getNodes()}\")\n",
    "            print(f\"   Attaques Set: {set_af.getAttacks()}\")\n",
    "\n",
    "\n",
    "            # --- Raisonnement SetAF ---\n",
    "            print(\"\\n--- Raisonnement SetAF ---\")\n",
    "            try:\n",
    "                gr_setaf_reasoner = SimpleGroundedSetAfReasoner()\n",
    "                gr_setaf_extension = gr_setaf_reasoner.getModel(set_af)\n",
    "                print(f\"\\n* Extension Fondée (Grounded): {gr_setaf_extension}\")\n",
    "\n",
    "                adm_setaf_reasoner = SimpleAdmissibleSetAfReasoner()\n",
    "                adm_setaf_extensions = adm_setaf_reasoner.getModels(set_af)\n",
    "                print(f\"\\n* Extensions Admissibles ({adm_setaf_extensions.size()}): {adm_setaf_extensions}\")\n",
    "\n",
    "                pref_setaf_reasoner = SimplePreferredSetAfReasoner()\n",
    "                pref_setaf_extensions = pref_setaf_reasoner.getModels(set_af)\n",
    "                print(f\"\\n* Extensions Préférées ({pref_setaf_extensions.size()}): {pref_setaf_extensions}\")\n",
    "\n",
    "            except jpype.JException as e_reason_java:\n",
    "                print(f\"❌ Erreur Java lors du raisonnement SetAF: {e_reason_java.message()}\")\n",
    "                # print(e_reason_java.stacktrace())\n",
    "            except Exception as e_reason_py:\n",
    "                print(f\"❌ Erreur Python lors du raisonnement SetAF: {e_reason_py}\")\n",
    "\n",
    "\n",
    "        else:\n",
    "             print(\"❌ Imports SetAF échoués. Impossible de continuer l'exemple.\")\n",
    "\n",
    "    # Gestion globale\n",
    "    except ImportError as e:\n",
    "        print(f\"❌ Erreur d'import pour SetAF : {e}. Vérifiez le JAR 'arg.setaf'.\")\n",
    "    except jpype.JException as e_java:\n",
    "        print(f\"❌ Erreur Java générale SetAF: {e_java.message()}\")\n",
    "        # print(e_java.stacktrace())\n",
    "    except Exception as e_gen:\n",
    "        print(f\"❌ Erreur Python inattendue SetAF: {e_gen}\")\n",
    "        import traceback; traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ddf622",
   "metadata": {},
   "source": [
    "### 5.6 Frameworks Étendus (Attaques sur Attaques)\n",
    "<a id=\"5.6\"></a>\n",
    "\n",
    "Les Frameworks d'Argumentation Étendus [Modgil, 2009] permettent de modéliser des scénarios où une attaque peut elle-même être attaquée par un argument. Cela permet de représenter des concepts comme la préférence ou la priorité entre attaques de manière plus directe qu'avec les AAF standards. Tweety supporte deux variantes principales :\n",
    "\n",
    "1.  **EAF (Extended Argumentation Frameworks)** (`org.tweetyproject.arg.extended.syntax.ExtendedTheory`): Permet aux arguments d'attaquer des attaques. Une attaque $(a, b)$ est représentée comme un objet qui peut être la cible d'une autre attaque $(c, (a, b))$.\n",
    "2.  **REAF (Recursive Extended Argumentation Frameworks)** (`org.tweetyproject.arg.extended.syntax.RecursiveExtendedTheory`): Généralise les EAF en permettant aux arguments d'attaquer des attaques sur des attaques (récursivement). Une attaque étendue $(a, \\alpha)$ peut avoir comme cible $\\alpha$ soit un argument, soit une autre attaque étendue.\n",
    "\n",
    "Le raisonnement sur ces frameworks étend les sémantiques classiques pour prendre en compte la réintégration potentielle d'arguments dont les attaquants sont eux-mêmes attaqués avec succès.\n",
    "\n",
    "* **Tweety :**\n",
    "    * `ExtendedTheory` / `RecursiveExtendedTheory`\n",
    "    * `ExtendedAttack` (pour REAF, représente une attaque dont la cible peut être une autre attaque)\n",
    "    * Raisonneurs (`org.tweetyproject.arg.extended.reasoner.*`) : `SimpleExtendedCompleteReasoner`, `SimpleRecursiveExtendedCompleteReasoner`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3537b896",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 5.6 Frameworks Étendus (EAF / REAF) ---\n",
    "print(\"\\n--- 5.6 Frameworks Étendus (EAF / REAF) ---\")\n",
    "\n",
    "if not jvm_ready:\n",
    "    print(\"❌ ERREUR: JVM non démarrée.\")\n",
    "else:\n",
    "    print(\"ℹ️ JVM prête. Exécution de l'exemple EAF/REAF...\")\n",
    "    eaf_reaf_imports_ok = False\n",
    "    try:\n",
    "        # Imports (inchangés)\n",
    "        import jpype\n",
    "        from jpype.types import *\n",
    "        from org.tweetyproject.arg.dung.syntax import Argument, Attack\n",
    "        from org.tweetyproject.arg.extended.syntax import ExtendedTheory, RecursiveExtendedTheory, ExtendedAttack\n",
    "        from org.tweetyproject.arg.extended.reasoner import SimpleExtendedCompleteReasoner, SimpleRecursiveExtendedCompleteReasoner\n",
    "        # Ajouter l'import pour JObject si nécessaire (dépend si utilisé dans d'autres cellules)\n",
    "        # from jpype import JObject\n",
    "\n",
    "        print(\"✔️ Imports EAF/REAF réussis.\")\n",
    "        eaf_reaf_imports_ok = True\n",
    "\n",
    "        # --- Exemple EAF (ExtendedTheory) ---\n",
    "        if eaf_reaf_imports_ok:\n",
    "            print(\"\\n--- Exemple Extended AF (EAF) ---\")\n",
    "            eaf_theory = ExtendedTheory()\n",
    "            # Arguments (inchangés)\n",
    "            a_eaf = Argument(\"a_e\"); b_eaf = Argument(\"b_e\"); c_eaf = Argument(\"c_e\")\n",
    "            d_eaf = Argument(\"d_e\"); e_eaf = Argument(\"e_e\")\n",
    "            eaf_theory.add(a_eaf); eaf_theory.add(b_eaf); eaf_theory.add(c_eaf)\n",
    "            eaf_theory.add(d_eaf); eaf_theory.add(e_eaf)\n",
    "\n",
    "            # *** CORRECTION: Appel de addAttack avec source et cible ***\n",
    "\n",
    "            # 1. Ajouter les attaques standard (Arg -> Arg)\n",
    "            print(\"   Ajout attaques standard EAF...\")\n",
    "            eaf_theory.addAttack(a_eaf, b_eaf)\n",
    "            eaf_theory.addAttack(b_eaf, a_eaf)\n",
    "            eaf_theory.addAttack(c_eaf, d_eaf)\n",
    "            eaf_theory.addAttack(d_eaf, c_eaf)\n",
    "            print(\"   ✔️ Attaques standard ajoutées.\")\n",
    "\n",
    "            # 2. Créer les objets Attack qui seront les cibles des attaques étendues\n",
    "            print(\"   Création des objets Attack cibles...\")\n",
    "            # Il FAUT créer l'objet Attack AVANT de pouvoir le cibler\n",
    "            attack_ba_target = Attack(b_eaf, a_eaf)\n",
    "            attack_ab_target = Attack(a_eaf, b_eaf)\n",
    "            attack_cd_target = Attack(c_eaf, d_eaf)\n",
    "            print(\"   ✔️ Objets Attack cibles créés.\")\n",
    "\n",
    "            # 3. Ajouter les attaques étendues (Arg -> Attack)\n",
    "            print(\"   Ajout attaques étendues EAF...\")\n",
    "            # c attaques (b->a)\n",
    "            eaf_theory.addAttack(c_eaf, attack_ba_target)\n",
    "            # d attaques (a->b)\n",
    "            eaf_theory.addAttack(d_eaf, attack_ab_target)\n",
    "            # e attaques (c->d)\n",
    "            eaf_theory.addAttack(e_eaf, attack_cd_target)\n",
    "            print(\"   ✔️ Attaques étendues ajoutées.\")\n",
    "\n",
    "\n",
    "            print(\"\\nFramework EAF créé:\")\n",
    "            # Utiliser prettyPrint pour une meilleure lisibilité si possible\n",
    "            try: print(str(eaf_theory.prettyPrint()))\n",
    "            except: print(str(eaf_theory)) # Fallback si prettyPrint échoue\n",
    "\n",
    "            # Raisonnement EAF (Complète) - Inchangé\n",
    "            print(f\"\\nCalcul des Extensions Complètes (EAF)...\")\n",
    "            try:\n",
    "                eaf_reasoner = SimpleExtendedCompleteReasoner()\n",
    "                eaf_extensions = eaf_reasoner.getModels(eaf_theory)\n",
    "                print(f\"Extensions Complètes (EAF): ({eaf_extensions.size()})\")\n",
    "                if eaf_extensions.isEmpty(): print(\"  - {}\")\n",
    "                else:\n",
    "                    for ext in eaf_extensions: print(f\"  - {ext}\") # Affichage standard\n",
    "            except Exception as e_eaf_reason:\n",
    "                print(f\"❌ Erreur raisonnement EAF: {e_eaf_reason}\")\n",
    "\n",
    "\n",
    "            # --- Exemple REAF (RecursiveExtendedTheory) ---\n",
    "            print(\"\\n\\n--- Exemple Recursive Extended AF (REAF) ---\")\n",
    "            reaf_theory = RecursiveExtendedTheory()\n",
    "            # Arguments (inchangés)\n",
    "            a_reaf = Argument(\"a_r\"); b_reaf = Argument(\"b_r\"); c_reaf = Argument(\"c_r\")\n",
    "            d_reaf = Argument(\"d_r\"); e_reaf = Argument(\"e_r\"); f_reaf = Argument(\"f_r\")\n",
    "            reaf_theory.add(a_reaf); reaf_theory.add(b_reaf); reaf_theory.add(c_reaf)\n",
    "            reaf_theory.add(d_reaf); reaf_theory.add(e_reaf); reaf_theory.add(f_reaf)\n",
    "\n",
    "            # *** CORRECTION: Appels à addAttack pour REAF ***\n",
    "            # 1. Ajouter les attaques standard (Arg -> Arg)\n",
    "            print(\"   Ajout attaques standard REAF...\")\n",
    "            reaf_theory.addAttack(a_reaf, b_reaf)\n",
    "            reaf_theory.addAttack(b_reaf, a_reaf)\n",
    "            reaf_theory.addAttack(d_reaf, c_reaf)\n",
    "            reaf_theory.addAttack(c_reaf, d_reaf)\n",
    "            print(\"   ✔️ Attaques standard ajoutées.\")\n",
    "\n",
    "            # 2. Créer les objets ExtendedAttack cibles (attaques de niveau 1)\n",
    "            print(\"   Création des objets ExtendedAttack cibles (niveau 1)...\")\n",
    "            # ExtendedAttack(Argument source, Object target) où target est un Argument\n",
    "            attack_ab_reaf_target = ExtendedAttack(a_reaf, b_reaf)\n",
    "            attack_ba_reaf_target = ExtendedAttack(b_reaf, a_reaf)\n",
    "            attack_cd_reaf_target = ExtendedAttack(c_reaf, d_reaf)\n",
    "            print(\"   ✔️ Objets ExtendedAttack cibles (niveau 1) créés.\")\n",
    "\n",
    "            # 3. Ajouter les attaques étendues de niveau 1 (Arg -> Attaque(Arg,Arg))\n",
    "            print(\"   Ajout attaques étendues REAF (niveau 1)...\")\n",
    "            # addAttack(Argument source, Object target) où target est un ExtendedAttack\n",
    "            # Utiliser JObject pour caster la cible en Object si nécessaire (bonne pratique)\n",
    "            reaf_theory.addAttack(c_reaf, JObject(attack_ba_reaf_target, ExtendedAttack)) # c -> (b->a)\n",
    "            reaf_theory.addAttack(d_reaf, JObject(attack_ab_reaf_target, ExtendedAttack)) # d -> (a->b)\n",
    "            reaf_theory.addAttack(e_reaf, JObject(attack_cd_reaf_target, ExtendedAttack)) # e -> (c->d)\n",
    "            print(\"   ✔️ Attaques étendues (niveau 1) ajoutées.\")\n",
    "\n",
    "            # 4. Créer l'objet ExtendedAttack cible de niveau 2\n",
    "            print(\"   Création de l'objet ExtendedAttack cible (niveau 2)...\")\n",
    "            # C'est l'attaque e -> (c->d) qui sera ciblée\n",
    "            attack_e_cd_target_lvl2 = ExtendedAttack(e_reaf, JObject(attack_cd_reaf_target, ExtendedAttack))\n",
    "            print(\"   ✔️ Objet ExtendedAttack cible (niveau 2) créé.\")\n",
    "\n",
    "            # 5. Ajouter l'attaque étendue de niveau 2 (Arg -> Attaque(Arg, Attaque(...)))\n",
    "            print(\"   Ajout attaque étendue REAF (niveau 2)...\")\n",
    "            reaf_theory.addAttack(f_reaf, JObject(attack_e_cd_target_lvl2, ExtendedAttack)) # f -> (e -> (c->d))\n",
    "            print(\"   ✔️ Attaque étendue (niveau 2) ajoutée.\")\n",
    "\n",
    "\n",
    "            print(\"\\nFramework REAF créé:\")\n",
    "            try: print(str(reaf_theory.prettyPrint()))\n",
    "            except: print(str(reaf_theory))\n",
    "\n",
    "            # Raisonnement REAF (Complète) - Inchangé\n",
    "            print(f\"\\nCalcul des Extensions Complètes (REAF)...\")\n",
    "            try:\n",
    "                reaf_reasoner = SimpleRecursiveExtendedCompleteReasoner()\n",
    "                reaf_extensions = reaf_reasoner.getModels(reaf_theory)\n",
    "                print(f\"Extensions Complètes (REAF): ({reaf_extensions.size()})\")\n",
    "                if reaf_extensions.isEmpty(): print(\"  - {}\")\n",
    "                else:\n",
    "                    for ext in reaf_extensions: print(f\"  - {ext}\")\n",
    "            except Exception as e_reaf_reason:\n",
    "                 print(f\"❌ Erreur raisonnement REAF: {e_reaf_reason}\")\n",
    "\n",
    "\n",
    "        else:\n",
    "             print(\"❌ Imports EAF/REAF échoués. Impossible de continuer l'exemple.\")\n",
    "\n",
    "    # Gestion globale (inchangée)\n",
    "    except ImportError as e: print(f\"❌ Erreur d'import pour EAF/REAF : {e}. Vérifiez le JAR 'arg.extended'.\")\n",
    "    except jpype.JException as e_java: print(f\"❌ Erreur Java générale EAF/REAF: {e_java.message()}\"); print(e_java.stacktrace())\n",
    "    except Exception as e_gen: print(f\"❌ Erreur Python inattendue EAF/REAF: {e_gen}\"); import traceback; traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd258f2",
   "metadata": {},
   "source": [
    "### 5.7 Sémantiques Basées sur le Classement (Ranking)\n",
    "<a id=\"5.7\"></a>\n",
    "\n",
    "Au lieu de simplement déterminer si un argument est accepté ou rejeté, les sémantiques basées sur le classement (Ranking Semantics) visent à établir un **ordre** (total ou partiel) entre les arguments, du plus \"fort\" ou \"acceptable\" au moins acceptable. Cela permet une analyse plus fine de la dialectique.\n",
    "\n",
    "De nombreuses approches existent, basées sur des principes variés :\n",
    "\n",
    "* **Comptage** (Attaquants/Défenseurs) : Ex: Burden-Based, Discussion-Based, Counting Semantics.\n",
    "* **Propagation de valeurs** : Ex: Categorizer, Propagation Semantics.\n",
    "* **Jeux/Stratégies** : Ex: Strategy-Based (Matt & Toni).\n",
    "* **Tuples/Matrices** : Ex: Tuples* (Cayrol & Lagasquie-Schiex).\n",
    "* **Sémantiques Graduées Itératives** : Ex: Iterated Graded Defense (Grossi & Modgil).\n",
    "* **Approches Sociales/Probabilistes** : Ex: SAF-Based, Probabilistic Ranking.\n",
    "\n",
    "Tweety fournit des implémentations pour plusieurs de ces sémantiques dans le package `org.tweetyproject.arg.rankings.reasoner.*`. Le résultat est souvent un objet `Ranking<Argument>` qui représente le classement. L'utilitaire `RankingTools.roundRanking` peut être utile pour arrondir les scores numériques.\n",
    "\n",
    "L'exemple suivant illustre l'application de plusieurs de ces raisonneurs sur différents AAFs tirés de la littérature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1f1d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 5.7 Sémantiques Basées sur le Classement (Ranking) ---\n",
    "print(\"\\n--- 5.7 Sémantiques Basées sur le Classement (Ranking) ---\")\n",
    "\n",
    "if not jvm_ready:\n",
    "    print(\"❌ ERREUR: JVM non démarrée.\")\n",
    "else:\n",
    "    print(\"ℹ️ JVM prête. Exécution des exemples de Ranking Semantics...\")\n",
    "    ranking_imports_ok = False\n",
    "    try:\n",
    "        # Imports\n",
    "        import jpype\n",
    "        from jpype.types import *\n",
    "\n",
    "        # Syntaxe Dung\n",
    "        from org.tweetyproject.arg.dung.syntax import DungTheory, Argument, Attack\n",
    "        # Raisonneurs de Classement (Importer ceux qu'on va utiliser)\n",
    "        from org.tweetyproject.arg.rankings.reasoner import (\n",
    "             CategorizerRankingReasoner, BurdenBasedRankingReasoner, DiscussionBasedRankingReasoner,\n",
    "             TuplesRankingReasoner, StrategyBasedRankingReasoner, SAFRankingReasoner,\n",
    "             CountingRankingReasoner, PropagationRankingReasoner, IteratedGradedDefenseReasoner,\n",
    "             ProbabilisticRankingReasoner # Ajouter si on l'inclut ici\n",
    "        )\n",
    "        # Outils Ranking\n",
    "        from org.tweetyproject.arg.rankings.util import RankingTools\n",
    "        # Dépendances possibles (ex: pour Probabilistic)\n",
    "        from org.tweetyproject.arg.dung.semantics import Semantics\n",
    "        from org.tweetyproject.math.probability import Probability\n",
    "\n",
    "        print(\"✔️ Imports pour Ranking Semantics réussis.\")\n",
    "        ranking_imports_ok = True\n",
    "\n",
    "        # --- Définition des AAFs exemples ---\n",
    "        if ranking_imports_ok:\n",
    "            print(\"\\nDéfinition des AAFs exemples...\")\n",
    "\n",
    "            # Example 1 (Bonzon et al. AAAI 2016)\n",
    "            aaf_ex1 = DungTheory()\n",
    "            args1 = {name: Argument(name) for name in \"abcde\"}\n",
    "            for arg in args1.values(): aaf_ex1.add(arg)\n",
    "            attacks1 = [(\"a\",\"e\"), (\"d\",\"a\"), (\"e\",\"d\"), (\"c\",\"e\"), (\"b\",\"c\"), (\"b\",\"a\")]\n",
    "            for s, t in attacks1: aaf_ex1.add(Attack(args1[s], args1[t]))\n",
    "            print(\"   - AAF Example 1 (Bonzon) défini.\")\n",
    "\n",
    "            # Example 2 (Pu et al. CoRR 2015, Fig 1a - pour Counting)\n",
    "            aaf_ex2 = DungTheory()\n",
    "            args2 = {f\"x{i}\": Argument(f\"x{i}\") for i in range(1, 5)}\n",
    "            for arg in args2.values(): aaf_ex2.add(arg)\n",
    "            attacks2 = [(\"x2\",\"x3\"), (\"x2\",\"x1\"), (\"x3\",\"x2\"), (\"x3\",\"x3\"), (\"x4\",\"x2\")]\n",
    "            for s, t in attacks2: aaf_ex2.add(Attack(args2[s], args2[t]))\n",
    "            print(\"   - AAF Example 2 (Pu) défini.\")\n",
    "\n",
    "            # Example 5 (Delobelle Thesis 2017, Fig 2.4 - pour Tuples*, Propagation)\n",
    "            aaf_ex5 = DungTheory()\n",
    "            args5 = {name: Argument(name) for name in \"abcdefghij\"}\n",
    "            for arg in args5.values(): aaf_ex5.add(arg)\n",
    "            attacks5 = [(\"a\",\"b\"), (\"b\",\"c\"), (\"b\",\"f\"), (\"d\",\"g\"), (\"d\",\"f\"),\n",
    "                        (\"e\",\"h\"), (\"e\",\"d\"), (\"e\",\"i\"), (\"h\",\"g\"), (\"j\",\"i\")]\n",
    "            for s, t in attacks5: aaf_ex5.add(Attack(args5[s], args5[t]))\n",
    "            print(\"   - AAF Example 5 (Delobelle) défini.\")\n",
    "\n",
    "            # Example 4a (Matt & Toni JELIA 2008, Fig 2 - pour StrategyBased)\n",
    "            aaf_ex4a = DungTheory()\n",
    "            args4a = {name: Argument(name) for name in \"abcdefg\"}\n",
    "            for arg in args4a.values(): aaf_ex4a.add(arg)\n",
    "            attacks4a = [(\"b\",\"a\"),(\"c\",\"a\"),(\"d\",\"a\"),(\"f\",\"a\"),(\"e\",\"d\"),(\"g\",\"f\")]\n",
    "            for s, t in attacks4a: aaf_ex4a.add(Attack(args4a[s], args4a[t]))\n",
    "            print(\"   - AAF Example 4a (Matt & Toni) défini.\")\n",
    "\n",
    "\n",
    "            # --- Application des Raisonneurs ---\n",
    "            print(\"\\n--- Application des Raisonneurs de Classement ---\")\n",
    "\n",
    "            # 1. Categorizer\n",
    "            print(\"\\n* Categorizer:\")\n",
    "            try:\n",
    "                r_cat = CategorizerRankingReasoner()\n",
    "                rank_cat1 = r_cat.getModel(aaf_ex1)\n",
    "                rank_cat2 = r_cat.getModel(aaf_ex2)\n",
    "                print(f\"  - AAF Ex1: {RankingTools.roundRanking(rank_cat1, 2)}\")\n",
    "                print(f\"  - AAF Ex2: {RankingTools.roundRanking(rank_cat2, 3)}\")\n",
    "            except Exception as e: print(f\"   ❌ Erreur Categorizer: {e}\")\n",
    "\n",
    "            # 2. Burden-Based\n",
    "            print(\"\\n* Burden-Based:\")\n",
    "            try:\n",
    "                r_bb = BurdenBasedRankingReasoner()\n",
    "                rank_bb1 = r_bb.getModel(aaf_ex1)\n",
    "                rank_bb5 = r_bb.getModel(aaf_ex5)\n",
    "                print(f\"  - AAF Ex1: {rank_bb1}\")\n",
    "                print(f\"  - AAF Ex5: {rank_bb5}\")\n",
    "            except Exception as e: print(f\"   ❌ Erreur BurdenBased: {e}\")\n",
    "\n",
    "            # 3. Discussion-Based\n",
    "            print(\"\\n* Discussion-Based:\")\n",
    "            try:\n",
    "                r_db = DiscussionBasedRankingReasoner()\n",
    "                rank_db1 = r_db.getModel(aaf_ex1)\n",
    "                rank_db2 = r_db.getModel(aaf_ex2) # Utiliser Ex2 comme dans Java\n",
    "                print(f\"  - AAF Ex1: {rank_db1}\")\n",
    "                print(f\"  - AAF Ex2: {rank_db2}\")\n",
    "            except Exception as e: print(f\"   ❌ Erreur DiscussionBased: {e}\")\n",
    "\n",
    "            # 4. Tuples*\n",
    "            print(\"\\n* Tuples*:\")\n",
    "            try:\n",
    "                r_tup = TuplesRankingReasoner()\n",
    "                rank_tup5 = r_tup.getModel(aaf_ex5)\n",
    "                print(f\"  - AAF Ex5 (Classement): {rank_tup5}\")\n",
    "                # prettyPrintTupledValues n'est pas directement appelable en Python\n",
    "                # Mais on peut essayer d'accéder aux valeurs via une méthode si elle existe\n",
    "                # ou simplement afficher le classement qui est la sortie principale.\n",
    "                # print(f\"  - AAF Ex5 (Valeurs): {r_tup.prettyPrintTupledValues()}\") # N'existe pas\n",
    "            except Exception as e: print(f\"   ❌ Erreur Tuples: {e}\")\n",
    "\n",
    "            # 5. Strategy-Based (Matt & Toni)\n",
    "            print(\"\\n* Strategy-Based:\")\n",
    "            try:\n",
    "                r_sb = StrategyBasedRankingReasoner()\n",
    "                rank_sb4a = r_sb.getModel(aaf_ex4a)\n",
    "                print(f\"  - AAF Ex4a: {RankingTools.roundRanking(rank_sb4a, 3)}\")\n",
    "            except Exception as e: print(f\"   ❌ Erreur StrategyBased: {e}\")\n",
    "\n",
    "            # 6. SAF-Based\n",
    "            print(\"\\n* SAF-Based (SimpleProduct):\")\n",
    "            try:\n",
    "                r_saf = SAFRankingReasoner() # Utilise SimpleProductSemantics par défaut\n",
    "                rank_saf1 = r_saf.getModel(aaf_ex1)\n",
    "                print(f\"  - AAF Ex1: {RankingTools.roundRanking(rank_saf1, 2)}\")\n",
    "            except Exception as e: print(f\"   ❌ Erreur SAFBased: {e}\")\n",
    "\n",
    "            # 7. Counting Semantics\n",
    "            print(\"\\n* Counting Semantics:\")\n",
    "            try:\n",
    "                # CountingRankingReasoner(double decay_factor, double tolerance)\n",
    "                r_count = CountingRankingReasoner(0.98, 0.001)\n",
    "                rank_count1 = r_count.getModel(aaf_ex1)\n",
    "                rank_count2 = r_count.getModel(aaf_ex2)\n",
    "                print(f\"  - AAF Ex1: {RankingTools.roundRanking(rank_count1, 2)}\")\n",
    "                print(f\"  - AAF Ex2: {RankingTools.roundRanking(rank_count2, 2)}\")\n",
    "            except Exception as e: print(f\"   ❌ Erreur Counting: {e}\")\n",
    "\n",
    "            # 8. Propagation Semantics (une variante)\n",
    "            print(\"\\n* Propagation Semantics (Variant 1 - Set-based):\")\n",
    "            try:\n",
    "                # PropagationRankingReasoner(double epsilon, boolean multiset, PropagationVariant variant)\n",
    "                # Variant 1 = PROPAGATION1\n",
    "                r_prop1 = PropagationRankingReasoner(0.75, False, PropagationRankingReasoner.PropagationSemantics.PROPAGATION1)\n",
    "                rank_prop1_ex5 = r_prop1.getModel(aaf_ex5)\n",
    "                print(f\"  - AAF Ex5 (ε=0.75, Set): {rank_prop1_ex5}\")\n",
    "            except Exception as e: print(f\"   ❌ Erreur Propagation: {e}\")\n",
    "\n",
    "            # 9. Iterated Graded Defense (Optionnel, peut être complexe/lent)\n",
    "            # print(\"\\n* Iterated Graded Defense:\")\n",
    "            # try:\n",
    "            #     r_igd = IteratedGradedDefenseReasoner()\n",
    "            #     # getAllMNCompleteExtensions(DungTheory, int m, int n)\n",
    "            #     igd_exts = r_igd.getAllMNCompleteExtensions(aaf_ex1, 2, 2) # Exemple m=2, n=2\n",
    "            #     print(f\"  - AAF Ex1 (m=2, n=2): {igd_exts}\")\n",
    "            # except Exception as e: print(f\"   ❌ Erreur IGD: {e}\")\n",
    "\n",
    "            # 10. Probabilistic Ranking (Optionnel)\n",
    "            # print(\"\\n* Probabilistic Ranking (Grounded, p=0.5):\")\n",
    "            # try:\n",
    "            #     r_prob = ProbabilisticRankingReasoner(Semantics.GROUNDED_SEMANTICS, Probability(0.5), True)\n",
    "            #     rank_prob2 = r_prob.getModel(aaf_ex2)\n",
    "            #     print(f\"  - AAF Ex2: {rank_prob2}\")\n",
    "            # except Exception as e: print(f\"   ❌ Erreur Probabilistic Ranking: {e}\")\n",
    "\n",
    "        else:\n",
    "             print(\"❌ Imports pour Ranking Semantics échoués. Impossible de continuer.\")\n",
    "\n",
    "    # Gestion globale\n",
    "    except ImportError as e:\n",
    "        print(f\"❌ Erreur d'import pour Ranking Semantics : {e}. Vérifiez les JARs 'arg.rankings', 'arg.dung', 'math'.\")\n",
    "    except jpype.JException as e_java:\n",
    "        print(f\"❌ Erreur Java générale Ranking: {e_java.message()}\")\n",
    "        print(e_java.stacktrace())\n",
    "    except Exception as e_gen:\n",
    "        print(f\"❌ Erreur Python inattendue Ranking: {e_gen}\")\n",
    "        import traceback; traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd395667",
   "metadata": {},
   "source": [
    "### 5.8 Argumentation Probabiliste\n",
    "<a id=\"5.8\"></a>\n",
    "\n",
    "L'argumentation probabiliste introduit la notion d'incertitude dans les cadres d'argumentation. Cette incertitude peut porter sur :\n",
    "\n",
    "1.  **L'existence des arguments ou des attaques** : Le graphe lui-même est incertain.\n",
    "2.  **L'acceptabilité des arguments** : On peut avoir des degrés de croyance sur le fait qu'un argument soit accepté.\n",
    "\n",
    "Tweety se concentre principalement sur le premier type d'incertitude via les **Distributions de Probabilité sur les Sous-Graphes**.\n",
    "\n",
    "* **`SubgraphProbabilityFunction`**: Représente une distribution de probabilité sur l'ensemble des sous-graphes possibles d'un AAF de référence. Chaque sous-graphe (un AAF potentiel) a une probabilité associée. Souvent initialisée de manière uniforme.\n",
    "* **Acceptabilité Probabiliste (`getAcceptanceProbability`)**: Étant donné une `SubgraphProbabilityFunction` et une sémantique de Dung, on peut calculer la probabilité qu'un argument (ou un ensemble d'arguments) soit accepté. Cela correspond à la somme des probabilités des sous-graphes où cet argument (ou ensemble) est accepté selon la sémantique choisie.\n",
    "* **Divisions (`Division`)**: Une partition des arguments en trois ensembles : acceptés (IN), rejetés (OUT), indécis (UNDEC). Utilisé pour raisonner sur des résultats d'évaluation plus fins.\n",
    "* **Loteries d'Argumentation (`ArgumentationLottery`, `UtilityFunction`)**: Permettent de modéliser des scénarios de décision sous incertitude, en associant des utilités aux différentes issues possibles (divisions) et en calculant l'utilité attendue en fonction des probabilités d'acceptation.\n",
    "\n",
    "L'exemple suivant s'inspire de `LotteryExample.java` pour illustrer ces concepts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70076b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 5.8 Argumentation Probabiliste ---\n",
    "print(\"\\n--- 5.8 Argumentation Probabiliste ---\")\n",
    "\n",
    "if not jvm_ready:\n",
    "    print(\"❌ ERREUR: JVM non démarrée.\")\n",
    "else:\n",
    "    print(\"ℹ️ JVM prête. Exécution de l'exemple d'argumentation probabiliste...\")\n",
    "    prob_imports_ok = False\n",
    "    try:\n",
    "        # Imports (inchangés)\n",
    "        import jpype\n",
    "        from jpype.types import *\n",
    "        from java.util import Collection, List as JavaList, Set as JavaSet\n",
    "\n",
    "        from org.tweetyproject.arg.dung.syntax import DungTheory, Argument, Attack\n",
    "        from org.tweetyproject.arg.dung.reasoner import AbstractExtensionReasoner, SimpleGroundedReasoner\n",
    "        from org.tweetyproject.arg.dung.semantics import Extension, Semantics\n",
    "        from org.tweetyproject.arg.dung.divisions import Division\n",
    "\n",
    "        from org.tweetyproject.arg.prob.lotteries import SubgraphProbabilityFunction, ArgumentationLottery, UtilityFunction\n",
    "        from org.tweetyproject.math.probability import Probability\n",
    "\n",
    "        print(\"✔️ Imports pour Argumentation Probabiliste réussis.\")\n",
    "        prob_imports_ok = True\n",
    "\n",
    "        # --- Création de l'AAF de base ---\n",
    "        if prob_imports_ok:\n",
    "            print(\"\\n1. Création de l'AAF de base...\")\n",
    "            theory_prob = DungTheory()\n",
    "            a = Argument(\"a\"); b = Argument(\"b\"); c = Argument(\"c\")\n",
    "            theory_prob.add(a); theory_prob.add(b); theory_prob.add(c)\n",
    "            theory_prob.add(Attack(a, b)); theory_prob.add(Attack(b, a)); theory_prob.add(Attack(c, b))\n",
    "            print(\"   AAF: \", theory_prob)\n",
    "\n",
    "            # --- Raisonnement standard (inchangé) ---\n",
    "            print(\"\\n2. Extensions Grounded (pour référence)...\")\n",
    "            reasoner_gr = SimpleGroundedReasoner()\n",
    "            extensions_gr_coll = reasoner_gr.getModels(theory_prob)\n",
    "            print(\"   Extensions Grounded:\", extensions_gr_coll)\n",
    "\n",
    "            # --- Fonction de Probabilité sur Sous-Graphes (inchangé) ---\n",
    "            print(\"\\n3. Création d'une fonction de probabilité uniforme sur les sous-graphes...\")\n",
    "            prob_function = SubgraphProbabilityFunction(theory_prob)\n",
    "            print(f\"   Nombre de sous-graphes possibles: {prob_function.size()}\")\n",
    "\n",
    "            # --- Calcul d'Acceptabilité Probabiliste ---\n",
    "            print(\"\\n4. Calcul des probabilités d'acceptation (Sémantique Grounded)...\")\n",
    "            target_semantics = Semantics.GROUNDED_SEMANTICS\n",
    "            try:\n",
    "                prob_obj_a = prob_function.getAcceptanceProbability(a, target_semantics)\n",
    "                prob_obj_b = prob_function.getAcceptanceProbability(b, target_semantics)\n",
    "                prob_obj_c = prob_function.getAcceptanceProbability(c, target_semantics)\n",
    "                val_a = prob_obj_a.doubleValue(); val_b = prob_obj_b.doubleValue(); val_c = prob_obj_c.doubleValue()\n",
    "                print(f\"   P(Accepté({a})) = {val_a:.4f}\")\n",
    "                print(f\"   P(Accepté({b})) = {val_b:.4f}\")\n",
    "                print(f\"   P(Accepté({c})) = {val_c:.4f}\")\n",
    "\n",
    "                print(\"\\n   Calcul probabilité pour Division ({a, c}, {b})...\")\n",
    "                in_set = Extension(); in_set.add(a); in_set.add(c)\n",
    "                out_set = Extension(); out_set.add(b)\n",
    "                # *** CORRECTION CONSTRUCTEUR Division : seulement IN et OUT ***\n",
    "                example_division = Division(in_set, out_set)\n",
    "                prob_obj_div = prob_function.getAcceptanceProbability(example_division, target_semantics)\n",
    "                val_div = prob_obj_div.doubleValue()\n",
    "                print(f\"   P(Division={example_division}) = {val_div:.4f}\") # Devrait fonctionner maintenant\n",
    "\n",
    "            except jpype.JException as e_prob_calc_java:\n",
    "                 if \"'doubleValue'\" in str(e_prob_calc_java.message()): print(\"   ⚠️ Erreur: La méthode .doubleValue() n'existe pas sur l'objet Probability.\")\n",
    "                 else: print(f\"   ❌ Erreur Java calcul probabilités: {e_prob_calc_java.message()}\")\n",
    "            except AttributeError as e_attr:\n",
    "                 if \"'doubleValue'\" in str(e_attr): print(\"   ⚠️ Erreur: La méthode .doubleValue() n'existe pas sur l'objet Probability.\")\n",
    "                 else: print(f\"   ❌ Erreur Python calcul probabilités (Attr): {e_attr}\")\n",
    "            except Exception as e_prob_calc: print(f\"   ❌ Erreur calcul probabilités: {e_prob_calc}\")\n",
    "\n",
    "\n",
    "            # --- Loteries et Utilités ---\n",
    "            print(\"\\n5. Loteries d'Argumentation et Utilité Attendue...\")\n",
    "            try:\n",
    "                # *** CORRECTION APPEL : Retirer le second argument (sémantique) ***\n",
    "                standard_divisions_coll = Division.getStandardDivisions(theory_prob)\n",
    "                # *** CORRECTION AFFICHAGE : Utiliser str() pour la sémantique ***\n",
    "                print(f\"   Divisions standard (basées sur {str(target_semantics)} extensions): {standard_divisions_coll}\")\n",
    "\n",
    "                if not standard_divisions_coll.isEmpty():\n",
    "                    lottery = ArgumentationLottery(standard_divisions_coll, prob_function, target_semantics)\n",
    "                    print(\"\\n   Loterie basée sur les divisions standard:\")\n",
    "                    print(f\"     {lottery}\")\n",
    "\n",
    "                    utility_func = UtilityFunction()\n",
    "                    from java.util import ArrayList # Assurer l'import ici\n",
    "                    standard_divisions_list = ArrayList(standard_divisions_coll)\n",
    "\n",
    "                    # Assigner des utilités (inchangé, mais dépend de standard_divisions_list correct)\n",
    "                    Division_class = jpype.JClass(\"org.tweetyproject.arg.dung.divisions.Division\") # Pour cast JObject\n",
    "                    if standard_divisions_list.size() >= 1: utility_func.put(JObject(standard_divisions_list.get(0), Division_class), 10.0)\n",
    "                    if standard_divisions_list.size() >= 2: utility_func.put(JObject(standard_divisions_list.get(1), Division_class), -5.0)\n",
    "\n",
    "                    if not utility_func.isEmpty():\n",
    "                        print(\"\\n   Fonction d'utilité exemple:\")\n",
    "                        print(f\"     {utility_func}\")\n",
    "                        expected_utility = utility_func.getExpectedUtility(lottery)\n",
    "                        # Utiliser doubleValue() ici aussi pour le formatage\n",
    "                        print(f\"\\n   Utilité Attendue de la loterie: {expected_utility.doubleValue():.4f}\")\n",
    "                    else: print(\"\\n   Pas assez de divisions standard ou erreur pour définir une fonction d'utilité exemple.\")\n",
    "                else: print(\"   Aucune division standard trouvée pour créer la loterie.\")\n",
    "\n",
    "            except jpype.JException as e_lottery_java: print(f\"   ❌ Erreur Java (Loteries/Utilité): {e_lottery_java.message()}\")\n",
    "            except Exception as e_lottery_py: print(f\"   ❌ Erreur Python (Loteries/Utilité): {e_lottery_py}\"); import traceback; traceback.print_exc()\n",
    "\n",
    "        else: print(\"❌ Imports pour Argumentation Probabiliste échoués. Impossible de continuer.\")\n",
    "\n",
    "    # Gestion globale (inchangée)\n",
    "    except ImportError as e: print(f\"❌ Erreur d'import Prob: {e}.\")\n",
    "    except jpype.JException as e_java: print(f\"❌ Erreur Java générale Prob: {e_java.message()}\"); print(e_java.stacktrace())\n",
    "    except Exception as e_gen: print(f\"❌ Erreur Python inattendue Prob: {e_gen}\"); import traceback; traceback.print_exc()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
