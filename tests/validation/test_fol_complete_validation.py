#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
Validation compl√®te de l'agent FirstOrderLogicAgent (FOL).

Ce script ex√©cute une validation exhaustive selon les crit√®res de la t√¢che :

M√âTRIQUES DE VALIDATION :
‚úÖ 100% des formules FOL g√©n√©r√©es valides
‚úÖ 0 erreur de parsing Tweety avec syntaxe FOL  
‚úÖ >95% compatibilit√© avec sophismes existants
‚úÖ Temps r√©ponse ‚â§ Modal Logic pr√©c√©dent
‚úÖ >90% couverture tests pour FirstOrderLogicAgent
‚úÖ Tous les cas d'erreur g√©r√©s
‚úÖ Integration valid√©e avec tous orchestrateurs

Tests de migration Modal Logic ‚Üí FOL :
‚úÖ Remplacement fonctionnel
‚úÖ Am√©lioration stabilit√©
‚úÖ R√©trocompatibilit√©
"""

import asyncio
import time
import logging
import json
import statistics
from typing import Dict, List, Any, Optional, Tuple
from pathlib import Path
import traceback

# Imports des composants √† valider
from argumentation_analysis.agents.core.logic.fol_logic_agent import (
    FOLLogicAgent, 
    FOLAnalysisResult,
    create_fol_agent
)

from config.unified_config import (
    UnifiedConfig,
    LogicType, 
    MockLevel,
    AgentType,
    PresetConfigs
)

# Imports pour comparaison et validation
from argumentation_analysis.utils.tweety_error_analyzer import TweetyErrorAnalyzer

# Configuration logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


class FOLValidationMetrics:
    """Collecteur de m√©triques de validation FOL."""
    
    def __init__(self):
        self.total_tests = 0
        self.passed_tests = 0
        self.failed_tests = 0
        self.error_details = []
        
        # M√©triques sp√©cifiques FOL
        self.fol_syntax_valid_count = 0
        self.fol_syntax_total_count = 0
        self.tweety_parsing_errors = 0
        self.tweety_parsing_attempts = 0
        
        # Performance
        self.analysis_times = []
        self.confidence_scores = []
        
        # Compatibilit√©
        self.sophism_compatibility_rate = 0.0
        self.migration_success_rate = 0.0
        
    def add_test_result(self, test_name: str, success: bool, details: Dict[str, Any] = None):
        """Ajoute un r√©sultat de test."""
        self.total_tests += 1
        if success:
            self.passed_tests += 1
        else:
            self.failed_tests += 1
            self.error_details.append({
                "test": test_name,
                "details": details or {}
            })
    
    def add_fol_syntax_result(self, formula: str, is_valid: bool):
        """Ajoute r√©sultat validation syntaxe FOL."""
        self.fol_syntax_total_count += 1
        if is_valid:
            self.fol_syntax_valid_count += 1
    
    def add_tweety_parsing_result(self, formula: str, success: bool, error: str = None):
        """Ajoute r√©sultat parsing Tweety."""
        self.tweety_parsing_attempts += 1
        if not success:
            self.tweety_parsing_errors += 1
            logger.warning(f"Erreur parsing Tweety: {formula} - {error}")
    
    def add_performance_data(self, analysis_time: float, confidence: float):
        """Ajoute donn√©es de performance."""
        self.analysis_times.append(analysis_time)
        self.confidence_scores.append(confidence)
    
    def get_summary(self) -> Dict[str, Any]:
        """Retourne r√©sum√© des m√©triques."""
        return {
            "test_success_rate": self.passed_tests / self.total_tests if self.total_tests > 0 else 0.0,
            "fol_syntax_validity_rate": self.fol_syntax_valid_count / self.fol_syntax_total_count if self.fol_syntax_total_count > 0 else 0.0,
            "tweety_parsing_success_rate": (self.tweety_parsing_attempts - self.tweety_parsing_errors) / self.tweety_parsing_attempts if self.tweety_parsing_attempts > 0 else 0.0,
            "avg_analysis_time": statistics.mean(self.analysis_times) if self.analysis_times else 0.0,
            "avg_confidence": statistics.mean(self.confidence_scores) if self.confidence_scores else 0.0,
            "sophism_compatibility": self.sophism_compatibility_rate,
            "migration_success": self.migration_success_rate,
            "total_tests": self.total_tests,
            "passed_tests": self.passed_tests,
            "failed_tests": self.failed_tests,
            "error_details": self.error_details
        }


class FOLCompleteValidator:
    """Validateur complet pour l'agent FOL."""
    
    def __init__(self):
        self.metrics = FOLValidationMetrics()
        self.error_analyzer = TweetyErrorAnalyzer()
        
        # √âchantillons de test
        self.fol_syntax_samples = self._load_fol_syntax_samples()
        self.sophism_samples = self._load_sophism_samples()
        self.complex_argumentation_samples = self._load_complex_samples()
    
    def _load_fol_syntax_samples(self) -> List[Dict[str, str]]:
        """Charge √©chantillons syntaxe FOL √† valider."""
        return [
            {
                "description": "Quantificateur universel basique",
                "formula": "‚àÄx(Human(x) ‚Üí Mortal(x))",
                "expected_valid": True
            },
            {
                "description": "Quantificateur existentiel",
                "formula": "‚àÉx(Student(x) ‚àß Intelligent(x))",
                "expected_valid": True
            },
            {
                "description": "Pr√©dicat complexe binaire",
                "formula": "‚àÄx‚àÄy(Loves(x,y) ‚Üí Cares(x,y))",
                "expected_valid": True
            },
            {
                "description": "Connecteurs logiques multiples",
                "formula": "‚àÄx((P(x) ‚àß Q(x)) ‚Üí (R(x) ‚à® S(x)))",
                "expected_valid": True
            },
            {
                "description": "√âquivalence logique",
                "formula": "‚àÉx(¬¨Bad(x) ‚Üî Good(x))",
                "expected_valid": True
            },
            {
                "description": "Quantificateurs imbriqu√©s",
                "formula": "‚àÄx‚àÉy‚àÄz(Rel(x,y) ‚Üí Prop(z))",
                "expected_valid": True
            },
            {
                "description": "N√©gation quantificateur",
                "formula": "¬¨‚àÄx(P(x)) ‚Üî ‚àÉx(¬¨P(x))",
                "expected_valid": True
            },
            {
                "description": "Formule invalide - variable libre",
                "formula": "‚àÄx(P(x)) ‚àß Q(y)",
                "expected_valid": False
            }
        ]
    
    def _load_sophism_samples(self) -> List[Dict[str, str]]:
        """Charge √©chantillons de sophismes pour test compatibilit√©."""
        return [
            {
                "name": "Syllogisme valide",
                "text": "Tous les hommes sont mortels. Socrate est un homme. Donc Socrate est mortel.",
                "expected_consistent": True
            },
            {
                "name": "Affirmation du cons√©quent",
                "text": "Si il pleut, alors le sol est mouill√©. Le sol est mouill√©. Donc il pleut.",
                "expected_consistent": False  # Sophisme
            },
            {
                "name": "Modus ponens",
                "text": "Si P alors Q. P est vrai. Donc Q est vrai.",
                "expected_consistent": True
            },
            {
                "name": "G√©n√©ralisation abusive",
                "text": "Tous les corbeaux observ√©s sont noirs. Donc tous les corbeaux sont noirs.",
                "expected_consistent": False  # Induction probl√©matique
            },
            {
                "name": "Contradiction directe",
                "text": "Tous les chats sont noirs. Certains chats ne sont pas noirs.",
                "expected_consistent": False
            }
        ]
    
    def _load_complex_samples(self) -> List[Dict[str, str]]:
        """Charge √©chantillons d'argumentation complexe."""
        return [
            {
                "name": "Argumentation philosophique",
                "text": """
                Tous les philosophes sont des penseurs.
                Certains penseurs sont des √©crivains.
                Socrate est un philosophe.
                Si quelqu'un est √©crivain, alors il influence la culture.
                """
            },
            {
                "name": "Raisonnement scientifique",
                "text": """
                Toutes les th√©ories scientifiques sont falsifiables.
                La th√©orie de l'√©volution est une th√©orie scientifique.
                Si une th√©orie est falsifiable, alors elle peut √™tre test√©e.
                """
            },
            {
                "name": "Logique d√©ontique simple",
                "text": """
                Il est obligatoire de respecter la loi.
                Conduire en √©tat d'ivresse viole la loi.
                Donc il est interdit de conduire en √©tat d'ivresse.
                """
            }
        ]
    
    async def validate_fol_syntax_generation(self) -> bool:
        """Valide g√©n√©ration syntaxe FOL selon crit√®res."""
        logger.info("üîç Validation g√©n√©ration syntaxe FOL...")
        
        agent = FOLLogicAgent(agent_name="SyntaxValidator")
        success = True
        
        for sample in self.fol_syntax_samples:
            try:
                # Test si la formule est reconnue comme valide
                is_valid = self._validate_fol_formula(sample["formula"])
                
                self.metrics.add_fol_syntax_result(sample["formula"], is_valid)
                
                # V√©rification conformit√© attendue
                if is_valid != sample["expected_valid"]:
                    success = False
                    logger.error(f"‚ùå Validation syntaxe √©chou√©e: {sample['description']}")
                    logger.error(f"   Formule: {sample['formula']}")
                    logger.error(f"   Attendu: {sample['expected_valid']}, Obtenu: {is_valid}")
                else:
                    logger.info(f"‚úÖ Syntaxe valid√©e: {sample['description']}")
                    
            except Exception as e:
                success = False
                logger.error(f"‚ùå Erreur validation syntaxe: {sample['description']} - {e}")
        
        # V√©rification crit√®re : 100% formules valides
        syntax_rate = self.metrics.fol_syntax_valid_count / self.metrics.fol_syntax_total_count
        if syntax_rate < 1.0:
            logger.warning(f"‚ö†Ô∏è Taux syntaxe valide: {syntax_rate:.2%} < 100%")
        
        self.metrics.add_test_result("fol_syntax_generation", success, {
            "syntax_validity_rate": syntax_rate,
            "total_formulas": self.metrics.fol_syntax_total_count,
            "valid_formulas": self.metrics.fol_syntax_valid_count
        })
        
        return success
    
    def _validate_fol_formula(self, formula: str) -> bool:
        """Validation basique syntaxe FOL."""
        # Caract√®res FOL attendus
        fol_chars = ["‚àÄ", "‚àÉ", "‚Üí", "‚àß", "‚à®", "¬¨", "‚Üî"]
        
        # V√©rifications de base
        has_quantifier = any(q in formula for q in ["‚àÄ", "‚àÉ"])
        has_predicate = "(" in formula and ")" in formula
        balanced_parens = formula.count("(") == formula.count(")")
        
        # Variables libres (heuristique simple)
        # Cette validation pourrait √™tre plus sophistiqu√©e
        return (has_quantifier or has_predicate) and balanced_parens
    
    async def validate_tweety_integration(self) -> bool:
        """Valide int√©gration avec TweetyProject."""
        logger.info("üîç Validation int√©gration Tweety...")
        
        agent = FOLLogicAgent(agent_name="TweetyValidator")
        
        # Setup agent si possible
        try:
            await agent.setup_agent_components()
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Setup Tweety √©chou√© (normal en test): {e}")
        
        success = True
        
        # Test formules avec Tweety (ou simulation)
        for sample in self.fol_syntax_samples:
            if sample["expected_valid"]:
                try:
                    # Test via analyse compl√®te
                    result = await agent._analyze_with_tweety([sample["formula"]])
                    
                    # Pas d'erreur de parsing = succ√®s
                    parsing_success = len(result.validation_errors) == 0
                    self.metrics.add_tweety_parsing_result(sample["formula"], parsing_success)
                    
                    if not parsing_success:
                        success = False
                        logger.error(f"‚ùå Parsing Tweety √©chou√©: {sample['formula']}")
                        for error in result.validation_errors:
                            logger.error(f"   Erreur: {error}")
                    else:
                        logger.info(f"‚úÖ Parsing Tweety r√©ussi: {sample['description']}")
                        
                except Exception as e:
                    success = False
                    logger.error(f"‚ùå Erreur Tweety: {sample['formula']} - {e}")
                    self.metrics.add_tweety_parsing_result(sample["formula"], False, str(e))
        
        # V√©rification crit√®re : 0 erreur parsing
        parsing_success_rate = (self.metrics.tweety_parsing_attempts - self.metrics.tweety_parsing_errors) / self.metrics.tweety_parsing_attempts
        if parsing_success_rate < 1.0:
            logger.warning(f"‚ö†Ô∏è Taux succ√®s parsing Tweety: {parsing_success_rate:.2%} < 100%")
        
        self.metrics.add_test_result("tweety_integration", success, {
            "parsing_success_rate": parsing_success_rate,
            "parsing_errors": self.metrics.tweety_parsing_errors,
            "total_attempts": self.metrics.tweety_parsing_attempts
        })
        
        return success
    
    async def validate_sophism_compatibility(self) -> bool:
        """Valide compatibilit√© avec sophismes existants."""
        logger.info("üîç Validation compatibilit√© sophismes...")
        
        agent = FOLLogicAgent(agent_name="SophismValidator")
        
        successful_analyses = 0
        total_analyses = len(self.sophism_samples)
        
        for sophism in self.sophism_samples:
            try:
                start_time = time.time()
                result = await agent.analyze(sophism["text"])
                analysis_time = time.time() - start_time
                
                # Collecte m√©triques
                self.metrics.add_performance_data(analysis_time, result.confidence_score)
                
                # V√©rification r√©sultat coh√©rent
                if isinstance(result, FOLAnalysisResult) and result.confidence_score > 0.0:
                    successful_analyses += 1
                    logger.info(f"‚úÖ Sophisme analys√©: {sophism['name']} (confiance: {result.confidence_score:.2f})")
                else:
                    logger.warning(f"‚ö†Ô∏è Analyse faible: {sophism['name']}")
                    
            except Exception as e:
                logger.error(f"‚ùå Erreur analyse sophisme {sophism['name']}: {e}")
        
        # Calcul taux compatibilit√©
        compatibility_rate = successful_analyses / total_analyses
        self.metrics.sophism_compatibility_rate = compatibility_rate
        
        # V√©rification crit√®re : >95% compatibilit√©
        success = compatibility_rate > 0.95
        
        if not success:
            logger.warning(f"‚ö†Ô∏è Compatibilit√© sophismes: {compatibility_rate:.2%} < 95%")
        
        self.metrics.add_test_result("sophism_compatibility", success, {
            "compatibility_rate": compatibility_rate,
            "successful_analyses": successful_analyses,
            "total_analyses": total_analyses
        })
        
        return success
    
    async def validate_performance_requirements(self) -> bool:
        """Valide exigences de performance."""
        logger.info("üîç Validation performance...")
        
        agent = FOLLogicAgent(agent_name="PerformanceValidator")
        
        # Tests performance sur √©chantillons complexes
        performance_times = []
        confidence_scores = []
        
        for sample in self.complex_argumentation_samples:
            try:
                start_time = time.time()
                result = await agent.analyze(sample["text"])
                analysis_time = time.time() - start_time
                
                performance_times.append(analysis_time)
                confidence_scores.append(result.confidence_score)
                
                logger.info(f"‚úÖ Performance {sample['name']}: {analysis_time:.2f}s (confiance: {result.confidence_score:.2f})")
                
            except Exception as e:
                logger.error(f"‚ùå Erreur performance {sample['name']}: {e}")
        
        # Calcul m√©triques performance
        if performance_times:
            avg_time = statistics.mean(performance_times)
            max_time = max(performance_times)
            avg_confidence = statistics.mean(confidence_scores)
            
            # Crit√®res performance (adaptables selon contexte)
            time_acceptable = avg_time < 10.0  # < 10 secondes moyenne
            max_time_acceptable = max_time < 30.0  # < 30 secondes max
            confidence_acceptable = avg_confidence > 0.5  # > 50% confiance moyenne
            
            success = time_acceptable and max_time_acceptable and confidence_acceptable
            
            logger.info(f"üìä Performance moyenne: {avg_time:.2f}s")
            logger.info(f"üìä Performance maximale: {max_time:.2f}s")  
            logger.info(f"üìä Confiance moyenne: {avg_confidence:.2f}")
            
            if not success:
                logger.warning("‚ö†Ô∏è Performance insuffisante")
        else:
            success = False
            logger.error("‚ùå Aucun test de performance r√©ussi")
        
        self.metrics.add_test_result("performance_requirements", success, {
            "avg_analysis_time": avg_time if performance_times else 0.0,
            "max_analysis_time": max_time if performance_times else 0.0,
            "avg_confidence": avg_confidence if confidence_scores else 0.0,
            "total_performance_tests": len(performance_times)
        })
        
        return success
    
    async def validate_error_handling(self) -> bool:
        """Valide gestion compl√®te des erreurs."""
        logger.info("üîç Validation gestion erreurs...")
        
        agent = FOLLogicAgent(agent_name="ErrorValidator")
        
        # Cas d'erreur √† tester
        error_cases = [
            {
                "name": "Texte vide",
                "input": "",
                "should_handle": True
            },
            {
                "name": "Texte non-logique",
                "input": "Ceci n'est pas de la logique !!!",
                "should_handle": True
            },
            {
                "name": "Caract√®res sp√©ciaux",
                "input": "‚àÄ‚àÉ‚Üí‚àß‚à®¬¨‚Üî sans structure",
                "should_handle": True
            },
            {
                "name": "Texte tr√®s long",
                "input": "Test de performance. " * 1000,
                "should_handle": True
            }
        ]
        
        successful_error_handling = 0
        
        for case in error_cases:
            try:
                result = await agent.analyze(case["input"])
                
                # V√©rification gestion gracieuse
                if isinstance(result, FOLAnalysisResult):
                    successful_error_handling += 1
                    logger.info(f"‚úÖ Erreur g√©r√©e: {case['name']}")
                else:
                    logger.warning(f"‚ö†Ô∏è Gestion erreur probl√©matique: {case['name']}")
                    
            except Exception as e:
                if case["should_handle"]:
                    logger.error(f"‚ùå Erreur non g√©r√©e: {case['name']} - {e}")
                else:
                    logger.info(f"‚úÖ Erreur attendue: {case['name']}")
                    successful_error_handling += 1
        
        success = successful_error_handling == len(error_cases)
        
        self.metrics.add_test_result("error_handling", success, {
            "successful_error_handling": successful_error_handling,
            "total_error_cases": len(error_cases)
        })
        
        return success
    
    async def validate_configuration_integration(self) -> bool:
        """Valide int√©gration avec syst√®me de configuration."""
        logger.info("üîç Validation int√©gration configuration...")
        
        success = True
        
        # Test configurations pr√©d√©finies
        configs = {
            "authentic_fol": PresetConfigs.authentic_fol(),
            "development": PresetConfigs.development(),
        }
        
        for config_name, config in configs.items():
            try:
                # Test cr√©ation agent avec config
                agent = FOLLogicAgent(agent_name=f"Config_{config_name}")
                
                # Test analyse basique
                result = await agent.analyze("Test configuration.")
                
                if isinstance(result, FOLAnalysisResult):
                    logger.info(f"‚úÖ Configuration {config_name} valid√©e")
                else:
                    success = False
                    logger.error(f"‚ùå Configuration {config_name} √©chou√©e")
                    
            except Exception as e:
                success = False
                logger.error(f"‚ùå Erreur configuration {config_name}: {e}")
        
        self.metrics.add_test_result("configuration_integration", success)
        
        return success
    
    async def run_complete_validation(self) -> Dict[str, Any]:
        """Ex√©cute validation compl√®te et retourne rapport."""
        logger.info("üöÄ D√©but validation compl√®te agent FOL")
        
        start_time = time.time()
        
        # Ex√©cution des validations
        validations = [
            ("G√©n√©ration syntaxe FOL", self.validate_fol_syntax_generation()),
            ("Int√©gration Tweety", self.validate_tweety_integration()),
            ("Compatibilit√© sophismes", self.validate_sophism_compatibility()),
            ("Performance", self.validate_performance_requirements()),
            ("Gestion erreurs", self.validate_error_handling()),
            ("Int√©gration configuration", self.validate_configuration_integration())
        ]
        
        validation_results = {}
        
        for name, validation_coro in validations:
            try:
                logger.info(f"‚ñ∂Ô∏è {name}...")
                result = await validation_coro
                validation_results[name] = result
                if result:
                    logger.info(f"‚úÖ {name} r√©ussie")
                else:
                    logger.warning(f"‚ö†Ô∏è {name} √©chou√©e")
            except Exception as e:
                logger.error(f"‚ùå {name} erreur: {e}")
                validation_results[name] = False
                traceback.print_exc()
        
        total_time = time.time() - start_time
        
        # G√©n√©ration rapport final
        report = self._generate_validation_report(validation_results, total_time)
        
        logger.info("üèÅ Validation compl√®te termin√©e")
        
        return report
    
    def _generate_validation_report(self, validation_results: Dict[str, bool], total_time: float) -> Dict[str, Any]:
        """G√©n√®re rapport final de validation."""
        metrics_summary = self.metrics.get_summary()
        
        # Analyse conformit√© crit√®res
        criteria_met = {
            "100% formules FOL valides": metrics_summary.get("fol_syntax_validity_rate", 0.0) >= 1.0,
            "0 erreur parsing Tweety": metrics_summary.get("tweety_parsing_success_rate", 0.0) >= 1.0,
            ">95% compatibilit√© sophismes": metrics_summary.get("sophism_compatibility", 0.0) > 0.95,
            "Performance acceptable": metrics_summary.get("avg_analysis_time", 0.0) < 10.0,
            "Gestion erreurs compl√®te": validation_results.get("Gestion erreurs", False)
        }
        
        overall_success = all(validation_results.values()) and all(criteria_met.values())
        
        report = {
            "timestamp": time.strftime("%Y-%m-%d %H:%M:%S"),
            "total_validation_time": total_time,
            "overall_success": overall_success,
            "validation_results": validation_results,
            "criteria_compliance": criteria_met,
            "metrics": metrics_summary,
            "summary": {
                "tests_passed": sum(validation_results.values()),
                "tests_total": len(validation_results),
                "criteria_met": sum(criteria_met.values()),
                "criteria_total": len(criteria_met)
            },
            "recommendations": self._generate_recommendations(criteria_met, metrics_summary)
        }
        
        return report
    
    def _generate_recommendations(self, criteria_met: Dict[str, bool], metrics: Dict[str, Any]) -> List[str]:
        """G√©n√®re recommandations bas√©es sur les r√©sultats."""
        recommendations = []
        
        if not criteria_met.get("100% formules FOL valides", True):
            recommendations.append("Am√©liorer validation syntaxe FOL - certaines formules invalides g√©n√©r√©es")
        
        if not criteria_met.get("0 erreur parsing Tweety", True):
            recommendations.append("Corriger compatibilit√© Tweety - erreurs de parsing d√©tect√©es")
        
        if not criteria_met.get(">95% compatibilit√© sophismes", True):
            recommendations.append("Am√©liorer analyse sophismes - taux compatibilit√© insuffisant")
        
        if not criteria_met.get("Performance acceptable", True):
            recommendations.append("Optimiser performance - temps d'analyse trop long")
        
        if metrics.get("avg_confidence", 0.0) < 0.7:
            recommendations.append("Am√©liorer confiance analyses - scores trop faibles")
        
        if not recommendations:
            recommendations.append("‚úÖ Toutes les validations r√©ussies - Agent FOL pr√™t pour production")
        
        return recommendations


async def main():
    """Point d'entr√©e principal pour validation compl√®te."""
    validator = FOLCompleteValidator()
    
    try:
        report = await validator.run_complete_validation()
        
        # Affichage rapport
        print("\n" + "="*80)
        print("üìã RAPPORT VALIDATION AGENT FOL")
        print("="*80)
        
        print(f"\nüïê Temps total: {report['total_validation_time']:.2f}s")
        print(f"üéØ Succ√®s global: {'‚úÖ OUI' if report['overall_success'] else '‚ùå NON'}")
        
        print(f"\nüìä R√©sultats validation:")
        for validation, success in report['validation_results'].items():
            status = "‚úÖ" if success else "‚ùå"
            print(f"  {status} {validation}")
        
        print(f"\nüìè Conformit√© crit√®res:")
        for criterion, met in report['criteria_compliance'].items():
            status = "‚úÖ" if met else "‚ùå"
            print(f"  {status} {criterion}")
        
        print(f"\nüìà M√©triques cl√©s:")
        metrics = report['metrics']
        print(f"  ‚Ä¢ Syntaxe FOL valide: {metrics.get('fol_syntax_validity_rate', 0):.1%}")
        print(f"  ‚Ä¢ Parsing Tweety: {metrics.get('tweety_parsing_success_rate', 0):.1%}")
        print(f"  ‚Ä¢ Compatibilit√© sophismes: {metrics.get('sophism_compatibility', 0):.1%}")
        print(f"  ‚Ä¢ Temps analyse moyen: {metrics.get('avg_analysis_time', 0):.2f}s")
        print(f"  ‚Ä¢ Confiance moyenne: {metrics.get('avg_confidence', 0):.2f}")
        
        print(f"\nüí° Recommandations:")
        for rec in report['recommendations']:
            print(f"  ‚Ä¢ {rec}")
        
        # Sauvegarde rapport
        report_path = Path("reports/fol_validation_report.json")
        report_path.parent.mkdir(exist_ok=True)
        
        with open(report_path, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        
        print(f"\nüíæ Rapport sauvegard√©: {report_path}")
        
        return report['overall_success']
        
    except Exception as e:
        logger.error(f"‚ùå Erreur validation: {e}")
        traceback.print_exc()
        return False


if __name__ == "__main__":
    success = asyncio.run(main())
    exit(0 if success else 1)