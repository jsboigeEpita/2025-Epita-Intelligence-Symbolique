#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
Script d'ex√©cution des tests FirstOrderLogicAgent (FOL).

Ce script lance une validation compl√®te de l'agent FOL selon les crit√®res :
‚úÖ Tests unitaires complets  
‚úÖ Tests d'int√©gration Tweety
‚úÖ Validation compl√®te avec m√©triques
‚úÖ Tests de migration Modal ‚Üí FOL
‚úÖ G√©n√©ration de rapport d√©taill√©

Usage:
    python scripts/run_fol_tests.py [options]
    
Options:
    --unit-only       : Tests unitaires seulement
    --integration     : Tests d'int√©gration (n√©cessite Tweety)
    --validation      : Validation compl√®te avec m√©triques
    --migration       : Tests migration Modal ‚Üí FOL
    --all            : Tous les tests (d√©faut)
    --real-tweety    : Force utilisation Tweety r√©el
    --report-path    : Chemin rapport de sortie
"""

import argparse
import asyncio
import subprocess
import sys
import time
import json
import logging
from pathlib import Path
from typing import Dict, List, Any, Optional

# Configuration logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class FOLTestRunner:
    """Ex√©cuteur de tests pour agent FOL."""
    
    def __init__(self, args):
        self.args = args
        self.results = {}
        self.start_time = time.time()
        
        # Chemins des tests
        self.test_paths = {
            "unit": "tests/unit/agents/test_fol_logic_agent.py",
            "integration": "tests/integration/test_fol_tweety_integration.py", 
            "validation": "tests/validation/test_fol_complete_validation.py",
            "migration": "tests/migration/test_modal_to_fol_migration.py"
        }
        
        # Configuration environnement
        self.env_config = self._setup_environment()
    
    def _setup_environment(self) -> Dict[str, str]:
        """Configure l'environnement pour les tests."""
        import os
        
        env = os.environ.copy()
        
        # Configuration Tweety si demand√©
        if self.args.real_tweety:
            env.update({
                "USE_REAL_JPYPE": "true",
                "TWEETY_JAR_PATH": "libs/tweety-full.jar",
                "JVM_MEMORY": "1024m"
            })
            logger.info("üîß Configuration Tweety r√©el activ√©e")
        else:
            env.update({
                "USE_REAL_JPYPE": "false"
            })
            logger.info("üîß Configuration Tweety mock activ√©e")
        
        # Configuration tests
        env.update({
            "UNIFIED_LOGIC_TYPE": "fol",
            "UNIFIED_MOCK_LEVEL": "none" if self.args.real_tweety else "partial",
            "PYTHONPATH": str(Path.cwd())
        })
        
        return env
    
    def run_pytest_suite(self, test_path: str, test_name: str) -> Dict[str, Any]:
        """Ex√©cute une suite de tests pytest."""
        logger.info(f"‚ñ∂Ô∏è Ex√©cution {test_name}...")
        
        start_time = time.time()
        
        # Construction commande pytest
        cmd = [
            sys.executable, "-m", "pytest",
            test_path,
            "-v",
            "--tb=short"
        ]
        
        # Options sp√©ciales pour int√©gration
        if test_name == "integration" and not self.args.real_tweety:
            cmd.extend(["-k", "not test_real_tweety"])
        
        try:
            # Cr√©ation r√©pertoire rapports
            Path("reports").mkdir(exist_ok=True)
            
            # Ex√©cution
            result = subprocess.run(
                cmd,
                env=self.env_config,
                capture_output=True,
                text=True,
                timeout=300  # 5 minutes max par suite
            )
            
            duration = time.time() - start_time
            
            # Analyse r√©sultats
            success = result.returncode == 0
            
            test_result = {
                "success": success,
                "duration": duration,
                "return_code": result.returncode,
                "stdout": result.stdout,
                "stderr": result.stderr,
                "command": " ".join(cmd)
            }
            
            # Lecture rapport JSON si disponible
            json_report_path = f"reports/{test_name}_report.json"
            if Path(json_report_path).exists():
                try:
                    with open(json_report_path, 'r') as f:
                        json_report = json.load(f)
                        test_result["detailed_report"] = json_report
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è Impossible de lire rapport JSON: {e}")
            
            if success:
                logger.info(f"‚úÖ {test_name} r√©ussi en {duration:.2f}s")
            else:
                logger.error(f"‚ùå {test_name} √©chou√© en {duration:.2f}s")
                logger.error(f"Erreur: {result.stderr}")
            
            return test_result
            
        except subprocess.TimeoutExpired:
            logger.error(f"‚ùå {test_name} timeout apr√®s 5 minutes")
            return {
                "success": False,
                "duration": 300,
                "return_code": -1,
                "error": "Timeout",
                "command": " ".join(cmd)
            }
        except Exception as e:
            logger.error(f"‚ùå Erreur ex√©cution {test_name}: {e}")
            return {
                "success": False,
                "duration": 0,
                "return_code": -1,
                "error": str(e),
                "command": " ".join(cmd)
            }
    
    async def run_validation_script(self) -> Dict[str, Any]:
        """Ex√©cute le script de validation compl√®te."""
        logger.info("‚ñ∂Ô∏è Ex√©cution validation compl√®te...")
        
        start_time = time.time()
        
        try:
            # Import et ex√©cution du validateur
            sys.path.insert(0, str(Path.cwd()))
            
            from tests.validation.test_fol_complete_validation import FOLCompleteValidator
            
            validator = FOLCompleteValidator()
            report = await validator.run_complete_validation()
            
            duration = time.time() - start_time
            
            validation_result = {
                "success": report.get("overall_success", False),
                "duration": duration,
                "validation_report": report
            }
            
            if validation_result["success"]:
                logger.info(f"‚úÖ Validation compl√®te r√©ussie en {duration:.2f}s")
            else:
                logger.warning(f"‚ö†Ô∏è Validation compl√®te avec probl√®mes en {duration:.2f}s")
            
            return validation_result
            
        except Exception as e:
            logger.error(f"‚ùå Erreur validation compl√®te: {e}")
            return {
                "success": False,
                "duration": time.time() - start_time,
                "error": str(e)
            }
    
    def run_unit_tests(self):
        """Ex√©cute les tests unitaires."""
        if not Path(self.test_paths["unit"]).exists():
            logger.error(f"‚ùå Tests unitaires non trouv√©s: {self.test_paths['unit']}")
            return {"success": False, "error": "Tests non trouv√©s"}
        
        return self.run_pytest_suite(self.test_paths["unit"], "unit")
    
    def run_integration_tests(self):
        """Ex√©cute les tests d'int√©gration."""
        if not Path(self.test_paths["integration"]).exists():
            logger.error(f"‚ùå Tests int√©gration non trouv√©s: {self.test_paths['integration']}")
            return {"success": False, "error": "Tests non trouv√©s"}
        
        return self.run_pytest_suite(self.test_paths["integration"], "integration")
    
    async def run_validation_tests(self):
        """Ex√©cute la validation compl√®te."""
        if not Path(self.test_paths["validation"]).exists():
            logger.error(f"‚ùå Tests validation non trouv√©s: {self.test_paths['validation']}")
            return {"success": False, "error": "Tests non trouv√©s"}
        
        return await self.run_validation_script()
    
    def run_migration_tests(self):
        """Ex√©cute les tests de migration."""
        if not Path(self.test_paths["migration"]).exists():
            logger.error(f"‚ùå Tests migration non trouv√©s: {self.test_paths['migration']}")
            return {"success": False, "error": "Tests non trouv√©s"}
        
        return self.run_pytest_suite(self.test_paths["migration"], "migration")
    
    async def run_all_tests(self):
        """Ex√©cute tous les tests selon la configuration."""
        logger.info("üöÄ D√©but ex√©cution tests FOL")
        
        # S√©lection des tests √† ex√©cuter
        if self.args.unit_only:
            test_suites = [("unit", self.run_unit_tests)]
        elif self.args.integration:
            test_suites = [("integration", self.run_integration_tests)]
        elif self.args.validation:
            test_suites = [("validation", self.run_validation_tests)]
        elif self.args.migration:
            test_suites = [("migration", self.run_migration_tests)]
        else:  # --all ou d√©faut
            test_suites = [
                ("unit", self.run_unit_tests),
                ("integration", self.run_integration_tests),
                ("validation", self.run_validation_tests),
                ("migration", self.run_migration_tests)
            ]
        
        # Ex√©cution des suites
        for suite_name, suite_func in test_suites:
            try:
                if asyncio.iscoroutinefunction(suite_func):
                    result = await suite_func()
                else:
                    result = suite_func()
                
                self.results[suite_name] = result
                
            except Exception as e:
                logger.error(f"‚ùå Erreur suite {suite_name}: {e}")
                self.results[suite_name] = {
                    "success": False,
                    "error": str(e)
                }
        
        # G√©n√©ration rapport final
        await self.generate_final_report()
    
    async def generate_final_report(self):
        """G√©n√®re le rapport final des tests."""
        total_duration = time.time() - self.start_time
        
        # Calcul statistiques globales
        total_suites = len(self.results)
        successful_suites = sum(1 for r in self.results.values() if r.get("success", False))
        
        # Cr√©ation rapport
        report = {
            "timestamp": time.strftime("%Y-%m-%d %H:%M:%S"),
            "total_duration": total_duration,
            "configuration": {
                "real_tweety": self.args.real_tweety,
                "test_selection": self._get_test_selection()
            },
            "summary": {
                "total_suites": total_suites,
                "successful_suites": successful_suites,
                "success_rate": successful_suites / total_suites if total_suites > 0 else 0.0,
                "overall_success": successful_suites == total_suites
            },
            "results": self.results,
            "recommendations": self._generate_recommendations()
        }
        
        # Sauvegarde rapport
        report_path = Path(self.args.report_path or "reports/fol_tests_complete_report.json")
        report_path.parent.mkdir(exist_ok=True)
        
        with open(report_path, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False, default=str)
        
        # Affichage r√©sum√©
        self._print_summary(report, report_path)
        
        return report
    
    def _get_test_selection(self) -> str:
        """Retourne la s√©lection de tests."""
        if self.args.unit_only:
            return "unit_only"
        elif self.args.integration:
            return "integration_only"
        elif self.args.validation:
            return "validation_only"
        elif self.args.migration:
            return "migration_only"
        else:
            return "all"
    
    def _generate_recommendations(self) -> List[str]:
        """G√©n√®re recommandations bas√©es sur les r√©sultats."""
        recommendations = []
        
        # Analyse des √©checs
        failed_suites = [name for name, result in self.results.items() 
                        if not result.get("success", False)]
        
        if not failed_suites:
            recommendations.append("‚úÖ Tous les tests r√©ussis - Agent FOL pr√™t pour production")
        else:
            for suite in failed_suites:
                if suite == "unit":
                    recommendations.append("Corriger les tests unitaires avant d√©ploiement")
                elif suite == "integration":
                    recommendations.append("V√©rifier int√©gration Tweety - possibles probl√®mes JAR/JVM")
                elif suite == "validation":
                    recommendations.append("Am√©liorer m√©triques validation selon rapport d√©taill√©")
                elif suite == "migration":
                    recommendations.append("Revoir migration Modal Logic - compatibilit√© insuffisante")
        
        # Recommandations configuration
        if not self.args.real_tweety:
            recommendations.append("Ex√©cuter avec --real-tweety pour validation compl√®te")
        
        return recommendations
    
    def _print_summary(self, report: Dict[str, Any], report_path: Path):
        """Affiche r√©sum√© des r√©sultats."""
        print("\n" + "="*80)
        print("üìã RAPPORT TESTS AGENT FOL")
        print("="*80)
        
        summary = report["summary"]
        print(f"\nüïê Dur√©e totale: {report['total_duration']:.2f}s")
        print(f"üéØ Succ√®s global: {'‚úÖ OUI' if summary['overall_success'] else '‚ùå NON'}")
        print(f"üìä Taux r√©ussite: {summary['success_rate']:.1%} ({summary['successful_suites']}/{summary['total_suites']})")
        
        print(f"\nüìã R√©sultats par suite:")
        for suite_name, result in self.results.items():
            status = "‚úÖ" if result.get("success", False) else "‚ùå"
            duration = result.get("duration", 0)
            print(f"  {status} {suite_name.title()}: {duration:.2f}s")
            
            if not result.get("success", False) and "error" in result:
                print(f"      Erreur: {result['error']}")
        
        print(f"\nüí° Recommandations:")
        for rec in report["recommendations"]:
            print(f"  ‚Ä¢ {rec}")
        
        print(f"\nüíæ Rapport d√©taill√©: {report_path}")
        
        if summary["overall_success"]:
            print("\nüéâ Agent FOL valid√© avec succ√®s!")
        else:
            print("\n‚ö†Ô∏è Agent FOL n√©cessite des corrections")


def main():
    """Point d'entr√©e principal."""
    parser = argparse.ArgumentParser(
        description="Ex√©cuteur de tests pour FirstOrderLogicAgent",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Exemples:
  python scripts/run_fol_tests.py --all
  python scripts/run_fol_tests.py --unit-only
  python scripts/run_fol_tests.py --integration --real-tweety
  python scripts/run_fol_tests.py --validation --report-path reports/custom.json
        """
    )
    
    # Options de s√©lection des tests
    group = parser.add_mutually_exclusive_group()
    group.add_argument("--unit-only", action="store_true",
                      help="Ex√©cuter seulement les tests unitaires")
    group.add_argument("--integration", action="store_true", 
                      help="Ex√©cuter seulement les tests d'int√©gration")
    group.add_argument("--validation", action="store_true",
                      help="Ex√©cuter seulement la validation compl√®te")
    group.add_argument("--migration", action="store_true",
                      help="Ex√©cuter seulement les tests de migration")
    group.add_argument("--all", action="store_true", default=True,
                      help="Ex√©cuter tous les tests (d√©faut)")
    
    # Options de configuration
    parser.add_argument("--real-tweety", action="store_true",
                       help="Utiliser Tweety r√©el (n√©cessite JAR)")
    parser.add_argument("--report-path", type=str,
                       help="Chemin du rapport de sortie")
    
    args = parser.parse_args()
    
    # Ex√©cution
    runner = FOLTestRunner(args)
    
    try:
        asyncio.run(runner.run_all_tests())
        
        # Code de sortie bas√© sur le succ√®s
        overall_success = all(r.get("success", False) for r in runner.results.values())
        sys.exit(0 if overall_success else 1)
        
    except KeyboardInterrupt:
        logger.info("üõë Interruption utilisateur")
        sys.exit(130)
    except Exception as e:
        logger.error(f"‚ùå Erreur fatale: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()