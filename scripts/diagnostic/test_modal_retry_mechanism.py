#!/usr/bin/env python3
"""
Script de test pour d√©montrer le m√©canisme de retry automatique corrig√©
pour les erreurs de syntaxe TweetyProject dans ModalLogicAgent.

Ce script compare le comportement de l'agent original vs l'agent corrig√©.
"""

import asyncio
import logging
import sys
import traceback
from semantic_kernel import Kernel
from semantic_kernel.connectors.ai.open_ai import OpenAIChatCompletion

# Configuration du logging pour voir les tentatives de retry
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

async def test_original_agent_behavior():
    """Test avec l'agent original (sans retry automatique)."""
    logger.info("=" * 80)
    logger.info("TEST 1: Agent Modal Logic ORIGINAL (sans retry automatique)")
    logger.info("=" * 80)
    
    try:
        # Initialiser le kernel
        kernel = Kernel()
        
        # Configurer le service LLM (remplacez par votre configuration)
        service_id = "openai"
        kernel.add_service(
            OpenAIChatCompletion(
                service_id=service_id,
                ai_model_id="gpt-4",
                api_key="your-api-key-here"  # Remplacez par votre cl√© API
            )
        )
        
        # Importer et initialiser l'agent original
        from argumentation_analysis.agents.core.logic.modal_logic_agent import ModalLogicAgent
        
        agent = ModalLogicAgent(kernel, "TestModalOriginal", service_id)
        agent.setup_agent_components(service_id)
        
        # Test avec un texte qui va g√©n√©rer une erreur de syntaxe TweetyProject
        test_text = "The annihilation of Aryan race is necessary for world peace."
        
        logger.info(f"Test avec: '{test_text}'")
        logger.info("Attente d'un √©chec SANS retry automatique...")
        
        belief_set, status = await agent.text_to_belief_set(test_text)
        
        if belief_set:
            logger.info(f"SUCC√àS INATTENDU: {status}")
            logger.info(f"Belief Set: {belief_set.content}")
        else:
            logger.warning(f"√âCHEC ATTENDU: {status}")
            
    except Exception as e:
        logger.error(f"ERREUR dans test original: {e}")
        logger.debug(traceback.format_exc())

async def test_fixed_agent_behavior():
    """Test avec l'agent corrig√© (avec retry automatique)."""
    logger.info("=" * 80)
    logger.info("TEST 2: Agent Modal Logic CORRIG√â (avec retry automatique)")
    logger.info("=" * 80)
    
    try:
        # Initialiser le kernel
        kernel = Kernel()
        
        # Configurer le service LLM (remplacez par votre configuration)
        service_id = "openai"
        kernel.add_service(
            OpenAIChatCompletion(
                service_id=service_id,
                ai_model_id="gpt-4",
                api_key="your-api-key-here"  # Remplacez par votre cl√© API
            )
        )
        
        # Importer et initialiser l'agent SK Retry
        from argumentation_analysis.agents.core.logic.modal_logic_agent_sk_retry import ModalLogicAgentSKRetry
        
        agent = ModalLogicAgentSKRetry(kernel, "TestModalSKRetry", service_id)
        agent.setup_agent_components(service_id)
        
        # Test avec le m√™me texte probl√©matique
        test_text = "The annihilation of Aryan race is necessary for world peace."
        
        logger.info(f"Test avec: '{test_text}'")
        logger.info("Attente d'un retry automatique et correction...")
        
        belief_set, status = await agent.text_to_belief_set(test_text)
        
        if belief_set:
            logger.info(f"SUCC√àS AVEC RETRY: {status}")
            logger.info(f"Belief Set: {belief_set.content}")
        else:
            logger.warning(f"√âCHEC M√äME AVEC RETRY: {status}")
            
    except Exception as e:
        logger.error(f"ERREUR dans test corrig√©: {e}")
        logger.debug(traceback.format_exc())

async def test_syntax_error_simulation():
    """Test de simulation d'erreur de syntaxe directe."""
    logger.info("=" * 80)
    logger.info("TEST 3: Simulation d'erreur de syntaxe TweetyProject")
    logger.info("=" * 80)
    
    try:
        # Simuler l'erreur exacte du rapport
        original_error = "Error parsing Modal Logic formula 'constant annihilation_of_aryan' for logic 'S4': Predicate 'constantannihilation_of_aryan' has not been declared."
        
        logger.info(f"Erreur originale: {original_error}")
        
        # Importer l'agent SK Retry pour tester l'enrichissement d'erreur
        from argumentation_analysis.agents.core.logic.modal_logic_agent_sk_retry import ModalLogicAgentSKRetry
        from argumentation_analysis.agents.core.logic.tweety_bridge_sk import TweetyBridgeSK
        
        # Cr√©er une instance temporaire pour tester l'enrichissement
        kernel = Kernel()  # Kernel minimal pour test
        agent = ModalLogicAgentSKRetry(kernel, "TestSyntax")
        bridge_sk = TweetyBridgeSK()
        
        # Tester l'enrichissement d'erreur avec BNF
        enriched_error = agent._enrich_error_with_bnf(
            original_error,
            "constant annihilation_of_aryan"
        )
        
        logger.info("Erreur enrichie avec BNF:")
        logger.info(enriched_error)
        
        # V√©rifier que la BNF est incluse
        if "BNF Syntaxe TweetyProject" in enriched_error:
            logger.info("‚úÖ SUCCESS: L'erreur contient maintenant la BNF pour aider le retry")
        else:
            logger.error("‚ùå FAILED: L'erreur n'a pas √©t√© enrichie correctement")
            
        # D√©montrer la diff√©rence avec le nouveau bridge SK
        logger.info("\n" + "="*60)
        logger.info("üîç D√âMONSTRATION DIFF√âRENCE SK vs CLASSIQUE")
        logger.info("="*60)
        
        problematic_text = "The annihilation of Aryan race is necessary for world peace."
        demo_result = bridge_sk.demonstrate_sk_retry_difference(problematic_text)
        
        logger.info(f"üìù Input probl√©matique: {demo_result['problematic_input']}")
        logger.info(f"\nüî¥ ANCIEN M√âCANISME (3 tentatives identiques):")
        logger.info(f"   M√©thode: {demo_result['old_approach']['method']}")
        logger.info(f"   Comportement: {demo_result['old_approach']['behavior']}")
        logger.info(f"   R√©sultat: {demo_result['old_approach']['result']}")
        logger.info(f"   Agent voit: {demo_result['old_approach'].get('agent_sees', 'N/A')}")
        
        logger.info(f"\nüü¢ NOUVEAU M√âCANISME SK (erreurs comme r√©sultats):")
        logger.info(f"   M√©thode: {demo_result['new_sk_approach']['method']}")
        logger.info(f"   Comportement: {demo_result['new_sk_approach']['behavior']}")
        logger.info(f"   R√©sultat: {demo_result['new_sk_approach']['result']}")
        logger.info(f"   Agent voit: {demo_result['new_sk_approach'].get('agent_sees', 'N/A')}")
        logger.info(f"   BNF fournie: {demo_result['new_sk_approach'].get('bnf_provided', False)}")
        
        logger.info(f"\nüí° DIFF√âRENCE CL√â: {demo_result['key_difference']}")
            
    except Exception as e:
        logger.error(f"ERREUR dans simulation: {e}")
        logger.debug(traceback.format_exc())

async def test_retry_settings_configuration():
    """Test de la configuration des settings de retry."""
    logger.info("=" * 80)
    logger.info("TEST 4: V√©rification de la configuration du retry automatique")
    logger.info("=" * 80)
    
    try:
        from argumentation_analysis.agents.core.logic.modal_logic_agent_sk_retry import ModalLogicAgentSKRetry
        from semantic_kernel.connectors.ai.prompt_execution_settings import PromptExecutionSettings
        
        # Cr√©er une instance pour tester la configuration
        kernel = Kernel()
        agent = ModalLogicAgentSKRetry(kernel, "TestRetryConfig")
        
        # Tester la cr√©ation des settings de retry
        base_settings = PromptExecutionSettings()
        retry_settings = agent._create_retry_execution_settings(base_settings)
        
        logger.info(f"Settings de base: max_auto_invoke_attempts = {getattr(base_settings, 'max_auto_invoke_attempts', 'Non d√©fini')}")
        logger.info(f"Settings de retry: max_auto_invoke_attempts = {getattr(retry_settings, 'max_auto_invoke_attempts', 'Non d√©fini')}")
        
        if hasattr(retry_settings, 'max_auto_invoke_attempts') and retry_settings.max_auto_invoke_attempts == 3:
            logger.info("‚úÖ SUCCESS: Configuration du retry automatique correcte (max_auto_invoke_attempts=3)")
        else:
            logger.error("‚ùå FAILED: Configuration du retry automatique incorrecte")
            
        # Tester les capacit√©s de l'agent
        capabilities = agent.get_agent_capabilities()
        features = capabilities.get('features', {})
        
        logger.info("Fonctionnalit√©s de l'agent corrig√©:")
        for feature, enabled in features.items():
            status = "‚úÖ" if enabled else "‚ùå"
            logger.info(f"  {status} {feature}: {enabled}")
            
    except Exception as e:
        logger.error(f"ERREUR dans test de configuration: {e}")
        logger.debug(traceback.format_exc())

async def main():
    """Fonction principale de test."""
    logger.info("üîç INVESTIGATION: M√©canisme de retry automatique pour erreurs TweetyProject")
    logger.info("üìã Tests comparatifs entre agent original et agent corrig√©")
    
    try:
        # Test 1: Agent original (pour comparaison)
        logger.info("\n" + "üî¨ " + "="*50)
        await test_original_agent_behavior()
        
        # Test 2: Agent corrig√©
        logger.info("\n" + "üõ†Ô∏è " + "="*50)
        await test_fixed_agent_behavior()
        
        # Test 3: Simulation d'erreur de syntaxe
        logger.info("\n" + "‚ö° " + "="*50)
        await test_syntax_error_simulation()
        
        # Test 4: Configuration du retry
        logger.info("\n" + "‚öôÔ∏è " + "="*50)
        await test_retry_settings_configuration()
        
        logger.info("\n" + "üèÅ " + "="*50)
        logger.info("INVESTIGATION TERMIN√âE")
        logger.info("üìä R√©sultats: Voir les logs ci-dessus pour les d√©tails")
        
    except Exception as e:
        logger.error(f"ERREUR CRITIQUE dans main: {e}")
        logger.debug(traceback.format_exc())
        return 1
    
    return 0

if __name__ == "__main__":
    """Point d'entr√©e du script de test."""
    print("üöÄ D√©marrage des tests du m√©canisme de retry automatique...")
    
    # Configuration des avertissements pour √©viter le spam
    import warnings
    warnings.filterwarnings("ignore", category=DeprecationWarning)
    
    try:
        # Ex√©cuter les tests async
        exit_code = asyncio.run(main())
        sys.exit(exit_code)
    except KeyboardInterrupt:
        logger.info("üõë Tests interrompus par l'utilisateur")
        sys.exit(1)
    except Exception as e:
        logger.error(f"üö® ERREUR FATALE: {e}")
        sys.exit(1)