#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
Script pour lancer l'analyse rhÃ©torique sur un extrait alÃ©atoire du corpus
en utilisant l'analyseur modulaire existant.
"""

import project_core.core_from_scripts.auto_env
import os
import sys
import asyncio
import random
import logging
from pathlib import Path

# Charger les variables d'environnement depuis .env
from dotenv import load_dotenv
load_dotenv()

# Configuration du logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s [%(levelname)s] %(message)s')
logger = logging.getLogger(__name__)

# Ajouter le rÃ©pertoire racine au sys.path
project_root = Path(__file__).resolve().parent
sys.path.insert(0, str(project_root))

async def analyze_random_extract():
    """
    Lance l'analyse sur un extrait alÃ©atoire en utilisant les analyseurs existants.
    """
    try:
        # Import des modules d'analyse
        from scripts.consolidated.universal_rhetorical_analyzer import UniversalRhetoricalAnalyzer
        from scripts.data_processing.decrypt_extracts import decrypt_and_load_extracts
        
        logger.info("=== Analyse d'un Extrait AlÃ©atoire ===")
        
        # 1. Charger la clÃ© de chiffrement
        encryption_key = os.getenv("TEXT_CONFIG_PASSPHRASE")
        if not encryption_key:
            logger.error("Variable d'environnement TEXT_CONFIG_PASSPHRASE requise")
            return False
        
        # 2. DÃ©chiffrer et charger les extraits
        logger.info("Chargement du corpus...")
        try:
            extract_definitions, status_message = decrypt_and_load_extracts(encryption_key)
        except Exception as e:
            logger.warning(f"Erreur lors du dÃ©chiffrement (clÃ© diffÃ©rente?): {str(e)[:100]}...")
            # Utiliser un texte de fallback pour la dÃ©monstration
            fallback_text = """
            L'analyse rhÃ©torique moderne doit identifier les sophismes dans le discours politique.
            Par exemple, l'argument d'autoritÃ© fallacieux consiste Ã  invoquer une autoritÃ© non qualifiÃ©e.
            L'ad hominem attaque la personne plutÃ´t que l'argument.
            Ces techniques manipulatoires sont courantes dans les dÃ©bats publics contemporains.
            De plus, l'appel Ã  l'Ã©motion dÃ©tourne l'attention des faits vers les sentiments.
            Le faux dilemme prÃ©sente seulement deux options alors qu'il en existe d'autres.
            """
            logger.info("Utilisation d'un texte de fallback pour la dÃ©monstration")
            return await analyze_text_with_modules(fallback_text.strip(), "Texte de dÃ©monstration (fallback)")
        
        if not extract_definitions:
            logger.warning("Aucune dÃ©finition d'extrait chargÃ©e - utilisation du fallback")
            fallback_text = """
            L'analyse rhÃ©torique moderne doit identifier les sophismes dans le discours politique.
            Par exemple, l'argument d'autoritÃ© fallacieux consiste Ã  invoquer une autoritÃ© non qualifiÃ©e.
            L'ad hominem attaque la personne plutÃ´t que l'argument.
            Ces techniques manipulatoires sont courantes dans les dÃ©bats publics contemporains.
            """
            return await analyze_text_with_modules(fallback_text.strip(), "Texte de dÃ©monstration (fallback)")
        
        # 3. SÃ©lectionner un extrait alÃ©atoire
        logger.info("SÃ©lection d'un extrait alÃ©atoire...")
        
        # Construire la liste de tous les extraits disponibles
        all_extracts = []
        for source_idx, source in enumerate(extract_definitions):
            source_name = source.get("source_name", f"Source_{source_idx}")
            extraits = source.get("extracts", [])
            
            # Ajouter le texte complet comme option
            if source.get("full_text"):
                all_extracts.append({
                    "source_name": source_name,
                    "extract_name": "Texte Complet",
                    "text": source["full_text"],
                    "type": "full_text"
                })
            
            # Ajouter les extraits spÃ©cifiques
            for extract_idx, extract in enumerate(extraits):
                extract_name = extract.get("extract_name", f"Extract_{extract_idx}")
                if extract.get("full_text"):
                    all_extracts.append({
                        "source_name": source_name,
                        "extract_name": extract_name,
                        "text": extract["full_text"],
                        "type": "extract"
                    })
        
        if not all_extracts:
            logger.error("Aucun extrait avec contenu trouvÃ©")
            return False
        
        # SÃ©lectionner alÃ©atoirement
        selected_extract = random.choice(all_extracts)
        logger.info(f"Extrait sÃ©lectionnÃ©: {selected_extract['source_name']} -> {selected_extract['extract_name']}")
        
        # 4. Lancer l'analyse avec l'analyseur modulaire
        return await analyze_text_with_modules(
            selected_extract["text"],
            f"{selected_extract['source_name']} - {selected_extract['extract_name']}"
        )
        
    except ImportError as e:
        logger.error(f"Erreur d'import: {e}")
        return False
    except Exception as e:
        logger.error(f"Erreur inattendue: {e}")
        return False

async def analyze_text_with_modules(text: str, description: str) -> bool:
    """
    Analyse un texte avec le pipeline unifiÃ© et GPT-4o-mini.
    
    Args:
        text: Le texte Ã  analyser
        description: Description de la source
        
    Returns:
        bool: True si l'analyse a rÃ©ussi
    """
    try:
        from argumentation_analysis.utils.unified_pipeline import (
            UnifiedAnalysisPipeline, AnalysisConfig, AnalysisMode, SourceType
        )
        
        logger.info(f"ğŸš€ Lancement de l'analyse avec GPT-4o-mini: {description}")
        logger.info(f"ğŸ“ Longueur du texte: {len(text)} caractÃ¨res")
        
        # Configuration du modÃ¨le depuis .env
        llm_model = os.getenv("OPENAI_CHAT_MODEL_ID", "gpt-4o-mini")
        logger.info(f"ğŸ¤– ModÃ¨le configurÃ©: {llm_model}")
        
        # Configuration de l'analyse avec GPT-4o-mini authentique
        config = AnalysisConfig(
            analysis_modes=[AnalysisMode.FALLACIES],  # Mode sophismes pour commencer
            llm_service="openai",
            llm_model=llm_model,
            llm_temperature=0.3,
            require_real_llm=True,  # â† CRITIQUE: Forcer l'utilisation rÃ©elle de l'LLM
            require_real_tweety=False,  # DÃ©sactiver TweetyProject pour Ã©viter les erreurs Java
            enable_fallback=True,
            detailed_logging=True,
            retry_count=2,
            enable_parallel=False  # Mode sÃ©quentiel pour debugging
        )
        
        # CrÃ©er le pipeline
        pipeline = UnifiedAnalysisPipeline(config)
        
        # Lancer l'analyse
        logger.info("ğŸ”¥ DÃ©but de l'analyse avec GPT-4o-mini authentique...")
        result = await pipeline.analyze_text(text, SourceType.TEXT)
        
        # Afficher les rÃ©sultats dÃ©taillÃ©s
        logger.info("ğŸ¯ === RÃ‰SULTATS DE L'ANALYSE GPT-4o-mini ===")
        logger.info(f"ğŸ“„ Source: {description}")
        logger.info(f"â±ï¸ Temps d'exÃ©cution: {result.execution_time:.2f}s")
        logger.info(f"âœ… Statut: {result.status}")
        
        if result.errors:
            logger.error(f"âŒ Erreurs: {result.errors}")
        
        if result.warnings:
            logger.warning(f"âš ï¸ Avertissements: {result.warnings}")
        
        # Afficher les rÃ©sultats d'analyse
        for mode, analysis_result in result.results.items():
            logger.info(f"\nğŸ” === RÃ‰SULTATS {mode.upper()} ===")
            logger.info(f"ğŸ¤– ModÃ¨le utilisÃ©: {analysis_result.get('model_used', 'N/A')}")
            logger.info(f"ğŸ¯ Authentique: {analysis_result.get('authentic', False)}")
            
            if analysis_result.get('fallacies_detected'):
                fallacies = analysis_result['fallacies_detected']
                logger.info(f"ğŸ­ Sophismes dÃ©tectÃ©s: {len(fallacies)}")
                for fallacy in fallacies:
                    logger.info(f"  ğŸš© {fallacy}")
            
            if analysis_result.get('result'):
                logger.info(f"ğŸ“Š RÃ©sultat: {analysis_result['result']}")
            
            if analysis_result.get('confidence'):
                logger.info(f"ğŸ¯ Confiance: {analysis_result['confidence']}")
        
        # Afficher le rÃ©sumÃ© de session
        session_summary = pipeline.get_session_summary()
        logger.info(f"\nğŸ“ˆ === RÃ‰SUMÃ‰ SESSION ===")
        logger.info(f"ğŸ†” Session ID: {session_summary['session_id']}")
        logger.info(f"ğŸ“Š Taux de succÃ¨s: {session_summary['success_rate']:.2%}")
        logger.info(f"â±ï¸ Temps moyen: {session_summary['average_execution_time']:.2f}s")
        
        logger.info("ğŸ‰ === FIN DE L'ANALYSE ===")
        return result.status == "completed"
        
    except Exception as e:
        logger.error(f"ğŸ’¥ Erreur lors de l'analyse: {e}")
        import traceback
        logger.error(f"ğŸ“‹ Traceback: {traceback.format_exc()}")
        return False

if __name__ == "__main__":
    success = asyncio.run(analyze_random_extract())
    
    if success:
        logger.info("Analyse terminÃ©e avec succÃ¨s!")
    else:
        logger.error("Analyse Ã©chouÃ©e")
        sys.exit(1)