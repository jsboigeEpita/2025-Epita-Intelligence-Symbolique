#!/usr/bin/env python3
# scripts/validation_cluedo_traces.py

"""
Script de validation des d√©mos Cluedo avec g√©n√©ration de traces compl√®tes.
Ce script teste les cas simples et complexes avec capture des conversations agentiques.
"""

import scripts.core.auto_env  # Activation automatique de l'environnement

import asyncio
import json
import os
import logging
import datetime
from pathlib import Path
from typing import Dict, List, Any, Optional

from semantic_kernel import Kernel
from semantic_kernel.connectors.ai.open_ai import OpenAIChatCompletion

# Imports sp√©cifiques au projet
from argumentation_analysis.orchestration.cluedo_orchestrator import run_cluedo_game
from argumentation_analysis.utils.core_utils.logging_utils import setup_logging

class CluedoTraceValidator:
    """Validateur avec capture de traces pour les d√©mos Cluedo."""
    
    def __init__(self, output_dir: str = ".temp/traces_cluedo"):
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)
        self.timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
        self.logger = logging.getLogger(__name__)
        
    def create_kernel(self, model_name: str = "gpt-4o-mini") -> Kernel:
        """Cr√©ation du kernel Semantic Kernel avec service OpenAI."""
        api_key = os.getenv("OPENAI_API_KEY")
        if not api_key:
            raise ValueError("OPENAI_API_KEY non d√©finie dans l'environnement")
            
        kernel = Kernel()
        chat_service = OpenAIChatCompletion(
            service_id="openai_chat",
            api_key=api_key,
            ai_model_id=model_name
        )
        kernel.add_service(chat_service)
        return kernel
        
    def generate_simple_case(self) -> str:
        """G√©n√®re un cas de Cluedo simple (3-4 indices)."""
        return """Enqu√™te Cluedo simple: 
        - T√©moin A: 'J'ai vu Mme Peacock dans la biblioth√®que vers 21h00'
        - T√©moin B: 'Le chandelier manquait dans le salon apr√®s 21h30'
        - T√©moin C: 'Professor Plum √©tait dans la cuisine √† 21h15'
        - Indice physique: Traces de cire dans la biblioth√®que
        
        Question: Qui a commis le meurtre, avec quelle arme et dans quel lieu ?"""
        
    def generate_complex_case(self) -> str:
        """G√©n√®re un cas de Cluedo complexe avec contradictions."""
        return """Enqu√™te Cluedo complexe avec contradictions:
        - T√©moin A: 'Mme Peacock √©tait dans la biblioth√®que vers 21h00'
        - T√©moin B: 'Mme Peacock √©tait dans le salon √† 21h00' (CONTRADICTION)
        - T√©moin C: 'J'ai entendu un bruit dans la biblioth√®que vers 21h15'
        - T√©moin D: 'Professor Plum avait le chandelier √† 20h45'
        - T√©moin E: 'Professor Plum n'avait pas d'arme √† 20h45' (CONTRADICTION)
        - Indice: Empreintes de Mme Peacock sur le chandelier
        - Indice: Traces de cire dans la biblioth√®que et le salon
        - Indice: Alibi partiel de Professor Plum en cuisine (20h30-21h00)
        - Indice: Porte de la biblioth√®que ferm√©e √† cl√© apr√®s 21h30
        
        Question: R√©solvez cette enqu√™te en g√©rant les contradictions."""
        
    async def run_cluedo_with_traces(self, case_description: str, case_name: str) -> Dict[str, Any]:
        """Ex√©cute un cas Cluedo avec capture compl√®te des traces."""
        
        self.logger.info(f"üïµÔ∏è D√©but de l'ex√©cution du cas: {case_name}")
        print(f"\n{'='*80}")
        print(f"üïµÔ∏è EX√âCUTION CAS CLUEDO: {case_name}")
        print(f"{'='*80}")
        
        try:
            # Cr√©ation du kernel
            kernel = self.create_kernel()
            
            # Capture du timestamp de d√©but
            start_time = datetime.datetime.now()
            
            # Ex√©cution du jeu Cluedo
            print(f"\nüìã Sc√©nario: {case_description[:100]}...")
            final_history, final_state = await run_cluedo_game(kernel, case_description)
            
            # Capture du timestamp de fin
            end_time = datetime.datetime.now()
            duration = (end_time - start_time).total_seconds()
            
            # Construction des r√©sultats complets
            results = {
                "metadata": {
                    "case_name": case_name,
                    "timestamp": self.timestamp,
                    "start_time": start_time.isoformat(),
                    "end_time": end_time.isoformat(),
                    "duration_seconds": duration,
                    "model_used": "gpt-4o-mini"
                },
                "input": {
                    "case_description": case_description,
                    "question": "Qui a commis le meurtre, avec quelle arme et dans quel lieu ?"
                },
                "conversation_history": final_history,
                "final_state": {
                    "final_solution": getattr(final_state, 'final_solution', None),
                    "solution_secrete": getattr(final_state, 'solution_secrete_cluedo', None),
                    "hypotheses": getattr(final_state, 'hypotheses_enquete', []),
                    "tasks": getattr(final_state, 'tasks', {}),
                    "confidence_level": self._extract_confidence(final_state)
                },
                "analysis": {
                    "conversation_length": len(final_history) if final_history else 0,
                    "agent_participation": self._analyze_agent_participation(final_history),
                    "tools_used": self._extract_tools_usage(final_history),
                    "logic_quality": self._assess_logic_quality(final_history, final_state)
                }
            }
            
            # Sauvegarde des traces
            trace_file = self.output_dir / f"trace_{case_name}_{self.timestamp}.json"
            with open(trace_file, 'w', encoding='utf-8') as f:
                json.dump(results, f, indent=2, ensure_ascii=False, default=str)
                
            self.logger.info(f"‚úÖ Traces sauvegard√©es: {trace_file}")
            
            # Affichage des r√©sultats
            self._display_results(results)
            
            return results
            
        except Exception as e:
            self.logger.error(f"‚ùå Erreur lors de l'ex√©cution de {case_name}: {e}")
            error_results = {
                "metadata": {"case_name": case_name, "error": str(e)},
                "error": str(e),
                "timestamp": self.timestamp
            }
            
            # Sauvegarde de l'erreur
            error_file = self.output_dir / f"error_{case_name}_{self.timestamp}.json"
            with open(error_file, 'w', encoding='utf-8') as f:
                json.dump(error_results, f, indent=2, ensure_ascii=False, default=str)
                
            raise
            
    def _extract_confidence(self, final_state) -> Optional[float]:
        """Extrait le niveau de confiance de la solution."""
        try:
            if hasattr(final_state, 'hypotheses_enquete') and final_state.hypotheses_enquete:
                confidences = [h.get('confidence_score', 0) for h in final_state.hypotheses_enquete 
                             if isinstance(h, dict) and 'confidence_score' in h]
                return max(confidences) if confidences else None
        except:
            pass
        return None
        
    def _analyze_agent_participation(self, history: List) -> Dict[str, int]:
        """Analyse la participation de chaque agent."""
        participation = {}
        if not history:
            return participation
            
        for entry in history:
            if isinstance(entry, dict) and 'sender' in entry:
                sender = entry['sender']
                participation[sender] = participation.get(sender, 0) + 1
                
        return participation
        
    def _extract_tools_usage(self, history: List) -> List[str]:
        """Extrait les outils utilis√©s pendant la conversation."""
        tools_used = set()
        if not history:
            return list(tools_used)
            
        for entry in history:
            if isinstance(entry, dict) and 'message' in entry:
                message = entry['message'].lower()
                # Recherche de mentions d'outils
                if 'tweetyproject' in message or 'tweety' in message:
                    tools_used.add('TweetyProject')
                if 'semantic_kernel' in message or 'fonction' in message:
                    tools_used.add('SemanticKernel')
                if 'oracle' in message:
                    tools_used.add('Oracle')
                    
        return list(tools_used)
        
    def _assess_logic_quality(self, history: List, final_state) -> Dict[str, Any]:
        """√âvalue la qualit√© du raisonnement logique."""
        return {
            "has_systematic_approach": self._check_systematic_approach(history),
            "handles_contradictions": self._check_contradiction_handling(history),
            "reaches_conclusion": final_state.final_solution is not None if hasattr(final_state, 'final_solution') else False,
            "evidence_based": self._check_evidence_usage(history)
        }
        
    def _check_systematic_approach(self, history: List) -> bool:
        """V√©rifie si l'approche est syst√©matique."""
        if not history or len(history) < 3:
            return False
        # Recherche de mots-cl√©s indiquant une approche syst√©matique
        systematic_keywords = ['hypoth√®se', 'analyse', 'd√©duction', 'logique', 'raisonnement']
        for entry in history:
            if isinstance(entry, dict) and 'message' in entry:
                message = entry['message'].lower()
                if any(keyword in message for keyword in systematic_keywords):
                    return True
        return False
        
    def _check_contradiction_handling(self, history: List) -> bool:
        """V√©rifie si les contradictions sont g√©r√©es."""
        if not history:
            return False
        for entry in history:
            if isinstance(entry, dict) and 'message' in entry:
                message = entry['message'].lower()
                if 'contradiction' in message or 'incoh√©ren' in message:
                    return True
        return False
        
    def _check_evidence_usage(self, history: List) -> bool:
        """V√©rifie si les preuves sont utilis√©es."""
        if not history:
            return False
        evidence_keywords = ['preuve', 'indice', 't√©moin', 'trace', 'empreinte']
        for entry in history:
            if isinstance(entry, dict) and 'message' in entry:
                message = entry['message'].lower()
                if any(keyword in message for keyword in evidence_keywords):
                    return True
        return False
        
    def _display_results(self, results: Dict[str, Any]):
        """Affiche les r√©sultats de l'analyse."""
        print(f"\nüìä R√âSULTATS ANALYSE - {results['metadata']['case_name']}")
        print(f"‚è±Ô∏è  Dur√©e: {results['metadata']['duration_seconds']:.2f}s")
        print(f"üí¨ Messages √©chang√©s: {results['analysis']['conversation_length']}")
        
        # Participation des agents
        participation = results['analysis']['agent_participation']
        print(f"\nüë• Participation des agents:")
        for agent, count in participation.items():
            print(f"   - {agent}: {count} messages")
            
        # Outils utilis√©s
        tools = results['analysis']['tools_used']
        print(f"\nüîß Outils utilis√©s: {', '.join(tools) if tools else 'Aucun d√©tect√©'}")
        
        # Qualit√© logique
        logic = results['analysis']['logic_quality']
        print(f"\nüß† Qualit√© logique:")
        print(f"   - Approche syst√©matique: {'‚úÖ' if logic['has_systematic_approach'] else '‚ùå'}")
        print(f"   - Gestion contradictions: {'‚úÖ' if logic['handles_contradictions'] else '‚ùå'}")
        print(f"   - Conclusion atteinte: {'‚úÖ' if logic['reaches_conclusion'] else '‚ùå'}")
        print(f"   - Bas√© sur preuves: {'‚úÖ' if logic['evidence_based'] else '‚ùå'}")
        
        # Solution finale
        final_solution = results['final_state']['final_solution']
        print(f"\nüéØ Solution finale: {final_solution if final_solution else 'Non r√©solue'}")

async def main():
    """Fonction principale de validation des traces Cluedo."""
    
    print("üîç VALIDATION D√âMOS CLUEDO AVEC TRACES COMPL√àTES")
    print("="*80)
    
    # Configuration du logging
    setup_logging()
    
    # Cr√©ation du validateur
    validator = CluedoTraceValidator()
    
    # R√©sultats globaux
    all_results = []
    
    try:
        # Test 1: Cas simple
        print(f"\nüü¢ TEST 1: CAS CLUEDO SIMPLE")
        simple_case = validator.generate_simple_case()
        simple_results = await validator.run_cluedo_with_traces(simple_case, "simple")
        all_results.append(simple_results)
        
        # Test 2: Cas complexe
        print(f"\nüî¥ TEST 2: CAS CLUEDO COMPLEXE") 
        complex_case = validator.generate_complex_case()
        complex_results = await validator.run_cluedo_with_traces(complex_case, "complexe")
        all_results.append(complex_results)
        
        # G√©n√©ration du rapport de synth√®se
        await validator.generate_synthesis_report(all_results)
        
        print(f"\n‚úÖ VALIDATION TERMIN√âE AVEC SUCC√àS")
        print(f"üìÅ Traces sauvegard√©es dans: {validator.output_dir}")
        
        return all_results
        
    except Exception as e:
        print(f"\n‚ùå ERREUR LORS DE LA VALIDATION: {e}")
        logging.error(f"Erreur validation: {e}", exc_info=True)
        raise

# Extension pour le rapport de synth√®se
async def generate_synthesis_report(self, all_results: List[Dict[str, Any]]):
    """G√©n√®re un rapport de synth√®se des tests."""
    
    synthesis = {
        "metadata": {
            "generation_time": datetime.datetime.now().isoformat(),
            "total_tests": len(all_results),
            "timestamp": self.timestamp
        },
        "summary": {
            "all_tests_completed": len(all_results) > 0,
            "total_duration": sum(r['metadata']['duration_seconds'] for r in all_results),
            "total_messages": sum(r['analysis']['conversation_length'] for r in all_results),
            "tools_coverage": self._analyze_tools_coverage(all_results),
            "logic_quality_summary": self._summarize_logic_quality(all_results)
        },
        "detailed_results": all_results
    }
    
    # Sauvegarde du rapport
    report_file = self.output_dir / f"synthesis_report_{self.timestamp}.json"
    with open(report_file, 'w', encoding='utf-8') as f:
        json.dump(synthesis, f, indent=2, ensure_ascii=False, default=str)
        
    print(f"\nüìã RAPPORT DE SYNTH√àSE")
    print(f"üìÅ Sauvegard√©: {report_file}")
    print(f"üß™ Tests r√©alis√©s: {synthesis['summary']['total_tests']}")
    print(f"‚è±Ô∏è  Dur√©e totale: {synthesis['summary']['total_duration']:.2f}s")
    print(f"üí¨ Messages totaux: {synthesis['summary']['total_messages']}")

def _analyze_tools_coverage(self, results: List[Dict[str, Any]]) -> Dict[str, int]:
    """Analyse la couverture des outils sur tous les tests."""
    tools_count = {}
    for result in results:
        for tool in result['analysis']['tools_used']:
            tools_count[tool] = tools_count.get(tool, 0) + 1
    return tools_count

def _summarize_logic_quality(self, results: List[Dict[str, Any]]) -> Dict[str, float]:
    """R√©sume la qualit√© logique sur tous les tests."""
    if not results:
        return {}
        
    total = len(results)
    summary = {
        "systematic_approach_rate": sum(1 for r in results if r['analysis']['logic_quality']['has_systematic_approach']) / total,
        "contradiction_handling_rate": sum(1 for r in results if r['analysis']['logic_quality']['handles_contradictions']) / total,
        "conclusion_rate": sum(1 for r in results if r['analysis']['logic_quality']['reaches_conclusion']) / total,
        "evidence_usage_rate": sum(1 for r in results if r['analysis']['logic_quality']['evidence_based']) / total
    }
    return summary

# Ajout des m√©thodes √† la classe
CluedoTraceValidator.generate_synthesis_report = generate_synthesis_report
CluedoTraceValidator._analyze_tools_coverage = _analyze_tools_coverage
CluedoTraceValidator._summarize_logic_quality = _summarize_logic_quality

if __name__ == "__main__":
    asyncio.run(main())