#!/usr/bin/env python3
"""
Script Monitoring Budget API Tests LLM R√©els - Mission D3.2
Affiche estimation co√ªts tokens temps r√©el pendant ex√©cution pytest

Usage:
    python -m pytest tests/ -m "llm_light" -v | python scripts/monitoring/monitor_llm_tests_budget.py

Note: Estimations bas√©es sur moyennes observ√©es par marker.
Pour monitoring r√©el tokens, int√©gration OpenAI API callbacks requise.
"""
import sys
import re
from datetime import datetime
from typing import Dict, Tuple


class LLMTestBudgetMonitor:
    """Monitore et estime les co√ªts des tests LLM en temps r√©el"""
    
    # Estimations co√ªts par marker (tokens, cost_usd)
    COST_ESTIMATES = {
        'llm_light': (50, 0.01),           # Tests l√©gers
        'llm_integration': (500, 0.10),    # Tests int√©gration
        'llm_critical': (1500, 0.25)       # Tests critiques
    }
    
    def __init__(self):
        self.total_cost = 0.0
        self.total_tokens = 0
        self.tests_passed = 0
        self.tests_failed = 0
        self.start_time = datetime.now()
        
    def estimate_cost_tokens(self, test_name: str, marker: str) -> Tuple[int, float]:
        """Estime co√ªt et tokens pour un test donn√©"""
        return self.COST_ESTIMATES.get(marker, (100, 0.05))
    
    def detect_marker(self, line: str) -> str:
        """D√©tecte marker du test depuis ligne pytest"""
        # Priorit√© ordre d√©croissant complexit√©
        if 'llm_critical' in line or '[llm_critical]' in line:
            return 'llm_critical'
        elif 'llm_integration' in line or '[llm_integration]' in line:
            return 'llm_integration'
        elif 'llm_light' in line or '[llm_light]' in line:
            return 'llm_light'
        
        # D√©tection via chemin fichier (fallback)
        if 'test_' in line:
            # Heuristique: tests critiques contiennent "complex", "advanced"
            if any(kw in line.lower() for kw in ['complex', 'advanced', 'critical']):
                return 'llm_critical'
            # Tests l√©gers contiennent "simple", "basic", "quick"
            elif any(kw in line.lower() for kw in ['simple', 'basic', 'quick', 'light']):
                return 'llm_light'
        
        return 'llm_integration'  # Par d√©faut
    
    def parse_test_result(self, line: str) -> Dict:
        """Parse ligne r√©sultat test pytest"""
        result = {
            'is_test': False,
            'passed': False,
            'failed': False,
            'test_name': None,
            'marker': None
        }
        
        # D√©tection format: tests/path/test_file.py::test_name PASSED
        test_match = re.search(r'(tests/.+?\.py)::(test_\w+)\s+(PASSED|FAILED)', line)
        if test_match:
            result['is_test'] = True
            result['test_name'] = f"{test_match.group(1)}::{test_match.group(2)}"
            result['passed'] = test_match.group(3) == 'PASSED'
            result['failed'] = test_match.group(3) == 'FAILED'
            result['marker'] = self.detect_marker(line)
        
        return result
    
    def update_stats(self, test_info: Dict):
        """Met √† jour statistiques monitoring"""
        if not test_info['is_test']:
            return
        
        marker = test_info['marker']
        tokens, cost = self.estimate_cost_tokens(test_info['test_name'], marker)
        
        self.total_tokens += tokens
        self.total_cost += cost
        
        if test_info['passed']:
            self.tests_passed += 1
        elif test_info['failed']:
            self.tests_failed += 1
    
    def format_budget_line(self, test_info: Dict) -> str:
        """Formate ligne affichage budget apr√®s test"""
        if not test_info['is_test']:
            return ""
        
        marker = test_info['marker']
        tokens, cost = self.estimate_cost_tokens(test_info['test_name'], marker)
        
        status_icon = "‚úÖ" if test_info['passed'] else "‚ùå"
        
        return (
            f"  üí∞ {status_icon} Budget: +${cost:.3f} "
            f"(total: ${self.total_cost:.2f}, ~{self.total_tokens} tokens) "
            f"[{marker}]"
        )
    
    def format_summary(self) -> str:
        """Formate synth√®se finale monitoring"""
        duration = (datetime.now() - self.start_time).total_seconds()
        total_tests = self.tests_passed + self.tests_failed
        
        summary = [
            "",
            "=" * 70,
            "üìä SYNTHESE MONITORING BUDGET LLM - Mission D3.2",
            "=" * 70,
            f"‚è±Ô∏è  Dur√©e ex√©cution       : {duration:.1f}s ({duration/60:.1f}min)",
            f"üìù Tests ex√©cut√©s        : {total_tests}",
            f"‚úÖ Tests PASSED          : {self.tests_passed}",
            f"‚ùå Tests FAILED          : {self.tests_failed}",
            "",
            f"üí∞ Budget Total Estim√©   : ${self.total_cost:.2f} USD",
            f"üî¢ Tokens Estim√©s        : ~{self.total_tokens} tokens",
            "",
        ]
        
        # Alertes budget
        if self.total_cost > 15.0:
            summary.append("‚ö†Ô∏è  ALERTE: Budget d√©passement seuil $15 USD !")
        elif self.total_cost > 10.0:
            summary.append("‚ö° INFO: Budget approche seuil estim√© ($10-15 USD)")
        
        # Taux succ√®s
        if total_tests > 0:
            success_rate = (self.tests_passed / total_tests) * 100
            summary.append(f"üìà Taux succ√®s           : {success_rate:.1f}%")
            
            if success_rate >= 80:
                summary.append("‚úÖ Objectif atteint (‚â•80% succ√®s)")
            elif success_rate >= 50:
                summary.append("‚ö†Ô∏è  Succ√®s partiel (50-79% succ√®s)")
            else:
                summary.append("‚ùå √âchec (<50% succ√®s)")
        
        summary.extend([
            "",
            "=" * 70,
            "‚ÑπÔ∏è  Note: Estimations bas√©es sur moyennes markers observ√©es.",
            "   Pour co√ªts r√©els, consulter dashboard OpenAI apr√®s ex√©cution.",
            "=" * 70,
            ""
        ])
        
        return "\n".join(summary)
    
    def monitor_pytest_output(self):
        """Parse sortie pytest stdin et affiche monitoring temps r√©el"""
        print("=" * 70)
        print("üîç Monitoring Budget Tests LLM D3.2 - D√©marr√©")
        print("=" * 70)
        print("")
        
        for line in sys.stdin:
            # Afficher sortie pytest normale
            print(line, end='')
            
            # Parser r√©sultat test
            test_info = self.parse_test_result(line)
            
            # Mettre √† jour stats et afficher budget si test d√©tect√©
            if test_info['is_test']:
                self.update_stats(test_info)
                budget_line = self.format_budget_line(test_info)
                if budget_line:
                    print(budget_line)
        
        # Afficher synth√®se finale
        print(self.format_summary())


def main():
    """Point d'entr√©e script"""
    monitor = LLMTestBudgetMonitor()
    
    try:
        monitor.monitor_pytest_output()
    except KeyboardInterrupt:
        print("\n\n‚ö†Ô∏è  Monitoring interrompu par utilisateur (Ctrl+C)")
        print(monitor.format_summary())
    except Exception as e:
        print(f"\n\n‚ùå Erreur monitoring: {e}")
        print(monitor.format_summary())


if __name__ == "__main__":
    main()