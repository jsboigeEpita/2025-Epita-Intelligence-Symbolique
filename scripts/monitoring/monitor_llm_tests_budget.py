#!/usr/bin/env python3
"""
Script Monitoring Budget API Tests LLM R√©els - Mission D3.2
Affiche estimation co√ªts tokens temps r√©el pendant ex√©cution pytest

Usage:
    python -m pytest tests/ -m "llm_light" -v | python scripts/monitoring/monitor_llm_tests_budget.py

Note: Estimations bas√©es sur moyennes observ√©es par marker.
Pour monitoring r√©el tokens, int√©gration OpenAI API callbacks requise.
"""

import sys
import re
from datetime import datetime
from typing import Dict, Tuple


class LLMTestBudgetMonitor:
    """Monitore et estime les co√ªts des tests LLM en temps r√©el"""

    # Estimations co√ªts par marker (tokens, cost_usd)
    COST_ESTIMATES = {
        "llm_light": (50, 0.01),  # Tests l√©gers
        "llm_integration": (500, 0.10),  # Tests int√©gration
        "llm_critical": (1500, 0.25),  # Tests critiques
    }

    def __init__(self):
        self.total_cost = 0.0
        self.total_tokens = 0
        self.tests_passed = 0
        self.tests_failed = 0
        self.start_time = datetime.now()

    def estimate_cost_tokens(self, test_name: str, marker: str) -> Tuple[int, float]:
        """Estime co√ªt et tokens pour un test donn√©"""
        return self.COST_ESTIMATES.get(marker, (100, 0.05))

    def detect_marker(self, line: str) -> str:
        """D√©tecte marker du test depuis ligne pytest"""
        # Priorit√© ordre d√©croissant complexit√©
        if "llm_critical" in line or "[llm_critical]" in line:
            return "llm_critical"
        elif "llm_integration" in line or "[llm_integration]" in line:
            return "llm_integration"
        elif "llm_light" in line or "[llm_light]" in line:
            return "llm_light"

        # D√©tection via chemin fichier (fallback)
        if "test_" in line:
            # Heuristique: tests critiques contiennent "complex", "advanced"
            if any(kw in line.lower() for kw in ["complex", "advanced", "critical"]):
                return "llm_critical"
            # Tests l√©gers contiennent "simple", "basic", "quick"
            elif any(
                kw in line.lower() for kw in ["simple", "basic", "quick", "light"]
            ):
                return "llm_light"

        return "llm_integration"  # Par d√©faut

    def parse_test_result(self, line: str) -> Dict:
        """Parse ligne r√©sultat test pytest"""
        result = {
            "is_test": False,
            "passed": False,
            "failed": False,
            "test_name": None,
            "marker": None,
        }

        # D√©tection format: tests/path/test_file.py::test_name PASSED
        test_match = re.search(r"(tests/.+?\.py)::(test_\w+)\s+(PASSED|FAILED)", line)
        if test_match:
            result["is_test"] = True
            result["test_name"] = f"{test_match.group(1)}::{test_match.group(2)}"
            result["passed"] = test_match.group(3) == "PASSED"
            result["failed"] = test_match.group(3) == "FAILED"
            result["marker"] = self.detect_marker(line)

        return result

    def update_stats(self, test_info: Dict):
        """Met √† jour statistiques monitoring"""
        if not test_info["is_test"]:
            return

        marker = test_info["marker"]
        tokens, cost = self.estimate_cost_tokens(test_info["test_name"], marker)

        self.total_tokens += tokens
        self.total_cost += cost

        if test_info["passed"]:
            self.tests_passed += 1
        elif test_info["failed"]:
            self.tests_failed += 1

    def format_budget_line(self, test_info: Dict) -> str:
        """Formate ligne affichage budget apr√®s test"""
        if not test_info["is_test"]:
            return ""

        marker = test_info["marker"]
        tokens, cost = self.estimate_cost_tokens(test_info["test_name"], marker)

        status_icon = "‚úÖ" if test_info["passed"] else "‚ùå"

        return (
            f"  üí∞ {status_icon} Budget: +${cost:.3f} "
            f"(total: ${self.total_cost:.2f}, ~{self.total_tokens} tokens) "
            f"[{marker}]"
        )

    def format_summary(self) -> str:
        """Formate synth√®se finale monitoring"""
        duration = (datetime.now() - self.start_time).total_seconds()
        total_tests = self.tests_passed + self.tests_failed

        summary = [
            "",
            "=" * 70,
            "üìä SYNTHESE MONITORING BUDGET LLM - Mission D3.2",
            "=" * 70,
            f"‚è±Ô∏è  Dur√©e ex√©cution       : {duration:.1f}s ({duration/60:.1f}min)",
            f"üìù Tests ex√©cut√©s        : {total_tests}",
            f"‚úÖ Tests PASSED          : {self.tests_passed}",
            f"‚ùå Tests FAILED          : {self.tests_failed}",
            "",
            f"üí∞ Budget Total Estim√©   : ${self.total_cost:.2f} USD",
            f"üî¢ Tokens Estim√©s        : ~{self.total_tokens} tokens",
            "",
        ]

        # Alertes budget
        if self.total_cost > 15.0:
            summary.append("‚ö†Ô∏è  ALERTE: Budget d√©passement seuil $15 USD !")
        elif self.total_cost > 10.0:
            summary.append("‚ö° INFO: Budget approche seuil estim√© ($10-15 USD)")

        # Taux succ√®s
        if total_tests > 0:
            success_rate = (self.tests_passed / total_tests) * 100
            summary.append(f"üìà Taux succ√®s           : {success_rate:.1f}%")

            if success_rate >= 80:
                summary.append("‚úÖ Objectif atteint (‚â•80% succ√®s)")
            elif success_rate >= 50:
                summary.append("‚ö†Ô∏è  Succ√®s partiel (50-79% succ√®s)")
            else:
                summary.append("‚ùå √âchec (<50% succ√®s)")

        summary.extend(
            [
                "",
                "=" * 70,
                "‚ÑπÔ∏è  Note: Estimations bas√©es sur moyennes markers observ√©es.",
                "   Pour co√ªts r√©els, consulter dashboard OpenAI apr√®s ex√©cution.",
                "=" * 70,
                "",
            ]
        )

        return "\n".join(summary)

    def monitor_pytest_output(self):
        """Parse sortie pytest stdin et affiche monitoring temps r√©el"""
        print("=" * 70)
        print("üîç Monitoring Budget Tests LLM D3.2 - D√©marr√©")
        print("=" * 70)
        print("")

        for line in sys.stdin:
            # Afficher sortie pytest normale
            print(line, end="")

            # Parser r√©sultat test
            test_info = self.parse_test_result(line)

            # Mettre √† jour stats et afficher budget si test d√©tect√©
            if test_info["is_test"]:
                self.update_stats(test_info)
                budget_line = self.format_budget_line(test_info)
                if budget_line:
                    print(budget_line)

        # Afficher synth√®se finale
        print(self.format_summary())


def main():
    """Point d'entr√©e script"""
    monitor = LLMTestBudgetMonitor()

    try:
        monitor.monitor_pytest_output()
    except KeyboardInterrupt:
        print("\n\n‚ö†Ô∏è  Monitoring interrompu par utilisateur (Ctrl+C)")
        print(monitor.format_summary())
    except Exception as e:
        print(f"\n\n‚ùå Erreur monitoring: {e}")
        print(monitor.format_summary())


if __name__ == "__main__":
    main()
