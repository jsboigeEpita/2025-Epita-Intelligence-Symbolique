# ===== AUTO-ACTIVATION ENVIRONNEMENT =====
import scripts.core.auto_env
# =========================================
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
SCRIPT UNIFI√â D'INVESTIGATION SHERLOCK-WATSON
==============================================

Ce script centralise et remplace les multiples scripts de d√©monstration 
Sherlock/Watson en un seul outil param√©trable.

Il int√®gre les logiques de :
- Workflows multiples (Cluedo, Einstein, JTMS)
- Modes d'ex√©cution (normal, robuste)
- D√©sactivation optionnelle de d√©pendances (Java/JPype, Tweety)

Exemples d'utilisation :
-----------------------
# Lancer le workflow Cluedo en mode normal
python scripts/sherlock_watson/run_unified_investigation.py --workflow cluedo

# Lancer le workflow Einstein en mode robuste, sans le pont Tweety
python scripts/sherlock_watson/run_unified_investigation.py --workflow einstein --mode robust --no-tweety

# Lancer le workflow JTMS sans d√©pendance Java
python scripts/sherlock_watson/run_unified_investigation.py --workflow jtms --no-java
"""

import argparse
import asyncio
import os
import sys
import json
import logging
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Any, Optional
from dotenv import load_dotenv

# --- Configuration initiale du chemin et de l'environnement ---
# Assurer que la racine du projet est dans sys.path pour les imports absolus
_SCRIPT_DIR = Path(__file__).resolve().parent
_PROJECT_ROOT = _SCRIPT_DIR.parent.parent
if str(_PROJECT_ROOT) not in sys.path:
    sys.path.insert(0, str(_PROJECT_ROOT))

# Auto-activation de l'environnement et chargement des variables .env
import scripts.core.auto_env

# --- Configuration du logging ---
def setup_logging(session_id: str, workflow: str, level=logging.DEBUG):
    """Configure le logging racine pour la session."""
    log_dir = _PROJECT_ROOT / "logs" / "unified_investigation"
    log_dir.mkdir(parents=True, exist_ok=True)
    log_file = log_dir / f"{session_id}_{workflow}.log"

    # S'assure de ne configurer qu'une fois
    if not logging.getLogger().handlers:
        logging.basicConfig(
            level=level,
            format='%(asctime)s [%(levelname)s] [%(name)s] %(message)s',
            handlers=[
                logging.StreamHandler(sys.stdout),
                logging.FileHandler(log_file, encoding='utf-8')
            ]
        )
    logging.getLogger().setLevel(level)
    # Appliquer le niveau √† tous les handlers existants
    for handler in logging.getLogger().handlers:
        handler.setLevel(level)

    return logging.getLogger("UnifiedInvestigation")

logger = logging.getLogger(__name__) # Logger temporaire jusqu'√† la configuration

# --- V√©rification des d√©pendances optionnelles ---
try:
    import jpype
    import jpype.imports
    JPYPE_AVAILABLE = True
except ImportError:
    JPYPE_AVAILABLE = False

try:
    from argumentation_analysis.agents.core.logic.tweety_bridge import TweetyBridge
    TWEETY_AVAILABLE = True
except ImportError:
    TWEETY_AVAILABLE = False


class UnifiedInvestigationEngine:
    """
    Moteur pour l'orchestration unifi√©e des investigations Sherlock-Watson.
    """

    def __init__(self, args: argparse.Namespace):
        self.args = args
        self.session_id = datetime.now().strftime("%Y%m%d_%H%M%S")
        self.kernel = None
        self.results_dir = _PROJECT_ROOT / "results" / "unified_investigation" / self.session_id
        self.results_dir.mkdir(parents=True, exist_ok=True)
        
        # La configuration du logging est maintenant globale
        setup_logging(self.session_id, self.args.workflow, level=logging.DEBUG)
        global logger
        logger = logging.getLogger("UnifiedInvestigation")
        
        logger.info(f"üöÄ Initialisation du moteur d'investigation unifi√© (Session: {self.session_id})")
        logger.info(f"   - Workflow: {self.args.workflow}")
        logger.info(f"   - Mode: {self.args.mode}")
        logger.info(f"   - Java (JPype): {'Activ√©' if not self.args.no_java else 'D√©sactiv√©'}")
        logger.info(f"   - Tweety: {'Activ√©' if not self.args.no_tweety else 'D√©sactiv√©'}")

    async def initialize_system(self):
        """Initialise le syst√®me, y compris Semantic Kernel et les ponts optionnels."""
        logger.info("üîß Initialisation du syst√®me...")

        # --- Gestion des d√©pendances optionnelles ---
        if self.args.no_java:
            logger.info("üö© Flag --no-java: D√©sactivation de la logique bas√©e sur Java.")
            os.environ['DISABLE_JAVA_LOGIC'] = '1'
        elif not JPYPE_AVAILABLE:
            logger.warning("üü° JPype n'est pas install√©. La logique Java sera d√©sactiv√©e.")
            os.environ['DISABLE_JAVA_LOGIC'] = '1'

        if self.args.no_tweety:
            logger.info("üö© Flag --no-tweety: D√©sactivation du pont Tweety.")
            os.environ['NO_TWEETY_BRIDGE'] = '1'
        elif not TWEETY_AVAILABLE:
            logger.warning("üü° Le pont Tweety n'est pas disponible. Passage en mode fallback.")
            os.environ['NO_TWEETY_BRIDGE'] = '1'

        # --- Initialisation de Semantic Kernel ---
        try:
            from semantic_kernel import Kernel
            from semantic_kernel.connectors.ai.open_ai import OpenAIChatCompletion

            self.kernel = Kernel()
            api_key = os.getenv("OPENAI_API_KEY")
            model_id = os.getenv("OPENAI_CHAT_MODEL_ID", "gpt-4o-mini")

            if not api_key or "simulation" in api_key:
                logger.error("‚ùå Cl√© API OpenAI r√©elle est requise.")
                return False
            
            main_service = OpenAIChatCompletion(
                service_id="chat_completion",
                api_key=api_key,
                ai_model_id=model_id,
            )
            self.kernel.add_service(main_service)
            logger.info(f"‚úÖ Semantic Kernel initialis√© avec le mod√®le {model_id}.")
            return True

        except ImportError:
            logger.error("‚ùå Semantic Kernel n'est pas install√©. Impossible de continuer.")
            return False
        except Exception as e:
            logger.error(f"‚ùå Erreur lors de l'initialisation de Semantic Kernel: {e}")
            return False

    async def run(self):
        """Lance le workflow d'investigation s√©lectionn√©."""
        if not await self.initialize_system():
            return

        workflow_map = {
            'cluedo': self.run_cluedo_workflow,
            'einstein': self.run_einstein_workflow,
            'jtms': self.run_jtms_workflow,
        }

        workflow_func = workflow_map.get(self.args.workflow)
        if not workflow_func:
            logger.error(f"‚ùå Workflow '{self.args.workflow}' non reconnu.")
            return

        logger.info(f"üé¨ Lancement du workflow: {self.args.workflow.upper()}")
        
        try:
            result = await workflow_func()
            result_file_path = await self.save_results(result)
            logger.info(f"‚úÖ Workflow {self.args.workflow.upper()} termin√© avec succ√®s.")
            # Affiche le contenu du JSON final dans les logs
            if result_file_path:
                try:
                    with open(result_file_path, 'r', encoding='utf-8') as f:
                        final_content = json.load(f)
                    logger.info(f"CONTENU FINAL:\n{json.dumps(final_content, indent=2, ensure_ascii=False)}")
                except Exception as json_error:
                    logger.error(f"Erreur lors de la lecture du JSON final: {json_error}")
        except Exception as e:
            logger.error(f"‚ùå Erreur critique durant le workflow {self.args.workflow}: {e}", exc_info=True)
            if self.args.mode == 'robust':
                logger.info("MODE ROBUSTE: Tentative de sauvegarde des donn√©es partielles.")
                await self.save_results({"status": "failed", "error": str(e)})

    async def run_cluedo_workflow(self) -> Dict[str, Any]:
        """Ex√©cute le workflow d'investigation Cluedo."""
        from argumentation_analysis.orchestration.cluedo_extended_orchestrator import run_cluedo_oracle_game
        
        initial_question = "Enqu√™te Cluedo: un meurtre a √©t√© commis. D√©couvrez le coupable, l'arme et le lieu."
        
        logger.info("üéÆ D√©marrage de l'enqu√™te Cluedo...")
        cluedo_result = await run_cluedo_oracle_game(self.kernel, initial_question)
        
        return {
            "workflow": "cluedo",
            "status": "completed",
            "result_summary": cluedo_result.get("solution_analysis", {}),
            "full_results": cluedo_result
        }

    async def run_einstein_workflow(self) -> Dict[str, Any]:
        """Ex√©cute le workflow de r√©solution de l'√©nigme d'Einstein."""
        from argumentation_analysis.orchestration.logique_complexe_orchestrator import LogiqueComplexeOrchestrator
        from argumentation_analysis.agents.core.pm.sherlock_enquete_agent import SherlockEnqueteAgent
        from argumentation_analysis.agents.core.logic.watson_logic_assistant import WatsonLogicAssistant
        
        orchestrateur = LogiqueComplexeOrchestrator(self.kernel)
        sherlock_agent = SherlockEnqueteAgent(kernel=self.kernel)
        watson_agent = WatsonLogicAssistant(kernel=self.kernel, use_tweety_bridge=(not self.args.no_tweety))

        logger.info("üß© D√©marrage de la r√©solution de l'√©nigme d'Einstein...")
        resultats = await orchestrateur.resoudre_enigme_complexe(sherlock_agent, watson_agent)

        return {
            "workflow": "einstein",
            "status": "completed",
            "enigme_resolue": resultats.get('enigme_resolue', False),
            "tours": resultats.get('tours_utilises', 0),
            "full_results": resultats
        }

    async def run_jtms_workflow(self) -> Dict[str, Any]:
        """Ex√©cute une investigation collaborative bas√©e sur JTMS."""
        from argumentation_analysis.agents.jtms_communication_hub import create_sherlock_watson_communication, run_investigation_session

        logger.info("üß† D√©marrage de l'investigation collaborative JTMS...")

        sherlock, watson, hub = await create_sherlock_watson_communication(
            self.kernel, use_tweety=not self.args.no_tweety
        )

        investigation_context = {
            "type": "jtms_murder_case",
            "description": "Meurtre myst√©rieux √† r√©soudre avec raisonnement tra√ßable."
        }
        
        session_results = await run_investigation_session(sherlock, watson, hub, investigation_context)

        return {
            "workflow": "jtms",
            "status": "completed",
            "success": session_results.get("success", False),
            "final_solution": session_results.get("final_solution", {}),
            "full_results": session_results
        }

    async def save_results(self, result_data: Dict[str, Any]) -> Optional[Path]:
        """Sauvegarde les r√©sultats et retourne le chemin du fichier."""
        result_file = self.results_dir / f"result_{self.args.workflow}_{self.session_id}.json"
        logger.info(f"üíæ Sauvegarde des r√©sultats dans {result_file}")
        
        try:
            # Ajout des m√©tadonn√©es de la session
            full_data = {
                "session_metadata": {
                    "session_id": self.session_id,
                    "timestamp": datetime.now().isoformat(),
                    "workflow": self.args.workflow,
                    "mode": self.args.mode,
                    "no_java": self.args.no_java,
                    "no_tweety": self.args.no_tweety,
                },
                "execution_result": result_data
            }
            with open(result_file, 'w', encoding='utf-8') as f:
                json.dump(full_data, f, indent=2, ensure_ascii=False, default=str)
            return result_file
        except Exception as e:
            logger.error(f"‚ùå Impossible de sauvegarder les r√©sultats: {e}")
            return None

def parse_arguments():
    """D√©finit et parse les arguments de la ligne de commande."""
    parser = argparse.ArgumentParser(
        description="Script unifi√© pour les investigations Sherlock-Watson.",
        formatter_class=argparse.RawTextHelpFormatter
    )
    
    parser.add_argument(
        '--workflow',
        type=str,
        required=True,
        choices=['cluedo', 'einstein', 'jtms'],
        help="Le type de workflow d'investigation √† lancer."
    )
    
    parser.add_argument(
        '--mode',
        type=str,
        default='normal',
        choices=['normal', 'robust'],
        help=(
            "Mode d'ex√©cution:\n"
            "  - normal: ex√©cution standard.\n"
            "  - robust: avec gestion d'erreurs avanc√©e et tentatives de re-ex√©cution."
        )
    )

    parser.add_argument(
        '--no-java',
        action='store_true',
        help="D√©sactive l'utilisation de JPype et de la logique bas√©e sur Java."
    )

    parser.add_argument(
        '--no-tweety',
        action='store_true',
        help="D√©sactive l'utilisation du pont Tweety pour la logique formelle."
    )

    return parser.parse_args()

async def main():
    """Point d'entr√©e principal du script."""
    args = parse_arguments()
    engine = UnifiedInvestigationEngine(args)
    await engine.run()


if __name__ == "__main__":
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        logger.info("\n‚èπÔ∏è Ex√©cution interrompue par l'utilisateur.")
    except Exception as general_error:
        logger.critical(f"‚ùå Une erreur non g√©r√©e est survenue: {general_error}", exc_info=True)
        sys.exit(1)