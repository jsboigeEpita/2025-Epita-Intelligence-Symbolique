# =====================================================================================
# V√âRIFICATION DE LA VERSION DE SEMANTIC-KERNEL
# Le projet requiert une version moderne et agentique. Cette importation pr√©coce
# garantit que le programme s'arr√™te imm√©diatement si la version est obsol√®te.
# =====================================================================================
try:
    from argumentation_analysis.utils import version_validator
except ImportError as e:
    import sys
    print(f"ERREUR CRITIQUE: {e}", file=sys.stderr)
    sys.exit(1)
# =====================================================================================
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""Point d'entr√©e unifi√© et intelligent pour l'analyse argumentative.

Objectif:
    Fournir une interface unique (`analyze_text`) pour lancer une analyse
    argumentative, tout en masquant la complexit√© du choix du moteur
    d'ex√©cution sous-jacent. Ce module agit comme un routeur qui s√©lectionne
    automatiquement le pipeline le plus appropri√© (original, hi√©rarchique,
    sp√©cialis√©) en fonction des entr√©es et des capacit√©s disponibles.

Donn√©es d'entr√©e:
    - Un texte brut √† analyser.
    - Des param√®tres de configuration (`mode`, `analysis_type`, etc.) qui
      guident la s√©lection du pipeline.

√âtapes (Logique de routage):
    1.  **D√©tection du Mode**: En mode "auto", d√©termine le meilleur pipeline
        disponible (`_detect_best_pipeline_mode`).
    2.  **Validation**: V√©rifie la validit√© des entr√©es.
    3.  **Ex√©cution du Pipeline S√©lectionn√©**:
        - **Mode "orchestration"**: Aiguille vers un orchestrateur sp√©cialis√©
          (`Cluedo`, `Conversation`, etc.) en fonction du contenu du texte ou
          des param√®tres (`_run_orchestration_pipeline`).
        - **Mode "original"**: Appelle l'ancien pipeline `unified_text_analysis`
          pour la r√©trocompatibilit√© (`_run_original_pipeline`).
        - **Mode "hybrid"**: Ex√©cute les deux pipelines et tente de synth√©tiser
          les r√©sultats (`_run_hybrid_pipeline`).
    4.  **Enrichissement**: Peut ajouter des comparaisons de performance et des
        recommandations aux r√©sultats finaux.
    5.  **Fallback**: En cas d'√©chec du pipeline principal, peut tenter de
        s'ex√©cuter avec le pipeline original.

Artefacts produits:
    - Un dictionnaire de r√©sultats unifi√©, contenant les m√©tadonn√©es de
      l'ex√©cution, les r√©sultats bruts du pipeline choisi, et des informations
      additionnelles (comparaison, recommandations).
"""

import asyncio
import logging
import warnings
from typing import Dict, List, Any, Optional, Union
from datetime import datetime

# Imports du pipeline original
try:
    from argumentation_analysis.pipelines.unified_text_analysis import (
        run_unified_text_analysis_pipeline,
        UnifiedAnalysisConfig,
        create_unified_config_from_legacy
    )
    ORIGINAL_PIPELINE_AVAILABLE = True
except ImportError as e:
    logging.warning(f"Pipeline original non disponible: {e}")
    ORIGINAL_PIPELINE_AVAILABLE = False

# Imports des nouveaux orchestrateurs sp√©cialis√©s
try:
    from argumentation_analysis.orchestrators.cluedo_orchestrator import CluedoOrchestrator
    from argumentation_analysis.orchestrators.conversation_orchestrator import ConversationOrchestrator
    from argumentation_analysis.orchestrators.real_llm_orchestrator import RealLLMOrchestrator
    from argumentation_analysis.orchestrators.logique_complexe_orchestrator import LogiqueComplexeOrchestrator
    from argumentation_analysis.services.llm_service import create_llm_service
    ORCHESTRATION_PIPELINE_AVAILABLE = True
except ImportError as e:
    logging.warning(f"Nouveaux orchestrateurs non disponibles: {e}")
    ORCHESTRATION_PIPELINE_AVAILABLE = False

logger = logging.getLogger("UnifiedPipeline")


class PipelineMode:
    """Modes de pipeline disponibles."""
    
    ORIGINAL = "original"           # Pipeline original seulement
    ORCHESTRATION = "orchestration" # Pipeline d'orchestration seulement
    AUTO = "auto"                   # S√©lection automatique
    HYBRID = "hybrid"               # Ex√©cution hybride avec comparaison


async def analyze_text(
    text: str,
    mode: str = "auto",
    analysis_type: str = "comprehensive",
    orchestration_mode: str = "auto_select",
    use_mocks: bool = False,
    source_info: Optional[str] = None,
    enable_orchestration: bool = True,
    enable_comparison: bool = False,
    **kwargs
) -> Dict[str, Any]:
    """
    Fonction d'entr√©e principale pour l'analyse argumentative unifi√©e.
    
    Cette fonction intelligente s√©lectionne automatiquement le meilleur pipeline
    selon la disponibilit√© des composants et les param√®tres fournis.
    
    Args:
        text: Texte √† analyser
        mode: Mode de pipeline ("original", "orchestration", "auto", "hybrid")
        analysis_type: Type d'analyse ("comprehensive", "rhetorical", "logical", etc.)
        orchestration_mode: Mode d'orchestration ("auto_select", "hierarchical", etc.)
        use_mocks: Utilisation des mocks pour les tests
        source_info: Information sur la source du texte
        enable_orchestration: Active l'orchestration √©tendue si disponible
        enable_comparison: Active la comparaison entre pipelines
        **kwargs: Param√®tres additionnels
    
    Returns:
        Dictionnaire des r√©sultats d'analyse avec m√©tadonn√©es de pipeline
    """
    start_time = datetime.now()
    
    logger.info(f"[UNIFIED] Analyse d√©marr√©e - Mode: {mode}, Type: {analysis_type}")
    
    # D√©tection automatique du meilleur pipeline
    if mode == "auto":
        mode = _detect_best_pipeline_mode(enable_orchestration)
        logger.info(f"[UNIFIED] Mode d√©tect√© automatiquement: {mode}")
    
    # Validation des param√®tres
    if not text or not text.strip():
        raise ValueError("Texte vide ou invalide fourni pour l'analyse")
    
    # Structure de r√©sultats unifi√©e
    results = {
        "metadata": {
            "analysis_timestamp": start_time.isoformat(),
            "pipeline_version": "unified_2.0_with_orchestration",
            "pipeline_mode": mode,
            "analysis_type": analysis_type,
            "orchestration_mode": orchestration_mode,
            "text_length": len(text),
            "source_info": source_info,
            "orchestration_available": ORCHESTRATION_PIPELINE_AVAILABLE,
            "original_available": ORIGINAL_PIPELINE_AVAILABLE
        },
        "pipeline_results": {},
        "comparison": {},
        "recommendations": [],
        "execution_time": 0,
        "status": "in_progress"
    }
    
    try:
        # Ex√©cution selon le mode s√©lectionn√©
        if mode == "orchestration":
            results = await _run_orchestration_pipeline(text, analysis_type, orchestration_mode, use_mocks, source_info, results, **kwargs)
        
        elif mode == "original":
            results = await _run_original_pipeline(text, analysis_type, use_mocks, source_info, results, **kwargs)
        
        elif mode == "hybrid":
            results = await _run_hybrid_pipeline(text, analysis_type, orchestration_mode, use_mocks, source_info, results, **kwargs)
        
        else:
            # Fallback vers le mode disponible
            if ORCHESTRATION_PIPELINE_AVAILABLE:
                results = await _run_orchestration_pipeline(text, analysis_type, orchestration_mode, use_mocks, source_info, results, **kwargs)
            elif ORIGINAL_PIPELINE_AVAILABLE:
                results = await _run_original_pipeline(text, analysis_type, use_mocks, source_info, results, **kwargs)
            else:
                raise RuntimeError("Aucun pipeline disponible")
        
        # Comparaison optionnelle des pipelines
        if enable_comparison and ORCHESTRATION_PIPELINE_AVAILABLE:
            comparison_results = await _compare_pipelines(text, analysis_type, use_mocks)
            results["comparison"] = comparison_results
        
        # G√©n√©ration des recommandations
        results["recommendations"] = _generate_unified_recommendations(results)
        
        results["status"] = "success"
        
    except Exception as e:
        logger.error(f"[UNIFIED] Erreur lors de l'analyse: {e}")
        results["status"] = "error"
        results["error"] = str(e)
        
        # Tentative de fallback en cas d'erreur
        if mode != "original" and ORIGINAL_PIPELINE_AVAILABLE:
            logger.info("[UNIFIED] Tentative de fallback vers le pipeline original...")
            try:
                fallback_results = await _run_original_pipeline(text, analysis_type, use_mocks, source_info, {}, **kwargs)
                results["pipeline_results"]["fallback"] = fallback_results["pipeline_results"]["original"]
                results["status"] = "partial_success"
                results["fallback_used"] = True
            except Exception as fallback_error:
                logger.error(f"[UNIFIED] √âchec du fallback: {fallback_error}")
    
    # Finalisation
    results["execution_time"] = (datetime.now() - start_time).total_seconds()
    
    logger.info(f"[UNIFIED] Analyse termin√©e - Statut: {results['status']}, Temps: {results['execution_time']:.2f}s")
    
    return results


def _detect_best_pipeline_mode(enable_orchestration: bool) -> str:
    """D√©tecte automatiquement le meilleur mode de pipeline."""
    if enable_orchestration and ORCHESTRATION_PIPELINE_AVAILABLE:
        return "orchestration"
    elif ORIGINAL_PIPELINE_AVAILABLE:
        return "original"
    else:
        raise RuntimeError("Aucun pipeline disponible")


async def _run_orchestration_pipeline(
    text: str,
    analysis_type: str,
    orchestration_mode: str,
    use_mocks: bool,
    source_info: Optional[str],
    results: Dict[str, Any],
    **kwargs
) -> Dict[str, Any]:
    """Ex√©cute l'orchestration en s√©lectionnant un orchestrateur sp√©cialis√©."""
    logger.info("[UNIFIED] Ex√©cution via un orchestrateur sp√©cialis√©...")

    if not ORCHESTRATION_PIPELINE_AVAILABLE:
        raise RuntimeError("Orchestrateurs sp√©cialis√©s non disponibles.")

    llm_service = create_llm_service(use_mocks=use_mocks)
    config = kwargs

    # Logique de s√©lection de l'orchestrateur
    orchestrator = None
    if orchestration_mode == 'cluedo' or "enqu√™te" in text.lower() or "t√©moin" in text.lower():
        orchestrator = CluedoOrchestrator(llm_service, config)
        analysis_method = orchestrator.orchestrate_investigation_analysis
    elif orchestration_mode == 'conversation' or ":" in text:
        orchestrator = ConversationOrchestrator(llm_service, config)
        analysis_method = orchestrator.orchestrate_dialogue_analysis
    elif orchestration_mode == 'logique' or "tous les hommes" in text.lower():
        orchestrator = LogiqueComplexeOrchestrator(llm_service, config)
        analysis_method = orchestrator.orchestrate_complex_logical_analysis
    else: # Fallback sur l'orchestrateur LLM g√©n√©rique
        orchestrator = RealLLMOrchestrator(llm_service, config)
        analysis_method = orchestrator.orchestrate_multi_llm_analysis

    logger.info(f"Orchestrateur s√©lectionn√©: {orchestrator.__class__.__name__}")

    # Ex√©cution
    orchestration_results = await analysis_method(text)

    # Int√©gration des r√©sultats
    results["pipeline_results"]["orchestration"] = orchestration_results
    results["specialized_orchestration"] = {
        "orchestrator_used": orchestrator.__class__.__name__,
        **orchestration_results
    }
    
    return results


async def _run_original_pipeline(
    text: str, 
    analysis_type: str, 
    use_mocks: bool, 
    source_info: Optional[str],
    results: Dict[str, Any],
    **kwargs
) -> Dict[str, Any]:
    """Ex√©cute le pipeline original."""
    logger.info("[UNIFIED] Ex√©cution du pipeline original...")
    
    if not ORIGINAL_PIPELINE_AVAILABLE:
        raise RuntimeError("Pipeline original non disponible")
    
    # Configuration originale
    config = create_unified_config_from_legacy(
        mode=_map_analysis_type_to_legacy_mode(analysis_type),
        use_mocks=use_mocks,
        **kwargs
    )
    
    # Ex√©cution
    original_results = await run_unified_text_analysis_pipeline(text, config, source_info)
    
    # Int√©gration des r√©sultats
    results["pipeline_results"]["original"] = original_results
    
    # Copier les champs principaux pour compatibilit√©
    for key in ["informal_analysis", "formal_analysis", "unified_analysis", "orchestration_analysis"]:
        if key in original_results:
            results[key] = original_results[key]
    
    return results


async def _run_hybrid_pipeline(
    text: str, 
    analysis_type: str, 
    orchestration_mode: str, 
    use_mocks: bool, 
    source_info: Optional[str],
    results: Dict[str, Any],
    **kwargs
) -> Dict[str, Any]:
    """Ex√©cute les deux pipelines et compare les r√©sultats."""
    logger.info("[UNIFIED] Ex√©cution du pipeline hybride...")
    
    # Ex√©cuter les deux pipelines si disponibles
    if ORCHESTRATION_PIPELINE_AVAILABLE:
        try:
            results = await _run_orchestration_pipeline(text, analysis_type, orchestration_mode, use_mocks, source_info, results, **kwargs)
        except Exception as e:
            logger.warning(f"[UNIFIED] √âchec pipeline orchestration: {e}")
    
    if ORIGINAL_PIPELINE_AVAILABLE:
        try:
            results = await _run_original_pipeline(text, analysis_type, use_mocks, source_info, results, **kwargs)
        except Exception as e:
            logger.warning(f"[UNIFIED] √âchec pipeline original: {e}")
    
    # Synth√®se hybride
    results = _synthesize_hybrid_results(results)
    
    return results


def _synthesize_hybrid_results(results: Dict[str, Any]) -> Dict[str, Any]:
    """Synth√©tise les r√©sultats des deux pipelines."""
    orchestration_results = results["pipeline_results"].get("orchestration", {})
    original_results = results["pipeline_results"].get("original", {})
    
    # Prendre les meilleurs r√©sultats de chaque pipeline
    if orchestration_results and original_results:
        # Combiner les analyses informelles
        orch_informal = orchestration_results.get("informal_analysis", {})
        orig_informal = original_results.get("informal_analysis", {})
        
        if orch_informal and orig_informal:
            orch_fallacies = orch_informal.get("fallacies", [])
            orig_fallacies = orig_informal.get("fallacies", [])
            
            # Fusionner les sophismes d√©tect√©s (sans doublons)
            all_fallacies = list(orch_fallacies)
            for fallacy in orig_fallacies:
                fallacy_type = fallacy.get("type", "")
                if not any(f.get("type") == fallacy_type for f in all_fallacies):
                    all_fallacies.append(fallacy)
            
            results["informal_analysis"] = {
                "fallacies": all_fallacies,
                "summary": {
                    "total_fallacies": len(all_fallacies),
                    "orchestration_count": len(orch_fallacies),
                    "original_count": len(orig_fallacies),
                    "source": "hybrid_synthesis"
                }
            }
    
    return results


async def _compare_pipelines(text: str, analysis_type: str, use_mocks: bool) -> Dict[str, Any]:
    """Compare les performances des diff√©rents pipelines."""
    logger.info("[UNIFIED] Comparaison des pipelines...")
    
    comparison = {
        "comparison_timestamp": datetime.now().isoformat(),
        "approaches_tested": [],
        "performance_metrics": {},
        "recommendations": []
    }
    
    try:
        pass # La comparaison est d√©sactiv√©e car compare_orchestration_approaches est obsol√®te.
    except Exception as e:
        logger.warning(f"[UNIFIED] Erreur comparaison pipelines: {e}")
        comparison["error"] = str(e)
    
    return comparison


def _map_analysis_type_to_legacy_mode(analysis_type: str) -> str:
    """Mappe les nouveaux types d'analyse vers les modes legacy."""
    mapping = {
        "comprehensive": "unified",
        "rhetorical": "informal",
        "logical": "formal",
        "investigative": "unified",
        "fallacy_focused": "informal",
        "argument_structure": "formal",
        "debate_analysis": "unified",
        "custom": "unified"
    }
    return mapping.get(analysis_type, "unified")


def _generate_unified_recommendations(results: Dict[str, Any]) -> List[str]:
    """G√©n√®re des recommandations bas√©es sur les r√©sultats unifi√©s."""
    recommendations = []
    
    # Recommandations bas√©es sur le mode utilis√©
    mode = results["metadata"]["pipeline_mode"]
    
    if mode == "orchestration":
        if "strategic_analysis" in results:
            recommendations.append("Architecture hi√©rarchique utilis√©e - Analyse strat√©gique disponible")
        if "specialized_orchestration" in results:
            orchestrator = results["specialized_orchestration"].get("orchestrator_used", "")
            if orchestrator:
                recommendations.append(f"Orchestrateur sp√©cialis√© '{orchestrator}' utilis√© avec succ√®s")
    
    elif mode == "hybrid":
        recommendations.append("Analyse hybride compl√©t√©e - Comparaison des approches disponible")
    
    # Recommandations bas√©es sur les performances
    exec_time = results.get("execution_time", 0)
    if exec_time > 10:
        recommendations.append("Temps d'ex√©cution √©lev√© - Consid√©rer l'optimisation ou les mocks")
    elif exec_time < 1:
        recommendations.append("Analyse rapide compl√©t√©e - Performance optimale")
    
    # Recommandations bas√©es sur les erreurs
    if results.get("status") == "error":
        recommendations.append("Erreur d√©tect√©e - V√©rifier la configuration et les d√©pendances")
    elif results.get("fallback_used"):
        recommendations.append("Fallback utilis√© - Consid√©rer la r√©solution des probl√®mes du pipeline principal")
    
    # Recommandation par d√©faut
    if not recommendations:
        recommendations.append("Analyse unifi√©e compl√©t√©e avec succ√®s")
    
    return recommendations


# ==========================================
# FONCTIONS DE COMPATIBILIT√â ET MIGRATION
# ==========================================

async def run_analysis(text: str, **kwargs) -> Dict[str, Any]:
    """
    Fonction de compatibilit√© simple pour l'analyse.
    
    Cette fonction maintient la compatibilit√© avec l'API la plus simple
    tout en utilisant les nouvelles capacit√©s d'orchestration.
    """
    return await analyze_text(text, **kwargs)


async def run_enhanced_analysis(
    text: str,
    enable_hierarchical: bool = True,
    enable_specialized: bool = True,
    orchestration_mode: str = "auto_select",
    **kwargs
) -> Dict[str, Any]:
    """
    Fonction pour l'analyse avanc√©e avec contr√¥le fin des capacit√©s d'orchestration.
    
    Args:
        text: Texte √† analyser
        enable_hierarchical: Active l'architecture hi√©rarchique
        enable_specialized: Active les orchestrateurs sp√©cialis√©s
        orchestration_mode: Mode d'orchestration sp√©cifique
        **kwargs: Param√®tres additionnels
    """
    if enable_hierarchical or enable_specialized:
        return await analyze_text(
            text, 
            mode="orchestration",
            orchestration_mode=orchestration_mode,
            **kwargs
        )
    else:
        return await analyze_text(text, mode="original", **kwargs)


def get_available_features() -> Dict[str, bool]:
    """
    Retourne les fonctionnalit√©s disponibles dans l'installation actuelle.
    
    Returns:
        Dictionnaire des fonctionnalit√©s disponibles
    """
    return {
        "original_pipeline": ORIGINAL_PIPELINE_AVAILABLE,
        "orchestration_pipeline": ORCHESTRATION_PIPELINE_AVAILABLE,
        "hierarchical_architecture": ORCHESTRATION_PIPELINE_AVAILABLE,
        "specialized_orchestrators": ORCHESTRATION_PIPELINE_AVAILABLE,
        "service_manager": ORCHESTRATION_PIPELINE_AVAILABLE,
        "communication_middleware": ORCHESTRATION_PIPELINE_AVAILABLE,
        "orchestration_comparison": ORCHESTRATION_PIPELINE_AVAILABLE,
        "hybrid_mode": ORIGINAL_PIPELINE_AVAILABLE and ORCHESTRATION_PIPELINE_AVAILABLE
    }


def print_feature_status():
    """Affiche le statut des fonctionnalit√©s disponibles."""
    features = get_available_features()
    
    print("=== STATUT DES FONCTIONNALIT√âS DU PIPELINE UNIFI√â ===")
    print()
    
    for feature, available in features.items():
        status = "‚úÖ Disponible" if available else "‚ùå Non disponible"
        print(f"  {feature:30} {status}")
    
    print()
    
    if features["orchestration_pipeline"]:
        print("üöÄ Pipeline d'orchestration √©tendu DISPONIBLE")
        print("   ‚Üí Architecture hi√©rarchique compl√®te")
        print("   ‚Üí Orchestrateurs sp√©cialis√©s")
        print("   ‚Üí Service manager centralis√©")
    else:
        print("‚ö†Ô∏è Pipeline d'orchestration √©tendu NON DISPONIBLE")
        print("   ‚Üí Utilisation du pipeline original uniquement")
    
    if features["hybrid_mode"]:
        print("üîÑ Mode hybride DISPONIBLE")
        print("   ‚Üí Comparaison automatique des approches")
    
    print()


# Message de migration pour les utilisateurs
_MIGRATION_MESSAGE_SHOWN = False

def _show_migration_message():
    """Affiche un message de migration vers les nouvelles fonctionnalit√©s."""
    global _MIGRATION_MESSAGE_SHOWN
    
    if not _MIGRATION_MESSAGE_SHOWN and ORCHESTRATION_PIPELINE_AVAILABLE:
        warnings.warn(
            "Nouvelles fonctionnalit√©s d'orchestration disponibles ! "
            "Utilisez mode='orchestration' ou enable_orchestration=True pour "
            "acc√©der √† l'architecture hi√©rarchique et aux orchestrateurs sp√©cialis√©s. "
            "Consultez la documentation dans docs/unified_orchestration_architecture.md",
            UserWarning,
            stacklevel=3
        )
        _MIGRATION_MESSAGE_SHOWN = True


# ==========================================
# POINT D'ENTR√âE PRINCIPAL
# ==========================================

if __name__ == "__main__":
    # Script de d√©monstration rapide
    import argparse
    
    parser = argparse.ArgumentParser(description="Pipeline Unifi√© d'Analyse Argumentative")
    parser.add_argument("text", help="Texte √† analyser")
    parser.add_argument("--mode", choices=["auto", "original", "orchestration", "hybrid"], 
                       default="auto", help="Mode de pipeline")
    parser.add_argument("--type", default="comprehensive", help="Type d'analyse")
    parser.add_argument("--status", action="store_true", help="Afficher le statut des fonctionnalit√©s")
    
    args = parser.parse_args()
    
    if args.status:
        print_feature_status()
    else:
        async def main():
            results = await analyze_text(args.text, mode=args.mode, analysis_type=args.type, use_mocks=False)
            print(f"Statut: {results['status']}")
            print(f"Temps d'ex√©cution: {results['execution_time']:.2f}s")
            print(f"Mode utilis√©: {results['metadata']['pipeline_mode']}")
            
            if results.get("recommendations"):
                print("Recommandations:")
                for rec in results["recommendations"]:
                    print(f"  ‚Ä¢ {rec}")
        
        asyncio.run(main())