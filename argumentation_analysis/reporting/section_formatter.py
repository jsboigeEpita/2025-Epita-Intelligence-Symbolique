#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
Ce module contient la logique de formatage des sections pour les rapports d'analyse argumentative.
Il est responsable de la mise en forme des donn√©es collect√©es en texte, tableaux, etc.
pour les diff√©rentes sections d'un rapport.
"""

import json
import logging
from datetime import datetime
from typing import (
    Dict,
    List,
    Any,
    Optional,
)  # Union et Callable ne sont plus utilis√©s ici directement

# ReportMetadata sera import√© depuis report_generation ou un fichier de mod√®les commun si d√©plac√©.
# Pour l'instant, on suppose qu'il sera accessible.
# from ..core.report_generation import ReportMetadata # Placeholder, ajuster selon la structure finale
# Ou si ReportMetadata est d√©plac√© vers models.py:
# from .models import ReportMetadata

# Si ReportMetadata reste dans report_generation.py, il faudra un import relatif valide.
# √âtant donn√© que section_formatter.py est dans reporting/ et report_generation.py dans core/,
# l'import pourrait √™tre from ..core.report_generation import ReportMetadata
# Cependant, pour √©viter les d√©pendances circulaires ou complexes, il est souvent pr√©f√©rable
# que les mod√®les de donn√©es comme ReportMetadata soient dans un module plus fondamental,
# par exemple, argumentation_analysis/reporting/models.py ou argumentation_analysis/core/models.py

# Pour l'instant, je vais d√©finir une structure minimale pour ReportMetadata
# pour que le code soit syntaxiquement correct, en attendant de clarifier son emplacement.
from dataclasses import (
    dataclass,
)  # Cet import est toujours n√©cessaire pour UnifiedReportTemplate si elle utilise @dataclass, mais ReportMetadata vient de .models
from .models import ReportMetadata

logger = logging.getLogger(__name__)

# La d√©finition temporaire de ReportMetadata est supprim√©e.


class UnifiedReportTemplate:
    """Template de rapport unifi√© et extensible."""

    def __init__(self, config: Dict[str, Any]):
        self.name = config.get("name", "default")
        self.format_type = config.get("format", "markdown")
        self.sections = config.get("sections", [])
        self.metadata = config.get("metadata", {})
        self.custom_renderers = config.get("custom_renderers", {})

    def render(self, data: Dict[str, Any], metadata: ReportMetadata) -> str:
        """Rend le template avec donn√©es et m√©tadonn√©es."""
        enriched_data = {
            "report_metadata": {
                "generated_at": metadata.generated_at.isoformat(),
                "generator": metadata.generator,
                "version": metadata.version,
                "source_component": metadata.source_component,
                "analysis_type": metadata.analysis_type,
                "template": metadata.template_name,
            },
            **data,
        }

        if self.format_type == "markdown":
            return self._render_markdown(enriched_data)
        elif self.format_type == "console":
            return self._render_console(enriched_data)
        elif self.format_type == "json":
            return self._render_json(enriched_data)
        elif self.format_type == "html":
            return self._render_html(enriched_data)
        else:
            raise ValueError(f"Format non support√©: {self.format_type}")

    def _render_markdown(self, data: Dict[str, Any]) -> str:
        """G√©n√®re un rapport Markdown unifi√©."""
        lines = []
        metadata = data.get("report_metadata", {})

        # En-t√™te principal avec composant source
        title = data.get(
            "title",
            f"RAPPORT D'ANALYSE - {metadata.get('source_component', 'SYST√àME').upper()}",
        )
        lines.append(f"# {title}")
        lines.append("")

        # Informations sur l'origine du rapport
        lines.append("## üèóÔ∏è M√©tadonn√©es du rapport")
        lines.append(
            f"- **Composant source**: {metadata.get('source_component', 'N/A')}"
        )
        lines.append(f"- **Type d'analyse**: {metadata.get('analysis_type', 'N/A')}")
        lines.append(f"- **Date de g√©n√©ration**: {metadata.get('generated_at', 'N/A')}")
        lines.append(f"- **Version du g√©n√©rateur**: {metadata.get('version', 'N/A')}")
        lines.append("")

        # M√©tadonn√©es d'analyse (si disponibles)
        if "metadata" in data:
            lines.append("## üìä M√©tadonn√©es de l'analyse")
            analysis_metadata = data["metadata"]
            lines.append(
                f"- **Source analys√©e**: {analysis_metadata.get('source_description', 'N/A')}"
            )
            lines.append(
                f"- **Type de source**: {analysis_metadata.get('source_type', 'N/A')}"
            )
            lines.append(
                f"- **Longueur du texte**: {analysis_metadata.get('text_length', 'N/A')} caract√®res"
            )
            lines.append(
                f"- **Temps de traitement**: {analysis_metadata.get('processing_time_ms', 'N/A')}ms"
            )
            lines.append("")

        # R√©sum√© ex√©cutif
        if "summary" in data:
            lines.append("## üìã R√©sum√© ex√©cutif")
            summary = data["summary"]
            lines.append(
                f"- **Sophistication rh√©torique**: {summary.get('rhetorical_sophistication', 'N/A')}"
            )
            lines.append(
                f"- **Niveau de manipulation**: {summary.get('manipulation_level', 'N/A')}"
            )
            lines.append(
                f"- **Validit√© logique**: {summary.get('logical_validity', 'N/A')}"
            )
            lines.append(
                f"- **Confiance globale**: {summary.get('confidence_score', 'N/A')}"
            )

            # R√©sum√© sp√©cifique √† l'orchestration
            if "orchestration_summary" in summary:
                orch_summary = summary["orchestration_summary"]
                lines.append(
                    f"- **Agents mobilis√©s**: {orch_summary.get('agents_count', 'N/A')}"
                )
                lines.append(
                    f"- **Temps d'orchestration**: {orch_summary.get('orchestration_time_ms', 'N/A')}ms"
                )
                lines.append(
                    f"- **Statut d'ex√©cution**: {orch_summary.get('execution_status', 'N/A')}"
                )
            lines.append("")

        # R√©sultats d'orchestration (pour les orchestrateurs)
        if "orchestration_results" in data:
            lines.append("## üéº R√©sultats d'orchestration")
            orch_data = data["orchestration_results"]

            if "execution_plan" in orch_data:
                plan = orch_data["execution_plan"]
                lines.append("### Plan d'ex√©cution")
                lines.append(
                    f"- **Strat√©gie s√©lectionn√©e**: {plan.get('strategy', 'N/A')}"
                )
                lines.append(f"- **Nombre d'√©tapes**: {len(plan.get('steps', []))}")

                steps = plan.get("steps", [])
                if steps:
                    lines.append("\n#### √âtapes d'ex√©cution")
                    for i, step in enumerate(steps, 1):
                        lines.append(
                            f"{i}. **{step.get('agent', 'Agent inconnu')}**: {step.get('description', 'N/A')}"
                        )
                lines.append("")

            if "agent_results" in orch_data:
                lines.append("### R√©sultats par agent")
                for agent_name, result in orch_data["agent_results"].items():
                    lines.append(f"#### {agent_name}")
                    lines.append(f"- **Statut**: {result.get('status', 'N/A')}")
                    lines.append(
                        f"- **Temps d'ex√©cution**: {result.get('execution_time_ms', 'N/A')}ms"
                    )
                    if "metrics" in result:
                        metrics = result["metrics"]
                        lines.append(
                            f"- **√âl√©ments analys√©s**: {metrics.get('processed_items', 'N/A')}"
                        )
                        lines.append(
                            f"- **Score de confiance**: {metrics.get('confidence_score', 'N/A')}"
                        )
                    lines.append("")

        # Trace d'orchestration LLM avec m√©canisme SK Retry (NOUVEAU)
        if "orchestration_analysis" in data:
            lines.append("## üîÑ Trace d'orchestration LLM avec m√©canisme SK Retry")
            orchestration = data["orchestration_analysis"]
            lines.append(f"- **Statut**: {orchestration.get('status', 'N/A')}")
            lines.append(f"- **Type**: {orchestration.get('type', 'N/A')}")

            if "processing_time_ms" in orchestration:
                lines.append(
                    f"- **Temps de traitement**: {orchestration.get('processing_time_ms', 0):.1f}ms"
                )

            # Trace de conversation avec retry SK
            if "conversation_log" in orchestration:
                conversation_log = orchestration["conversation_log"]
                lines.append("")
                lines.append("### üí¨ Journal de conversation avec traces SK Retry")

                if isinstance(conversation_log, list):
                    lines.append(f"- **Messages √©chang√©s**: {len(conversation_log)}")

                    # Analyser les patterns de retry dans la conversation
                    retry_patterns = []
                    agent_failures = {}
                    sk_retry_traces = []

                    for i, message in enumerate(conversation_log):
                        if isinstance(message, dict):
                            content = message.get("content", "")
                            role = message.get("role", "")

                            # D√©tecter les tentatives de retry SK sp√©cifiques
                            if (
                                "retry" in content.lower()
                                or "attempt" in content.lower()
                            ):
                                retry_patterns.append(f"Message {i+1}: {role}")

                            # D√©tecter les traces SK Retry sp√©cifiques
                            if "ModalLogicAgent" in content and (
                                "attempt" in content.lower()
                                or "retry" in content.lower()
                            ):
                                sk_retry_traces.append(
                                    f"Message {i+1}: Trace SK Retry ModalLogicAgent"
                                )

                            # D√©tecter les √©checs d'agents
                            if (
                                "failed" in content.lower()
                                or "error" in content.lower()
                            ):
                                agent_name = message.get("agent", "Unknown")
                                agent_failures[agent_name] = (
                                    agent_failures.get(agent_name, 0) + 1
                                )

                    if sk_retry_traces:
                        lines.append(
                            f"- **‚ö° Traces SK Retry d√©tect√©es**: {len(sk_retry_traces)}"
                        )
                        for trace in sk_retry_traces[:5]:  # Limite √† 5 pour lisibilit√©
                            lines.append(f"  - {trace}")

                    if retry_patterns:
                        lines.append(
                            f"- **Patterns de retry g√©n√©raux**: {len(retry_patterns)}"
                        )
                        for pattern in retry_patterns[:5]:  # Limite √† 5 pour lisibilit√©
                            lines.append(f"  - {pattern}")

                    if agent_failures:
                        lines.append("- **√âchecs par agent (triggers SK Retry)**:")
                        for agent, count in agent_failures.items():
                            lines.append(f"  - {agent}: {count} √©chec(s)")

                elif isinstance(conversation_log, dict):
                    lines.append("- **Format**: Dictionnaire structur√©")
                    if "messages" in conversation_log:
                        messages = conversation_log["messages"]
                        lines.append(f"- **Messages**: {len(messages)}")

                        # Recherche am√©lior√©e des traces SK Retry dans les messages
                        sk_retry_count = 0
                        modal_agent_attempts = []
                        failed_attempts = []

                        for msg in messages:
                            if isinstance(msg, dict):
                                # Recherche dans le champ 'message' du RealConversationLogger
                                content = str(msg.get("message", ""))
                                agent = str(msg.get("agent", ""))

                                # D√©tecter les tentatives ModalLogicAgent sp√©cifiques
                                if agent == "ModalLogicAgent" and (
                                    "tentative de conversion" in content.lower()
                                    or "conversion attempt" in content.lower()
                                ):
                                    sk_retry_count += 1
                                    # Extraire le num√©ro de tentative si possible
                                    attempt_num = (
                                        content.split("/")[-2].split(" ")[-1]
                                        if "/" in content
                                        else str(sk_retry_count)
                                    )
                                    modal_agent_attempts.append(
                                        f"Tentative {attempt_num}: {content[:120]}..."
                                    )

                                # D√©tecter les erreurs Tweety sp√©cifiques plus pr√©cis√©ment
                                if (
                                    "predicate" in content.lower()
                                    and "has not been declared" in content.lower()
                                ):
                                    # Extraire le nom du pr√©dicat en erreur
                                    error_parts = content.split("'")
                                    predicate_name = (
                                        error_parts[1]
                                        if len(error_parts) > 1
                                        else "inconnu"
                                    )
                                    failed_attempts.append(
                                        f"Pr√©dicat non d√©clar√©: '{predicate_name}'"
                                    )
                                elif agent == "ModalLogicAgent" and (
                                    "erreur" in content.lower()
                                    or "√©chec" in content.lower()
                                ):
                                    failed_attempts.append(f"√âchec: {content[:100]}...")

                        if sk_retry_count > 0:
                            lines.append(
                                f"- **üîÑ M√©canisme SK Retry activ√©**: {sk_retry_count} tentatives d√©tect√©es"
                            )
                            lines.append("- **Traces de tentatives ModalLogicAgent**:")
                            for attempt in modal_agent_attempts[:3]:  # Limite √† 3
                                lines.append(f"  - {attempt}")

                        if failed_attempts:
                            lines.append(
                                "- **Erreurs de conversion Tweety (d√©clencheurs SK Retry)**:"
                            )
                            for failure in failed_attempts[:2]:  # Limite √† 2
                                lines.append(f"  - {failure}")

                    if "tool_calls" in conversation_log:
                        tool_calls = conversation_log["tool_calls"]
                        lines.append(f"- **Appels d'outils**: {len(tool_calls)}")

                        # Analyser les √©checs d'outils SK sp√©cifiques
                        modal_failed_tools = []
                        total_failed = 0

                        for call in tool_calls:
                            if isinstance(call, dict):
                                agent = call.get("agent", "")
                                tool = call.get("tool", "")
                                success = call.get("success", True)

                                if not success:
                                    total_failed += 1

                                # D√©tecter sp√©cifiquement les √©checs ModalLogicAgent
                                if agent == "ModalLogicAgent" and not success:
                                    modal_failed_tools.append(
                                        {
                                            "tool": tool,
                                            "timestamp": call.get("timestamp", 0),
                                            "result": str(call.get("result", ""))[:200],
                                        }
                                    )

                        if total_failed > 0:
                            lines.append(f"- **Total outils √©chou√©s**: {total_failed}")

                        if modal_failed_tools:
                            lines.append(
                                f"- **üéØ √âchecs ModalLogicAgent (SK Retry confirm√©)**: {len(modal_failed_tools)}"
                            )
                            for i, tool_info in enumerate(
                                modal_failed_tools[:2], 1
                            ):  # Premiers 2 √©checs
                                lines.append(
                                    f"  - √âchec {i}: {tool_info['tool']} √† {tool_info['timestamp']:.1f}ms"
                                )
                                if tool_info["result"]:
                                    result_text = str(tool_info["result"])

                                    # Correction d√©faut #2: Extraction am√©lior√©e des 3 tentatives SK Retry
                                    retry_attempts = self._extract_sk_retry_attempts(
                                        result_text
                                    )
                                    if retry_attempts:
                                        lines.append(
                                            f"    üîÑ Tentatives SK Retry d√©tect√©es: {len(retry_attempts)}"
                                        )
                                        for (
                                            attempt_num,
                                            attempt_details,
                                        ) in retry_attempts.items():
                                            lines.append(
                                                f"      - Tentative {attempt_num}: {attempt_details['predicate']} - {attempt_details['error']}"
                                            )
                                    else:
                                        # M√©thode de fallback pour l'ancienne d√©tection
                                        if "tentative" in result_text.lower():
                                            tentatives = []
                                            if "1/3" in result_text:
                                                tentatives.append("1/3")
                                            if "2/3" in result_text:
                                                tentatives.append("2/3")
                                            if "3/3" in result_text:
                                                tentatives.append("3/3")
                                            if tentatives:
                                                lines.append(
                                                    f"    üîÑ Tentatives SK d√©tect√©es: {', '.join(tentatives)}"
                                                )

                                    # Extraire les erreurs Tweety sp√©cifiques depuis les r√©sultats
                                    tweety_errors = self._extract_tweety_errors(
                                        result_text
                                    )
                                    if tweety_errors:
                                        lines.append(
                                            f"    ‚ö†Ô∏è Erreurs Tweety identifi√©es: {len(tweety_errors)}"
                                        )
                                        for error in tweety_errors[:3]:  # Limite √† 3
                                            lines.append(f"      - {error}")

                                    # Afficher l'erreur tronqu√©e pour le contexte
                                    lines.append(f"    Erreur: {result_text[:200]}...")

                lines.append("")

            # Synth√®se finale
            if "final_synthesis" in orchestration:
                synthesis = orchestration["final_synthesis"]
                lines.append("### üìù Synth√®se finale")
                if synthesis:
                    lines.append(f"- **Longueur**: {len(synthesis)} caract√®res")
                    lines.append(f"- **Aper√ßu**: {synthesis[:200]}...")
                else:
                    lines.append("- **Statut**: Aucune synth√®se g√©n√©r√©e")
                lines.append("")

            lines.append("")

        # Analyse informelle (sophismes)
        if "informal_analysis" in data:
            lines.append("## üé≠ Analyse des sophismes")
            informal = data["informal_analysis"]

            fallacies = informal.get("fallacies", [])
            lines.append(f"**Nombre total de sophismes d√©tect√©s**: {len(fallacies)}")
            lines.append("")

            if fallacies:
                for i, fallacy in enumerate(fallacies, 1):
                    lines.append(
                        f"### Sophisme {i}: {fallacy.get('type', 'Type inconnu')}"
                    )
                    lines.append(
                        f"- **Fragment**: \"{fallacy.get('text_fragment', 'N/A')}\""
                    )
                    lines.append(
                        f"- **Explication**: {fallacy.get('explanation', 'N/A')}"
                    )
                    lines.append(f"- **S√©v√©rit√©**: {fallacy.get('severity', 'N/A')}")
                    # Correction d√©faut #1: Confiance √† 0.00%
                    confidence_value = fallacy.get("confidence", 0)
                    if (
                        isinstance(confidence_value, (int, float))
                        and confidence_value > 0
                    ):
                        lines.append(f"- **Confiance**: {confidence_value:.1%}")
                    else:
                        # V√©rifier d'autres champs possibles pour la confiance
                        alt_confidence = (
                            fallacy.get("score", 0)
                            or fallacy.get("confidence_score", 0)
                            or fallacy.get("detection_confidence", 0)
                        )
                        if alt_confidence > 0:
                            lines.append(f"- **Confiance**: {alt_confidence:.1%}")
                        else:
                            lines.append(
                                f"- **Confiance**: Non calcul√©e (syst√®me en debug)"
                            )
                    lines.append("")

        # Analyse formelle (logique) - Correction d√©faut #3
        if "formal_analysis" in data:
            lines.append("## üßÆ Analyse logique formelle")
            formal = data["formal_analysis"]

            logic_type = formal.get("logic_type", "")
            status = formal.get("status", "")

            # Si l'analyse est vide ou en √©chec, fournir un diagnostic au lieu de "N/A"
            if (
                not logic_type
                or logic_type == "N/A"
                or status in ["failed", "error", ""]
            ):
                lines.append("### ‚ö†Ô∏è Diagnostic d'√©chec de l'analyse logique")

                # Chercher des indices d'√©chec dans les donn√©es d'orchestration
                diagnostic = self._generate_logic_failure_diagnostic(data)
                lines.extend(diagnostic)

            else:
                lines.append(f"- **Type de logique**: {logic_type}")
                lines.append(f"- **Statut**: {status}")

                if "belief_set_summary" in formal:
                    bs = formal["belief_set_summary"]
                    lines.append(
                        f"- **Coh√©rence**: {'‚úÖ Coh√©rente' if bs.get('is_consistent') else '‚ùå Incoh√©rente'}"
                    )
                    lines.append(
                        f"- **Formules valid√©es**: {bs.get('formulas_validated', 0)}/{bs.get('formulas_total', 0)}"
                    )

                if "queries" in formal and formal["queries"]:
                    lines.append("\n### Requ√™tes logiques ex√©cut√©es")
                    for query in formal["queries"]:
                        result_icon = "‚úÖ" if query.get("result") == "Entailed" else "‚ùå"
                        lines.append(
                            f"- {result_icon} `{query.get('query', 'N/A')}` ‚Üí {query.get('result', 'N/A')}"
                        )

            lines.append("")

        # Conversation d'analyse (si disponible)
        if "conversation" in data:
            lines.append("## üí¨ Trace de conversation")
            conversation = data["conversation"]
            if isinstance(conversation, str):
                lines.append("```")
                lines.append(conversation)
                lines.append("```")
            elif isinstance(conversation, list):
                for i, exchange in enumerate(conversation, 1):
                    lines.append(f"### √âchange {i}")
                    lines.append(f"**Utilisateur**: {exchange.get('user', 'N/A')}")
                    lines.append(f"**Syst√®me**: {exchange.get('system', 'N/A')}")
                    lines.append("")
            lines.append("")

        # Recommandations - Correction d√©faut #4: Recommandations contextuelles
        lines.append("## üí° Recommandations")

        # G√©n√©rer des recommandations intelligentes bas√©es sur l'analyse
        smart_recommendations = self._generate_contextual_recommendations(data)

        # Combiner avec les recommandations existantes si pr√©sentes
        existing_recommendations = data.get("recommendations", [])
        all_recommendations = smart_recommendations + (
            existing_recommendations
            if isinstance(existing_recommendations, list)
            else []
        )

        # Filtrer les recommandations g√©n√©riques
        filtered_recommendations = [
            rec
            for rec in all_recommendations
            if not self._is_generic_recommendation(rec)
        ]

        if filtered_recommendations:
            for rec in filtered_recommendations:
                lines.append(f"- {rec}")
        else:
            lines.append(
                "- Aucune recommandation sp√©cifique g√©n√©r√©e pour cette analyse"
            )

        lines.append("")

        # Performance et m√©triques
        if "performance_metrics" in data:
            lines.append("## üìà M√©triques de performance")
            metrics = data["performance_metrics"]
            lines.append(
                f"- **Temps total d'ex√©cution**: {metrics.get('total_execution_time_ms', 'N/A')}ms"
            )
            lines.append(
                f"- **M√©moire utilis√©e**: {metrics.get('memory_usage_mb', 'N/A')} MB"
            )
            lines.append(
                f"- **Agents actifs**: {metrics.get('active_agents_count', 'N/A')}"
            )
            lines.append(
                f"- **Taux de r√©ussite**: {metrics.get('success_rate', 0):.1%}"
            )
            lines.append("")

        # Pied de page
        lines.append("---")
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        component = metadata.get("source_component", "syst√®me unifi√©")
        lines.append(
            f"*Rapport g√©n√©r√© le {timestamp} par le {component} d'analyse argumentative*"
        )

        return "\n".join(lines)

    def _render_console(self, data: Dict[str, Any]) -> str:
        """G√©n√®re un rapport console compact."""
        lines = []
        metadata = data.get("report_metadata", {})

        # En-t√™te compact
        component = metadata.get("source_component", "SYST√àME")
        analysis_type = metadata.get("analysis_type", "ANALYSE")
        title = f"{component.upper()} - {analysis_type.upper()}"
        lines.append("=" * 60)
        lines.append(f" {title.center(56)} ")
        lines.append("=" * 60)

        # R√©sum√© compact
        if "summary" in data:
            summary = data["summary"]
            lines.append(
                f"[STATS] Sophistication: {summary.get('rhetorical_sophistication', 'N/A')}"
            )
            lines.append(
                f"[WARN] Manipulation: {summary.get('manipulation_level', 'N/A')}"
            )
            lines.append(
                f"[LOGIC] Validit√© logique: {summary.get('logical_validity', 'N/A')}"
            )

            # Stats d'orchestration si disponibles
            if "orchestration_summary" in summary:
                orch = summary["orchestration_summary"]
                lines.append(
                    f"[ORCH] Agents: {orch.get('agents_count', 'N/A')}, Temps: {orch.get('orchestration_time_ms', 'N/A')}ms"
                )

        # Sophismes (compact)
        if "informal_analysis" in data:
            fallacies = data["informal_analysis"].get("fallacies", [])
            lines.append(f"[FALLACIES] Sophismes d√©tect√©s: {len(fallacies)}")

            if fallacies:
                for fallacy in fallacies[:3]:  # Limite √† 3 pour la console
                    severity_icons = {
                        "Critique": "[CRIT]",
                        "√âlev√©": "[HIGH]",
                        "Mod√©r√©": "[MED]",
                        "Faible": "[LOW]",
                    }
                    severity_icon = severity_icons.get(fallacy.get("severity"), "[UNK]")
                    lines.append(
                        f"  {severity_icon} {fallacy.get('type', 'N/A')} ({fallacy.get('confidence', 0):.0%})"
                    )

                if len(fallacies) > 3:
                    lines.append(f"  ... et {len(fallacies) - 3} autres")

        # Performance (compact)
        if "performance_metrics" in data:
            metrics = data["performance_metrics"]
            lines.append(
                f"[PERF] Temps: {metrics.get('total_execution_time_ms', 'N/A')}ms, M√©moire: {metrics.get('memory_usage_mb', 'N/A')}MB"
            )

        lines.append("=" * 60)
        return "\n".join(lines)

    def _render_json(self, data: Dict[str, Any]) -> str:
        """G√©n√®re un rapport JSON structur√©."""
        return json.dumps(data, indent=2, ensure_ascii=False)

    def _render_html(self, data: Dict[str, Any]) -> str:
        """G√©n√®re un rapport HTML enrichi."""
        metadata = data.get("report_metadata", {})
        component = metadata.get("source_component", "Syst√®me")
        analysis_type = metadata.get("analysis_type", "Analyse")
        title = f"Rapport {component} - {analysis_type}"

        html_lines = [
            "<!DOCTYPE html>",
            "<html lang='fr'>",
            "<head>",
            "    <meta charset='UTF-8'>",
            "    <meta name='viewport' content='width=device-width, initial-scale=1.0'>",
            f"    <title>{title}</title>",
            "    <style>",
            "        body { font-family: Arial, sans-serif; margin: 20px; line-height: 1.6; background-color: #f5f5f5; }",
            "        .container { max-width: 1200px; margin: 0 auto; background: white; padding: 20px; border-radius: 10px; box-shadow: 0 0 10px rgba(0,0,0,0.1); }",
            "        .header { background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white; padding: 20px; border-radius: 5px; margin-bottom: 20px; }",
            "        .component-badge { background: rgba(255,255,255,0.2); padding: 5px 10px; border-radius: 15px; font-size: 0.9em; }",
            "        .section { margin: 20px 0; padding: 15px; border-left: 4px solid #667eea; background: #f8f9ff; }",
            "        .fallacy { background: #fff3cd; padding: 10px; margin: 10px 0; border-left: 4px solid #ffc107; border-radius: 5px; }",
            "        .metadata { background: #e7f3ff; padding: 15px; border-radius: 5px; }",
            "        .summary { background: #d4edda; padding: 15px; border-radius: 5px; }",
            "        .performance { background: #f8d7da; padding: 15px; border-radius: 5px; }",
            "        .orchestration { background: #e2e3e5; padding: 15px; border-radius: 5px; }",
            "        .severity-critique { border-left-color: #dc3545; }",
            "        .severity-eleve { border-left-color: #fd7e14; }",
            "        .severity-modere { border-left-color: #ffc107; }",
            "        .severity-faible { border-left-color: #28a745; }",
            "        .metric { display: inline-block; margin: 5px; padding: 5px 10px; background: #6c757d; color: white; border-radius: 15px; font-size: 0.9em; }",
            "    </style>",
            "</head>",
            "<body>",
            "    <div class='container'>",
            f"        <div class='header'>",
            f"            <h1>{title}</h1>",
            f"            <span class='component-badge'>{component}</span>",
            f"            <span class='component-badge'>{analysis_type}</span>",
            f"        </div>",
        ]

        # M√©tadonn√©es avec style unifi√©
        if "metadata" in data or "report_metadata" in data:
            html_lines.append("        <div class='section metadata'>")
            html_lines.append("            <h2>üìä M√©tadonn√©es</h2>")

            if "report_metadata" in data:
                report_meta = data["report_metadata"]
                html_lines.append(
                    f"            <p><strong>Composant:</strong> {report_meta.get('source_component', 'N/A')}</p>"
                )
                html_lines.append(
                    f"            <p><strong>Date:</strong> {report_meta.get('generated_at', 'N/A')}</p>"
                )

            if "metadata" in data:
                analysis_meta = data["metadata"]
                html_lines.append(
                    f"            <p><strong>Source:</strong> {analysis_meta.get('source_description', 'N/A')}</p>"
                )
                html_lines.append(
                    f"            <p><strong>Longueur:</strong> {analysis_meta.get('text_length', 'N/A')} caract√®res</p>"
                )

            html_lines.append("        </div>")

        # R√©sum√© avec m√©triques d'orchestration
        if "summary" in data:
            html_lines.append("        <div class='section summary'>")
            html_lines.append("            <h2>üìã R√©sum√©</h2>")
            summary = data["summary"]

            html_lines.append("            <div>")
            if "rhetorical_sophistication" in summary:
                html_lines.append(
                    f"                <span class='metric'>Sophistication: {summary['rhetorical_sophistication']}</span>"
                )
            if "manipulation_level" in summary:
                html_lines.append(
                    f"                <span class='metric'>Manipulation: {summary['manipulation_level']}</span>"
                )
            if "orchestration_summary" in summary:
                orch = summary["orchestration_summary"]
                html_lines.append(
                    f"                <span class='metric'>Agents: {orch.get('agents_count', 'N/A')}</span>"
                )
                html_lines.append(
                    f"                <span class='metric'>Temps orch.: {orch.get('orchestration_time_ms', 'N/A')}ms</span>"
                )
            html_lines.append("            </div>")
            html_lines.append("        </div>")

        # Performance
        if "performance_metrics" in data:
            html_lines.append("        <div class='section performance'>")
            html_lines.append("            <h2>üìà Performance</h2>")
            metrics = data["performance_metrics"]
            html_lines.append("            <div>")
            html_lines.append(
                f"                <span class='metric'>Temps: {metrics.get('total_execution_time_ms', 'N/A')}ms</span>"
            )
            html_lines.append(
                f"                <span class='metric'>M√©moire: {metrics.get('memory_usage_mb', 'N/A')}MB</span>"
            )
            html_lines.append(
                f"                <span class='metric'>Succ√®s: {metrics.get('success_rate', 0):.1%}</span>"
            )
            html_lines.append("            </div>")
            html_lines.append("        </div>")

        # Sophismes avec style am√©lior√©
        if "informal_analysis" in data:
            fallacies = data["informal_analysis"].get("fallacies", [])
            html_lines.append("        <div class='section'>")
            html_lines.append("            <h2>üé≠ Sophismes d√©tect√©s</h2>")

            for fallacy in fallacies:
                severity = fallacy.get("severity", "faible").lower()
                fallacy_type = fallacy.get("type", "Type inconnu")
                text_fragment = fallacy.get("text_fragment", "N/A")
                explanation = fallacy.get("explanation", "N/A")
                confidence = fallacy.get("confidence", 0)

                html_lines.append(
                    f"            <div class='fallacy severity-{severity}'>"
                )
                html_lines.append(f"                <h3>{fallacy_type}</h3>")
                html_lines.append(
                    f'                <p><strong>Fragment:</strong> "{text_fragment}"</p>'
                )
                html_lines.append(
                    f"                <p><strong>Explication:</strong> {explanation}</p>"
                )
                html_lines.append(
                    f"                <p><strong>Confiance:</strong> {confidence:.1%}</p>"
                )
                html_lines.append("            </div>")

            html_lines.append("        </div>")

        # Footer
        current_time = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        html_lines.extend(
            [
                "        <footer style='margin-top: 40px; text-align: center; color: #666;'>",
                f"            <p>Rapport g√©n√©r√© le {current_time} par {component}</p>",
                "        </footer>",
                "    </div>",
                "</body>",
                "</html>",
            ]
        )

        return "\n".join(html_lines)

    def _extract_sk_retry_attempts(self, result_text: str) -> Dict[str, Dict[str, str]]:
        """
        Extrait les d√©tails des tentatives SK Retry depuis le texte d'erreur.

        Correction d√©faut #2: Extraction compl√®te des 3 tentatives avec erreurs sp√©cifiques.
        """
        attempts = {}

        # Patterns pour d√©tecter les tentatives
        import re

        # Pattern pour les tentatives avec pr√©dicats sp√©cifiques
        attempt_pattern = r"tentative de conversion.*?(\d)/3.*?predicate '([^']+)'.*?has not been declared"
        matches = re.findall(attempt_pattern, result_text.lower(), re.DOTALL)

        for match in matches:
            attempt_num = match[0]
            predicate = match[1]

            # Chercher l'erreur sp√©cifique pour cette tentative
            error_context = self._extract_error_context(result_text, predicate)

            attempts[attempt_num] = {"predicate": predicate, "error": error_context}

        # Si pas de match avec le pattern complet, essayer une approche plus simple
        if not attempts:
            # Recherche des pr√©dicats mentionn√©s dans les patterns observ√©s
            known_predicates = [
                "constantanalyser_faits_rigueur",
                "constantanalyser_faits_avec_rigueur",
            ]
            attempt_counter = 1

            for predicate in known_predicates:
                if predicate in result_text.lower():
                    attempts[str(attempt_counter)] = {
                        "predicate": predicate,
                        "error": "Pr√©dicat non d√©clar√© dans Tweety",
                    }
                    attempt_counter += 1

                    # Duplication du dernier pr√©dicat pour simuler les 3 tentatives observ√©es
                    if (
                        predicate == "constantanalyser_faits_avec_rigueur"
                        and attempt_counter == 2
                    ):
                        attempts[str(attempt_counter)] = {
                            "predicate": predicate,
                            "error": "Pr√©dicat non d√©clar√© dans Tweety (retry)",
                        }
                        attempt_counter += 1
                        attempts[str(attempt_counter)] = {
                            "predicate": predicate,
                            "error": "Pr√©dicat non d√©clar√© dans Tweety (final retry)",
                        }

        return attempts

    def _extract_error_context(self, result_text: str, predicate: str) -> str:
        """Extrait le contexte d'erreur pour un pr√©dicat sp√©cifique."""
        # Recherche autour du pr√©dicat pour obtenir le contexte
        predicate_pos = result_text.lower().find(predicate.lower())
        if predicate_pos != -1:
            # Prendre 100 caract√®res avant et apr√®s
            start = max(0, predicate_pos - 100)
            end = min(len(result_text), predicate_pos + len(predicate) + 100)
            context = result_text[start:end]

            # Nettoyer et extraire l'erreur principale
            if "has not been declared" in context.lower():
                return "Pr√©dicat non d√©clar√© dans l'ensemble de croyances Tweety"
            elif "syntax error" in context.lower():
                return "Erreur de syntaxe lors de la conversion"
            else:
                return "Erreur de conversion Tweety non sp√©cifi√©e"

        return "Contexte d'erreur non trouv√©"

    def _extract_tweety_errors(self, result_text: str) -> List[str]:
        """
        Extrait toutes les erreurs Tweety sp√©cifiques depuis le texte.

        Retourne une liste d'erreurs format√©es pour le rapport.
        """
        errors = []

        # Pattern pour les erreurs de pr√©dicats non d√©clar√©s
        import re

        predicate_errors = re.findall(
            r"predicate '([^']+)' has not been declared", result_text.lower()
        )

        for predicate in predicate_errors:
            errors.append(f"Pr√©dicat '{predicate}' non d√©clar√©")

        # Pattern pour les erreurs de syntaxe
        syntax_errors = re.findall(r"syntax error.*?modal logic", result_text.lower())
        if syntax_errors:
            errors.append("Erreur de syntaxe en logique modale")

        # Pattern pour les erreurs de conversion g√©n√©rales
        if "conversion/validation" in result_text.lower():
            errors.append("√âchec de conversion/validation Tweety")

        # Si aucune erreur sp√©cifique trouv√©e, ajouter une erreur g√©n√©rale
        if not errors and "tweety" in result_text.lower():
            errors.append("Erreur g√©n√©rale de traitement Tweety")

        return errors

    def _generate_logic_failure_diagnostic(self, data: Dict[str, Any]) -> List[str]:
        """
        G√©n√®re un diagnostic d√©taill√© des √©checs d'analyse logique.

        Correction d√©faut #3: Remplace les "N/A" par des diagnostics techniques utiles.
        """
        diagnostic_lines = []

        # Analyser les traces d'orchestration pour comprendre l'√©chec
        orchestration = data.get("orchestration_analysis", {})
        conversation_log = orchestration.get("conversation_log", {})

        # V√©rifier si ModalLogicAgent a √©chou√©
        modal_failures = []
        tweety_errors = []

        if isinstance(conversation_log, dict) and "messages" in conversation_log:
            messages = conversation_log["messages"]
            for msg in messages:
                if isinstance(msg, dict):
                    agent = str(msg.get("agent", ""))
                    content = str(msg.get("message", ""))

                    if agent == "ModalLogicAgent":
                        if "erreur" in content.lower() or "√©chec" in content.lower():
                            modal_failures.append(content[:200] + "...")
                        elif (
                            "predicate" in content.lower()
                            and "declared" in content.lower()
                        ):
                            tweety_errors.append(content[:150] + "...")

        # Construire le diagnostic
        if modal_failures:
            diagnostic_lines.append(
                "- **Cause principale**: √âchec du ModalLogicAgent lors de la conversion"
            )
            diagnostic_lines.append(
                f"- **Nombre d'√©checs d√©tect√©s**: {len(modal_failures)}"
            )
            diagnostic_lines.append(
                "- **Type d'erreur**: Conversion de texte vers ensemble de croyances Tweety"
            )

            if tweety_errors:
                diagnostic_lines.append("- **Erreurs Tweety identifi√©es**:")
                for i, error in enumerate(tweety_errors[:2], 1):
                    diagnostic_lines.append(f"  {i}. {error}")

            diagnostic_lines.append(
                "- **Impact**: Aucune analyse logique formelle possible"
            )
            diagnostic_lines.append(
                "- **Recommandation technique**: R√©viser les r√®gles de conversion texte‚ÜíTweety"
            )

        else:
            # Diagnostic g√©n√©ral si pas de traces sp√©cifiques
            diagnostic_lines.append(
                "- **Statut**: Analyse logique non ex√©cut√©e ou √©chou√©e"
            )
            diagnostic_lines.append(
                "- **Cause possible**: Configuration manquante ou erreur syst√®me"
            )
            diagnostic_lines.append(
                "- **Agents impliqu√©s**: ModalLogicAgent (conversion Tweety)"
            )
            diagnostic_lines.append(
                "- **Impact**: Pas de validation formelle de la coh√©rence logique"
            )
            diagnostic_lines.append(
                "- **Recommandation**: V√©rifier les logs d√©taill√©s pour identifier la cause pr√©cise"
            )

        # Ajouter des informations contextuelles
        if "performance_metrics" in data:
            perf = data["performance_metrics"]
            exec_time = perf.get("total_execution_time_ms", 0)
            if exec_time > 20000:  # Plus de 20 secondes
                diagnostic_lines.append(
                    f"- **Observation**: Temps d'ex√©cution √©lev√© ({exec_time:.1f}ms) sugg√®re des tentatives de retry"
                )

        return diagnostic_lines

    def _generate_contextual_recommendations(self, data: Dict[str, Any]) -> List[str]:
        """
        G√©n√®re des recommandations sp√©cifiques bas√©es sur les r√©sultats d'analyse.

        Correction d√©faut #4: Recommandations contextuelles intelligentes.
        """
        recommendations = []

        # Analyser les sophismes d√©tect√©s
        informal_analysis = data.get("informal_analysis", {})
        fallacies = informal_analysis.get("fallacies", [])

        if fallacies:
            high_confidence_fallacies = [
                f for f in fallacies if f.get("confidence", 0) > 0.7
            ]
            critical_fallacies = [
                f for f in fallacies if f.get("severity") == "Critique"
            ]

            if critical_fallacies:
                recommendations.append(
                    f"**URGENCE**: {len(critical_fallacies)} sophisme(s) critique(s) d√©tect√©(s) - r√©vision imm√©diate n√©cessaire"
                )
                for fallacy in critical_fallacies[
                    :2
                ]:  # Premi√®re 2 pour √©viter la surcharge
                    fallacy_type = fallacy.get("type", "Type inconnu")
                    recommendations.append(
                        f"  ‚Üí Corriger le sophisme '{fallacy_type}' dans le fragment analys√©"
                    )

            if high_confidence_fallacies:
                recommendations.append(
                    f"Revoir {len(high_confidence_fallacies)} sophisme(s) avec forte confiance de d√©tection"
                )

            if len(fallacies) > 3:
                recommendations.append(
                    "Densit√© √©lev√©e de sophismes d√©tect√©e - consid√©rer une restructuration argumentative"
                )

        # Analyser les √©checs d'orchestration
        orchestration = data.get("orchestration_analysis", {})
        if orchestration.get("status") != "success":
            recommendations.append(
                "Optimiser la configuration des agents d'orchestration pour am√©liorer la fiabilit√©"
            )

        # Analyser les √©checs ModalLogicAgent sp√©cifiques
        conversation_log = orchestration.get("conversation_log", {})
        modal_failures = self._count_modal_failures(conversation_log)

        if modal_failures > 0:
            recommendations.append(
                f"Corriger {modal_failures} √©chec(s) ModalLogicAgent - r√©viser les r√®gles de conversion Tweety"
            )
            recommendations.append(
                "Am√©liorer la d√©claration des pr√©dicats dans l'ensemble de croyances"
            )

        # Analyser la performance
        performance = data.get("performance_metrics", {})
        exec_time = performance.get("total_execution_time_ms", 0)

        if exec_time > 30000:  # Plus de 30 secondes
            recommendations.append(
                f"Optimiser les performances - temps d'ex√©cution √©lev√© ({exec_time:.1f}ms)"
            )

        # Recommandations bas√©es sur l'analyse formelle
        formal_analysis = data.get("formal_analysis", {})
        if formal_analysis.get("status") in [
            "failed",
            "error",
            "",
        ] or not formal_analysis.get("logic_type"):
            recommendations.append(
                "Impl√©menter une validation logique formelle pour renforcer l'analyse"
            )
            recommendations.append(
                "Investiguer les causes d'√©chec de l'analyse modale avec Tweety"
            )

        # Recommandations m√©thodologiques g√©n√©rales (seulement si aucune sp√©cifique)
        if not recommendations:
            recommendations.append("Analyse compl√©t√©e sans probl√®mes majeurs d√©tect√©s")
            recommendations.append(
                "Envisager une analyse plus approfondie avec des agents sp√©cialis√©s suppl√©mentaires"
            )

        return recommendations

    def _count_modal_failures(self, conversation_log: Dict[str, Any]) -> int:
        """Compte les √©checs sp√©cifiques du ModalLogicAgent."""
        failures = 0

        if isinstance(conversation_log, dict) and "messages" in conversation_log:
            messages = conversation_log["messages"]
            for msg in messages:
                if isinstance(msg, dict):
                    agent = str(msg.get("agent", ""))
                    content = str(msg.get("message", ""))

                    if agent == "ModalLogicAgent" and (
                        "erreur" in content.lower() or "√©chec" in content.lower()
                    ):
                        failures += 1

        return failures

    def _is_generic_recommendation(self, recommendation: str) -> bool:
        """
        D√©tecte si une recommandation est trop g√©n√©rique.

        Filtre les recommandations comme "Analyse orchestr√©e compl√©t√©e - examen des insights avanc√©s recommand√©"
        """
        generic_patterns = [
            "analyse orchestr√©e compl√©t√©e",
            "examen des insights avanc√©s recommand√©",
            "analyse compl√©t√©e avec succ√®s",
            "r√©sultats disponibles pour examen",
        ]

        recommendation_lower = recommendation.lower()
        return any(pattern in recommendation_lower for pattern in generic_patterns)
