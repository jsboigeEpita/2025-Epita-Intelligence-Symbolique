#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
Service d'analyse compl√®te utilisant le moteur d'analyse argumentative.
"""

import time
import logging
from typing import Dict, List, Any, Optional
import semantic_kernel as sk

# Imports du moteur d'analyse (style b282af4 avec gestion d'erreur)
try:
    from argumentation_analysis.agents.core.informal.informal_agent import InformalAnalysisAgent as InformalAgent
    from argumentation_analysis.agents.tools.analysis.complex_fallacy_analyzer import ComplexFallacyAnalyzer
    from argumentation_analysis.agents.tools.analysis.contextual_fallacy_analyzer import ContextualFallacyAnalyzer
    from argumentation_analysis.agents.tools.analysis.fallacy_severity_evaluator import FallacySeverityEvaluator
    from argumentation_analysis.orchestration.hierarchical.operational.manager import OperationalManager
    from argumentation_analysis.core.llm_service import create_llm_service # Ajout√©
    from argumentation_analysis.utils.taxonomy_loader import get_taxonomy_path # Ajout√©
except ImportError as e:
    logging.warning(f"Impossible d'importer les modules d'analyse ou llm_service/taxonomy_loader: {e}")
    # Mode d√©grad√© pour les tests
    InformalAgent = None
    ComplexFallacyAnalyzer = None
    ContextualFallacyAnalyzer = None
    FallacySeverityEvaluator = None
    OperationalManager = None

# Imports des mod√®les (style HEAD)
from argumentation_analysis.services.web_api.models.request_models import AnalysisRequest
from argumentation_analysis.services.web_api.models.response_models import (
    AnalysisResponse, FallacyDetection, ArgumentStructure
)

# Import du FallacyService corrig√©
from argumentation_analysis.services.web_api.services.fallacy_service import FallacyService

logger = logging.getLogger("AnalysisService")


class AnalysisService:
    """
    Service pour l'analyse compl√®te de textes argumentatifs.
    
    Ce service utilise le moteur d'analyse existant pour fournir
    une analyse compl√®te incluant la d√©tection de sophismes,
    l'analyse de structure et l'√©valuation de coh√©rence.
    """
    
    def __init__(self):
        """Initialise le service d'analyse."""
        self.logger = logger
        self.is_initialized = False
        self._initialize_components()
    
    def _initialize_components(self) -> None:
        """Initialise les composants d'analyse internes du service.

        Tente d'instancier `ComplexFallacyAnalyzer`, `ContextualFallacyAnalyzer`,
        `FallacySeverityEvaluator`, et `InformalAgent`.
        Met √† jour `self.is_initialized` en fonction du succ√®s.

        :return: None
        :rtype: None
        """
        try:
            # Initialisation des analyseurs
            if ComplexFallacyAnalyzer:
                self.complex_analyzer = ComplexFallacyAnalyzer()
            else:
                self.complex_analyzer = None
                
            if ContextualFallacyAnalyzer:
                self.contextual_analyzer = ContextualFallacyAnalyzer()
            else:
                self.contextual_analyzer = None
                
            if FallacySeverityEvaluator:
                self.severity_evaluator = FallacySeverityEvaluator()
            else:
                self.severity_evaluator = None
            
            # Initialisation du FallacyService corrig√©
            try:
                self.fallacy_service = FallacyService()
                self.logger.info("FallacyService corrig√© initialis√© avec succ√®s")
            except Exception as e:
                self.logger.error(f"Erreur lors de l'initialisation du FallacyService: {e}")
                self.fallacy_service = None
            
            # Configuration des outils pour l'agent informel
            self.tools = {}
            if self.complex_analyzer:
                self.tools['complex_fallacy_analyzer'] = self.complex_analyzer
            if self.contextual_analyzer:
                self.tools['contextual_fallacy_analyzer'] = self.contextual_analyzer
            if self.severity_evaluator:
                self.tools['fallacy_severity_evaluator'] = self.severity_evaluator
            
            # Initialisation de l'agent informel (version b282af4)
            if InformalAgent:
                # Cr√©ation du kernel et ajout du service LLM
                kernel = sk.Kernel()
                llm_service = None
                if create_llm_service:
                    try:
                        llm_service = create_llm_service(service_id="default_analysis_llm")
                        kernel.add_service(llm_service)
                        self.logger.info("Service LLM cr√©√© et ajout√© au kernel pour AnalysisService.")
                    except Exception as llm_e:
                        self.logger.error(f"Erreur lors de la cr√©ation ou de l'ajout du service LLM: {llm_e}")
                else:
                    self.logger.error("create_llm_service non disponible.")

                taxonomy_path = None
                if get_taxonomy_path:
                    try:
                        taxonomy_path = get_taxonomy_path()
                        self.logger.info(f"Chemin de la taxonomie obtenu: {taxonomy_path}")
                    except Exception as tax_e:
                        self.logger.error(f"Erreur lors de l'obtention du chemin de la taxonomie: {tax_e}")
                else:
                    self.logger.error("get_taxonomy_path non disponible.")
                
                if kernel and llm_service: # S'assurer que le kernel et le service LLM sont pr√™ts
                    self.informal_agent = InformalAgent(
                        kernel=kernel,
                        agent_name="web_api_informal_agent", # Utilisation de agent_name
                        taxonomy_file_path=str(taxonomy_path) if taxonomy_path else None # Passer le chemin de la taxonomie
                    )
                    # Configurer les composants de l'agent (plugins, fonctions s√©mantiques)
                    # L'ID du service LLM est n√©cessaire ici. create_llm_service devrait le retourner ou le rendre accessible.
                    # Supposons que l'ID est "default_analysis_llm" comme utilis√© ci-dessus.
                    try:
                        self.informal_agent.setup_agent_components(llm_service_id="default_analysis_llm")
                        self.logger.info("Composants de InformalAgent configur√©s.")
                    except Exception as setup_e:
                        self.logger.error(f"Erreur lors de la configuration des composants de InformalAgent: {setup_e}")
                        self.informal_agent = None # Invalider l'agent si la configuration √©choue
                else:
                    self.logger.error("Kernel ou LLM Service non initialis√©, impossible de cr√©er InformalAgent.")
                    self.informal_agent = None
            else:
                self.informal_agent = None
                self.logger.warning("Classe InformalAgent non disponible.")
            
            self.is_initialized = True # Peut-√™tre conditionner cela au succ√®s de l'init de l'agent
            if self.informal_agent:
                self.logger.info("Service d'analyse initialis√© avec succ√®s (avec InformalAgent).")
            else:
                self.logger.warning("Service d'analyse initialis√©, mais InformalAgent n'a pas pu √™tre cr√©√©/configur√©.")
            
        except Exception as e:
            self.logger.error(f"Erreur lors de l'initialisation: {e}")
            self.is_initialized = False
    
    def is_healthy(self) -> bool:
        """V√©rifie l'√©tat de sant√© du service d'analyse.

        :return: True si le service est initialis√© et qu'au moins un composant
                 d'analyse (agent informel ou analyseur sp√©cifique) est disponible,
                 False sinon.
        :rtype: bool
        """
        return self.is_initialized and (
            self.informal_agent is not None or
            any([self.complex_analyzer, self.contextual_analyzer, self.severity_evaluator])
        )
    
    async def analyze_text(self, request: AnalysisRequest) -> AnalysisResponse:
        """
        Effectue une analyse compl√®te d'un texte argumentatif.

        Orchestre la d√©tection de sophismes, l'analyse de la structure argumentative,
        et le calcul de m√©triques globales comme la qualit√© et la coh√©rence.

        :param request: L'objet `AnalysisRequest` contenant le texte √† analyser
                        et les options d'analyse.
        :type request: AnalysisRequest
        :return: Un objet `AnalysisResponse` contenant les r√©sultats de l'analyse.
                 En cas d'√©chec d'initialisation du service, une r√©ponse de fallback
                 est retourn√©e.
        :rtype: AnalysisResponse
        """
        start_time = time.time()
        
        # üö® LOGS ULTRA-VISIBLES POUR DIAGNOSTIC
        self.logger.critical(f"üö®üö®üö® analyze_text APPEL√âE avec texte: '{request.text[:30]}...'")
        self.logger.critical(f"üö® Options: {request.options}")
        
        try:
            # V√©rification de l'√©tat du service
            self.logger.critical(f"üö® V√©rification is_healthy(): {self.is_healthy()}")
            if not self.is_healthy():
                self.logger.critical("üö® Service NOT HEALTHY - cr√©ation fallback response")
                return self._create_fallback_response(request, start_time)
            
            self.logger.critical("üö® Service healthy - appel de _detect_fallacies")
            # Analyse des sophismes
            fallacies = await self._detect_fallacies(request.text, request.options)
            
            # Analyse de la structure argumentative
            structure = self._analyze_structure(request.text, request.options)
            
            # Calcul des m√©triques globales
            overall_quality = self._calculate_overall_quality(fallacies, structure)
            coherence_score = self._calculate_coherence_score(structure)
            
            processing_time = time.time() - start_time
            
            return AnalysisResponse(
                success=True,
                text_analyzed=request.text,
                fallacies=fallacies,
                argument_structure=structure,
                overall_quality=overall_quality,
                coherence_score=coherence_score,
                fallacy_count=len(fallacies),
                processing_time=processing_time,
                analysis_options=request.options.dict() if request.options else {}
            )
            
        except Exception as e:
            self.logger.error(f"Erreur lors de l'analyse: {e}")
            processing_time = time.time() - start_time
            
            return AnalysisResponse(
                success=False,
                text_analyzed=request.text,
                fallacies=[],
                argument_structure=None,
                overall_quality=0.0,
                coherence_score=0.0,
                fallacy_count=0,
                processing_time=processing_time,
                analysis_options=request.options.dict() if request.options else {}
            )
    
    async def _detect_fallacies(self, text: str, options: Optional[Any]) -> List[FallacyDetection]:
        """D√©tecte les sophismes dans le texte en utilisant les analyseurs disponibles.

        Utilise `self.informal_agent` si disponible, sinon `self.contextual_analyzer`.
        Filtre les r√©sultats en fonction du `severity_threshold` des options.

        :param text: Le texte √† analyser.
        :type text: str
        :param options: Les options d'analyse (par exemple, `AnalysisOptions` ou `FallacyOptions`)
                        pouvant contenir `severity_threshold`.
        :type options: Optional[Any]
        :return: Une liste d'objets `FallacyDetection`.
        :rtype: List[FallacyDetection]
        """
        fallacies = []
        
        # üö® LOGS ULTRA-VISIBLES POUR DIAGNOSTIC
        self.logger.critical(f"üö®üö®üö® _detect_fallacies APPEL√âE avec texte: '{text[:30]}...'")
        
        try:
            # D√âBOGAGE CRITIQUE: V√©rifier l'√©tat du FallacyService
            fallacy_service_exists = hasattr(self, 'fallacy_service')
            fallacy_service_not_none = self.fallacy_service if fallacy_service_exists else None
            self.logger.critical(f"üö® DIAGNOSTIC: fallacy_service_exists={fallacy_service_exists}")
            self.logger.critical(f"üö® DIAGNOSTIC: fallacy_service_not_none={fallacy_service_not_none is not None}")
            if fallacy_service_not_none:
                self.logger.critical(f"üö® DIAGNOSTIC: Type de fallacy_service: {type(fallacy_service_not_none)}")
            
            # PRIORIT√â 1: Utilisation du FallacyService corrig√© avec les patterns regex fixes
            if hasattr(self, 'fallacy_service') and self.fallacy_service:
                self.logger.info("Utilisation du FallacyService corrig√© pour la d√©tection")
                try:
                    # Cr√©er une requ√™te compatible
                    from argumentation_analysis.services.web_api.models.request_models import FallacyRequest, FallacyOptions
                    # Conversion correcte AnalysisOptions ‚Üí FallacyOptions
                    if not options:
                        fallacy_options = FallacyOptions()
                    else:
                        fallacy_options = FallacyOptions(
                            detect_fallacies=getattr(options, 'detect_fallacies', True),
                            analyze_structure=getattr(options, 'analyze_structure', True),
                            evaluate_coherence=getattr(options, 'evaluate_coherence', True),
                            include_context=getattr(options, 'include_context', True),
                            severity_threshold=getattr(options, 'severity_threshold', 0.5)
                        )
                    fallacy_request = FallacyRequest(text=text, options=fallacy_options)
                    
                    result = self.fallacy_service.detect_fallacies(fallacy_request)
                    
                    if result and hasattr(result, 'fallacies'):
                        for fallacy_data in result.fallacies:
                            if hasattr(fallacy_data, 'dict'):
                                fallacy_dict = fallacy_data.dict()
                            else:
                                fallacy_dict = fallacy_data
                                
                            fallacy = FallacyDetection(
                                type=fallacy_dict.get('type', 'pattern'),
                                name=fallacy_dict.get('name', 'Sophisme d√©tect√©'),
                                description=fallacy_dict.get('description', ''),
                                severity=fallacy_dict.get('severity', 0.7),
                                confidence=fallacy_dict.get('confidence', 0.8),
                                location=fallacy_dict.get('location'),
                                context=fallacy_dict.get('context'),
                                explanation=fallacy_dict.get('explanation')
                            )
                            fallacies.append(fallacy)
                            
                    self.logger.info(f"FallacyService a d√©tect√© {len(fallacies)} sophismes")
                    
                except Exception as e:
                    self.logger.error(f"Erreur avec FallacyService: {e}")
                    # Continuer avec les autres m√©thodes en cas d'erreur
            
            # PRIORIT√â 2: Utilisation de l'agent informel si FallacyService non disponible
            if not fallacies and self.informal_agent:
                self.logger.info("Utilisation de l'agent informel pour la d√©tection")
                result = await self.informal_agent.analyze_text(text) # La signature de analyze_text peut varier
                if result and 'fallacies' in result:
                    for fallacy_data in result['fallacies']:
                        fallacy = FallacyDetection(
                            type=fallacy_data.get('type', 'semantic'),
                            name=fallacy_data.get('nom', fallacy_data.get('name', 'Sophisme non identifi√©')),
                            description=fallacy_data.get('explication', fallacy_data.get('description', fallacy_data.get('explanation', ''))),
                            severity=fallacy_data.get('severity', 0.7),
                            confidence=fallacy_data.get('confidence', 0.8),
                            location=fallacy_data.get('location'),  # Garde seulement le vrai dict de position
                            context=fallacy_data.get('context', fallacy_data.get('reformulation')),
                            explanation=fallacy_data.get('explication', fallacy_data.get('explanation', ''))
                        )
                        fallacies.append(fallacy)
            
            # PRIORIT√â 3: Analyse contextuelle si les autres m√©thodes n'ont rien donn√©
            elif not fallacies and self.contextual_analyzer:
                self.logger.info("Utilisation de l'analyseur contextuel pour la d√©tection")
                result = self.contextual_analyzer.analyze_fallacies(text)
                if result:
                    for fallacy_data in result:
                        fallacy = FallacyDetection(
                            type=fallacy_data.get('type', 'contextual'),
                            name=fallacy_data.get('name', 'Sophisme contextuel'),
                            description=fallacy_data.get('description', ''),
                            severity=fallacy_data.get('severity', 0.5),
                            confidence=fallacy_data.get('confidence', 0.5),
                            context=fallacy_data.get('context')
                        )
                        fallacies.append(fallacy)
            
            # Filtrage par seuil de s√©v√©rit√©
            if options and hasattr(options, 'severity_threshold') and options.severity_threshold is not None:
                fallacies = [f for f in fallacies if f.severity >= options.severity_threshold]
            
        except Exception as e:
            self.logger.error(f"Erreur lors de la d√©tection de sophismes: {e}")
        
        return fallacies
    
    def _analyze_structure(self, text: str, options: Optional[Any]) -> Optional[ArgumentStructure]:
        """Analyse la structure argumentative du texte avec d√©tection am√©lior√©e des connecteurs logiques.

        Cette m√©thode utilise la d√©tection de connecteurs logiques pour identifier
        les pr√©misses et conclusions plus pr√©cis√©ment que la simple division par phrases.
        
        :param text: Le texte √† analyser.
        :type text: str
        :param options: Options d'analyse (non utilis√©es actuellement dans cette m√©thode).
        :type options: Optional[Any]
        :return: Un objet `ArgumentStructure` ou None si une erreur survient.
        :rtype: Optional[ArgumentStructure]
        """
        try:
            import re
            
            # Nettoyage et normalisation du texte
            clean_text = text.strip()
            
            # Connecteurs logiques pour identifier les structures argumentatives
            conclusion_indicators = [
                r'\bdonc\b', r'\bpar cons√©quent\b', r'\bainsi\b', r'\bde ce fait\b',
                r'\bc\'est pourquoi\b', r'\bpar suite\b', r'\bde l√†\b', r'\ben conclusion\b'
            ]
            
            premise_indicators = [
                r'\bparce que\b', r'\bcar\b', r'\bpuisque\b', r'\b√©tant donn√© que\b',
                r'\bcomme\b', r'\ben effet\b', r'\bdu fait que\b', r'\bvu que\b'
            ]
            
            causal_patterns = [
                r'\bsi\b.*\balors\b', r'\bquand\b.*\balors\b'
            ]
            
            # D√©tection de structures argumentatives
            premises = []
            conclusion = ""
            argument_type = "simple"
            
            # 1. Recherche de connecteurs de conclusion
            conclusion_found = False
            for indicator in conclusion_indicators:
                matches = list(re.finditer(indicator, clean_text, re.IGNORECASE))
                if matches:
                    conclusion_found = True
                    # La conclusion est g√©n√©ralement apr√®s le connecteur
                    conclusion_start = matches[-1].end()
                    conclusion = clean_text[conclusion_start:].strip()
                    premises_text = clean_text[:matches[-1].start()].strip()
                    if premises_text:
                        premises = [premises_text]
                    argument_type = "deductive"
                    break
            
            # 2. Si pas de connecteur de conclusion, recherche de connecteurs de pr√©misse
            if not conclusion_found:
                for indicator in premise_indicators:
                    matches = list(re.finditer(indicator, clean_text, re.IGNORECASE))
                    if matches:
                        # Structure: [Conclusion] parce que [Pr√©misse]
                        premise_start = matches[0].end()
                        premise_text = clean_text[premise_start:].strip()
                        conclusion_text = clean_text[:matches[0].start()].strip()
                        
                        if premise_text and conclusion_text:
                            premises = [premise_text]
                            conclusion = conclusion_text
                            argument_type = "causal"
                            conclusion_found = True
                            break
            
            # 3. D√©tection de patterns causaux (si...alors)
            if not conclusion_found:
                for pattern in causal_patterns:
                    matches = list(re.finditer(pattern, clean_text, re.IGNORECASE))
                    if matches:
                        # Structure conditionnelle d√©tect√©e
                        match = matches[0]
                        si_match = re.search(r'\bsi\b(.*?)\balors\b', clean_text, re.IGNORECASE)
                        if si_match:
                            condition = si_match.group(1).strip()
                            conclusion_start = si_match.end()
                            conclusion_text = clean_text[conclusion_start:].strip()
                            
                            premises = [f"Si {condition}"]
                            conclusion = conclusion_text
                            argument_type = "conditional"
                            conclusion_found = True
                            break
            
            # 4. Fallback : division par phrases avec am√©lioration
            if not conclusion_found:
                # Division par points, points d'exclamation, points d'interrogation
                sentences = re.split(r'[.!?]+', clean_text)
                sentences = [s.strip() for s in sentences if s.strip()]
                
                if len(sentences) >= 2:
                    conclusion = sentences[-1]
                    premises = sentences[:-1]
                    argument_type = "simple"
                elif len(sentences) == 1:
                    conclusion = sentences[0]
                    premises = []
                    argument_type = "assertion"
                else:
                    conclusion = clean_text
                    premises = []
                    argument_type = "fragment"
            
            # Calcul de la force et coh√©rence am√©lior√©s
            strength = self._calculate_argument_strength(premises, conclusion, argument_type)
            coherence = self._calculate_structural_coherence(premises, conclusion, argument_type, clean_text)
            
            self.logger.debug(f"Structure analys√©e: type={argument_type}, premises={len(premises)}, strength={strength:.2f}, coherence={coherence:.2f}")
            
            return ArgumentStructure(
                premises=premises,
                conclusion=conclusion,
                argument_type=argument_type,
                strength=strength,
                coherence=coherence
            )
            
        except Exception as e:
            self.logger.error(f"Erreur lors de l'analyse de structure: {e}")
            return None
    
    def _calculate_argument_strength(self, premises: List[str], conclusion: str, argument_type: str) -> float:
        """Calcule la force de l'argument bas√©e sur la structure d√©tect√©e."""
        try:
            base_strength = 0.3
            
            # Bonus selon le type d'argument
            type_bonus = {
                "deductive": 0.4,
                "causal": 0.3,
                "conditional": 0.35,
                "simple": 0.2,
                "assertion": 0.1,
                "fragment": 0.05
            }
            base_strength += type_bonus.get(argument_type, 0.1)
            
            # Bonus selon le nombre de pr√©misses
            if premises:
                premise_bonus = min(0.3, len(premises) * 0.1)
                base_strength += premise_bonus
            
            # P√©nalit√© pour arguments trop courts ou incomplets
            if not conclusion or len(conclusion.strip()) < 10:
                base_strength *= 0.7
            if not premises or all(len(p.strip()) < 5 for p in premises):
                base_strength *= 0.6
            
            return min(1.0, max(0.0, base_strength))
            
        except Exception as e:
            self.logger.error(f"Erreur calcul force argument: {e}")
            return 0.3
    
    def _calculate_structural_coherence(self, premises: List[str], conclusion: str, argument_type: str, original_text: str) -> float:
        """Calcule la coh√©rence structurelle bas√©e sur la qualit√© des connecteurs et la logique."""
        try:
            import re
            
            base_coherence = 0.3
            
            # Bonus pour pr√©sence de connecteurs logiques
            logical_connectors = [
                r'\bdonc\b', r'\bparce que\b', r'\bcar\b', r'\bpuisque\b',
                r'\bpar cons√©quent\b', r'\bainsi\b', r'\bde ce fait\b'
            ]
            
            connector_count = 0
            for connector in logical_connectors:
                if re.search(connector, original_text, re.IGNORECASE):
                    connector_count += 1
            
            if connector_count > 0:
                base_coherence += min(0.4, connector_count * 0.15)
            
            # Bonus selon le type d'argument
            type_coherence = {
                "deductive": 0.3,
                "causal": 0.25,
                "conditional": 0.2,
                "simple": 0.1,
                "assertion": 0.05,
                "fragment": 0.0
            }
            base_coherence += type_coherence.get(argument_type, 0.05)
            
            # P√©nalit√© pour incoh√©rences structurelles
            if argument_type in ["assertion", "fragment"]:
                base_coherence *= 0.5
            
            # P√©nalit√© pour raisonnement circulaire d√©tect√©
            if self._detect_circular_reasoning_patterns(original_text):
                base_coherence *= 0.2  # Forte p√©nalit√©
            
            return min(1.0, max(0.0, base_coherence))
            
        except Exception as e:
            self.logger.error(f"Erreur calcul coh√©rence: {e}")
            return 0.3
    
    def _detect_circular_reasoning_patterns(self, text: str) -> bool:
        """D√©tecte des patterns de raisonnement circulaire dans le texte."""
        try:
            import re
            
            circular_patterns = [
                r'(.+)\s+parce que\s+(.+)\s+dit.+et\s+(.+)\s+est\s+(vraie?|correct)\s+parce que',
                r'(.+)\s+existe\s+parce que\s+(.+)\s+le dit.+et\s+(.+)\s+est\s+(vraie?|v√©ridique)\s+parce que',
                r'A\s+parce que\s+B.+et\s+B\s+parce que\s+A',
                r'est vrai parce que.+est vrai',
                r'existe parce que.+dit.+est vraie? parce que'
            ]
            
            for pattern in circular_patterns:
                if re.search(pattern, text, re.IGNORECASE | re.DOTALL):
                    return True
            
            return False
            
        except Exception as e:
            self.logger.error(f"Erreur d√©tection circularit√©: {e}")
            return False
    
    def _calculate_overall_quality(self, fallacies: List[FallacyDetection], structure: Optional[ArgumentStructure]) -> float:
        """Calcule un score de qualit√© globale bas√© sur les sophismes et la structure.

        Combine un score bas√© sur la p√©nalit√© des sophismes et un score bas√© sur
        la force de la structure argumentative. Am√©lioration : p√©nalise davantage
        les sophismes et les arguments mal structur√©s.

        :param fallacies: Liste des sophismes d√©tect√©s.
        :type fallacies: List[FallacyDetection]
        :param structure: La structure argumentative analys√©e.
        :type structure: Optional[ArgumentStructure]
        :return: Un score de qualit√© globale entre 0.0 et 1.0.
        :rtype: float
        """
        try:
            # Calcul du score bas√© sur les sophismes (p√©nalit√© plus forte)
            if fallacies:
                # P√©nalit√© progressive : chaque sophisme r√©duit significativement le score
                fallacy_penalty = 0.0
                for fallacy in fallacies:
                    # P√©nalit√© bas√©e sur la s√©v√©rit√© et le type de sophisme
                    severity_penalty = fallacy.severity * 0.4  # Augmentation de 0.1 √† 0.4
                    fallacy_penalty += severity_penalty
                
                # P√©nalit√© suppl√©mentaire pour les sophismes multiples
                if len(fallacies) > 1:
                    fallacy_penalty += len(fallacies) * 0.1
                
                fallacy_score = max(0.0, 1.0 - fallacy_penalty)
            else:
                fallacy_score = 1.0
            
            # Calcul du score de structure (plus strict)
            if structure:
                structure_score = structure.strength
                
                # P√©nalit√© pour arguments mal structur√©s
                if structure.argument_type == "simple" and len(structure.premises) == 0:
                    # Argument sans pr√©misses claires = qualit√© tr√®s faible
                    structure_score = max(0.1, structure_score * 0.3)
                elif structure.argument_type == "unknown":
                    structure_score = max(0.1, structure_score * 0.5)
                
                # Bonus pour arguments bien structur√©s
                if len(structure.premises) >= 2 and structure.argument_type == "deductive":
                    structure_score = min(1.0, structure_score * 1.2)
            else:
                structure_score = 0.1  # Tr√®s faible si pas de structure
            
            # Pond√©ration ajust√©e : plus d'importance aux sophismes
            overall = (fallacy_score * 0.7 + structure_score * 0.3)
            result = min(1.0, max(0.0, overall))
            
            self.logger.debug(f"Qualit√© calcul√©e: fallacy_score={fallacy_score:.2f}, structure_score={structure_score:.2f}, overall={result:.2f}")
            return result
            
        except Exception as e:
            self.logger.error(f"Erreur lors du calcul de qualit√©: {e}")
            return 0.2  # Valeur plus faible en cas d'erreur
    
    def _calculate_coherence_score(self, structure: Optional[ArgumentStructure]) -> float:
        """Calcule le score de coh√©rence bas√© sur la structure argumentative.

        :param structure: La structure argumentative analys√©e.
        :type structure: Optional[ArgumentStructure]
        :return: Le score de coh√©rence de la structure, ou 0.3 par d√©faut si
                 la structure est None ou si une erreur survient.
        :rtype: float
        """
        try:
            if structure:
                return structure.coherence
            return 0.3 # Coh√©rence faible par d√©faut
        except Exception as e:
            self.logger.error(f"Erreur lors du calcul de coh√©rence: {e}")
            return 0.3
    
    def _create_fallback_response(self, request: AnalysisRequest, start_time: float) -> AnalysisResponse:
        """Cr√©e une r√©ponse `AnalysisResponse` de fallback en cas d'√©chec d'initialisation du service.

        :param request: La requ√™te d'analyse originale.
        :type request: AnalysisRequest
        :param start_time: Le timestamp du d√©but du traitement de la requ√™te.
        :type start_time: float
        :return: Un objet `AnalysisResponse` indiquant un √©chec avec des valeurs par d√©faut.
        :rtype: AnalysisResponse
        """
        processing_time = time.time() - start_time
        
        return AnalysisResponse(
            success=False,
            text_analyzed=request.text,
            fallacies=[],
            argument_structure=ArgumentStructure( # Fournir une structure par d√©faut
                premises=[],
                conclusion=request.text, # Au moins retourner le texte comme conclusion
                argument_type="unknown",
                strength=0.0,
                coherence=0.0
            ),
            overall_quality=0.0,
            coherence_score=0.0,
            fallacy_count=0,
            processing_time=processing_time,
            analysis_options=request.options.dict() if request.options else {}
        )