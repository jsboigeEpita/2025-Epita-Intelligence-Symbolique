# üß± Noyau Applicatif (`core/`)

Ce r√©pertoire contient les classes et fonctions fondamentales partag√©es par l'ensemble de l'application d'analyse rh√©torique. Il assure la gestion de l'√©tat, l'interaction avec les services externes (LLM, JVM) et d√©finit les r√®gles d'orchestration.

[Retour au README Principal](../README.md)

## Contenu

### Gestion de l'√âtat

* **[`shared_state.py`](./shared_state.py)** : D√©finit la classe `RhetoricalAnalysisState`.
    * Repr√©sente l'√©tat mutable de l'analyse (texte brut, t√¢ches assign√©es, arguments identifi√©s, sophismes trouv√©s, belief sets logiques, logs de requ√™tes, r√©ponses des agents, conclusion finale, prochain agent d√©sign√©).
    * Inclut des m√©thodes pour ajouter/modifier ces √©l√©ments et pour s√©rialiser/d√©s√©rialiser l'√©tat (JSON).
    * Poss√®de un logging interne pour tracer les modifications.
    * Supporte la persistance de l'√©tat pour la reprise d'analyse.

* **[`state_manager_plugin.py`](./state_manager_plugin.py)** : D√©finit la classe `StateManagerPlugin`.
    * Un plugin Semantic Kernel qui encapsule une instance de `RhetoricalAnalysisState`.
    * Expose des fonctions natives (`@kernel_function`) aux agents pour lire (`get_current_state_snapshot`) et √©crire (`add_task`, `add_argument`, `add_fallacy`, `add_belief_set`, `log_query_result`, `add_answer`, `set_final_conclusion`, `designate_next_agent`) dans l'√©tat partag√© de mani√®re contr√¥l√©e et tra√ßable.
    * Impl√©mente des m√©canismes de validation pour garantir l'int√©grit√© des donn√©es.

### Orchestration

* **[`strategies.py`](./strategies.py)** : D√©finit les strat√©gies d'orchestration pour `AgentGroupChat` de Semantic Kernel.
    * `SimpleTerminationStrategy` üö¶ : Arr√™te la conversation si `final_conclusion` est pr√©sente dans l'√©tat ou si un nombre maximum de tours (`max_steps`) est atteint.
    * `DelegatingSelectionStrategy` üîÄ : Choisit le prochain agent. Priorise la d√©signation explicite (`_next_agent_designated` dans l'√©tat). Sinon, retourne par d√©faut au `ProjectManagerAgent` apr√®s l'intervention d'un autre agent.
    * Supporte des strat√©gies avanc√©es comme la s√©lection bas√©e sur les comp√©tences ou la charge de travail.

### Int√©gration Externe

* **[`jvm_setup.py`](./jvm_setup.py)** : G√®re l'interaction avec l'environnement Java. üî•‚òï
    * Contient la logique (`initialize_jvm`) pour :
        * V√©rifier/t√©l√©charger les JARs Tweety requis et leurs binaires natifs dans `libs/`.
        * Trouver un JDK valide (via `JAVA_HOME` ou d√©tection automatique).
        * D√©marrer la JVM via JPype avec le classpath et `java.library.path` corrects.
    * Retourne un statut indiquant si la JVM est pr√™te, essentiel pour l'agent `PropositionalLogicAgent`.
    * G√®re les erreurs de configuration Java avec des messages explicatifs.

* **[`llm_service.py`](./llm_service.py)** : G√®re la cr√©ation du service LLM. ‚òÅÔ∏è
    * Contient la logique (`create_llm_service`) pour lire la configuration LLM depuis `.env` (OpenAI ou Azure).
    * Cr√©e et retourne l'instance du service (`OpenAIChatCompletion` ou `AzureChatCompletion`) qui sera inject√©e dans le kernel et utilis√©e par les `ChatCompletionAgent`.
    * Supporte la configuration de param√®tres avanc√©s comme la temp√©rature, le nombre de tokens maximum, etc.
    * Impl√©mente un m√©canisme de fallback en cas d'erreur de connexion.

## Utilisation

### Initialisation de l'√âtat

```python
from core.shared_state import RhetoricalAnalysisState
from core.state_manager_plugin import StateManagerPlugin

# Cr√©er un nouvel √©tat
state = RhetoricalAnalysisState()
state.raw_text = "Texte √† analyser"

# Cr√©er un plugin de gestion d'√©tat
state_manager = StateManagerPlugin(state)
```

### Configuration du Service LLM

```python
from core.llm_service import create_llm_service

# Cr√©er le service LLM √† partir des variables d'environnement
llm_service = create_llm_service()

# Ou avec des param√®tres sp√©cifiques
llm_service = create_llm_service(
    temperature=0.7,
    max_tokens=2000,
    model_id="gpt-4o-mini"
)
```

### Initialisation de la JVM pour Tweety

```python
from core.jvm_setup import initialize_jvm

# Initialiser la JVM
jvm_status = initialize_jvm()

if jvm_status.is_ready:
    print("JVM initialis√©e avec succ√®s")
    print(f"Version Java: {jvm_status.java_version}")
    print(f"Tweety version: {jvm_status.tweety_version}")
else:
    print(f"Erreur d'initialisation JVM: {jvm_status.error_message}")
```

## Bonnes Pratiques

- Utilisez toujours le `StateManagerPlugin` pour acc√©der √† l'√©tat partag√©, jamais directement l'objet `RhetoricalAnalysisState`
- Initialisez la JVM une seule fois au d√©but de l'application
- Configurez correctement les variables d'environnement dans le fichier `.env`
- Utilisez les strat√©gies d'orchestration fournies pour contr√¥ler le flux de conversation
- Impl√©mentez une gestion d'erreurs robuste pour les appels aux services externes (LLM, JVM)