#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Test de validation de la migration du Comprehensive Workflow Processor
====================================================================

Valide la transformation vers l'architecture centralisÃ©e utilisant le
pipeline d'orchestration unifiÃ© selon les spÃ©cifications techniques.

Tests couverts :
- Import et initialisation du pipeline unifiÃ©
- Configuration workflow selon les spÃ©cifications
- Support corpus chiffrÃ© avec dÃ©chiffrement Fernet
- Workflows complets selon les diffÃ©rents modes
- GÃ©nÃ©ration de rapports multi-formats
- Tests de performance et validation systÃ¨me

Date: 10/06/2025
Version: Test Migration v3.0.0
"""

import os
import sys
import asyncio
import logging
import tempfile
import json
from pathlib import Path
from datetime import datetime

# Configuration du projet
PROJECT_ROOT = Path(__file__).resolve().parent
if str(PROJECT_ROOT) not in sys.path:
    sys.path.insert(0, str(PROJECT_ROOT))

# Configuration du logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s [%(levelname)s] %(name)s: %(message)s',
    datefmt='%H:%M:%S'
)
logger = logging.getLogger("TestComprehensiveMigration")

class ComprehensiveMigrationTester:
    """Testeur pour la migration du Comprehensive Workflow Processor."""
    
    def __init__(self):
        self.logger = logging.getLogger(f"{__name__}.ComprehensiveMigrationTester")
        self.test_results = {}
        self.start_time = datetime.now()
        
    async def run_all_tests(self) -> bool:
        """ExÃ©cute tous les tests de validation de migration."""
        self.logger.info("ğŸš€ DÃ©marrage des tests de migration architecture centralisÃ©e")
        self.logger.info("="*70)
        
        success = True
        
        # Tests d'importation et configuration
        success &= await self._test_import_unified_pipeline()
        success &= await self._test_workflow_config_building()
        
        # Tests de fonctionnalitÃ©s core
        success &= await self._test_processor_initialization()
        success &= await self._test_encrypted_corpus_support()
        success &= await self._test_workflow_modes()
        
        # Tests d'intÃ©gration
        success &= await self._test_report_generation()
        success &= await self._test_performance_integration()
        
        # RÃ©sumÃ© final
        await self._log_test_summary(success)
        
        return success
    
    async def _test_import_unified_pipeline(self) -> bool:
        """Test 1: Import du pipeline d'orchestration unifiÃ©."""
        self.logger.info("ğŸ”§ Test 1: Import pipeline d'orchestration unifiÃ©")
        
        try:
            # Import du processeur migrÃ©
            from scripts.consolidated.comprehensive_workflow_processor import (
                ComprehensiveWorkflowProcessor,
                WorkflowConfig,
                WorkflowMode,
                UNIFIED_PIPELINE_AVAILABLE
            )
            
            # VÃ©rification de la disponibilitÃ© du pipeline unifiÃ©
            if UNIFIED_PIPELINE_AVAILABLE:
                self.logger.info("  OK - Pipeline d'orchestration unifie disponible")
                
                # VÃ©rification des imports spÃ©cifiques
                from scripts.consolidated.comprehensive_workflow_processor import (
                    ExtendedOrchestrationConfig,
                    OrchestrationMode,
                    AnalysisType
                )
                self.logger.info("  OK - Configuration etendue d'orchestration importee")
                
            else:
                self.logger.warning("  WARN - Pipeline d'orchestration unifie non disponible (mode degrade)")
            
            self.test_results["import_unified_pipeline"] = {
                "status": "success",
                "unified_available": UNIFIED_PIPELINE_AVAILABLE,
                "message": "Import pipeline unifiÃ© rÃ©ussi"
            }
            
            return True
            
        except Exception as e:
            self.logger.error(f"  âŒ Erreur import pipeline unifiÃ©: {e}")
            self.test_results["import_unified_pipeline"] = {
                "status": "error",
                "error": str(e)
            }
            return False
    
    async def _test_workflow_config_building(self) -> bool:
        """Test 2: Construction de la configuration workflow."""
        self.logger.info("ğŸ”§ Test 2: Construction configuration workflow")
        
        try:
            from scripts.consolidated.comprehensive_workflow_processor import (
                WorkflowConfig,
                WorkflowMode,
                ProcessingEnvironment,
                UNIFIED_PIPELINE_AVAILABLE
            )
            
            # CrÃ©ation d'une configuration de test
            config = WorkflowConfig(
                mode=WorkflowMode.FULL,
                environment=ProcessingEnvironment.DEV,
                parallel_workers=4,
                corpus_files=["test_corpus.enc"],
                encryption_passphrase="test_passphrase"
            )
            
            self.logger.info(f"  âœ… Configuration de base crÃ©Ã©e - Mode: {config.mode.value}")
            
            # Test de construction de la configuration workflow
            if UNIFIED_PIPELINE_AVAILABLE:
                orchestration_config = config._build_workflow_config()
                
                self.logger.info(f"  âœ… Configuration orchestration construite")
                self.logger.info(f"    â€¢ Mode orchestration: {orchestration_config.orchestration_mode}")
                self.logger.info(f"    â€¢ Type d'analyse: {orchestration_config.analysis_type}")
                self.logger.info(f"    â€¢ HiÃ©rarchique activÃ©: {orchestration_config.enable_hierarchical}")
                self.logger.info(f"    â€¢ Orchestrateurs spÃ©cialisÃ©s: {orchestration_config.enable_specialized_orchestrators}")
                
                # VÃ©rification de la configuration middleware
                middleware_config = orchestration_config.middleware_config
                assert "enable_corpus_processing" in middleware_config
                assert "enable_encryption_support" in middleware_config
                assert "corpus_files" in middleware_config
                
                self.logger.info("  âœ… Configuration middleware corpus chiffrÃ© validÃ©e")
                
            else:
                self.logger.warning("  âš ï¸ Configuration workflow simulÃ©e (pipeline non disponible)")
            
            self.test_results["workflow_config_building"] = {
                "status": "success",
                "config_mode": config.mode.value,
                "corpus_files": len(config.corpus_files),
                "message": "Construction configuration workflow rÃ©ussie"
            }
            
            return True
            
        except Exception as e:
            self.logger.error(f"  âŒ Erreur construction configuration: {e}")
            self.test_results["workflow_config_building"] = {
                "status": "error",
                "error": str(e)
            }
            return False
    
    async def _test_processor_initialization(self) -> bool:
        """Test 3: Initialisation du processeur unifiÃ©."""
        self.logger.info("ğŸ”§ Test 3: Initialisation processeur unifiÃ©")
        
        try:
            from scripts.consolidated.comprehensive_workflow_processor import (
                ComprehensiveWorkflowProcessor,
                WorkflowConfig,
                WorkflowMode
            )
            
            # CrÃ©ation d'une configuration minimale
            config = WorkflowConfig(
                mode=WorkflowMode.ANALYSIS_ONLY,
                parallel_workers=2
            )
            
            # CrÃ©ation du processeur
            processor = ComprehensiveWorkflowProcessor(config)
            self.logger.info("  âœ… Processeur crÃ©Ã© avec succÃ¨s")
            
            # Test d'initialisation du pipeline unifiÃ©
            if hasattr(processor, 'initialize_unified_pipeline'):
                initialization_success = await processor.initialize_unified_pipeline()
                
                if initialization_success:
                    self.logger.info("  âœ… Pipeline unifiÃ© initialisÃ© avec succÃ¨s")
                    assert processor.initialized == True
                    assert processor.unified_pipeline is not None
                else:
                    self.logger.warning("  âš ï¸ Initialisation pipeline en mode dÃ©gradÃ©")
            else:
                self.logger.warning("  âš ï¸ MÃ©thode d'initialisation non disponible")
            
            self.test_results["processor_initialization"] = {
                "status": "success",
                "processor_created": True,
                "pipeline_initialized": getattr(processor, 'initialized', False),
                "message": "Initialisation processeur rÃ©ussie"
            }
            
            return True
            
        except Exception as e:
            self.logger.error(f"  âŒ Erreur initialisation processeur: {e}")
            self.test_results["processor_initialization"] = {
                "status": "error",
                "error": str(e)
            }
            return False
    
    async def _test_encrypted_corpus_support(self) -> bool:
        """Test 4: Support corpus chiffrÃ©."""
        self.logger.info("ğŸ”§ Test 4: Support corpus chiffrÃ©")
        
        try:
            from scripts.consolidated.comprehensive_workflow_processor import (
                ComprehensiveWorkflowProcessor,
                WorkflowConfig,
                WorkflowMode
            )
            
            # CrÃ©ation d'un fichier corpus de test temporaire
            with tempfile.NamedTemporaryFile(mode='w', suffix='.json', delete=False) as temp_file:
                test_corpus_data = {
                    "definitions": [
                        {"content": "Test de fallacieux: Si on fait A, alors B se produira forcÃ©ment."},
                        {"content": "Exemple neutre: Il fait beau aujourd'hui."}
                    ]
                }
                json.dump(test_corpus_data, temp_file)
                temp_corpus_path = temp_file.name
            
            try:
                # Configuration avec corpus
                config = WorkflowConfig(
                    mode=WorkflowMode.FULL,
                    corpus_files=[temp_corpus_path],
                    enable_decryption=False,  # Test avec fichier non chiffrÃ©
                    encryption_passphrase="test_key"
                )
                
                processor = ComprehensiveWorkflowProcessor(config)
                
                # Test de traitement corpus (simulation sans chiffrement)
                if hasattr(processor, '_prepare_analysis_texts'):
                    # Simulation de rÃ©sultats de dÃ©chiffrement
                    decryption_results = {
                        "status": "success",
                        "loaded_files": [
                            {
                                "file": temp_corpus_path,
                                "definitions_count": 2,
                                "definitions": test_corpus_data["definitions"]
                            }
                        ]
                    }
                    
                    texts = processor._prepare_analysis_texts(decryption_results)
                    
                    assert len(texts) == 2
                    assert "fallacieux" in texts[0]
                    assert "beau aujourd'hui" in texts[1]
                    
                    self.logger.info(f"  âœ… Extraction textes corpus rÃ©ussie: {len(texts)} textes")
                    
                else:
                    self.logger.warning("  âš ï¸ MÃ©thode prÃ©paration textes non disponible")
                
                # Test de la mÃ©thode de traitement corpus chiffrÃ©
                if hasattr(processor, '_process_encrypted_corpus'):
                    self.logger.info("  âœ… MÃ©thode traitement corpus chiffrÃ© disponible")
                else:
                    self.logger.warning("  âš ï¸ MÃ©thode traitement corpus chiffrÃ© non disponible")
                
            finally:
                # Nettoyage du fichier temporaire
                Path(temp_corpus_path).unlink(missing_ok=True)
            
            self.test_results["encrypted_corpus_support"] = {
                "status": "success",
                "corpus_processing_available": True,
                "text_extraction_tested": True,
                "message": "Support corpus chiffrÃ© validÃ©"
            }
            
            return True
            
        except Exception as e:
            self.logger.error(f"  âŒ Erreur support corpus chiffrÃ©: {e}")
            self.test_results["encrypted_corpus_support"] = {
                "status": "error",
                "error": str(e)
            }
            return False
    
    async def _test_workflow_modes(self) -> bool:
        """Test 5: DiffÃ©rents modes de workflow."""
        self.logger.info("ğŸ”§ Test 5: Modes de workflow")
        
        try:
            from scripts.consolidated.comprehensive_workflow_processor import (
                ComprehensiveWorkflowProcessor,
                WorkflowConfig,
                WorkflowMode
            )
            
            modes_to_test = [
                WorkflowMode.ANALYSIS_ONLY,
                WorkflowMode.TESTING_ONLY,
                WorkflowMode.PERFORMANCE,
                WorkflowMode.VALIDATION_ONLY
            ]
            
            workflow_results = {}
            
            for mode in modes_to_test:
                self.logger.info(f"    Testing mode: {mode.value}")
                
                config = WorkflowConfig(
                    mode=mode,
                    parallel_workers=2,
                    performance_iterations=1,  # RÃ©duit pour les tests
                    enable_api_tests=False  # DÃ©sactivÃ© pour les tests
                )
                
                processor = ComprehensiveWorkflowProcessor(config)
                
                # Test rapide du workflow (simulation)
                if hasattr(processor, 'run_comprehensive_workflow'):
                    # Pour les tests, on peut simuler ou faire un test trÃ¨s lÃ©ger
                    self.logger.info(f"      âœ… Workflow {mode.value} disponible")
                    workflow_results[mode.value] = "available"
                else:
                    self.logger.warning(f"      âš ï¸ Workflow {mode.value} non disponible")
                    workflow_results[mode.value] = "unavailable"
            
            successful_modes = len([r for r in workflow_results.values() if r == "available"])
            total_modes = len(modes_to_test)
            
            self.logger.info(f"  âœ… Modes de workflow testÃ©s: {successful_modes}/{total_modes}")
            
            self.test_results["workflow_modes"] = {
                "status": "success",
                "modes_tested": total_modes,
                "modes_available": successful_modes,
                "workflow_results": workflow_results,
                "message": "Modes de workflow validÃ©s"
            }
            
            return successful_modes > 0
            
        except Exception as e:
            self.logger.error(f"  âŒ Erreur modes de workflow: {e}")
            self.test_results["workflow_modes"] = {
                "status": "error",
                "error": str(e)
            }
            return False
    
    async def _test_report_generation(self) -> bool:
        """Test 6: GÃ©nÃ©ration de rapports."""
        self.logger.info("ğŸ”§ Test 6: GÃ©nÃ©ration de rapports")
        
        try:
            from scripts.consolidated.comprehensive_workflow_processor import (
                ComprehensiveWorkflowProcessor,
                WorkflowConfig,
                WorkflowResults,
                ReportFormat
            )
            
            # Configuration avec formats de rapport
            config = WorkflowConfig(
                mode=WorkflowMode.ANALYSIS_ONLY,
                report_formats=[ReportFormat.JSON, ReportFormat.MARKDOWN],
                output_dir=Path(tempfile.mkdtemp())
            )
            
            processor = ComprehensiveWorkflowProcessor(config)
            
            # CrÃ©ation de rÃ©sultats de test
            results = WorkflowResults(start_time=datetime.now())
            results.analysis_results = {
                "analyses": [
                    {"text": "test", "status": "success"}
                ]
            }
            results.finalize("completed")
            
            # Test des mÃ©thodes de gÃ©nÃ©ration de rapports
            report_methods = [
                "_generate_json_report",
                "_generate_markdown_report",
                "_generate_html_report"
            ]
            
            available_methods = []
            for method_name in report_methods:
                if hasattr(processor, method_name):
                    available_methods.append(method_name)
                    self.logger.info(f"    âœ… MÃ©thode {method_name} disponible")
                else:
                    self.logger.warning(f"    âš ï¸ MÃ©thode {method_name} non disponible")
            
            # Test de la mÃ©thode principale de gÃ©nÃ©ration
            if hasattr(processor, '_generate_comprehensive_reports'):
                self.logger.info("  âœ… MÃ©thode gÃ©nÃ©ration rapports principale disponible")
            else:
                self.logger.warning("  âš ï¸ MÃ©thode gÃ©nÃ©ration rapports principale non disponible")
            
            # Nettoyage du rÃ©pertoire temporaire
            import shutil
            shutil.rmtree(config.output_dir, ignore_errors=True)
            
            self.test_results["report_generation"] = {
                "status": "success",
                "report_methods_available": len(available_methods),
                "total_methods": len(report_methods),
                "formats_configured": len(config.report_formats),
                "message": "GÃ©nÃ©ration de rapports validÃ©e"
            }
            
            return len(available_methods) > 0
            
        except Exception as e:
            self.logger.error(f"  âŒ Erreur gÃ©nÃ©ration de rapports: {e}")
            self.test_results["report_generation"] = {
                "status": "error",
                "error": str(e)
            }
            return False
    
    async def _test_performance_integration(self) -> bool:
        """Test 7: IntÃ©gration tests de performance."""
        self.logger.info("ğŸ”§ Test 7: IntÃ©gration tests de performance")
        
        try:
            from scripts.consolidated.comprehensive_workflow_processor import (
                ComprehensiveWorkflowProcessor,
                WorkflowConfig,
                WorkflowMode
            )
            
            config = WorkflowConfig(
                mode=WorkflowMode.PERFORMANCE,
                performance_iterations=1,  # Test minimal
                parallel_workers=2
            )
            
            processor = ComprehensiveWorkflowProcessor(config)
            
            # Test des mÃ©thodes de performance
            performance_methods = [
                "_run_performance_tests_unified",
                "_perf_pipeline_init",
                "_perf_text_analysis",
                "_perf_corpus_decryption"
            ]
            
            available_perf_methods = []
            for method_name in performance_methods:
                if hasattr(processor, method_name):
                    available_perf_methods.append(method_name)
                    self.logger.info(f"    âœ… MÃ©thode {method_name} disponible")
                else:
                    self.logger.warning(f"    âš ï¸ MÃ©thode {method_name} non disponible")
            
            # Test rapide d'une mÃ©thode de performance
            if hasattr(processor, '_perf_pipeline_init'):
                start_time = asyncio.get_event_loop().time()
                await processor._perf_pipeline_init()
                duration = asyncio.get_event_loop().time() - start_time
                self.logger.info(f"    âœ… Test performance pipeline init: {duration:.3f}s")
            
            self.test_results["performance_integration"] = {
                "status": "success",
                "performance_methods_available": len(available_perf_methods),
                "total_methods": len(performance_methods),
                "iterations_configured": config.performance_iterations,
                "message": "IntÃ©gration tests de performance validÃ©e"
            }
            
            return len(available_perf_methods) > 0
            
        except Exception as e:
            self.logger.error(f"  âŒ Erreur intÃ©gration performance: {e}")
            self.test_results["performance_integration"] = {
                "status": "error",
                "error": str(e)
            }
            return False
    
    async def _log_test_summary(self, overall_success: bool):
        """Affiche le rÃ©sumÃ© des tests."""
        duration = datetime.now() - self.start_time
        
        self.logger.info("="*70)
        self.logger.info("ğŸ¯ RÃ‰SUMÃ‰ DES TESTS DE MIGRATION")
        self.logger.info("="*70)
        self.logger.info(f"â±ï¸  DurÃ©e totale: {duration.total_seconds():.2f}s")
        
        # Statistiques des tests
        total_tests = len(self.test_results)
        successful_tests = len([r for r in self.test_results.values() if r["status"] == "success"])
        
        self.logger.info(f"ğŸ“Š Tests exÃ©cutÃ©s: {total_tests}")
        self.logger.info(f"âœ… Tests rÃ©ussis: {successful_tests}")
        self.logger.info(f"âŒ Tests Ã©chouÃ©s: {total_tests - successful_tests}")
        self.logger.info(f"ğŸ“ˆ Taux de rÃ©ussite: {(successful_tests / total_tests * 100):.1f}%")
        
        # DÃ©tail des tests
        for test_name, result in self.test_results.items():
            status_icon = "âœ…" if result["status"] == "success" else "âŒ"
            self.logger.info(f"{status_icon} {test_name}: {result.get('message', result['status'])}")
        
        # Statut final
        if overall_success:
            self.logger.info("ğŸ‰ MIGRATION VALIDÃ‰E AVEC SUCCÃˆS")
            self.logger.info("ğŸ—ï¸ Architecture centralisÃ©e fonctionnelle")
        else:
            self.logger.error("âŒ MIGRATION AVEC PROBLÃˆMES")
            self.logger.error("ğŸ”§ RÃ©vision nÃ©cessaire")
        
        self.logger.info("="*70)

async def main():
    """Point d'entrÃ©e principal."""
    print("ğŸš€ Test de Validation - Migration Comprehensive Workflow Processor")
    print("Architecture CentralisÃ©e avec Pipeline d'Orchestration UnifiÃ©")
    print("="*70)
    
    tester = ComprehensiveMigrationTester()
    success = await tester.run_all_tests()
    
    return 0 if success else 1

if __name__ == "__main__":
    exit_code = asyncio.run(main())
    sys.exit(exit_code)